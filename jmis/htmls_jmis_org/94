<!doctype html>
	<html>
		<head>
			    		
                                <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
                    		<title>JMIS - Journal of Management Information Systems</title>
                                <!--link rel='stylesheet' type='text/css' href='/assets/bower_components/bootswatch/journal/bootstrap.min.css'/-->
<link rel='stylesheet' type='text/css' href='/assets/bower_components/bootstrap/dist/css/bootstrap.min.css'/>
<link rel='stylesheet' type='text/css' href='/assets/css/styles.css'/>				<script src='/assets/bower_components/jquery/dist/jquery.js'></script>
				<script src='/assets/bower_components/bootstrap/dist/js/bootstrap.js'></script>
			
    <style>
        h4 + h4 {
            margin-top:0;
        }
    </style>
		</head>
		<body>
                    <div class="container">
                                
                                                                    <h4><em><a href="/">Journal of Management Information Systems</a></em></h4>
                                                                
        
    <div><a href="/issues/5">    Volume 4 Number 2 1987
</a> pp. 93-112</div>
                                
                                    <div class="margin-bottom-5">
        <h3>Transaction Processing and Consistency Control of Replicated Copies during Failures in Distributed Databases</h3>
    </div>
    <div class="margin-bottom-10">
            <a href="/contributors/190">Bhargava, Bharat</a>    </div>

<p>ABSTRACT: Consistency of replicated copies is difficult to maintain and recover during multiple failures of sites and network communication in a distributed database system. Transaction processing must continue as long as a single copy is available. But in a multiple failure environment, each operational site must make correct decisions about which copy to update and which one will be updated by the recovery system. This requires refreshing the copies on failed sites that missed the updates and doing this correctly while other transactions are updating and some more sites are either failing or recovering. This problem has been classified as the "replicated copy control problem." In this paper, we present several ideas that are necessary to attack and manage this problem. We introduce the ideas of session numbers, nominal session vectors, fail locks, and view serializability and discuss their role in transaction processing on operational, recovering, and partitioned sites. We have experimented with many of these ideas in a prototype system called RAID and we present the implementation issues. There is little overhead associated with our approach if no failures occur.</p>

    <strong>Key words and phrases: </strong>
        <a href="/keywords/237">replicated databases</a>,    <a href="/keywords/238">multiple site failures</a>,    <a href="/keywords/239">consistency control of replicated copies</a>,    <a href="/keywords/240">distributed databases</a>
                                
                        
                            </div>
                        </div>
                    </div>
		</body>
	</html>


