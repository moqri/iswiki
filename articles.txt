 
---start---
'''Using Accountability to Reduce Access Policy Violations in Information Systems'''
{{header}}
{{article
|author= Anthony Vance,Paul Benjamin Lowry,Denis Eggett,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Access policy violations by organizational insiders are a major security concern for organizations because these violations commonly result in fraud, unauthorized disclosure, theft of intellectual property, and other abuses. Given the operational demands of dynamic organizations, current approaches to curbing access policy violations are insufficient. This study presents a new approach for reducing access policy violations, introducing both the theory of accountability and the factorial survey to the information systems field. We identify four system mechanisms that heighten an individual's perception of accountability: identifiability, awareness of logging, awareness of audit, and electronic presence. These accountability mechanisms substantially reduce intentions to commit access policy violations. These results not only point to several avenues for future research on access policy violations but also suggest highly practical design-artifact solutions that can be easily implemented with minimal impact on organizational insiders.
|keyword = access policy violations,accountability,accountability theory,awareness,evaluation,factorial survey method,identifiability,information security,monitoring,social presence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''BEYOND DETERRENCE: AN EXPANDED VIEW OF EMPLOYEE COMPUTER ABUSE'''
{{header}}
{{article
|author= Robert Willison,Merrill Warkentin,
|source= MIS QUARTERLY
|year= 2013
|abstract = Recent academic investigations of computer security policy violations have largely focused on non-malicious noncompliance due to poor training, low employee motivation, weak affective commitment, or individual oversight. Established theoretical foundations applied to this domain have related to protection motivation, deterrence, planned behavior, self-efficacy, individual adoption factors, organizational commitment, and other individual cognitive factors. But another class of violation demands greater research emphasis: the intentional commission of computer security policy violation, or insider computer abuse. Whether motivated by greed, disgruntlement, or other psychological processes, this act has the greatest potential for loss and damage to the employer. We argue the focus must include not only the act and its immediate antecedents of intention (to commit computer abuse) and deterrence (of the crime), but also phenomena which temporally precede these areas. Specifically, we assert the need to consider the thought processes of the potential offender and how these are influenced by the organizational context, prior to deterrence. We believe the interplay between thought processes and this context may significantly impact the efficacy of IS security controls, specifically deterrence safeguards. Through this focus, we extend the Straub and Welke (1998) security action cycle framework and propose three areas worthy of empirical investigation-techniques of neutralization (rationalization), expressive/instrumental criminal motivations, and disgruntlement as a result of perceptions of organizational injustice-and propose questions for future research in these areas.
|keyword = Computer abuse,employee computer crime,information systems security,deterrence,neutralization,motivation,disgruntlement,organizational justice,instrumental crimes,expressive crimes,insider,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''BRIDGING THE QUALITATIVE-QUANTITATIVE DIVIDE: GUIDELINES FOR CONDUCTING MIXED METHODS RESEARCH IN INFORMATION SYSTEMS'''
{{header}}
{{article
|author= Viswanath Venkatesh,Susan A. Brown,Hillol Bala,
|source= MIS QUARTERLY
|year= 2013
|abstract = Mixed methods research is an approach that combines quantitative and qualitative research methods in the same research inquiry. Such work can help develop rich insights into various phenomena of interest that cannot be fully understood using only a quantitative or a qualitative method. Notwithstanding the benefits and repeated calls for such work, there is a dearth of mixed methods research in information systems. Building on the literature on recent methodological advances in mixed methods research, we develop a set of guidelines for conducting mixed methods research in IS. We particularly elaborate on three important aspects of conducting mixed methods research: (1) appropriateness of a mixed methods approach; (2) development of meta-inferences (i.e., substantive theory) from mixed methods research; and (3) assessment of the quality of meta-inferences (i.e., validation of mixed methods research). The applicability of these guidelines is illustrated using two published IS papers that used mixed methods.
|keyword = Meta-inferences,mixed methods,multimethod,positivist,qualitative,quantitative,research method,research design,validity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IMPACT OF INFORMATION FEEDBACK IN CONTINUOUS COMBINATORIAL AUCTIONS: AN EXPERIMENTAL STUDY OF ECONOMIC PERFORMANCE'''
{{header}}
{{article
|author= Gediminas Adomavicius,Shawn P. Curley,Alok Gupta,Pallab Sanyal,
|source= MIS QUARTERLY
|year= 2013
|abstract = Advancements in information technology offer opportunities for designing and deploying innovative market mechanisms that can improve the allocation and procurement processes of businesses. For example, combinatorial auctions-in which bidders can bid on combinations of goods-have been shown to increase the economic efficiency of a trade when goods have complementarities. However, the lack of real-time decision support tools for bidders has prevented this mechanism from reaching its full potential. With the objective of facilitating bidder participation in combinatorial auctions, this study, using recent research in real-time bidder support metrics, discusses several novel feedback schemes that can aid bidders in formulating combinatorial bids in real-time. The feedback schemes allow us to conduct continuous combinatorial auctions, where bidders can submit bids at any time. Using laboratory experiments with two different setups, we compare the economic performance of the continuous mechanism under three progressively advanced levels of feedback. Our findings indicate that information feedback plays a major role in influencing the economic outcomes of combinatorial auctions. We compare several important bid characteristics to explain the observed differences in aggregate measures. This study advances the ongoing research on combinatorial auctions by developing continuous auctions that differentiate themselves from earlier combinatorial auction mechanisms by facilitating free-flowing participation of bidders and providing exact prices of bundles on demand in real time. For practitioners, the study provides insights on how the nature of feedback can influence the economic outcomes of a complex trading mechanism.
|keyword = Online auctions,continuous combinatorial auctions,experimental economics,information feedback,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IT-MEDIATED CUSTOMER SERVICE CONTENT AND DELIVERY IN ELECTRONIC GOVERNMENTS: AN EMPIRICAL INVESTIGATION OF THE ANTECEDENTS OF SERVICE QUALITY'''
{{header}}
{{article
|author= Chee-Wee Tan,Izak Benbasat,Ronald T. Cenfetelli,
|source= MIS QUARTERLY
|year= 2013
|abstract = Despite extensive deliberations in contemporary literature, the design of citizen-centric e-government websites remains an unresolved theoretical and pragmatic conundrum. Operationalizing e-government service quality to investigate and improve the design of e-government websites has been a much sought-after objective. Yet, there is a lack of actionable guidance on how to develop e-government websites that exhibit high levels of service quality. Drawing from marketing literature, we undertake a goal approach to this problem by delineating e-government service quality into aspects of IT-mediated service content and service delivery. Whereas service content describes the functions available on an e-government website that assist citizens in completing their transactional goals, service delivery defines the manner by which these functions are made accessible via the web interface as a delivery channel. We construct and empirically test a research model that depicts a comprehensive collection of web-enabled service content functions and delivery dimensions desirable by citizens. Empirical findings from an online survey of 647 respondents attest to the value of distinguishing between service content functions and delivery dimensions in designing e-government websites. Both service content and delivery are found to be significant contributors to achieving e-government service quality. These IT-mediated service content functions and delivery dimensions represent core areas of e-government website design where the application of technology makes a difference, especially when considered in tandem with the type of transactional activity. A split sample analysis of the data further demonstrates our model's robustness when applied to e-government transactions of varying frequency.
|keyword = Electronic government service quality,IT-mediated service content functions,IT-mediated service delivery dimensions,service content quality,service delivery quality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DIGITAL GAMES AND BEYOND: WHAT HAPPENS WHEN PLAYERS COMPETE?'''
{{header}}
{{article
|author= De Liu,Xun Li,Radhika Santhanam,
|source= MIS QUARTERLY
|year= 2013
|abstract = Because digital games are fun, engaging, and popular, organizations are attempting to integrate them within organizational activities as serious components, with the anticipation that they can improve employees' motivation and performance. But in order to do so and to obtain the intended outcomes, it is necessary to first obtain an understanding of how different digital game designs impact players' behaviors and emotional responses. Hence, in this study, we address one key element of popular game designs: competition. Using extant research on tournaments and intrinsic motivation, we model competitive games as a skill-based tournament and conduct an experimental study to understand player behaviors and emotional responses under different competition conditions. When players compete with players of similar skill levels, they apply more effort as indicated by more games played and longer duration of play. But when players compete with players of lower skill levels, they report higher levels of enjoyment and lower levels of arousal after game-playing. We discuss the implications for organizations seeking to introduce games premised on competition and provide a framework to guide information system researchers to embark on a study of games.
|keyword = Digital games,intrinsic motivation,experimental study,tournament theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DATA MODEL DEVELOPMENT FOR FIRE RELATED EXTREME EVENTS: AN ACTIVITY THEORY APPROACH'''
{{header}}
{{article
|author= Rui Chen,Raj Sharman,H. Raghav Rao,Shambhu J. Upadhyaya,
|source= MIS QUARTERLY
|year= 2013
|abstract = Post-analyses of major extreme events reveal that information sharing is critical for effective emergency response. The lack of consistent data standards for current emergency management practice, however, hinders efficient critical information flow among incident responders. In this paper, we adopt a third-generation activity theory guided approach to develop a data model that can be used in the response to fire-related extreme events. This data model prescribes the core data standards to reduce information interoperability barriers. The model is validated through a three-step approach including a request for comment (RFC) process, case application, and prototype system test. This study contributes to the literature in the area of interoperability and data modeling; it also informs practice in emergency response system design.
|keyword = Data model,extreme events,design science,activity theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EXAMINING THE RELATIONAL BENEFITS OF IMPROVED INTERFIRM INFORMATION PROCESSING CAPABILITY IN BUYER-SUPPLIER DYADS'''
{{header}}
{{article
|author= Eric T. G. Wang,Jeffrey C. F. Tai,Varun Grover,
|source= MIS QUARTERLY
|year= 2013
|abstract = Information Systems research has studied how buyers and suppliers can benefit from improved information visibility in supply chains characterized by uncertainty. However, the relation-specific information processing solutions that provide visibility can only be exploited if the two firms engage in sufficient coordination efforts. This work takes a nuanced look at how dyadic benefits are derived in the supply chain. Drawing on the information processing view, resource-based view, and transaction cost theory, this study explicates how buyer performance can result from buyer's use of relation-specific information processing solutions and supplier's relational responses. Two interfirm information processing solutions are proposed and examined: the use of IT-based systems for planning and control, and the use of relational (normative) contracts. Based on a sample of 144 manufacturing firms, eight of the nine proposed research hypotheses receive empirical support using PLS analysis. The findings suggest that as buyers and suppliers utilize the IT and relational solutions, they induce relation-specific responses represented as supplier's business process investments and modification flexibility, which in turn lead to positive buyer outcomes. The results help us gain a more granular understanding on how relation-specific interfirm information processing solutions can lead to performance through enhanced interfirm governance capabilities.
|keyword = IT-enabled planning and control,normative contracts,information processing view,resource-based view,transaction cost theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INTERNATIONALIZATION STRATEGIES OF CHINESE IT SERVICE SUPPLIERS'''
{{header}}
{{article
|author= Ning Su,
|source= MIS QUARTERLY
|year= 2013
|abstract = With China emerging as a new frontier of global IT outsourcing, many Chinese IT service suppliers are actively expanding in three major markets: Asia, especially Japan, the West, especially the United States, and the Chinese domestic market. Compared to multinational suppliers and established Indian suppliers, Chinese IT service firms are at a relatively early, but rapidly growing stage, which offers a unique opportunity to explore an understudied topic in the information systems literature: internationalization strategies of IT service suppliers from emerging economies. Through a three-part qualitative case study of 13 China-based IT service firms, including almost all of the Chinese suppliers recognized globally, this study elaborates the internationalization behavior and decision rationale of these suppliers. The findings show that these major Chinese suppliers include both firms that incrementally internationalize and firms that are "born global." For both types of firms, the entry and growth in different markets is a highly dynamic activity combining a strategically planned, resource-seeking process and a flexible, opportunistic bricolage process based on existing operation capabilities and client relationships. The suppliers dynamically oscillate between these processes to exploit and create opportunities while expanding in multiple markets.
|keyword = IT outsourcing,supplier's perspective,internationalization,strategy process,China,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A RHETORICAL APPROACH TO IT DIFFUSION: RECONCEPTUALIZING THE IDEOLOGY-FRAMING RELATIONSHIP IN COMPUTERIZATION MOVEMENTS'''
{{header}}
{{article
|author= Michael Barrett,Loizos Heracleous,Geoff Walsham,
|source= MIS QUARTERLY
|year= 2013
|abstract = In this paper we propose rhetoric as a valuable yet underdeveloped alternative paradigm for examining IT diffusion. Building on recent developments of computerization movements theory, our rhetorical approach proposes that two central elements of the theory, framing and ideology, rather than being treated as separate can be usefully integrated. We suggest that IT diffusion can be usefully explored through examining the interrelationship of the deep structures underlying ideology and the type and sequence of rhetorical claims underpinning actors' framing strategies. Our theoretical developments also allow us to better understand competing discourses influencing the diffusion process. These discourses reflect the ideologies and shape the framing strategies of actors in the broader field context. We illuminate our theoretical approach by drawing on the history of the diffusion of free and open source software.
|keyword = Computerization movements,diffusion,IT innovation,discourse,open source,free software,ideology,rhetoric,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE EMBEDDEDNESS OF INFORMATION SYSTEMS HABITS IN ORGANIZATIONAL AND INDIVIDUAL LEVEL ROUTINES: DEVELOPMENT AND DISRUPTION'''
{{header}}
{{article
|author= Greta L. Polites,Elena Karahanna,
|source= MIS QUARTERLY
|year= 2013
|abstract = Despite recent interest in studying information system habits, our understanding of how these habits develop and operate in an organizational context is still limited. Within organizations, IS habits may develop over long periods of time and are typically embedded within larger, frequently practiced, higher-level work routines or task sequences. When new systems are introduced for the purpose of at least partially replacing incumbent systems, existing IS habits embedded in these routines may inhibit adoption and use of the new systems. Therefore, understanding how work-related IS habits form, how they enable and inhibit behavior, and how they can be disrupted or encouraged requires that we examine them within the context of organizational and individual level work routines. The current study integrates psychology and organizational behavior literature on cognitive scripts and work routines to examine IS habits as they occur embedded within larger, more complex task sequences. The objective of the paper is to contribute to the IS habit literature by (1) situating IS habits within the context of their associated work routines and task sequences, and (2) providing a theoretical understanding of how incumbent system habits can be disrupted, and how development of new system habits can be encouraged, within this context. We draw from extant research in psychology, organizational behavior, and consumer behavior to offer propositions about context-focused organizational interventions to break, or otherwise discourage, the continued performance of incumbent system habits and to encourage the development of new system habits. Specifically, our theoretical development includes script disruption techniques, training-in-context, and performance goal suspension as organizational interventions that disrupt incumbent system habits. We further theorize how stabilizing contextual variables associated with modified work routines can facilitate the development of new system habits. The paper concludes by discussing the importance of combining intervention strategies to successfully disrupt incumbent system habits and encourage development of new system habits and thus facilitate adoption of new systems.
|keyword = IS habit,automaticity,organizational routines,cognitive scripts,environmental triggers,context change,habit disruption,incumbent system,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE AFFECTIVE RESPONSE MODEL: A THEORETICAL FRAMEWORK OF AFFECTIVE CONCEPTS AND THEIR RELATIONSHIPS IN THE ICT CONTEXT'''
{{header}}
{{article
|author= Ping Zhang,
|source= MIS QUARTERLY
|year= 2013
|abstract = Affect is a critical factor in human decisions and behaviors within many social contexts. In the information and communication technology (ICT) context, a growing number of studies consider the affective dimension of human interaction with ICTs. However, few of these studies take systematic approaches, resulting in inconsistent conclusions and contradictory advice for researchers and practitioners. Many of these issues stem from ambiguous conceptualizations of various affective concepts and their relationships. Before researchers can address questions such as "what causes affective responses in an ICT context" and "what impacts do affective responses have on human interaction with ICTs," a theoretical foundation for affective concepts and their relationships has to be established. This theory and review paper addresses three research questions: (1) What are pertinent affective concepts in the ICT context? (2) In what ways are these affective concepts similar to, or different from each other? (3) How do these affective concepts relate to or influence one another? Based on theoretical reasoning and empirical evidence, the affective response model (ARM) is developed. ARM is a theoretically bound conceptual framework that provides a systematic and holistic reference map for any ICT study that considers affect. It includes a taxonomy that classifies affective concepts along five dimensions: the residing, the temporal, the particular/general stimulus, the object/behavior stimulus, and the process/outcome dimensions. ARM also provides a nomological network to indicate the causal or co-occurring relationships among the various types of affective concepts in an ICT interaction episode. ARM has the power for explaining and predicting, as well as prescribing, potential future research directions.
|keyword = Affect,emotion,mood,affective response,affective evaluation,affective quality,individual reactions toward ICT,theory,affective response model,ARM,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INTERNET PRIVACY CONCERNS: AN INTEGRATED CONCEPTUALIZATION AND FOUR EMPIRICAL STUDIES'''
{{header}}
{{article
|author= Weiyin Hong,James Y. L. Thong,
|source= MIS QUARTERLY
|year= 2013
|abstract = Internet privacy concerns (IPC) is an area of study that is receiving increased attention due to the huge amount of personal information being gathered, stored, transmitted, and published on the Internet. While there is an emerging literature on IPC, there is limited agreement about its conceptualization in terms of its key dimensions and its factor structure. Based on the multidimensional developmental theory and a review of the prior literature, we identify alternative conceptualizations of IPC. We examine the various conceptualizations of IPC with four online surveys involving nearly 4,000 Internet users. As a baseline, study 1 compares the integrated conceptualization of IPC to two existing conceptualizations in the literature. While the results provide support for the integrated conceptualization, the second-order factor model does not outperform the correlated first-order factor model. Study 2 replicates the study on a different sample and confirms the results of study 1. We also investigate whether the prior results are affected by the different perspectives adopted in the wording of items in the original instruments. In study 3, we find that focusing on one's concern for website behavior (rather than one's expectation of website behavior) and adopting a consistent perspective in the wording of the items help to improve the validity of the factor structure. We then examine the hypothesized third-order conceptualizations of IPC through a number of alternative higher-order models. The empirical results confirm that, in general, the third-order conceptualizations of IPC outperform their lower-order alternatives. In addition, the conceptualization of IPC that has the best fit with the data contains a third-order general IPC factor, two second-order factors of interaction management and information management, and six first-order factors (i.e., collection, secondary usage, errors, improper access, control, and awareness). Study 4 cross-validates the results with another data set and examines IPC within the context of a nomological network. The results confirm that the third-order conceptualization of IPC has nomological validity, and it is a significant determinant of both trusting beliefs and risk beliefs. Our research helps to resolve inconsistencies in the key underlying dimensions of IPC, the factor structure of IPC, and the wording of the original items in prior instruments of IPC. Finally, we discuss the implications of this research.
|keyword = Internet privacy concerns,information privacy concerns,online privacy,multidimensional development theory,higher-order factors,confirmatory factor analysis,LISREL,nomological validity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''SOCIAL INFLUENCE AND KNOWLEDGE MANAGEMENT SYSTEMS USE: EVIDENCE FROM PANEL DATA'''
{{header}}
{{article
|author= Yinglei Wang,Darren B. Meister,Peter H. Gray,
|source= MIS QUARTERLY
|year= 2013
|abstract = Theory suggests that coworkers may influence individuals' technology use behaviors, but there is limited research in the technology diffusion literature that explicates how such social influence processes operate after initial adoption. We investigate how two key social influence mechanisms (identification and internalization) may explain the growth over time in individuals' use of knowledge management systems (KMS)-a technology that because of its publicly visible use provides a rich context for investigating social influence. We test our hypotheses using longitudinal KMS usage data on over 80,000 employees of a management consulting firm. Our approach infers the presence of identification and internalization from associations between actual system use behaviors by a focal individual and prior system use by a range of reference groups. Evidence of these kinds of associations between system use behaviors helps construct a more complete picture of social influence mechanisms, and is to our knowledge novel to the technology diffusion literature. Our results confirm the utility of this approach for understanding social influence effects and reveal a fine-grained pattern of influence across different social groups: we found strong support for bottom-up social influence across hierarchical levels, limited support for peer-level influence within levels, and no support for top-down influence.
|keyword = Information technology diffusion,social influence,knowledge management,knowledge management systems,longitudinal research,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION TECHNOLOGY OUTSOURCING AND NON-IT OPERATING COSTS: AN EMPIRICAL INVESTIGATION'''
{{header}}
{{article
|author= Kunsoo Han,Sunil Mithas,
|source= MIS QUARTERLY
|year= 2013
|abstract = Does information technology outsourcing reduce non-IT operating costs? This study examines this question and also asks whether internal IT investments moderate the relationship between IT outsourcing and non-IT operating costs. Using a panel data set of approximately 300 U. S. firms from 1999 to 2003, we find that IT outsourcing has a significant negative association with firms' non-IT operating costs. However, this finding does not imply that firms should completely outsource their entire IT function. Our results suggest that firms benefit more in terms of reduction in non-IT operating costs when they also have higher levels of complementary investments in internal IT, especially IT labor. Investments in internal IT systems can make business processes more amenable to outsourcing, and complementary investments in internal IT staff can facilitate monitoring of vendor performance and coordination with vendors. We discuss the implications of these findings for further research and for practice.
|keyword = IT outsourcing,information technology,IT expenditures,IT impacts,IT services,IT labor,IT human capital,non-IT operating costs,business value of IT,IT governance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''When Social Media Can Be Bad for You: Community Feedback Stifles Consumer Creativity and Reduces Satisfaction with Self-Designed Products'''
{{header}}
{{article
|author= Christian Hildebrand,Gerald Haeubl,Andreas Herrmann,Jan R. Landwehr,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Enabling consumers to self-design unique products that match their idiosyncratic preferences is the key value driver of modern mass customization systems. These systems are increasingly becoming "social," allowing for consumer-to-consumer interactions such as commenting on each other's self-designed products. The present research examines how receiving others' feedback on initial product configurations affects consumers' ultimate product designs and their satisfaction with these self-designed products. Evidence from a field study in a European car manufacturer's brand community and from two follow-up experiments reveals that receiving feedback from other community members on initial self-designs leads to less unique final self-designs, lower satisfaction with self-designed products, lower product usage frequency, and lower monetary product valuations. We provide evidence that the negative influence of feedback on consumers' satisfaction with self-designed products is mediated by an increase in decision uncertainty and perceived process complexity. The implications of socially enriched mass customization systems for both consumer welfare and seller profitability are discussed.
|keyword = mass customization systems,user self-design,product configurators,consumer decision making,social influence,field study,experiment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Social Network Effects on Productivity and Job Security: Evidence from the Adoption of a Social Networking Tool'''
{{header}}
{{article
|author= Lynn Wu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = By studying the change in employees' network positions before and after the introduction of a social networking tool, I find that information=rich networks (low in cohesion and rich in structural holes), enabled by social media, have a positive effect on various work outcomes. Contrary to the notion that network positions are difficult to alter, I show that social media can induce a change in network structure, one from which individuals can derive economic benefits. In addition, I consider two intermediate mechanisms by which an informationrich network is theorized to improve work performance-information diversity and social communication-and quantify their effects on productivity and job security. Analysis shows that productivity, as measured by billable revenue, is more associated with information diversity than with social communication. However, the opposite is true for job security. Social communication is more correlated with reduced layoff risks than with information diversity. This, in turn, suggests that information-rich networks enabled through the use of social media can drive both work performance and job security, but that there is a trade-off between engaging in social communication and gathering diverse information.
|keyword = social media,social network,productivity,job security,information diversity,social communication,knowledge management,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Active Social Media Management: The Case of Health Care'''
{{header}}
{{article
|author= Amalia R. Miller,Catherine Tucker,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Given the demand for authentic personal interactions over social media, it is unclear how much firms should actively manage their social media presence. We study this question empirically in a health care setting. We show that active social media management drives more user-generated content. However, we find that this is due to an incremental increase in user postings from an organization's employees rather than from its clients. This result holds when we explore exogenous variation in social media policies, employees, and clients that are explained by medical marketing laws, medical malpractice laws, and distortions in Medicare incentives. Further examination suggests that content being generated mainly by employees can be avoided if a firm's postings are entirely client focused. However, most firm postings seem not to be specifically targeted to clients' interests, instead highlighting more general observations or achievements of the firm itself. We show that untargeted postings like these provoke activity by employees rather than clients. This may not be a bad thing because employee-generated content may help with employee motivation, recruitment, or retention, but it does suggest that social media should not be funded or managed exclusively as a marketing function of the firm.
|keyword = business value of IT,computer-mediated communication and collaboration,social media,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Social Ties and User Content Generation: Evidence from Flickr'''
{{header}}
{{article
|author= Xiaohua Zeng,Liyuan Wei,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = The content created by the users of social networking sites has reached such high levels of quality and variety that it is comparable to that produced by professional agencies. Therefore, understanding what types of content users generate and the underlying motivational factors is vital to the success of the sites. The extant research on content generation has primarily focused on the amount of content and on how to encourage participation in content creation, and less attention has been paid to the content itself and how social relations affect the types of content that users upload. This study aims to empirically document the relationship between social ties and the similarities between the types of content that people create online. We collected a large data set from the photo-hosting website Flickr detailing the users' social relations over time in conjunction with their photo-uploading behavior. We found that around the time of the formation of a social tie, members of dyads began to upload more similar photos than they did before that time. After a social tie was formed, this similarity evolved in different ways in different subgroups of dyads. Whereas the similarity between photos uploaded by dyads experiencing notably different popularity levels on the site continued to grow, the dyads of users with similar levels of popularity gradually began to upload less similar photos. In cultural production, individuals appear to present themselves as unique; this feature is more salient when the social contacts are similar in popularity status. Photo-shooting behaviors have been found to exhibit the same patterns. Furthermore, we show that the most divergent uploading behavior is observed when a high-popularity user initiates a tie with a user with lower popularity. We use social psychological motivations to explain these results.
|keyword = user-generated content,social networks,computer-mediated communication and collaboration,within-subjects design,photography,distinctiveness,tags,Flickr,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Social Media Brand Community and Consumer Behavior: Quantifying the Relative Impact of User- and Marketer-Generated Content'''
{{header}}
{{article
|author= Khim-Yong Goh,Cheng-Suang Heng,Zhijie Lin,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Despite the popular use of social media by consumers and marketers, empirical research investigating their economic values still lags. In this study, we integrate qualitative user-marketer interaction content data from a fan page brand community on Facebook and consumer transactions data to assemble a unique data set at the individual consumer level. We then quantify the impact of community contents from consumers (usergenerated content, i.e., UGC) and marketers (marketer-generated content, i.e., MGC) on consumers' apparel purchase expenditures. A content analysis method was used to construct measures to capture the informative and persuasive nature of UGC and MGC while distinguishing between directed and undirected communication modes in the brand community. In our empirical analysis, we exploit differences across consumers' fan page joining decision and across timing differences in fan page joining dates for our model estimation and identification strategies. Importantly, we also control for potential self-selection biases and relevant factors such as pricing, promotion, social network attributes, consumer demographics, and unobserved heterogeneity. Our findings show that engagement in social media brand communities leads to a positive increase in purchase expenditures. Additional examinations of UGC and MGC impacts show evidence of social media contents affecting consumer purchase behavior through embedded information and persuasion. We also uncover the different roles played by UGC and MGC, which vary by the type of directed or undirected communication modes by consumers and the marketer. Specifically, the elasticities of demand with respect to UGC information richness are 0.006 (directed communication) and 3.140 (undirected communication), whereas those for MGC information richness are insignificant. Moreover, the UGC valence elasticity of demand is 0.180 (undirected communication), whereas that for MGC valence is 0.004 (directed communication). Overall, UGC exhibits a stronger impact than MGC on consumer purchase behavior. Our findings provide various implications for academic research and practice.
|keyword = social media,brand community,consumer behavior,user-generated content,marketer-generated content,communication mode,text mining,econometric modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Effect of Customers' Social Media Participation on Customer Visit Frequency and Profitability: An Empirical Investigation'''
{{header}}
{{article
|author= Rishika Rishika,Ashish Kumar,Ramkumar Janakiraman,Ram Bezawada,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = In this study we examine the effect of customers' participation in a firm's social media efforts on the intensity of the relationship between the firm and its customers as captured by customers' visit frequency. We further hypothesize and test for the moderating roles of social media activity and customer characteristics on the link between social media participation and the intensity of customer-firm relationship. Importantly, we also quantify the impact of social media participation on customer profitability. We assemble a novel data set that combines customers' social media participation data with individual customer level transaction data. To account for endogeneity that could arise because of customer self-selection, we utilize the propensity score matching technique in combination with difference in differences analysis. Our results suggest that customer participation in a firm's social media efforts leads to an increase in the frequency of customer visits. We find that this participation effect is greater when there are high levels of activity in the social media site and for customers who exhibit a strong patronage with the firm, buy premium products, and exhibit lower levels of buying focus and deal sensitivity. We find that the above set of results holds for customer profitability as well. We discuss theoretical implications of our results and offer prescriptions for managers on how to engage customers via social media. Our study emphasizes the need for managers to integrate knowledge from customers' transactional relationship with their social media participation to better serve customers and create sustainable business value.
|keyword = social media marketing,social media participation,customer-firm relationship,shopping visit,frequency,customer profitability,propensity score matching,quasi-experiment,difference-in-differences,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Predicting Adoption Probabilities in Social Networks'''
{{header}}
{{article
|author= Xiao Fang,Paul Jen-Hwa Hu,Zhepeng (Lionel) Li,Weiyu Tsai,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = In a social network, adoption probability refers to the probability that a social entity will adopt a product, service, or opinion in the foreseeable future. Such probabilities are central to fundamental issues in social network analysis, including the influence maximization problem. In practice, adoption probabilities have significant implications for applications ranging from social network-based target marketing to political campaigns, yet predicting adoption probabilities has not received sufficient research attention. Building on relevant social network theories, we identify and operationalize key factors that affect adoption decisions: social influence, structural equivalence, entity similarity, and confounding factors. We then develop the locally weighted expectation-maximization method for Naive Bayesian learning to predict adoption probabilities on the basis of these factors. The principal challenge addressed in this study is how to predict adoption probabilities in the presence of confounding factors that are generally unobserved. Using data from two large-scale social networks, we demonstrate the effectiveness of the proposed method. The empirical results also suggest that cascade methods primarily using social influence to predict adoption probabilities offer limited predictive power and that confounding factors are critical to adoption probability predictions.
|keyword = adoption probability,social network,Bayesian learning,social influence,structural equivalence,entity similarity,confounding factor,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Social Media and Firm Equity Value'''
{{header}}
{{article
|author= Xueming Luo,Jie Zhang,Wenjing Duan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Companies have increasingly advocated social media technologies to transform businesses and improve organizational performance. This study scrutinizes the predictive relationships between social media and firm equity value, the relative effects of social media metrics compared with conventional online behavioral metrics, and the dynamics of these relationships. The results derived from vector autoregressive models suggest that social media-based metrics (Web blogs and consumer ratings) are significant leading indicators of firm equity value. Interestingly, conventional online behavioral metrics (Google searches and Web traffic) are found to have a significant yet substantially weaker predictive relationship with firm equity value than social media metrics. We also find that social media has a faster predictive value, i.e., shorter "wear-in" time, than conventional online media. These findings are robust to a consistent set of volume-based measures (total blog posts, rating volume, total page views, and search intensity). Collectively, this study proffers new insights for senior executives with respect to firm equity valuations and the transformative power of social media.
|keyword = social media,word of mouth,online reviews,Web blogs,vector autoregression,firm equity value,stock market performance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Engineering Optimal Network Effects via Social Media Features and Seeding in Markets for Digital Goods and Services'''
{{header}}
{{article
|author= Yifan Dou,Marius F. Niculescu,D. J. Wu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Firms nowadays are increasingly proactive in trying to strategically capitalize on consumer networks and social interactions. In this paper, we complement an emerging body of research on the engineering of word-of-mouth effects by exploring a different angle through which firms can strategically exploit the value-generation potential of the user network. Namely, we consider how software firms should optimize the strength of network effects at utility level by adjusting the level of embedded social media features in tandem with the right market seeding and pricing strategies in the presence of seeding disutility. We explore two opposing seeding cost models where seeding-induced disutility can be either positively or negatively correlated with customer type. We consider both complete and incomplete information scenarios for the firm. Under complete information, we uncover a complementarity relationship between seeding and building social media features that holds for both disutility models. When the cost of any of these actions increases, rather than compensating by a stronger action on the other dimension to restore the overall level of network effects, the firm will actually scale back on the other initiative as well. Under incomplete information, this complementarity holds when seeding disutility is negatively correlated with customer type but may not always hold in the other disutility model, potentially leading to fundamentally different optimal strategies. We also discuss how our insights apply to asymmetric networks.
|keyword = social commerce and social media,network effects,social interaction,seeding,adoption process,digital goods and services,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Effects of Rewarding User Engagement: The Case of Facebook Apps'''
{{header}}
{{article
|author= Jorg Claussen,Tobias Kretschmer,Philip Mayrhofer,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = We study the market for apps on Facebook, the dominant social networking platform, and make use of a rule change by Facebook by which highly engaging apps were rewarded with further opportunities to engage users. The rule change led to new applications with significantly higher user ratings being developed. Moreover, user ratings became more important drivers of app success. Other drivers of app success are also affected by the rule change; sheer network size became a less important driver for app success, update frequency benefitted apps more in staying successful, and active users of Facebook apps declined less rapidly with age. Our results show that social media channels do not necessarily have to be managed through hard exclusion of participants but can also be steered through "softer" changes in reward and incentive systems.
|keyword = app markets,social media,platform management,Facebook,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Everybody Needs Somebody: The Influence of Team Network Structure on Information Technology Use'''
{{header}}
{{article
|author= Masimo Magni,Corey M. Angst,Ritu Agarwal,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Team network structure has been shown to be an important determinant of both team and individual performance outcomes, yet few studies have investigated the relationship between team network structure and technology usage behaviors. Drawing from social network and technology use literature, we examine how the structure of a team's advice-seeking network affects individual use of a newly implemented information technology. We develop cross-level hypotheses related to the effects of the structure of mutually interconnected ties within the team (i.e., internal closure) as well as the structure of nonredundant ties outside the team boundaries (i.e., external bridging). The hypotheses are tested in a field study of 265 employees working in 44 teams in a large financial services institution. Results show that internal closure has a U-shaped effect on individual use such that individual usage of the system is higher when the number of internaladvice-seeking ties within the team is low or high, suggesting that medium levels of internal closure are the least desirable network configurations because in such instances teams neither realize the benefits of high closure information sharing nor are they able to avoid in-group biases associated with low closure conditions. Our results also reveal that in addition to having a direct positive effect on individual use, external bridging interacts with internal closure in a complex manner. The U-shaped effect of closure is dominant when bridging is high but assumes an inverted U-shaped pattern when bridging is low. Several implications for managers follow from these findings. First, in order to increase usage of technology, in teams characterized by low internal closure, managers should encourage the development of ties across team boundaries. Second, managers should maximize within-team interconnections in order to facilitate the circulation of external knowledge within team boundaries. Finally, managers should be aware that maximizing internal closure by facilitating interconnections among team members could be dangerous if not accompanied by mechanisms for external bridging.
|keyword = advice-seeking network,external bridging,integration perspective,internal closure,social categorization theory,technology use,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Toward an Integrated Model of Group Development: Disruption of Routines by Technology-Induced Change'''
{{header}}
{{article
|author= Monica J. Garfield,Alan R. Denis,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Current research argues that the most prominent models of group development (the linear stage model and the punctuated equilibrium model) are simply different lenses for studying the same phenomenon. We argue that the two models are distinct (groups do not simultaneously follow both models) and that the key to understanding their use lies in routines. We studied six newly formed groups whose members came from the same organization that worked on similar projects over a seven-week period. Three groups worked nonmediated and three groups used a collaboration technology that was new to them. The three nonmediated groups followed the punctuated equilibrium model and the three collaboration technology groups followed the stage model. We argue that groups that enact the shared routines common in their organizations will experience a different group development path than those groups whose shared routines are disrupted and which must adapt to a new technology. When group members enact shared routines (which they may share due to having a common organizational culture), they can quickly begin work, and group development follows the punctuated equilibrium model. When groups cannot enact shared routines, they must first negotiate how they will work before work can begin, so group development follows the stage model. Thus, the introduction of new collaboration technology (or any new technology or work process) influences how group development occurs.
|keyword = case study,collaboration technology,field experiment,group development models,mixed methods,routines,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Corporate Wikis: The Effects of Owners' Motivation and Behavior on Group Members' Engagement'''
{{header}}
{{article
|author= Ofer Arazy,Ian R. Gellatly,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Originally designed as a tool to alleviate bottlenecks associated with knowledge management, the suitability of wikis for corporate settings has been questioned given the inherent tensions between wiki affordances and the realities of organizational life. Drawing on regulatory focus theory and social cognitive theory, we developed and tested a model of the motivational dynamics underlying corporate wikis. We examined leaders (owners) and users of 187 wiki-based projects within a large multinational firm. Our findings revealed two countervailing motivational forces, one oriented toward accomplishment and achievement (promotion focus) and one oriented toward safety and security (prevention focus), that not only predicted owners' participation but also the overall level of engagement within the wiki groups. Our primary contribution is in showing that, notwithstanding the potential benefits to users, wikis can trigger risk-avoidance motives that potentially impede engagement. Practically, our findings call for an alignment between organizational procedures surrounding wiki deployment and the technology's affordances.
|keyword = knowledge management (KM),knowledge management systems (KMS),knowledge sharing,motivation,owner,regulatory focus theory,social cognitive theory,wiki,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Security Outsourcing with System Interdependency and Mandatory Security Requirement'''
{{header}}
{{article
|author= Kai-Lung Hui,Wendy Hui,Wei T. Yue,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = The rapid growth of computer networks has led to a proliferation of information security standards. To meet these security standards, some organizations outsource security protection to a managed security service provider (MSSP). However, this may give rise to system interdependency risks. This paper analyzes how such system interdependency risks interact with a mandatory security requirement to affect the equilibrium behaviors of an MSSP and its clients. We show that a mandatory security requirement will increase the MSSP's effort and motivate it to serve more clients. Although more clients can benefit from the MSSP's protection, they are also subjected to greater system interdependency risks. Social welfare will decrease if the mandatory security requirement is high, and imposing verifiability may exacerbate social welfare losses. Our results imply that recent initiatives such as issuing certification to enforce computer security protection, or encouraging auditing of managed security services, may not be advisable.
|keyword = information security,information security outsourcing,interdependency risks,mandatory security requirement,security compliance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Organizations' Information Security Policy Compliance: Stick or Carrot Approach?'''
{{header}}
{{article
|author= Yan Chen,K. (Ram) Ramamurthy,Kuang-Wei Wen,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Companies' information security efforts are often threatened by employee negligence and insider breach. To deal with these insider issues, this study draws on the compliance theory and the general deterrence theory to propose a research model in which the relations among coercive control, which has been advocated by scholars and widely practiced by companies; remunerative control, which is generally missing in both research and practice; and certainty of control are studied. A Web-based field experiment involving real-world employees in their natural settings was used to empirically test the model. While lending further support to the general deterrence theory, our findings highlight that reward enforcement, a remunerative control mechanism in the information systems security context, could be an alternative for organizations where sanctions do not successfully prevent violation. The significant interactions between punishment and reward found in the study further indicate a need for a more comprehensive enforcement system that should include a reward enforcement scheme through which the organizational moral standards and values are established or reemphasized. The findings of this study can potentially be used to guide the design of more effective security enforcement systems that encompass remunerative control mechanisms.
|keyword = coercive control,compliance theory,general deterrence theory,information security policy,punishment,remunerative control,reward,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Competitive Target Advertising and Consumer Data Sharing'''
{{header}}
{{article
|author= Xia Zhao,Ling Xue,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Advances in information technologies enable firms to collect detailed consumer data and target individual consumers with tailored ads. Consumer data are among the most valuable assets that firms own. An interesting phenomenon is that competing firms often trade their consumer data with each other. Based on a common-value all-pay auction framework, this paper studies the advertising competition between two firms that target the same consumer but are asymmetrically informed about the consumer value. We characterize firms' equilibrium competition strategies. The results show that better consumer information does not help the better-informed firm save the advertising expenditure but does enable it to reap a higher expected profit in competition. Sharing individual-level consumer data may soften the competition even though firms compete head-to-head for the same consumer. We also find that the better-informed firm may sell its data to its competitor but never voluntarily shares it with its competitor.
|keyword = advertising,all-pay auction,common-value auction,information asymmetry,information sharing,target marketing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Alternate Strategies for a Win-Win Seeking Agent in Agent-Human Negotiations'''
{{header}}
{{article
|author= Yinping Yang,Sharad Singhal,Yunjie (Calvin) Xu,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = With the growth of e-commerce and e-markets, there is an increasing potential for the use of software agents to negotiate business tasks with human negotiators. Guided by design science methodology, this research prescribes and validates a win-win seeking negotiation agent using strategies of "simultaneous-equivalent offers" and "delayed acceptance" and compares their effects against the use of conventional sequential-single offer and immediate acceptance strategies. To evaluate the alternate strategies, a negotiation agent system was implemented and an experiment was conducted in which 110 agent-human dyads negotiated over a four-issue online purchase task. Our results indicate that the proposed agent strategies can enhance the economic performance of the negotiated outcome (counterpart agreement ratio, individual utility, joint utility, and the distance to Pareto-efficient frontier) and maintain the human counterparts' positive perceptions toward the outcome and the agent. The findings confirm the efficacy of the proposed design and showcase an innovative system to facilitate e-commerce transactions.
|keyword = agent-human negotiation,delayed acceptance,design science,electronic markets,negotiation agent,simultaneous-equivalent offers,win-win negotiation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Inducing Intrinsic Motivation to Explore the Enterprise System: The Supremacy of Organizational Levers'''
{{header}}
{{article
|author= Weiling Ke,Chuan-Ho Tan,Choon-Ling Sia,Kwok-Kee Wei,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = The adoption of an organization-wide system, such as an enterprise system (ES), has often been mandated by organizational management, which may not necessarily motivate users to proactively explore the system's features and subsequently apply pertinent features that best support their job tasks. Anchoring on self-determination theory, this research investigates the antecedents and consequences of users' intrinsic motivation to explore ES features. We propose two organizational levers (i.e., autonomous job design and socialization tactics) that the management could exercise to trigger intrinsic motivation, thereby leading to improved ES feature exploration. Intrinsic motivation is manifested by hedonic motivation and normative motivation, whereas ES feature exploration is conceptualized as a dual-dimensional outcome reflected by cognitive behavior (exploratory usage) and positive affect (exploration satisfaction). Through a two-stage survey of 127 organizational users in China, we find general support for our research model. We further observe significant moderating effects of prevention focus on the association between organizational levers and intrinsic motivations. Beyond demonstrating how organizational users respond to different organizational levers, this research examines a broader, enduring challenge, which is to determine how organizational users can be induced to be intrinsically inspired to innovatively harness implemented information systems.
|keyword = enterprise system,exploration usage,intrinsic motivation,organizational levers,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding Postadoptive Behaviors in Information Systems Use: A Longitudinal Analysis of System Use Problems in the Business Intelligence Context'''
{{header}}
{{article
|author= Xuefei (Nancy) Deng,Lei Chi,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = For an organization to gain maximum benefits from a new information system (IS), individual users in the organization must use it effectively and extensively. To do so, users need to overcome many problems associated with their system use in order to integrate the new IS into their work routines. Much remains to be learned about the types of problems that users encounter in using the new system, in particular, the root causes of system use problems and how they relate to and co-evolve with the problems over time. In this study, we seek to develop a comprehensive and dynamic view of system use problems in organizations. Using a combined method of revealed causal mapping and in-depth network analysis, we analyze nine-month archival data on user-reported problems with a new business intelligence application in a large organization. Our data analysis revealed seven emergent constructs of system use problems and causes, including reporting, data, workflow, role authorization, users' lack of knowledge, system error, and user-system interaction. The seven constructs were found to interact differentially across two usage phases (initial versus continued) and between two types of users (regular versus power user). This study contributes to advancing our theoretical understanding of postadoptive IS use by focusing on its problematic aspect. This study also suggests useful methods for organizations to effectively monitor users' system use problems over time and thus guides organizations to effectively target mechanisms to promote the use of new technologies.
|keyword = business intelligence,IS use,postadoptive behavior,revealed causal mapping,social network analysis,system use problem,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Investigating the Value of Sociomaterialism in Conceptualizing IT Capability of a Firm'''
{{header}}
{{article
|author= Gimun Kim,Bongsik Shin,Ohbyung Kwon,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Sociomateriality (or sociomaterialism) allows us to approach the information technology (IT) capability research from an angle that has been rarely visited by information systems scholars. While relevant studies presume that humans and materials are distinct and largely independent, sociomateriality emphasizes agency that represents the relational, emergent, and shifting capacity realized through the association of actors (both humans and materials). The objective of this paper is to explore the value of conducting IT capability research through the theoretical lens of sociomaterialism. For this, we expand the imbrication metaphor introduced in an early study to explain the formation and advancement of a firm's IT capability from the sociomaterial perspective. Then, the key building blocks of IT capability of an organization are conceptualized based on the combination of existing studies and the expanded imbrication metaphor. Lastly, the effectiveness of formulating IT capability as a third-order construct that substantiates the entanglement concept of sociomaterialism is examined in comparison with that of traditional modeling approaches. We confirm the value of sociomaterialism in conceptualizing IT capability and subsequently in unraveling the true contribution of IT capability toward strengthening business performance. The findings also have practical implications in which IT capability is a function of IT management capability as well as IT personnel capability and IT infrastructure capability.
|keyword = imbrication metaphor,IT capability,sociomaterialism,sociomateriality,third-order factor,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Generalizability of Information Systems Research Using Student Subjects-A Reflection on Our Practices and Recommendations for Future Research'''
{{header}}
{{article
|author= Deborah Compeau,Barbara Marcolin,Helen Kelley,Chris Higgins,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Information systems researchers, like those in many other disciplines in the social sciences, have debated the value and appropriateness of using students as research subjects. This debate appears in several articles that have been published on the subject as well as in the review process. In this latter arena, however, the debate has become increasingly like a script-the actors (authors and reviewers) simply read their parts of the script; some avoid the underlying issues whereas others cursorily address generalizability without real consideration of those issues. As a result, despite the extent of debate, we seem no closer to a resolution. Authors who use student subjects rely on their scripted arguments to justify the use of student subjects and do not always consider whether those arguments are valid. But reviewers who oppose the use of student subjects are equally culpable. They, too, rely on scripted arguments to criticize work using student subjects, and do not always consider whether those arguments are salient to the particular study. By presenting and reviewing one version of this script in the context of theoretical discussions of generalizability, we hope to demonstrate its limitations so that we can move beyond these scripted arguments into a more meaningful discussion. To do this, We review empirical studies from the period 1990-2010 to examine the extent to which student subjects are being used in the field and to critically assess the discussions within the field about the use of student samples. We conclude by presenting recommendations for authors and reviewers, for determining whether the use of students is appropriate in a particular context, and for presenting and discussing work that uses student subjects.
|keyword = external validity,student samples,review process,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Advancing Public Trust Relationships in Electronic Government: The Singapore E-Filing Journey'''
{{header}}
{{article
|author= Eric T. K. Lim,Chee-Wee Tan,Dianne Cyr,Shan L. Pan,Bo Xiao,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = E-governments have become an increasingly integral part of the virtual economic landscape. However, e-government systems have been plagued by an unsatisfactory, or even a decreasing, level of trust among citizen users. The political exclusivity and longstanding bureaucracy of governmental institutions have amplified the level of difficulty in gaining citizens' acceptance of e-government systems. Through the synthesis of trust-building processes with trust relational forms, we construct a multidimensional, integrated analytical framework to guide our investigation of how e-government systems can be structured to restore trust in citizen-government relationships. Specifically, the analytical framework identifies trust-building strategies (calculative-based, prediction-based, intentionality-based, capability-based, and transference-based trust) to be enacted for restoring public trust via e-government systems. Applying the analytical framework to the case of Singapore's Electronic Tax-Filing (E-Filing) system, we advance an e-government developmental model that yields both developmental prescriptions and technological specifications for the realization of these trust-building strategies. Further, we highlight the impact of sociopolitical climates on the speed of e-government maturity.
|keyword = e-government,public trust,calculative-based trust,prediction-based trust,intentionality-based trust,capability-based trust,transference-based trust,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Adoption and Impacts of Interorganizational Business Process Standards: Role of Partnering Synergy'''
{{header}}
{{article
|author= Viswanath Venkatesh,Hillol Bala,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Notwithstanding potential benefits, such as quality of interorganizational relationships and operational and strategic gains, adoption of information technology (IT)-enabled interorganizational business process standards (IBPS) is still limited. Given that these standards are designed for interorganizational business processes, we suggest that adoption of these standards depends not only on the factors pertinent to a focal firm but also on factors that represent synergies between a focal firm and its trading partners. In this paper, building on the technological, organizational, and environmental (TOE) framework and interorganizational theories, we propose a model that postulates that a set of TOE factors will have synergistic effects (i.e., interactions between a focal firm's and its partner's factors) on IBPS adoption. We tested our model in a study of 248 firms (124 dyads) in the high-tech industry implementing Rosetta Net-based IBPS and found that three TOE factors (i.e., process compatibility, standards uncertainty, and technology readiness) had synergistic effects and two factors (i.e., expected benefits and relational trust) had direct effects on IBPS adoption. We also found that IBPS adoption led to greater relationship quality (i.e., partnering satisfaction) and operational efficiency (i.e., cycle time). Further, we found that IBPS adoption mediated the effect of TOE factors on partnering satisfaction and cycle time.
|keyword = interorganizational relationships,business process,process standards,process compatibility,standards uncertainty,cycle time,relationship quality,partnering synergy,synergistic effects,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Corporate IT Standardization: Product Compatibility, Exclusive Purchase Commitment, and Competition Effects'''
{{header}}
{{article
|author= Xinxin Li,Yuxin Chen,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = When companies purchase information technology (IT) products for their employees, departments, or divisions, whether to standardize on one product or to allow the users to make their own choices is an important decision for IT managers to make. By consolidating demand and committing to buy from a single seller, standardization ensures product compatibility within the corporation and has a potential to induce intense price competition among sellers, but this potential is subject to whether competing products are compatible and the relative competitive advantages of the sellers. This paper studies when it is optimal for an employer to commit to exclusive purchase from a single seller to enforce standardization and sellers' incentives to invest in mutual compatibility. Our results suggest that the employer is more likely to make such a commitment when the competing products are compatible, less vertically differentiated, and/or more horizontally differentiated. We also find that the sellers agree to cooperate and invest in mutual compatibility only when the gap between their competitive advantages is moderate, but the availability of third party converters that enable partial compatibility can induce more collaboration among the sellers.
|keyword = corporate IT standardization,product compatibility,network effects,exclusive purchase commitment,competition effects,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Synergy and Its Limits in Managing Information Technology Professionals'''
{{header}}
{{article
|author= Thomas W. Ferratt,Jayesh Prasad,Harvey G. Enns,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = We examine the effects of human resource management (HRM) practices (e.g., career development, social support, compensation, and security) on information technology (IT) professionals' job search behavior. Job search is a relatively novel dependent variable in studies of voluntary withdrawal behavior in general and for IT professionals in particular. From a universalistic perspective, FIRM practices individually and in combination exhibit independently additive effects on job search behavior. Our study contrasts this perspective with configurational theory, hypothesizing that proposed ideal-type configurations of HRM practices have synergistic effects on job search behavior. We contribute to the IT and broader HRM literature by theoretically explicating and empirically demonstrating with IT professionals the power of configurational theory to explain the relationship between HRM practices and job search behavior. Our empirical results show that two configurations of HRM practices-Human Capital Focused (HCF) and Task Focused (TF), which are high and low on all HRM practices, respectively-exhibit a synergistic relationship with the job search behavior of IT professionals. HCF has lower job search behavior than would be expected based on the independently additive effects of the HRM practices, whereas TF has correspondingly higher job search behavior. Our results also show that less than perfect horizontal fit detracts from the synergy of these extreme configurations. Just as importantly, several other nonextreme configurations of HRM practices exhibit independently additive effects for the HRM practices but not synergy, suggesting that synergy is limited to extreme configurations. We also discuss a number of implications for research and practice.
|keyword = synergy,configurations,information technology professionals,management of IT resources,human resource practices,staffing,strategic human resource management,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''User Satisfaction with Information Technology Service Delivery: A Social Capital Perspective'''
{{header}}
{{article
|author= Yongqiang Sun,Yulin Fang,Kai H. Lim,Detmar Straub,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Existing research has long considered service quality as a primary determinant of user satisfaction with information technology (IT) service delivery. In response to the knowledge-intensive and collaborative nature of IT service delivery in the contemporary business context, we advance the theoretical understanding of user satisfaction by re-conceptualizing IT service delivery as a bilateral, relational process between the IT staff and users. Based on this reconceptualization, we draw on social capital theory to examine the antecedents of user satisfaction with IT service delivery. Specifically, we posit that two major dimensions of social capital, i.e., cognitive capital and relational capital, not only positively affect user satisfaction but also strengthen the established relationship between service quality and user satisfaction. Furthermore, we propose that the effect of the other dimension of social capital-structural capital-on user satisfaction is fully mediated through cognitive capital and relational capital. A field study of 159 users in four financial companies provides general empirical support for our hypotheses. Theoretical and practical implications of these findings are discussed.
|keyword = IT service,social capital,service quality,user satisfaction,survey,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Ushering Buyers into Electronic Channels: An Empirical Analysis'''
{{header}}
{{article
|author= Nishtha Langer,Chris Forman,Sunder Kekre,Baohong Sun,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Despite many success stories, B2B e-commerce penetration remains low. Many firms introduce electronic channels in addition to their traditional sales channels but find that buyer usage of the e-channel over time does not keep up with initial expectations. Firms must understand the underlying factors that drive channel usage and how these factors change over time and across buyers. Using panel data pertaining to the purchase histories of 683 buyers over a 43-month period, we estimate a dynamic discrete choice model in a B2B setting that (i) recognizes how price, channel inertia, and inventory change over time; (ii) allows buyers to dynamically trade off these factors when making e-channel adoption decisions; and (iii) takes into account buyer heterogeneity. We find that channel usage is both heterogeneous and dynamic across buyers. Our findings reveal the dynamic tradeoff between channel inertia and the adverse price effect, which interact in opposing directions as the e-channel grows more popular over time: price increases resulting from more bids deter buyers, whereas channel inertia built from sampling experience helps retain repeat buyers for the new channel. Second, we find that the buyers' size and diversity influence purchase decisions, and the e-channel appears more attractive to small and/or diversified buyers. Based on our analysis, we postulate that the seller's allocation decisions of products across channels, if not aligned with buyer behavior, can alienate some buyers. Based on the parameter estimates from the buyer response model, we propose an improved channel allocation that enables firms to selectively attract more buyers to the e-channel and improve revenues. Channel acceptance increases as a result of smart allocation when firms understand and account for individual buyers' channel usage behavior.
|keyword = electronic markets,channel choice,buyer heterogeneity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''What Motivates People to Purchase Digital Items on Virtual Community Websites? The Desire for Online Self-Presentation'''
{{header}}
{{article
|author= Hee-Woong Kim,Hock Chuan Chan,Atreyi Kankanhalli,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The sale of digital items, such as avatars and decorative objects, is becoming an important source of revenue for virtual community (VC) websites. However, some websites are unable to leverage this source of revenue, and there is a corresponding lack of understanding about what motivates people to purchase digital items in VCs. To explain the phenomenon, we develop a model based on the theory of self-presentation. The model proposes that the desire for online self-presentation is a key driver for such purchases. We also hypothesize that the social influence factors of online self-presentation norms and VC involvement as well as personal control in the form of online presentation self-efficacy are antecedents of the desire for online self-presentation. The model was validated by using survey data collected from Cyworld (N = 217) and Habbo (N = 197), two online social network communities that have been pioneers in the sale of digital items. This work contributes to our understanding of the purchase of digital items by extending the theory of self-presentation and adds to the broader line of research on online identity. It also lends insights into how VC providers can tap this source of revenue.
|keyword = digital item purchase,virtual community,desire for online self-presentation,VC norms,VC involvement,online presentation self-efficacy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Two Worlds of Trust for Potential E-Commerce Users: Humans as Cognitive Misers'''
{{header}}
{{article
|author= Ben Q. Liu,Dale L. Goodhue,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = In this paper we consider the impact of trust on a new visitor's intention to revisit a website, but instead of using the typical expectancy-value theories as our conceptual basis, we look at the issue from the perspective of cognitive complexity and "humans as cognitive misers." Starting with the suggestion that it is cognitively taxing to distrust, we propose that in order to conserve on cognitive resources, once a new visitor has convinced him or herself that a website is "trustworthy enough," that user will drop trustworthiness from their concerns and only consider other characteristics of the website (e.g., task-technology fit, aesthetic appeal, etc.) in determining their revisit intention. This leads to what we call a "trust tipping point" and two different worlds of trust. Above the tipping point revisit intention is constructed in one way, and below the trust tipping point it is constructed in a quite different way. This perspective results in very different recommendations for website designers as to the likely payoff from improving task-technology fit, aesthetic appeal, or trustworthiness, depending upon where their existing website stands relative to the trust tipping point. To test our hypotheses we used data from 314 student website users, and expanded a technique called piecewise regression (Neter et al. Applied Linear Statistical Models, 4th ed.) to allow us to analyze data as two different linear surfaces, joined at the tipping point. We found good support for our assertions that users operate differently above and below a trust tipping point.
|keyword = accessibility-diagnosticity,bounded rationality,humans as cognitive misers,piecewise regression,task-technology fit,trust,web aesthetics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Real-Time Tactical and Strategic Sales Management for Intelligent Agents Guided by Economic Regimes'''
{{header}}
{{article
|author= Wolfgang Ketter,John Collins,Maria Gini,Alok Gupta,Paul Schrater,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Many enterprises that participate in-dynamic markets need to make product pricing and inventory resource utilization decisions in real time. We describe a family of statistical models that addresses these needs by combining characterization of the economic environment with the ability to predict future economic conditions to make tactical (short-term) decisions, such as product pricing, and strategic (long-term) decisions, such as level of finished goods inventories. Our models characterize economic conditions, called economic regimes, in the form of recurrent statistical patterns that have clear qualitative interpretations. We show how these models can be used to predict prices, price trends, and the probability of receiving a customer order at a given price. These "regime" models are developed using statistical analysis of historical data and are used in real time to characterize observed market conditions and predict the evolution of market conditions over multiple time scales. We evaluate our models using a testbed derived from the Trading Agent Competition for Supply Chain Management, a supply chain environment characterized by competitive procurement, sales markets, and dynamic pricing. We show how regime models can be used to inform both short-term pricing decisions and long-term resource allocation decisions. Results show that our method outperforms more traditional short- and long-term predictive modeling approaches.
|keyword = enabling technologies,agent-mediated electronic commerce,dynamic pricing,price forecasting,economic regimes,supply chain,dynamic markets,trading agent competition,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Effects of the Presence of Organic Listing in Search Advertising'''
{{header}}
{{article
|author= Lizhen Xu,Jianqing Chen,Andrew Whinston,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = This paper analyzes how the presence of organic listing as a competing information source affects advertisers' sponsored bidding and the equilibrium outcomes in search advertising. We consider a game-theoretic model in which two firms bid for sponsored advertising slots provided by a monopolistic search engine and then compete for consumers in price in the product market. Firms are asymmetrically differentiated in market preference and are given different exposure in organic listing aligned with their market appeal. We identify two aspects of a firm's sponsored bidding incentive, namely,. the promotive and the preventive incentives. The presence of organic listing alters firms' sponsored bidding incentives such that the stronger firm has primarily preventive incentive, whereas the weaker has mainly promotive incentive. We show that the preventive incentive decreases and the promotive incentive increases as the difference in firms' market appeal decreases, and as a result, even the weaker firm may outbid the stronger competitor under such a co-listing setting. We further examine how the presence of organic listing affects the equilibrium outcomes by comparing it with a benchmark case in which there is only a sponsored list. We show that the differentiated exposure in the organic list gives the weaker advertiser chances to win a better sponsored position, which improves the overall information structure the search engine provides. As a result, the equilibrium social welfare, sales diversity, and consumer surplus increase. Although the presence of the free exposure from the organic list may reduce advertisers' sponsored bidding incentive per se, the overall effect benefits the search engine's growth in the long run.
|keyword = organic listing,sponsored bidding,search advertising,information structure,asymmetric differentiation,price competition,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Network Neutrality and Congestion Sensitive Content Providers: Implications for Content Variety, Broadband Investment, and Regulation'''
{{header}}
{{article
|author= Jan Kraemer,Lukas Wiewiorra,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = We study departures from network neutrality through implementing a quality of service tiering regime in which an Internet service provider charges for prioritization on a nondiscriminatory basis. We find that quality of service tiering may be more efficient in the short run because it better allocates the existing network capacity and in the long run because it provides higher investment incentives due to the increased demand for priority services by the entry of new congestion sensitive content providers. Which network regime is the most efficient depends on the distribution of congestion sensitivity among content providers, but a guideline is that the regime that provides higher incentives for infrastructure investments is more efficient in the long run.
|keyword = telecommunications,net neutrality,quality of service,content variety,investment,regulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Underlying Consumer Heterogeneity in Markets for Subscription-Based IT Services with Network Effects'''
{{header}}
{{article
|author= Marius F. Niculescu,Hyoduk Shin,Seungjin Whang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = In this paper we explore the underlying consumer heterogeneity in competitive markets for subscription-based information technology services that exhibit network effects. Insights into consumer heterogeneity with respect to a given service are paramount in forecasting future subscriptions, understanding the impact of price and information dissemination on market penetration growth, and predicting the adoption path for complementary products that target the same customers as the original service. Employing a continuous-time utility model, we capture the behavior of a continuum of consumers who are differentiated by their intrinsic valuations from using the service. We study service subscription patterns under both perfect and imperfect information dissemination. In each case, we first specify the conditions under which consumer rational behavior supported by the utility model can explain a general observed adoption path, and if so, we explicitly derive the analytical closed-form expression for the consumer valuation distribution. We further explore the impact of awareness and distribution skewness on adoption. In particular, we highlight the practical forecasting importance of understanding the information dissemination process in the market as observed past adoption may be explained by several distinct awareness and heterogeneity scenarios that may lead to divergent adoption paths in the future. Moreover, we show that in the later part of the service lifecycle the subscription decision for new customers can be driven predominantly by information dissemination instead of further price markdowns. We also extend our results to time-varying consumer valuation scenarios. Furthermore, based on our framework, we advance a set of heuristic methods to be applied to discrete-time real industry data for estimation and forecasting purposes. In an empirical exercise, we apply our methodology to the Japanese mobile voice services market and provide relevant managerial insights from the analysis.
|keyword = subscription-based IT services,consumer utility models,consumer information awareness,network effects,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Effects of Individual Self-Protection, Industry Self-Regulation, and Government Regulation on Privacy Concerns: A Study of Location-Based Services'''
{{header}}
{{article
|author= Heng Xu,Hock-Hai Teo,Bernard C. Y. Tan,Ritu Agarwal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = This study seeks to clarify the nature of control in the context of information privacy to generate insights into the effects of different privacy assurance approaches on context-specific concerns for information privacy. We theorize that such effects are exhibited through mediation by perceived control over personal information and develop arguments in support of the interaction effects involving different privacy assurance approaches (individual self-protection, industry self-regulation, and government legislation). We test the research model in the context of location-based services using data obtained from 178 individuals in Singapore. In general, the results support our core assertion that perceived control over personal information is a key factor affecting context-specific concerns for information privacy. In addition to enhancing our theoretical understanding of the link between control and privacy concerns, these findings have important implications for service providers and consumers as well as for regulatory bodies and technology developers.
|keyword = privacy,context-specific concerns for information privacy,psychological control,control agency,individual self-protection,industry self-regulation,and government regulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Analyzing Pricing Strategies for Online Services with Network Effects'''
{{header}}
{{article
|author= Min-Seok Pang,Hila Etzion,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = In this study, we model firms that sell a product and a complementary online service, where only the latter displays positive network effects. That is, the value each consumer derives from the service increases with the total number of consumers that subscribe to the service. In addition, the service is valuable only to consumers who buy the product. We consider two pricing strategies: (1) bundle pricing, in which the firm charges a single price for the product and the service, and (2) separate pricing, in which the firm sets the prices of the product and the service separately, and consumers self-select whether to buy both or only the product. We show that in contrast to the common result in the bundling literature, often the monopolist chooses not to offer the bundle (he either sells the service separately or not at all) although bundling would increase both consumer surplus and social welfare. Thus, underprovision of the service can be the market outcome. We also demonstrate that network effects may cause the underprovision of the service.
|keyword = bundling,network effects,price discrimination,online services,online game industry,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''BIDDING BEHAVIOR EVOLUTION IN SEQUENTIAL AUCTIONS: CHARACTERIZATION AND ANALYSIS'''
{{header}}
{{article
|author= Paulo B. Goes,Gilbert G. Karuga,Arvind K. Tripathi,
|source= MIS QUARTERLY
|year= 2012
|abstract = Retailers are increasingly exploiting sequential online auctions as an effective and low cost distribution channel for disposing large quantities of inventory. In such auction environments, bidders have the opportunity of participating in many auctions to learn and choose the bidding strategy that best fits their preferences. Previous studies have mostly focused on identifying bidding strategies in single, isolated online auctions. Using a large data set collected from sequential online auctions, we first characterize bidding strategies in this interesting online environment and then develop an empirical model to explain bidders' adoption of different strategies. We also examine how bidders change their strategies over time. Our findings challenge the general belief that bidders employ their strategies regardless of experience or their specific demand. We. find that bidders' demand, participation experience, and auction design parameters affect their choice of bidding strategies. Bidders with unit demand are likely to choose early bidding strategies, while those with multiple unit demand adopt late bidding strategies. Auction design parameters that affect bidders' perception of demand and supply trends affect bidders' choice of bidding strategies. As bidders gain experience within a sequence of auctions, they start choosing late bidding strategies. Our findings help auctioneers to design auction sequences that maximize their objectives.
|keyword = Sequential online auctions,bidding behavior,bidding strategies,auction design,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION TECHNOLOGY OUTSOURCING, KNOWLEDGE TRANSFER, AND FIRM PRODUCTIVITY: AN EMPIRICAL ANALYSIS'''
{{header}}
{{article
|author= Young Bong Chang,Vijay Gurbaxani,
|source= MIS QUARTERLY
|year= 2012
|abstract = Firms are increasingly sourcing internal information systems functions,from external service providers. However, there is limited empirical evidence of the economic impact of this delivery option and, more specifically, of the productivity gains accruing to firms that have outsourced. Moreover, there is little evidence of the role and contributions of the individual mechanisms by which service providers create value for client firms. We are particularly interested in whether client firms benefit from the accumulated knowledge held by information technology (IT) service firms. In this paper, we examine the impact of IT outsourcing on the productivity of firms that choose this mode of services delivery focusing, on the role of IT-related knowledge. Since firms self-select into their optimal sourcing mode, we use a variety of econometric techniques including propensity score-based matching and switching regression to control for potential bias arising from endogenously determined sourcing modes. We demonstrate that IT outsourcing does lead to productivity gains for firms that select this mode of service delivery. Our results also suggest that IT-related knowledge held by IT services vendors enables these productivity gains, the magnitude of which is moderated by a firm's IT intensity. Moreover, the value of outsourcing to a client firm increases with its propensity for outsourcing, which in turn depends on firm-specific attributes including efficiency level, financial leverage, and variability in business conditions. Our analyses also show that firms that outsource have been able to achieve additional productivity gains from contracting out compared with their counterfactuals.
|keyword = IT outsourcing,productivity,knowledge transfer,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IMPACT OF USER SATISFACTION WITH MANDATED CRM USE ON EMPLOYEE SERVICE QUALITY'''
{{header}}
{{article
|author= J. J. Po-An Hsieh,Arun Rai,Stacie Petter,Ting Zhang,
|source= MIS QUARTERLY
|year= 2012
|abstract = An increasing number of organizations are now implementing customer relationship management (CRM) systems to support front-line employees' service tasks. With the belief that CRM can enhance employees' service quality, management often mandates employees to use the implemented CRM. However, challenges emerge if/when employees are dissatisfied with using the system. To understand the role of front-line employee users' satisfaction with their mandated use of CRM in determining their service quality, we conducted afield study in one of the largest telecommunications service organizations in China and gathered time-lagged data from self-reported employee surveys, as well as from the firm's archival data sources. Our results suggest that employees' overall user satisfaction (UserSat) with their mandated use of CRM has a positive impact on employee service quality (ESQ) above and beyond the expected positive impacts that job dedication (JD) and embodied service knowledge (ESK) have on ESQ. Interestingly, the positive effect of UserSat on ESQ is comparable to the positive effects of JD and ESK, respectively, on ESQ. Importantly, UserSat and ESK have a substitutive effect on ESQ, suggesting that the impact of UserSat on ESQ is stronger/weaker for employees with lower/higher levels of ESK. Finally, ESQ predicts customer satisfaction with customer service employees (CSWCSE); ESQ also fully mediates the impacts of UserSat and ESK, and partially mediates the impact of JD, on CSWCSE. The results of this study emphasize the importance of user satisfaction in determining employees' task outcomes when use of an information system is mandated.
|keyword = User satisfaction,mandatory use,customer relationship management systems,employee service quality,job dedication,embodied service knowledge,task performance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DIALECTICS OF COLLECTIVE MINDING: CONTRADICTORY APPROPRIATIONS OF INFORMATION TECHNOLOGY IN A HIGH-RISK PROJECT'''
{{header}}
{{article
|author= Jessica Luo Carlo,Kalle Lyytinen,Jr. Richard J. Boland,
|source= MIS QUARTERLY
|year= 2012
|abstract = In unpredictable and unforgiving environments, organizations need to act with care and reliability, often referred to as collective mindfulness. We present a theory-generating, interpretative field study of a highly complex and successful building project by architect Frank O. Gehry. We argue that what has been labeled collective mindfulness is only possible through a dialectic process of collective minding, in which organizational actors simultaneously exhibit elements of being mindful and mindless. Our analysis reveals that collective minding emerges from struggling with contradictions in the five elements of mindfulness. We argue that when actors struggle with these dialectic tensions, the same information technology capabilities are enacted as multiple, contradictory technologies-in-practice. Implications for the further study of collective minding and the appropriation of IT capabilities are discussed.
|keyword = Collective minding,collective mindfulness,high-reliability organizations (HROs),complex socio-technical systems,dialectics,IT affordances,IT capabilities,technology-in-practice,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''GROWTH AND SUSTAINABILITY OF MANAGED SECURITY SERVICES NETWORKS: AN ECONOMIC PERSPECTIVE'''
{{header}}
{{article
|author= Alok Gupta,Dmitry Zhdanov,
|source= MIS QUARTERLY
|year= 2012
|abstract = Managed security service provider (MSSP) networks are a form of collaboration where several firms share resources such as diagnostics, prevention tools, and policies to provide security for their computer networks. While the decision to outsource the security operations of an organization may seem counterintuitive, there are potential benefits from joining an MSSP network that include pooling of risk and access to more security-enabling resources and expertise. We examine structural results explaining the reasons firms join an MSSP network, and characterize the growth of MSSP network size under different forms of ownership (monopoly versus consortium). We find that the need for an initial investment in MSSP networks (which is necessary to overcome the stalling effect) only affects the optimal network size for a consortium but has no impact on the optimal network size for a profit-maximizing monopolist. Our results provide an explanation why the majority of the MSSPs are for-profit entities and consortium-based MSSPs are less common. Such a market structure can be attributed to the potential for larger size by the for-profit MSSP owner combined with beneficial pricing structure and a lack of growth uncertainty for the early clients.
|keyword = Information security,managed security services,outsourcing,network effects,network growth,network ownership structure,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE EFFECTIVENESS OF ONLINE SHOPPING CHARACTERISTICS AND WELL-DESIGNED WEBSITES ON SATISFACTION'''
{{header}}
{{article
|author= Jifeng Luo,Sulin Ba,Han Zhang,
|source= MIS QUARTERLY
|year= 2012
|abstract = Electronic commerce has grown rapidly in recent years. However, surveys of online customers continue to indicate that many remain unsatisfied with their online purchase experiences. Clearly, more research is needed to better understand what affects customers' evaluations of their online experiences. Through a large dataset gathered from two online websites, this study investigates the importance of product uncertainty and retailer visibility in customers' online purchase decisions, as well as the mitigating effects of retailer characteristics. We find that high product uncertainty and low retailer visibility have a negative impact on customer satisfaction. However, a retailer's service quality, website design, and pricing play important roles in mitigating the negative impact of high product uncertainty and low retailer visibility. Specifically, service quality can mitigate the negative impacts of low retailer visibility and high product uncertainty in online markets. Website design, on the other hand, helps to reduce the impact of product uncertainty when experience goods are involved.
|keyword = Product uncertainty,retailer visibility,service quality,website design,customer satisfaction,search goods,experience goods,archival data,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DOES INFORMATION TECHNOLOGY INVESTMENT INFLUENCE A FIRM'S MARKET VALUE? A CASE OF NON-PUBLICLY TRADED HEALTHCARE FIRMS'''
{{header}}
{{article
|author= Rajiv Kohli,Sarv Devaraj,Terence T. Ow,
|source= MIS QUARTERLY
|year= 2012
|abstract = Managers make informed information technology investment decisions when they are able to quantify how IT contributes to firm performance. While financial accounting measures inform IT's influence on retrospective firm performance, senior managers expect evidence of how IT influences prospective measures such as the firm's market value. We examine the efficacy of IT's influence on firm value combined with measures of financial performance for non-publicly traded (NPT) hospitals that lack conventional market-based measures. We gathered actual sale transactions for NPT hospitals in the United States to derive the q ratio, a measure of market value. Our findings indicate that the influence of IT investment on the firm is more pronounced and statistically significant on firm value than exclusively on the accounting performance measures. Specifically, we find that the impact of IT investment is not significant on return on assets (ROA) and operating income for the same set of hospitals. This research note contributes to research and practice by demonstrating that the overall impact of IT is better understood when accounting measures are complemented with the firm's market value. Such market valuation is also critical in merger and acquisition decisions, an activity that is likely to accelerate in the healthcare industry. Our findings provide hospitals, as well as other NPT firms, with insights into the impact of IT investment and a pragmatic approach to demonstrating IT's contribution to firm value.
|keyword = IT payoff,firm valuation,non-publicly traded hospitals,NPT,health care,firm performance,market value,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''BUSINESS INTELLIGENCE AND ANALYTICS: FROM BIG DATA TO BIG IMPACT'''
{{header}}
{{article
|author= Hsinchun Chen,Roger H. L. Chiang,Veda C. Storey,
|source= MIS QUARTERLY
|year= 2012
|abstract = Business intelligence and analytics (BI&A) has emerged as an important area of study for both practitioners and researchers, reflecting the magnitude and impact of data-related problems to be solved in contemporary business organizations. This introduction to the MIS Quarterly Special Issue on Business Intelligence Research first provides a framework that identifies the evolution, applications, and emerging research areas of BI&A. BI&A 1.0, BI&A 2.0, and BI&A 3.0 are defined and described in terms of their key characteristics and capabilities. Current research in BI&A is analyzed and challenges and opportunities associated with BI&A research and education are identified. We also report a bibliometric study of critical BI&A publications, researchers, and research topics based on more than a decade of related academic and industry publications. Finally, the six articles that comprise this special issue are introduced and characterized in terms of the proposed BI&A research framework.
|keyword = Business intelligence and analytics,big data analytics,Web 2.0,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''BUSINESS INTELLIGENCE IN BLOGS: UNDERSTANDING CONSUMER INTERACTIONS AND COMMUNITIES'''
{{header}}
{{article
|author= Michael Chau,Jennifer Xu,
|source= MIS QUARTERLY
|year= 2012
|abstract = The increasing popularity of Web 2.0 has led to exponential growth of user-generated content in both volume and significance. One important type of user-generated content is the blog. Blogs encompass useful information (e.g., insightful product reviews and information-rich consumer communities) that could potentially be a gold mine for business intelligence, bringing great opportunities for both academic research and business applications. However, performing business intelligence on blogs is quite challenging because of the vast amount of information and the lack of commonly adopted methodology for effectively collecting and analyzing such information. In this paper, we propose a framework fir gathering business intelligence from blogs by automatically collecting and analyzing blog contents and bloggers' interaction networks. Through a system developed using the framework, we conducted two case studies with one case focusing on a consumer product and the other on a company. Our case studies demonstrate how to use the framework and appropriate techniques to effectively collect, extract, and analyze blogs related to the topics of interest, reveal novel patterns in the blogger interactions and communities, and answer important business intelligence questions in the domains. The framework is sufficiently generic and can be applied to any topics of interest, organizations, and products. Future academic research and business applications related to the topics examined in the two cases can also be built using the findings of this study.
|keyword = Business intelligence,Web mining,blog mining,social networks,design science,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A SOCIAL NETWORK-BASED INFERENCE MODEL FOR VALIDATING CUSTOMER PROFILE DATA'''
{{header}}
{{article
|author= Sung-Hyuk Park,Soon-Young Huh,Wonseok Oh,Sang Pil Han,
|source= MIS QUARTERLY
|year= 2012
|abstract = Drawing from the social and relational perspectives, this study offers an innovative conceptualization and operational approach regarding the validation of self:reported customer demographic data, which has become an essential corporate asset for harnessing business intelligence. Specifically, based on social network and homophily paradigms in which individuals have a natural tendency to associate and interact frequently with others with similar characteristics, we constructed a relational inference model to determine the accuracy of self-administered consumer profiles. In addition, to flirt her enhance the reliability of our model's prediction capability, we employed the entropy mechanism that minimizes potential biases that may arise from a simple probabilistic approach. To empirically validate the accuracy of our inference framework, we obtained and analyzed over 20 million actual call transactions supplied by one of the largest global telecommunication service providers. The results suggest that our social network-based inference model consistently outperforms other competing mechanisms (e.g., weighted average and simple relational classifier) regardless of the criteria choice (e.g., number of call receivers, call duration, and call frequency), with an accuracy rate of approximately 93 percent. Finally, to confirm the generalizability of our findings, we conducted simulation experiments to validate the robustness of the results in response to variations in parameter values and increases in potential noise in the data. We discuss several implications related to business intelligence for both research and practice, and offer new directions for future studies.
|keyword = Customer profile,data quality,business intelligence,inference model,social network,query processing system,simulation experiment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WEB 2.0 ENVIRONMENTAL SCANNING AND ADAPTIVE DECISION SUPPORT FOR BUSINESS MERGERS AND ACQUISITIONS'''
{{header}}
{{article
|author= Raymond Y. K. Lau,Stephen S. Y. Liao,K. F. Wong,Dickson K. W. Chiu,
|source= MIS QUARTERLY
|year= 2012
|abstract = Globalization has triggered a rapid increase in cross-border mergers and acquisitions (M&As). However, research shows that only 17 percent of cross-border M&As create shareholder value. One of the main reasons for this poor track record is top management's lack of attention to nonfinancial aspects (e.g., sociocultural aspects) of M&As. With the rapid growth of Web 2.0 applications, online environmental scanning provides top executives with unprecedented opportunities to tap into collective web intelligence to develop better insights about the sociocultural and political-economic factors that cross-border M&As face. Grounded in Porter's five forces model, one major contribution of our research is the design of a novel due diligence scorecard model that leverages collective web intelligence to enhance M&A decision making. Another important contribution of our work is the design and development of an adaptive business intelligence (BI) 2.0 system underpinned by an evolutionary learning approach, domain-specific sentiment analysis, and business relation mining to operationalize the aforementioned scorecard model for adaptive M&A decision support. With Chinese companies' cross-border M&As as the business context, our experimental results confirm that the proposed adaptive BI 2.0 system can significantly aid decision makers under different M&A scenarios. The managerial implication of our findings is that firms can apply the proposed BI 2.0 technology to enhance their strategic decision making, particularly when making cross-border investments in targeted markets for which private information may not be readily available.
|keyword = Domain-specific sentiment analysis,business relation mining,statistical learning,evolutionary learning,business intelligence,Web 2.0,mergers and acquisitions,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''NETWORK-BASED MODELING AND ANALYSIS OF SYSTEMIC RISK IN BANKING SYSTEMS'''
{{header}}
{{article
|author= Daning Hu,J. Leon Zhao,Zhimin Hua,Michael C. S. Wong,
|source= MIS QUARTERLY
|year= 2012
|abstract = In the wake of the 2008 financial tsunami, existing methods and tools for managing financial risk have been criticized for weaknesses in monitoring and alleviating risks at the systemic level. A 2009 article in Nature suggested new approaches to modeling economic meltdowns are needed to prevent future financial crises. However, existing studies have not focused on analysis of systemic risk at the individual bank level in a banking network, which is essential for monitoring and mitigating contagious bank failures. To this end, we develop a network approach to risk management (NARM) for modeling and analyzing systemic risk in banking systems. NARM views banks as a network linked through financial relationships. It incorporates network and financial principles into a business intelligence (BI) algorithm to analyze systemic risk attributed to each individual bank via simulations based on real-world data from the Federal Deposit Insurance Corporation. Our research demonstrates the feasibility of modeling and analyzing systemic risk at the individual bank level in a banking network using a BI-based approach. In terms of business impact, NARM offers a new means for predicting contagious bank failures and determining capital injection priorities in the wake of financial crises. Our simulation study shows that under significant market shocks, the interbank payment relationship becomes more influential than the correlated bank portfolio relationship in determining an individual bank's survival. These insights should help financial regulators devise more effective policies and mechanisms to prevent the collapse of a banking system. Further, NARM and the simulation procedure driven by real-world data proposed in this study have instructional value to similar research areas such as bank stress testing, where time series data and business networks may be studied.
|keyword = Systemic risk,contagious bank failures,business intelligence,simulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''METAFRAUD: A META-LEARNING FRAMEWORK FOR DETECTING FINANCIAL FRAUD'''
{{header}}
{{article
|author= Ahmed Abbasi,Conan Albrecht,Anthony Vance,James Hansen,
|source= MIS QUARTERLY
|year= 2012
|abstract = Financial fraud can have serious ramifications for the long-term sustainability of an organization, as well as adverse effects on its employees and investors, and on the economy as a whole. Several of the largest bankruptcies in U.S. history involved firms that engaged in major fraud. Accordingly, there has been considerable emphasis on the development of automated approaches for detecting financial fraud. However, most methods have yielded performance results that are less than ideal. In consequence, financial fraud detection continues as an important challenge for business intelligence technologies. In light of the need for more robust identification methods, we use a design science approach to develop MetaFraud, a novel meta-learning framework for enhanced financial fraud detection. To evaluate the proposed framework, a series of experiments are conducted on a test bed encompassing thousands of legitimate and fraudulent firms. The results reveal that each component of the framework significantly contributes to its overall effectiveness. Additional experiments demonstrate the effectiveness of the meta-learning framework over state-of-the-art financial fraud detection methods. Moreover, the MetaFraud framework generates confidence scores associated with each prediction that can facilitate unprecedented financial fraud detection performance and serve as a useful decision-making aid The results have important implications for several stakeholder groups, including compliance officers, investors, audit firms, and regulators.
|keyword = Fraud detection,financial statement fraud,feature construction,meta-learning,business intelligence,design science,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A HIDDEN MARKOV MODEL FOR COLLABORATIVE FILTERING'''
{{header}}
{{article
|author= Nachiketa Sahoo,Param Vir Singh,Tridas Mukhopadhyay,
|source= MIS QUARTERLY
|year= 2012
|abstract = In this paper, we present a method to make personalized recommendations when user preferences change over time. Most of the works in the recommender systems literature have been developed under the assumption that user preference has a static pattern. However, this is a strong assumption especially when the user is observed over a long period of time. With the help of a data set on employees' blog reading behavior, we show that users' product selection behaviors change overtime. We propose a hidden Markov model to correctly interpret the users' product selection behaviors and make personalized recommendations. The user preference is modeled as a hidden Markov sequence. A variable number of product selections of different types by each user in each time period requires a novel observation model. We propose a negative binomial mixture of multinomial to model such observations. This allows us to identify stable global preferences of users and to track individual users through these preferences. We evaluate our model using three real-world data sets with different characteristics. They include data on employee blog reading behavior inside a firm, users' movie rating behavior at Netflix, and users' music listening behavior collected through last.fm. We compare the recommendation performance of the proposed model with that of a number of a filtering algorithms and a recently proposed temporal link prediction algorithm. We find that the proposed HMM-based collaborative filter performs as well as the best among the alternative algorithms when the data is sparse or static. However, it outperforms the existing algorithms when the data is less sparse and the user preference is changing. We further examine the performances of the algorithms using simulated data with different characteristics and highlight the scenarios where it is beneficial to use a dynamic model to generate product recommendation.
|keyword = Recommender systems,collaborative filtering,changing preference,dynamic models,latent class model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Network Positions and Contributions to Online Public Goods: The Case of Chinese Wikipedia'''
{{header}}
{{article
|author= Xiaoquan (Michael) Zhang,Chong (Alex) Wang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = We study the effect of collaboration network structure on the contribution behavior of participating editors in Wikipedia. Collaboration in Wikipedia is organized around articles, and any two editors co-editing an article have a collaborative relationship. Based on the economic theories about network games and social role theory, we propose that an editor's position in the collaboration network influences the editor's decisions about her total contribution as well as the allocation of her efforts. By leveraging panel data collected from the Chinese language version of Wikipedia and a natural experiment resulting from blocking it in mainland China, we find strong support for the proposed effect of network position on contribution behavior. Our analysis further reveals that different aspects of an individual's network position have distinct implications. This research enhances our understanding about how collaboration network structure shapes individual behavior in online mass collaboration platforms.
|keyword = effort allocation,mass collaboration,natural experiment,network centrality,online public goods,Wikipedia,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Content Contribution for Revenue Sharing and Reputation in Social Media: A Dynamic Structural Model'''
{{header}}
{{article
|author= Qian Tang,Bin Gu,Andrew B. Whinston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = This study examines the incentives for content contribution in social media. We propose that exposure and reputation are the major incentives for contributors. Besides, as more and more social media Web sites offer advertising-revenue sharing with some of their contributors, shared revenue provides an extra incentive for contributors who have joined revenue-sharing programs. We develop a dynamic structural model to identify a contributor's underlying utility function from observed contribution behavior. We recognize the dynamic nature of the content-contribution decision-that contributors are forward-looking, anticipating how their decisions affect future rewards. Using data collected from YouTube, we show that content contribution is driven by a contributor's desire for exposure, revenue sharing, and reputation and that the contributor makes decisions dynamically.
|keyword = content contribution,contribution motivation,dynamic structural model,reputation,revenue sharing,social media,YouTube,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Hacker Behavior, Network Effects, and the Security Software Market'''
{{header}}
{{article
|author= Debabrata Dey,Atanu Lahiri,Guoying Zhang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = The market for security software has witnessed an unprecedented growth in recent years. A closer examination of this market reveals certain idiosyncrasies that are not observed in a traditional market. For example, it is a highly competitive market with over 80 vendors. Yet the market coverage is relatively low. Prior research has not attempted to explain what makes this market so different. In this paper, we develop an economic model to find possible answers to this question. Our model uses existing classification of different types of attacks and models their resulting network effects. We find that the negative network effect from indirect attacks, which is further enhanced by value-based targeted attacks, provides a possible explanation for the unique structure of this market. Overall, our results highlight the unique nature of the security software market, furnish rigorous arguments for several counterintuitive observations in the real world, and provide managerial insights for vendors on market competition.
|keyword = market structure,mass attacks,negative network effect,network effect,oligopoly,pricing,security software,strategic hacker,targeted attacks,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Co-opetition Between Differentiated Platforms in Two-Sided Markets'''
{{header}}
{{article
|author= Ravi Mantena,Rajib L. Saha,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Technology is an important factor underlying the value propositions of intermediary platforms in two-sided markets. Here, we address two key questions related to the effect of technology in platform markets. First, how does technology asymmetry affect competition between platforms? Second, how does it affect the incentives for platforms to collaborate? Using a game-theoretic model of a two-sided market where technology strongly influences network value, we show that small asymmetries in platform technologies can translate into large differences in their profitability. We find that technology improvements by the inferior platform do not significantly increase its profits, but can reduce opportunities for fruitful cooperation, since collaboration is less likely in markets with closely matched competitors. We also show that collaboration is most profitable when it takes the form of direct network interconnection. Interestingly, collaboration may provide incentives for a dominant platform to accommodate entry, where it would not otherwise do so.
|keyword = competitive strategy,co-opetition,game theory,network sharing,platform interconnections,technology platforms,two-sided markets,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Theory and Analysis of Company-Sponsored Value Co-Creation'''
{{header}}
{{article
|author= Li Chen,James R. Marsden,Zhongju Zhang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = In today's dynamic business environment, companies are under tremendous pressure to become more innovative and maintain a steady stream of ideas that can lead to new and improved products and services. Companies have begun to explore the possibility of capturing consumers' "collective intelligence" by establishing firm-sponsored online brainstorming sites where individuals can share their ideas and offer comments on the ideas contributed by others. We term these sites "Company-Sponsored Online Co-Creation Brainstorming" (COCB). The value of this open and voluntary co-creation depends largely on members' contribution levels, the quality of the contributions, and sustained participation. In this paper, utilizing Zwass's taxonomy of co-creation value as a base, we structure a taxonomic framework of COCBs and an accompanying basic model of COCBs. We then present a series of hypotheses concerning the relationships between the model's various factors and specific COCB activities. We validate the model using empirical data collected over two and a half years, starting from the initiation of a pioneering company-sponsored online brainstorming site. Our analyses demonstrate that the level of peer feedback and the responsiveness (speed) of sponsor company feedback have significant influences on both members' contribution levels and duration of active participation. The sponsoring company's feedback, however, seems to influence only the quality of member's contribution level. On the practical side, the outcomes suggest that sponsoring companies should develop efficient processes for reviewing and responding to submitted ideas. Regarding theory, our findings provide an initial piece of contextualized research that offers implications for theory building in the COCB context, most notably the identification of key relationships between feedback (both peer and company) and participant activity levels and duration of participation.
|keyword = brainstorming,co-creation,contribution quality,sustained participation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Data-Driven Approach to Measure Web Site Navigability'''
{{header}}
{{article
|author= Xiao Fang,Paul Jen-Hwa Hu,Michael Chau,Han-fen Hu,Zhuo Yang,Olivia R. Liu Sheng,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Web site navigability refers to the degree to which a visitor can follow a Web site's hyperlink structure to successfully find information with efficiency and ease. In this study, we take a data-driven approach to measure Web site navigability using Web data readily available in organizations. Guided by information foraging and information-processing theories, we identify fundamental navigability dimensions that should be emphasized in metric development. Accordingly, we propose three data-driven metrics-namely, power, efficiency, and directness-that consider Web structure, usage, and content data to measure a Web site's navigability. We also develop a Web mining-based method that processes Web data to enable the calculation of the proposed metrics. We further implement a prototype system based on the Web mining-based method and use it to assess the navigability of two sizable, real-world Web sites with the metrics. To examine the analysis results by the metrics, we perform an evaluation study that involves these two sites and 248 voluntary participants. The evaluation results show that user performance and assessments are consistent with the analysis results revealed by our metrics. Our study demonstrates the viability and practical value of data-driven metrics for measuring Web site navigability, which can be used for evaluative, diagnostic, or predictive purposes.
|keyword = data-driven navigability metrics,Web metrics,Web mining,Web site navigability,Web site navigation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Hybrid Relational-Contractual Governance for Business Process Outsourcing'''
{{header}}
{{article
|author= Arun Rai,Mark Keil,Rob Hornyak,Kim Wuellenweber,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = We examined 335 business process outsourcing (BPO) ventures to understand the effect of contractual and relational governance factors on BPO satisfaction from the client's perspective. While both contractual and relational factors explain significant variance in BPO satisfaction, relational factors dominate. By examining interactions between key contractual and relational mechanisms, we found that elements of the two governance approaches operate as substitutes with respect to BPO satisfaction. Specifically, the relational mechanism, trust, was found to substitute for contractually specified activity expectations, goal expectations, and contractual flexibility. Similarly, the relational mechanism, information exchange, was found to substitute for contractually specified activity expectations and goal expectations. Finally, the relational mechanism, conflict resolution, was found to substitute for contractually specified goal expectations. Our results can be applied to more effectively realize controls in outsourcing contexts and to design governance systems that integrate contractual and relational governance mechanisms based on the characteristics of client-vendor relationships.
|keyword = business process outsourcing,controls,formal contract,hybrid governance,relational governance,services,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Dual Role of IT-Assisted Communication in Patient Care: A Validated Structure-Process-Outcome Framework'''
{{header}}
{{article
|author= Corey M. Angst,Sarv Devaraj,John D'Arcy,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Despite the fact that about 90 percent of information transactions in hospitals are communications between patients, doctors, nurses, and other staff, little research has addressed the role that information technology (IT) plays in improving the efficiency and effectiveness of these communications-based transactions. Addressing this research gap is important considering that a substantial number of adverse hospital events stem from communication failures. Furthermore, effective communication is a major driver of patient satisfaction in hospitals. Using a structure-process-outcome (SPO) framework and guided by the strategic role of IT literature, we develop a model that includes "structure," operationalized as organizational characteristics and two different categories of IT; " process," two different communication-based processes; and " outcomes," quantified as case-mix adjusted mortality, patient loyalty, and patient ratings. Specifically, we hypothesize that a subset of clinical IT (cardiology IT) will affect technical protocols of patient care, which in turn affects mortality, while administrative IT will affect interpersonal patient care, which relates to patient loyalty and ratings. Thus, IT can serve as a double-edged sword affecting both technical and interpersonal processes of care, but possibly independently and differentially. We test our hypotheses on 2,179 hospitals using data collected and matched from three different sources. Our findings suggest that different types of IT differentially affect hospital processes and these same processes influence performance metrics such as mortality and patient satisfaction. For example, cardiology IT has a greater effect on objective patient health status through improvements in the technical protocols of care. Surprisingly, administrative IT was shown to adversely affect interpersonal care processes. It could be true that the IT is intrusive and interferes in the doctor-patient relationship; however, a post hoc analysis suggests the possibility of curvilinear impacts. Thus, managers should recognize that over- and underinvestment in IT can potentially have negative effects on performance and these results vary by IT type. Both technical and interpersonal processes yielded significant relationships to their respective outcomes and some cross-outcome effects were found, further suggesting that the mediating role of processes is an important link between IT and value.
|keyword = business value of IT,health information technology,operational IT,strategic IT,structure-process-outcome,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding Contingencies Associated with the Early Adoption of Customer-Facing Web Portals'''
{{header}}
{{article
|author= Aaron Baird,Michael F. Furukawa,T. S. Raghu,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Web-based portals extend many convenient and collaborative capabilities to consumers and are being adopted by small firms with ever greater frequency, especially in the context of health care. The early adoption of patient portals by ambulatory-care clinics (outpatient health providers) presents a unique opportunity to more fully understand the characteristics of supply-side adopters in a context where firms (ambulatory-care clinics) are extending digital services to consumers (patients). Using diffusion of innovations literature and contingency theory as the theoretical base, we expand upon the firm characteristics traditionally considered to be predictors of adoption (e.g., firm size, slack resources, competition, capabilities, and management support) and examine how demand contingencies, service contingencies, and learning externality contingencies affect patient portal adoption by ambulatory-care clinics in the United States. We find that early adopters often have a structure in place that provides support for innovations (e.g., part of integrated delivery systems), as would be predicted by diffusion of innovation theory. We also find, though, that service contingencies associated with continuity of care, learning externality contingencies associated with local influences, and select demand contingencies associated with the local market significantly influence patient portal adoption decisions. Our findings suggest that the adoption and diffusion of patient portals may be affected by more than traditionally considered "dominant" firm characteristics and provide insights into how such customer-facing systems may be affected by contingent factors.
|keyword = adoption of innovations,bivariate probit with sample selection,demand contingencies,factors of adoption,learning externality contingencies,patient portals,service contingencies,Web portals,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Resource Structuring or Capability Building? An Empirical Study of the Business Value of Information Technology'''
{{header}}
{{article
|author= Nianxin Wang,Huigang Liang,Weijun Zhong,Yajiong Xue,Jinghua Xiao,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = This paper examines two ways to create business value of information technology (BVIT): resource structuring and capability building. We develop a research model positing that IT resources and IT capabilities enhance a firm's performance by providing support to its competitive strategies and core competencies, and the strengths of these supports vary in accord with environmental dynamism. The model is empirically tested using data collected from 296 firms in China. It is found that IT resources generate more business effects in stable environments than in dynamic environments, while IT capabilities generate more business effects in dynamic environments than in stable environments. The results suggest that the BVIT creation mechanism in stable environments is primarily resource structuring while the mechanism in dynamic environments is primarily capability building.
|keyword = business value of IT,capability building,competitive strategy,core competence,environmental dynamism,resource structuring,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Productivity of Information Technology Investments: New Evidence from IT Labor Data'''
{{header}}
{{article
|author= Prasanna Tambe,Lorin M. Hitt,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = This paper uses newly collected panel data that allow for significant improvements in the measurement and modeling of information technology (IT) productivity to address some longstanding empirical limitations in the IT business value literature. First, we show that using generalized method of moments-based estimators to account for the endogeneity of IT spending produces coefficient estimates that are only about 10% lower than unadjusted estimates, suggesting that the effects of endogeneity on IT productivity estimates may be relatively small. Second, analysis of the expanded panel suggests that (a) IT returns are substantially lower in midsize firms than in Fortune 500 firms; (b) they materialize more slowly in large firms-in midsize firms, unlike in larger firms, the short-run contribution of IT to output is similar to the long-run output contribution; and (c) the measured marginal product of IT spending is higher from 2000 to 2006 than in any previous period, suggesting that firms, and especially large firms, have been continuing to develop new, valuable IT-enabled business process innovations. Furthermore, we show that the productivity of TT investments is higher in manufacturing sectors and that our productivity results are robust to controls for IT labor quality and outsourcing levels.
|keyword = business value of IT,economics of IS,econometrics,productivity,IT labor,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Empirical Analysis of the Contractual and Information Structures of Business Process Outsourcing Relationships'''
{{header}}
{{article
|author= Deepa Mani,Anitesh Barua,Andrew B. Whinston,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The emergence of information-intensive business process outsourcing (BPO) relationships calls for the study of exchange performance beyond traditional considerations of the contractual structure that facilitates cooperative intent to include the information structure that facilitates the mutual exchange of information to enact cooperative intent and coordinate actions between the user firm and the service provider. Yet, there has been little analysis of the drivers and performance effects of the information structure of BPO relationships, including its linkages to the underlying contractual structure. This study integrates perspectives in neo-institutional economics and information processing to develop and test the theoretical argument that the extent of use and performance effects of the information structure of the BPO relationship are greater in time and materials BPO contracts than in fixed-price BPO contracts. Survey data on 134 BPO relationships provide empirical support for our hypotheses. The synergistic impact of incentives and information on BPO performance emphasizes that their joint assessment is necessary to enhance the explanatory power of extant theories of organization. This result also has implications for achieving maximum benefits from complex BPO arrangements that are more likely to be characterized by time and material contracts.
|keyword = BPO,outsourcing,governance,contractual structure,information structure,coordination,information processing,performance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Postrelease Testing and Software Release Policy for Enterprise-Level Systems'''
{{header}}
{{article
|author= Zhengrui Jiang,Sumit Sarkar,Varghese S. Jacob,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = prior work on software release policy implicitly assumes that testing stops at the time of software release. In this research, we propose an alternative release policy for custom-built enterprise-level software projects that allows testing to continue for an additional period after the software product is released. Our analytical results show that the software release policy with postrelease testing has several important advantages over the policy without postrelease testing. First, the total expected cost is lower. Second, even though the optimal time to release the software is shortened, the reliability of the software is improved throughout its lifecycle. Third, although the expected number of undetected bugs is higher at the time of release, the expected number of software failures in the field is reduced. We also analyze the impact of market uncertainty on the release policy and find that all our prior findings remain valid. Finally, we examine a comprehensive scenario where in addition to uncertain market opportunity cost, testing resources allocated to the focal project can change before the end of testing. Interestingly, the software should be released earlier when testing resources are to be reduced after release.
|keyword = software reliability,market opportunity cost,market uncertainty,learning,Bayes risk principle,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Effects of Social Network Structure on Enterprise Systems Success: A Longitudinal Multilevel Analysis'''
{{header}}
{{article
|author= Sharath Sasidharan,Radhika Santhanam,Daniel J. Brass,Vallabh Sambamurthy,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The implementation of enterprise systems has yielded mixed and unpredictable outcomes in organizations. Although the focus of prior research has been on training and individual self-efficacy as important enablers, we examine the roles that the social network structures of employees, and the organizational units where they work, play in influencing the postimplementation success. Data were gathered across several units within. a large organization: immediately after the implementation, six months after the implementation, and one year after the implementation. Social network analysis was used to understand the effects of network structures, and hierarchical linear modeling was used to capture the multilevel effects at unit and individual levels. At the unit level of analysis, we found that centralized structures inhibit implementation success. At the individual level of analysis, employees with high in-degree and betweenness centrality reported high task impact and information quality. We also found a cross-level effect such that central employees in centralized units reported implementation success. This suggests that individual-level success can occur even within a unit structure that is detrimental to unit-level success. Our research has significant implications for the implementation of enterprise systems in large organizations.
|keyword = enterprise systems,postimplementation,information exchange,learning,social networks,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''What's in a "Name"? Impact of Use of Customer Information in E-Mail Advertisements'''
{{header}}
{{article
|author= Sunil Wattal,Rahul Telang,Tridas Mukhopadhyay,Peter Boatwright,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = In this study, we examine how consumers respond to firms' use of two types of information for personalization: product preferences and name. We collect a unique data set of over 10 million e-mail advertisements sent by a website to over 600,000 customers who could buy the advertised products from the online merchant. We estimate a two-stage hierarchical model using Bayesian analysis to account for observable and unobservable consumer heterogeneity. Our analysis suggests several interesting results regarding consumers' responses to firms' use of information. When firms use product-based personalization (where the use of information is not explicitly mentioned), consumers respond positively. On the other hand, consumers respond negatively when firms are explicit in their use of personally identifiable information (i.e., a personalized greeting). We also find that negative responses to personalized greetings are moderated by consumers' familiarity with firms. The main contribution of this study is that it not only indicates the economic benefits of personalization in e-mails but also highlights consumers' concerns over the use of information in personalization.
|keyword = personalization,privacy,information use,hierarchical Bayesian model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''From Business Intelligence to Competitive Intelligence: Inferring Competitive Measures Using Augmented Site-Centric Data'''
{{header}}
{{article
|author= Zhiqiang (Eric) Zheng,Peter Fader,Balaji Padmanabhan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Managers routinely seek to understand firm performance relative to the competitors. Recently, competitive intelligence (CI) has emerged as an important area within business intelligence (BI) where the emphasis is on understanding and measuring a firm's external competitive environment. A requirement of such systems is the availability of the rich data about a firm's competitors, which is typically hard to acquire. This paper proposes a method to incorporate competitive intelligence in BI systems by using less granular and aggregate data, which is usually easier to acquire. We motivate, develop, and validate an approach to infer key competitive Measures about customer activities without requiring detailed cross-firm data. Instead, our method derives these competitive measures for online firms from simple "site-centric" data that are commonly available, augmented with aggregate data summaries that may be obtained from syndicated data providers. Based on data provided by comScore Networks, we show empirically that our method performs well in inferring several key diagnostic competitive measures-the penetration, market share, and the share of wallet-for various online retailers.
|keyword = business intelligence,competitive intelligence,competitive measures,probability models,NBD/Dirichlet,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Does the Web Reduce Customer Service Cost? Empirical Evidence from a Call Center'''
{{header}}
{{article
|author= Anuj Kumar,Rahul Telang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Firms are investing millions to deploy Web-based self-services at their call centers. The rationale for such investment is that the firm's cost of interacting with its customers through the Web-based channel is an order of magnitude cheaper than the assisted channels such as telephony. We conduct a field study at the call center of a prominent U.S. health insurance firm to examine this cost-saving rationale of the Web-based self-service channel. On the one hand, the Web channel may substitute for the telephony channel in some cases. On the other hand, the Web also exposes customers to a vast amount of information about their health policy, claims, and coverage; this information can create uncertainty leading to customers seeking more information and hence making more telephone calls. We designed a quasi-natural experiment in our field setting and used difference-in-difference specifications to show that the Web-based self-service usage leads to a 14% increase in telephone calls. We conduct several robustness checks to show that our specifications are robust to any potential selection of customers in the Web-based self-service usage. We further find that the impact of Web portal usage is moderated by the Web portal characteristics. We find that if the information is unambiguous and easily retrievable on the Web, calls for such information decline by 29%. However, for ambiguous information, the calls increase substantially. Our research provides insights into the challenges and opportunities of self-service technologies design.
|keyword = self-service,call center,customer support,Web portal,multichannel service management,health insurance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Electronic Health Records Assimilation and Physician Identity Evolution: An Identity Theory Perspective'''
{{header}}
{{article
|author= Abhay Nath Mishra,Catherine Anderson,Corey M. Angst,Ritu Agarwal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = With the lack of timely and relevant patient information at the point of care increasingly being linked to adverse medical outcomes, effective management and exchange of patient data has emerged as a strategic imperative for the healthcare industry. Healthcare informaticians have suggested that electronic health record systems (EHRS) can facilitate information sharing within and between healthcare stakeholders such as physician practices, hospitals, insurance companies, and laboratories. We examine the assimilation of EHRS in physician practices through a novel and understudied theoretical lens of physicians' identities. Physician practices and the physicians that lead them occupy a central position in the healthcare value chain and possess a number of unique characteristics that differentiate them from other institutional contexts, including a strong sense of affiliation with other physicians, potent professional identities, and a desire for autonomy. We investigate two salient physician identities, those of careprovider and physician community, grounded in the roles physicians play and the groups with which they affiliate. We argue that these identities and their evolution, triggered by EHRS, manifest as both identity reinforcement and deterioration, and are important drivers of EHRS assimilation. We use survey data from 206 physician practices, spread across the United States, to test our theoretical model. Results suggest that physician community identity reinforcement and physician community identity deterioration directly influence the assimilation of EHRS. We further find that the effects of careprovider identity reinforcement and careprovider identity deterioration on EHRS assimilation are moderated by governmental influence. Theoretical and pragmatic implications of the findings are discussed.
|keyword = assimilation,careprovider identity,EHR,electronic health records,health informatics,health IT,identity deterioration,identity reinforcement,identity theory,physician community identity,physician practices,professional identity,role identity,self-categorization theory,social identity,social identity theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Design Principles of Integrated Information Platform for Emergency Responses: The Case of 2008 Beijing Olympic Games'''
{{header}}
{{article
|author= Lili Yang,Guofeng Su,Hongyong Yuan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = This paper investigates the challenges faced in designing an integrated information platform for emergency response management and uses the Beijing Olympic Games as a case study. The research methods are grounded in action research, participatory design, and situation-awareness oriented design. The completion of a more than two-year industrial secondment and six-month field studies ensured that a full understanding of user requirements had been obtained. A service-centered architecture was proposed to satisfy these user requirements. The proposed architecture consists mainly of information gathering, database management, and decision support services. The decision support services include situational overview, instant risk assessment, emergency response preplan, and disaster development prediction. Abstracting from the experience obtained while building this system, we outline a set of design principles in the general domain of information systems (IS) development for emergency management. These design principles form a contribution to the information systems literature because they provide guidance to developers who are aiming to support emergency response and the development of such systems that have not yet been adequately met by any existing types of IS. We are proud that the information platform developed was deployed in the real world and used in the 2008 Beijing Olympic Games.
|keyword = emergency response,fire safety,Olympic games,situation-awareness oriented design,participatory design,action research,integrated information platform,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''In Search of Efficient Flexibility: Effects of Software Component Granularity on Development Effort, Defects, and Customization Effort'''
{{header}}
{{article
|author= Ramanath Subramanyam,Narayan Ramasubbu,M. S. Krishnan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Simultaneously achieving efficiency and flexibility in enterprise software production has been a considerable challenge for firms. Newer software development paradigms such as component-based and model-driven development attempt to overcome this challenge by emphasizing modular design of complex systems. However, there is a paucity of rigorous empirical research on the use of such software methodologies and the associated extent to which trade-offs between efficiency and flexibility can be influenced. Addressing this gap, we investigate the performance outcomes of a model-driven, component-based software development methodology using data collected from an enterprise software development firm that deployed such a methodology for its product development processes. Examining the design, development, and implementation of 92 business software components of the firm's enterprise resource planning product, we discuss how the design of software components, specifically component granularity, affects development efficiency (development effort and defects) and flexibility (customization effort). Our results suggest that (a) components that are coarse grained are associated with higher flexibility (lower customization effort) but are also associated with lower development efficiency (more development effort and defects), and (b) defect proneness of a component plays a mediating role on the relationship between component granularity and flexibility. These findings present strong evidence for the existence of trade-offs between efficiency and flexibility in mass-customized software product life cycles. They establish component granularity as a key design dimension that needs to be managed judiciously to enable potential trade-off shifting mechanisms through the use of software methodologies that emphasize modular design approaches.
|keyword = modular design,model-driven development,component-based software development,efficiency,flexibility,complexity,component granularity,software engineering,project performance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Pricing Models for Online Advertising: CPM vs. CPC'''
{{header}}
{{article
|author= Kursad Asdemir,Nanda Kumar,Varghese S. Jacob,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Online advertising has transformed the advertising industry with its measurability and accountability. Online software and services supported by online advertising is becoming a reality as evidenced by the success of Google and its initiatives. Therefore, the choice of a pricing model for advertising becomes a critical issue for these firms. We present a formal model of pricing models in online advertising using the principal-agent framework to study the two most popular pricing models: input-based cost per thousand impressions (CPM) and performance-based cost per click-through (CPC). We identify four important factors that affect the preference of CPM to the CPC model, and vice versa. In particular, we highlight the interplay between uncertainty in the decision environment, value of advertising, cost of mistargeting advertisements, and alignment of incentives. These factors shed light on the preferred online-advertising pricing model for publishers and advertisers under different market conditions.
|keyword = online advertising,cost per impression (CPM),cost per click (CPC),pricing models,asymmetric information,delegation,principal agent model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Computational Analysis of Bundle Trading Markets Design for Distributed Resource Allocation'''
{{header}}
{{article
|author= Zhiling Guo,Gary J. Koehler,Andrew B. Whinston,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Online auction markets play increasingly important roles for resource allocations in distributed systems. This paper builds upon a market-based framework presented by Guo et al. (Guo, Z., G. J. Koehler, A. B. Whinston. 2007. A market-based optimization algorithm for distributed systems. Management Sci. 53(8) 1345-1458), where a distributed system optimization problem is solved by self-interested agents iteratively trading bundled resources in a double auction market run by a dealer. We extend this approach to a dynamic, asynchronous Internet market environment and investigate how various market design factors including dealer inventory policies, market communication patterns, and agent learning strategies affect the computational market efficiency, market liquidity, and implementation. We prove finite convergence to an optimal solution under these various schemes, where individual rational and budget-balanced trading leads to an efficient auction outcome. Empirical investigations further show that the algorithmic implementation is robust to a number of dealer and agent manipulations and scalable to larger sizes and more complicated bundle trading markets. Interestingly, we find that, though both asynchronous communication and asymmetric market information negatively affect the speed of market convergence and lead to more agent welfare loss, agents' ability to predict market prices has a positive effect on both. Contrary to conventional wisdom that a dealer's intertemporal liquidity provisions improve market performance, we find that the dealer's active market intervention may not be desirable in a simple market trading environment where an inherent market liquidity effect dominates, especially when the dealer owns a significant amount of resources. Different from the traditional market insight, our trading data suggest that high trading volume does not correlate to low price volatility and quicker price discovery.
|keyword = electronic markets and auctions,electronic commerce,resource allocation,computational experiment,simulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information, Technology, and Information Worker Productivity'''
{{header}}
{{article
|author= Sinan Aral,Erik Brynjolfsson,Marshall Van Alstyne,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = We econometrically evaluate information worker productivity at a midsize executive recruiting firm and assess whether the knowledge that workers accessed through their electronic communication networks enabled them to multitask more productively. We estimate dynamic panel data models of multitasking, knowledge networks, and productivity using several types of micro-level data: (a) direct observation of more than 125,000 email messages over a period of 10 months; (b) detailed accounting data on individuals' project output and team membership for more than 1,300 projects spanning five years; and (c) survey and interview data about the same workers' IT skills, IT use, and information sharing. We find that (1) more multitasking is associated with more project output, but diminishing marginal returns, and (2) recruiters whose network contacts have heterogeneous knowledge an even distribution of expertise over many project types are less productive on average but more productive when juggling diverse multitasking portfolios. These results show how multitasking affects productivity and how knowledge networks, enabled by IT, can improve worker performance. The methods developed can be replicated in other settings, opening new frontiers for research on social networks and IT value.
|keyword = social networks,productivity,information worker,IT,multitasking,dynamic panel data,system GMM,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of IT-Related Spillovers on Long-Run Productivity: An Empirical Analysis'''
{{header}}
{{article
|author= Young Bong Chang,Vijay Gurbaxani,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = This paper examines the effects of IT-related spillovers on firm-level productivity improvements over a long-term horizon. In contrast, prior research has largely focused on the direct and contemporaneous impacts of IT investments. As a result, we do not fully understand how IT investments are associated with ongoing productivity improvements in future periods and how spillovers influence these gains. In this paper, we examine whether firms receive incremental benefits from IT-related spillovers and whether these spillovers lead to more persistent returns. We focus on the spillovers that accrue to firms from their interindustry transactions, especially the IT services industry. We model and estimate the impact of spillovers on long-run productivity using firm-level data from the manufacturing, transportation, trade, and services sectors. We find that spillover impacts are highly significant, but that the magnitude and persistence of the impacts vary. Firms with high IT intensity receive greater spillover benefits from the IT services industry. Moreover, these benefits are sustained over a long-term horizon. However, the impact of IT-related spillovers does not persist in low IT intensity firms regardless of the source. Overall, our results shed light on the existence and sources of IT-related spillovers and on their important role in shaping the long-run returns to IT investment. Our results also help explain the findings of excess returns to IT investment in the IT productivity literature.
|keyword = long-run productivity,business value of IT,economics of IS,spillovers,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Learning Curve of IT Knowledge Workers in a Computing Call Center'''
{{header}}
{{article
|author= Youngsoo Kim,Ramayya Krishnan,Linda Argote,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = We analyze learning and knowledge transfer in a computing call center. The information technology (IT) technical services provided by call centers are characterized by constant changes in relevant knowledge and a wide variety of support requests. Under this IT problem-solving context, we analyze the learning curve relationship between problem-solving experience and performance enhancement. Based on data collected from a university computing call center consisting of different types of consultants, our empirical findings indicate that (a) the learning effect-as measured by the reduction of average resolution time-occurs with experience, (b) knowledge transfer within a group occurs among lower-level consultants utilizing application-level knowledge (as opposed to technical-level knowledge), and (c) knowledge transfers across IT problem types. These estimates of learning and knowledge transfer contribute to the development of an empirically grounded understanding of IT knowledge workers' learning behavior. The results also have implications for operational decisions about the staffing and problem-solving strategy of call centers.
|keyword = computing call center,learning curves,knowledge transfer,IT problem type,knowledge classification,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Advertising Strategies in Electronic Retailing: A Differential Games Approach'''
{{header}}
{{article
|author= Dengpan Liu,Subodha Kumar,Vijay S. Mookerjee,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = We consider advertising problems under an information technology (IT) capacity constraint encountered by electronic retailers in a duopolistic setting. There is a considerable amount of literature on advertising games between firms, yet introducing an IT capacity constraint fundamentally changes this problem. In the presence of information processing constraints, although advertising may still cause a customer to switch, it may not result in a sale, i.e., the customer may be lost by both firms. This situation could occur when customers have a limited tolerance for processing delays and leave the website of a firm because of slow response. In such situations, attracting more traffic to a firm's site (by increasing advertising expenditure) may not generate enough additional revenue to warrant this expenditure. We use a differential game formulation to obtain closed-form solutions for the advertising effort over time in the presence of IT capacity constraints. Based on these solutions, we present several useful managerial insights.
|keyword = IT capacity,advertising,optimal control theory,differential game,reneging,Nash equilibrium,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Institutional Influences on Information Systems Security Innovations'''
{{header}}
{{article
|author= Carol Hsu,Jae-Nam Lee,Detmar W. Straub,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = This research investigates information security management as an administrative innovation. Although a number of institutional theories deal with information systems (IS) innovation in organizations, most of these institutional-centered frameworks overlook external economic efficiency and internal organizational capability in the presence of pressures of institutional conformity. Using Korea as the institutional setting, our research model posits that economic-based consideration will moderate the institutional conformity pressure on information security adoption while organization capability will influence the institutional confirmation of information security assimilation. The model is empirically tested using two-stage survey data from a field study of 140 organizations in Korea. The results indicate that in addition to institutional influences, our six proposed economic-based and organizational capability moderating variables all have significant influences on the degree of the adoption and assimilation of information security management. We conclude with implications for research in the area of organizational theory and the information security management literature, and for practices regarding how managers can factor into their information security planning the key implementation variables discovered in this study. The robust setting of the study in Korean firms allows us to generalize the theory to a new context and across cultures.
|keyword = administrative innovation,information security management,institutional theories,adoption and assimilation,economic,organizational,IT capability factors,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Boundaries of Trust and Risk: The Quadratic Moderating Role of Institutional Structures'''
{{header}}
{{article
|author= David Gefen,Paul A. Pavlou,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = A prevalent assumption in the literature is that trust and risk are always relevant in online marketplaces, and that there is always a need to build trust and reduce risk irrespective of context. Challenging this assumption, this study seeks to identify the boundaries of the effects of trust and risk on transaction activity in the context of institutional structures in online marketplaces. The perceived effectiveness of institutional structures (PETS), defined as the extent buyers believe that appropriate conditions are in place to facilitate transactions with sellers, sets the boundaries of trust and risk by moderating their effects on transaction activity in a quadratic (inverted-U) fashion. Specifically, at the lower boundary condition of PETS (among buyers who believe institutional structures are ineffective), the high situational uncertainty they perceive should make these buyers unwilling to become vulnerable to sellers, thus rendering trust and risk immaterial to their decision making. Trust and risk should also be immaterial at the higher boundary condition of PEIS (among buyers who believe institutional structures are very effective), because the insufficient situational uncertainty makes trust and risk irrelevant to these buyers' decision making because of a lack of vulnerability. Only between these two boundary conditions (among buyers who perceive moderate levels of PEIS), and thus a moderate degree of situational uncertainty and vulnerability in the marketplace, should trust and risk have a significant effect on transaction activity. Data from 398 buyers on eBay's and Amazon's online marketplaces support the quadratic moderating role of PETS on the effect of risk on transaction activity, but not on the effect of trust. Theoretical and practical implications on specifying the boundaries of the effects of trust and risk and understanding the direct and moderating role of institutional structures are discussed.
|keyword = online marketplaces,trust,risk,institutional structures,quadratic moderating effects,polynomial regression,response surface methodology,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Content Provision Strategies in the Presence of Content Piracy'''
{{header}}
{{article
|author= Monica Johar,Nanda Kumar,Vijay Mookeijee,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = We consider a publisher that earns advertising revenue while providing content to serve a heterogeneous population of consumers. The consumers derive benefit from consuming content but suffer from delivery delays. A publisher's content provision strategy comprises two decisions: (a) the content quality (affecting consumption benefit) and (b) the content distribution delay (affecting consumption cost). The focus here is on how a publisher should choose the content provision strategy in the presence of a content pirate such as a peer-to-peer (P2P) network. Our study sheds light on how a publisher could leverage a pirate's presence to increase profits, even though the pirate essentially encroaches on the demand for the publisher's content. We find that a publisher should sometimes decrease the delivery speed but increase quality in the presence of a pirate (a quality focused strategy). At other times, a distribution focused strategy is better; namely, increase delivery speed, but lower quality. In most cases, however, we show that the publisher should improve at least one dimension of content provision (quality or delay) in the presence of a pirate.
|keyword = content provision and distribution,delivery delay,content piracy,P2P networks,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Putting Money Where the Mouths Are: The Relation Between Venture Financing and Electronic Word-of-Mouth'''
{{header}}
{{article
|author= Rohit Aggarwal,Ram Gopal,Alok Gupta,Harpreet Singh,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = External financing is critical to ventures that do not have a revenue source but need to recruit employees, develop products, pay suppliers, and market their products/services. There is an increasing belief among entrepreneurs that electronic word-of-mouth (eWOM), specifically blog coverage, can aid in achieving venture capital financing. Conflicting findings reported by past studies examining eWOM make it unclear what to make of such beliefs of entrepreneurs. Even if there were generally agreed-upon results, a stream of literature indicates that because of the differences in traits between the prior investigated contexts and venture capital financing, the findings from the prior studies cannot be generalized to venture capital financing. Extant studies also fall short in examining the role of time and the status of entities generating eWOM in determining the influence of eWOM on decision making. To address this dearth of literature in a context that attracts billions of dollars every year, we investigate the effect of eWOM on venture capital financing. This study entails the challenging task of gathering data from hundreds of ventures along with other sources including VentureXpert, surveys, Google Blogsearch, Lexis-Nexis, and Archive.org. The key findings of our econometric analysis are that the impact of negative eWOM is greater than is the impact of positive eWOM and that the effect of eWOM on financing decreases with the progress through the financing stages. We also find that the eWOM of popular bloggers helps ventures in getting higher funding amounts and valuations. The empirical model used in this work accounts for inherent selection biases of entrepreneurs and venture capitalists, and we conduct numerous robustness checks for potential issues of endo-geneity, selection bias, nonlinearities, and popularity cutoff for blogs. The findings have important implications for entrepreneurs and suggest ways by which entrepreneurs can take advantage of eWOM.
|keyword = electronic word-of-mouth,blogs,venture funding,VC funding,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Cross-Purposes of Cross-Posting: Boundary Reshaping Behavior in Online Discussion Communities'''
{{header}}
{{article
|author= Brian S. Butler,Xiaoqing Wang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Increasingly, online discussion communities are used to support activities ranging from software development to political campaigns. An important feature of an online discussion community is its content boundaries, which are individual perceptions of what materials and discussions are part of the community and what are not, and how that community is related to others within a larger system. Yet in spite of its importance, many community infrastructures allow individual participants to reshape content boundaries by simultaneously associating their contributions with multiple online discussion communities. This reshaping behavior is a controversial aspect of the creation and management of many types of online discussion communities. On one hand, many communities explicitly discourage boundary reshaping behaviors in their frequently asked questions or terms-of-use document. On the other hand, community infrastructures continue to allow such reshaping behaviors. To explain this controversy, we theorize how the extent of boundary reshaping in an online discussion community has simultaneously positive and negative effects on its member dynamics and responsiveness. We test predictions about the conflicting effects of reshaping behaviors with 60 months of longitudinal data from 140 USENET newsgroups, focusing on cross-posting activities as a form of reshaping behavior. Empirical results are consistent with the proposed hypotheses that reshaping behaviors within a discussion community affect member dynamics and community responsiveness in both positive and negative ways. Taken together, the findings highlight the boundary-related design challenges faced by managers seeking to support ongoing activity within online discussion communities.
|keyword = online communities,virtual communities,boundaries,social computing,design,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Using Real Options to Investigate the Market Value of Virtual World Businesses'''
{{header}}
{{article
|author= Sung-Byung Yang,Jee-Hae Lim,Wonseok Oh,Artimesh Animesh,Alain Pinsonneault,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Virtual worlds are relatively nascent IT platforms with the potential to radically transform business processes and generate significant payoffs. However, in striving to achieve specific outcomes, firms may incur significant risks. Although many companies claim to have attained substantial benefits from their virtual world initiatives, many others have recently scaled down or even abandoned their experimental virtual world projects. This paper assesses the value proposition of virtual world initiatives from the real options perspective. Specifically, we argue that virtual worlds act as a firm's growth option, and we adopt the lens of real options to evaluate the value of this emerging and uncertain technological platform. We employ the event study method to assess the stock market's perception of the future revenue streams of 261 virtual world initiatives announced between 2006 and 2008. Our results indicate that, overall, the market reacts positively to virtual world initiatives. Our findings also show that investors' reactions to virtual world initiatives are contingent on four key characteristics of virtual world initiatives: interpretive flexibility (i.e., technologies that allow managers to experiment), divisibility (i.e., ability to incrementally implement the technology), strategic importance (i.e., an initiative that affects a process of strategic importance to the firm), and exploitable absorptive capacity (i.e., ability to exploit the knowledge acquired through the initiative). We discuss the key implications for real-world practitioners and suggest directions for future research.
|keyword = virtual world investments,value creation,real options,strategic importance,divisibility,exploitative absorptive capacity,event study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Performance-Based Advertising: Advertising as Signals of Product Quality'''
{{header}}
{{article
|author= Juan Feng,Jinhong Xie,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Performance-based advertising is becoming increasingly popular in the online advertising industry, where advertisers pay the publisher only when the advertisement generates an "action" (e.g., a click-through or a purchase). This paper illustrates that adopting this emerging advertising scheme has profound impacts on one fundamental function of advertising-signaling product quality. We identify several important dimensions that affect the signaling function of performance-based advertising relative to its traditional counterpart (impression-based advertising). These include: (1) information-total advertising expenditure is determined after the demand is realized, so it is unobservable to consumers when making purchase decisions; (2) ad performance-the measured "performance" (e.g., recorded click-throughs) includes actions generated by first-time buyers (i.e., advertising performance) and actions generated by repeat buyers (i.e., product performance), which increases the cost of signaling through advertising; (3) demand uncertainty-the merchant pays only when a response to the advertisement is generated, which reduces the merchant's advertising uncertainty. We build a model of performance-based advertising by explicitly incorporating these factors, and we derive the conditions under which switching to performance-based advertising will (a) disable or strengthen the signaling function of advertising, (b) help or hurt the merchant, and (c) lead to a higher or lower advertising expenditure.
|keyword = performance-based pricing,advertising,signaling,sponsored search,quality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Do Electronic Linkages Reduce the Bullwhip Effect? An Empirical Analysis of the US Manufacturing Supply Chains'''
{{header}}
{{article
|author= Yuliang Yao,Kevin Xiaoguo Zhu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The bullwhip effect is a major source of supply chain inefficiency. Whereas prior literature has identified a number of potential contributing factors and recommended such remedies as information sharing enabled by information technology (IT) or electronic linkage (EL), few studies have provided empirical support. We use industry-level data to examine whether EL use with buyer and supplier industries helps reduce the bullwhip effect as measured by inventory demand variance ratio. Our major findings are that (1) EL use with supplier industries reduces the bullwhip effect, whereas (2), surprisingly, EL use with buyer industries increases it, but (3) this adverse effect tends to be mitigated by IT use. These findings point to the possible asymmetric effects of EL use in supply chains and provide a different perspective to the existing conclusions in the literature that EL use improves performance. Combining the above results, we have learned that the use of EL tends to behave differently depending on whether it is used upstream or downstream in the supply chain. This also sheds light on the conditions under which such investment may be more (or less) beneficial.
|keyword = supply chain management,bullwhip effect,information technology,electronic markets,empirical operations,econometrics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Music Blogging, Online Sampling, and the Long Tail'''
{{header}}
{{article
|author= Sanjeev Dewan,Jui Ramaprasad,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Online social media such as blogs are transforming how consumers make consumption decisions, and the music industry is at the forefront of this revolution. Based on data from a leading music blog aggregator, we analyze the relationship between music blogging and full-track sampling, drawing on theories of online social interaction. Our results suggest that intensity of music sampling is positively associated with the popularity of a blog among previous consumers and that this association is stronger in the tail than in the body of music sales distribution. At the same time, the incremental effect of music popularity on sampling is also stronger in the tail relative to the body. in the last part of the paper, we discuss the implications of our results for music sales and potential long-tailing of music sampling and sales. Put together, our analysis sheds new light on how social media are reshaping music sharing and consumption.
|keyword = blogs,social interactions,observational learning,word of mouth,long tail,music industry,social media,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Cost Impact of Spam Filters: Measuring the Effect of Information System Technologies in Organizations'''
{{header}}
{{article
|author= Marco Caliendo,Michel Clement,Dominik Papies,Sabine Scheel-Kopeinig,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Dealing with spam is very costly, and many organizations have tried to reduce spam-related costs by installing spam filters. Relying on modern econometric methods to reduce the selection bias of installing a spam filter, we use a unique data setting implemented at a German university to measure the costs associated with spam and the costs savings of spam filters. Our methodological framework accounts for effect heterogeneity and can be easily used to estimate the effect of other IS technologies implemented in organizations. The majority of costs stem from the time that employees spend identifying and deleting spam, amounting to an average of approximately five minutes per employee per day. Our analysis, which accounts for selection bias, finds that the installation of a spam filter reduces these costs by roughly one third. Failing to account for the selection bias would lead to a result that suggests that installing a spam filter does not reduce working time losses. However, cost savings only occur when the spam burden is high, indicating that spam filters do not necessarily reduce costs and are therefore no universal remedy. The analysis further shows that spam filters alone are a countermeasure against spam that exhibits only limited effectiveness because they only reduce costs by one third.
|keyword = spam,spam filter,selection bias,propensity score matching,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ON THE USE OF NEUROPHYSIOLOGICAL TOOLS IN IS RESEARCH: DEVELOPING A RESEARCH AGENDA FOR NEUROIS'''
{{header}}
{{article
|author= Angelika Dimoka,Rajiv D. Banker,Izak Benbasat,Fred D. Davis,Alan R. Dennis,David Gefen,Alok Gupta,Anja Lschebeck,Peter H. Kenning,Paul A. Pavlou,Gernot Mueller-Putz,Rene Riedl,Jan vom Brocke,Bernd Weber,
|source= MIS QUARTERLY
|year= 2012
|abstract = This article discusses the role of commonly used neurophysiological tools such as psychophysiological tools (e.g., EKG, eye tracking) and neuroimaging tools (e.g., fMRI, EEG) in Information Systems research. There is heated interest now in the social sciences in capturing presumably objective data directly from the human body, and this interest in neurophysiological tools has also been gaining momentum in IS research (termed NeuroIS). This article first reviews commonly used neurophysiological tools with regard to their major strengths and weaknesses. It then discusses several promising application areas and research questions where IS researchers can benefit from the use of neurophysiological data. The proposed research topics are presented within three thematic areas: (1) development and use of systems, (2) IS strategy and business outcomes, and (3) group work and decision support. The article concludes with recommendations on how to use neurophysiological tools in IS research along with a set of practical suggestions for developing a research agenda for NeuroIS and establishing NeuroIS as a viable subfield in the IS literature.
|keyword = NeuroIS,neuroscience,neurophysiological tools,psychophysiological tools,neuroimaging,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COMPARING PLS TO REGRESSION AND LISREL: A RESPONSE TO MARCOULIDES, CHIN, AND SAUNDERS'''
{{header}}
{{article
|author= Dale L. Goodhue,William Lewis,Ron Thompson,
|source= MIS QUARTERLY
|year= 2012
|abstract = In the Foreword to an NHS Quarterly Special Issue on PLS, the senior editors for the special issue noted that they rejected a number of papers because the authors attempted comparisons between results from PLS, multiple regression, and structural equation modeling (Marcoulides et al. 2009). They raised several issues they argued had to be taken into account to have legitimate comparison studies, supporting their position primarily by citing three authors: Dijkstra (1983), McDonald(1996), and Schneeweiss (1993). As researchers interested in conducting comparison studies, we read the Foreword carefully, but found it did not provide clear guidance on how to conduct "legitimate" comparisons. Nor did our reading of Dijksta, McDonald, and Schneeweiss raise any red flags about dangers in this kind of comparison research. We were concerned that instead of helping researchers to successfully engage in comparison research, the Foreword might end up discouraging that type of work, and might even be used incorrectly to reject legitimate comparison studies. This Issues and Opinions piece addresses the question of why one might conduct comparison studies, and gives an overview of the process of comparison research with a focus on what is required to make those comparisons legitimate. In addition, we explicitly address the issues raised by Marcoulides et al., to explore where they might (or might not) come into play when conducting or evaluating this type of study.
|keyword = Comparing statistical techniques,partial least squares,structural equation modeling,regression,Monte Carlo simulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''GENERALIZATION AND INDUCTION: MISCONCEPTIONS, CLARIFICATIONS, AND A CLASSIFICATION OF INDUCTION'''
{{header}}
{{article
|author= Eric W. K. Tsang,John N. Williams,
|source= MIS QUARTERLY
|year= 2012
|abstract = In "Generalizing Generalizability in Information Systems Research," Lee and Baskerville (2003) try to clarify generalization and classify it into four types. Unfortunately, their account is problematic. We propose repairs. Central among these is our balance-of-evidence argument that we should adopt the view that Hume's problem of induction has a solution, even if we do not know what it is. We build upon this by proposing an alternative classification of induction. There are five types of generalization: (1) theoretical, (2) within-population, (3) cross-population, (4) contextual, and (5) temporal, with theoretical generalization being across the empirical and theoretical levels and the rest within the empirical level. Our classification also includes two kinds of inductive reasoning that do not belong to the domain of generalization. We then discuss the implications of our classification for information systems research.
|keyword = Research methodology,generalization,generalizability,induction,deduction,statistical generalization,statistical syllogism,inductive analogy,Hume's problem of induction,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CONCEPTUALIZING GENERALIZABILITY: NEW CONTRIBUTIONS AND A REPLY'''
{{header}}
{{article
|author= Allen S. Lee,Richard L. Baskerville,
|source= MIS QUARTERLY
|year= 2012
|abstract = Tsang and Williams offer some good and provocative ideas in their critique of our earlier article on generalizing and generalizability. In this essay we will advance some new ideas by building on those collected in both Tsang and Williams and our original article (Lee and Baskerville 2003). Because IS is a pluralist scientific discipline, one in which both qualitative and quantitative (and both interpretive and positivist) research approaches are valued, "generalize" is unlikely to be a viable term or concept if only one IS research paradigm may lay claim to it and excludes others from using it. Both papers agree on this point, but approach the problem differently. Where we originally generalized generalizability by offering new language, Tsang and Williams conceptualize generalizability by framing it more closely to its older, more statistically oriented form. We agree about the importance of induction and about the classification or taxonomy of different types of induction. We build further in this essay, advancing the ethical questions raised by generalization: A formulation of judgment calls that need to be made when generalizing a theory to a new setting. We further demonstrate how the process of generalizing may actually proceed, based on the common ground between Tsang and Williams and our original article.
|keyword = Research approach,philosophical approach,philosophy,reference theory,type of theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE ROLES OF THEORY IN CANONICAL ACTION RESEARCH'''
{{header}}
{{article
|author= Robert M. Davison,Maris G. Martinsons,Carol X. J. Ou,
|source= MIS QUARTERLY
|year= 2012
|abstract = Canonical action research (CAR) aims to address real-world problems and improve organizational performance by combining scholarly observations with practical interventions. However, efforts to conduct CAR have revealed challenges that reflect a significant research-practice gap. We examine these challenges by revisiting the process, principles, and criteria of CAR developed earlier. The specific roles of two different types of theory in the cyclical action research process are considered. A project undertaken in two public relations firms illustrates how our methodological revision improves the rigor and quality of CAR. This article contributes both a significantly enhanced action research method, with detailed guidelines and suggestions that emphasize the roles of focal and instrumental theories, and an emerging theory of knowledge sharing that incorporates key elements of Chinese management and culture.
|keyword = Canonical action research,instrumental theory,focal theory,principles and criteria,knowledge management,knowledge sharing,culture,organizational change,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PRINCIPLES FOR CONDUCTING CRITICAL REALIST CASE STUDY RESEARCH IN INFORMATION SYSTEMS'''
{{header}}
{{article
|author= Jr. Donald Wynn,Clay K. Williams,
|source= MIS QUARTERLY
|year= 2012
|abstract = Critical realism is emerging as a viable philosophical paradigm for conducting social science research, and has been proposed as an alternative to the more prevalent paradigms of positivism and interpretivism. Few papers, however, have offered clear guidance for applying this philosophy to actual research methodologies. Under critical realism, a causal explanation for a given phenomenon is inferred by explicitly identifying the means by which structural entities and contextual conditions interact to generate a given set of events. Consistent with this view of causality, we propose a set of methodological principles for conducting and evaluating critical realism-based explanatory case study research within the information systems field. The principles are derived directly from the ontological and epistemological assumptions of critical realism. We demonstrate the utility of each of the principles through examples drawn from existing critical realist case studies. The article concludes by discussing the implications of critical realism based research for IS research and practice.
|keyword = Critical realism,case study research,methodology,philosophy,causal explanation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''HOW TO CONDUCT A FUNCTIONAL MAGNETIC RESONANCE (FMRI) STUDY IN SOCIAL SCIENCE RESEARCH'''
{{header}}
{{article
|author= Angelika Dimoka,
|source= MIS QUARTERLY
|year= 2012
|abstract = This research essay outlines a set of guidelines for conducting functional Magnetic Resonance Imaging (fMRI) studies in social science research in general and also, accordingly, in Information Systems research. Given the increased interest in using neuroimaging tools across the social sciences, this study aims at specifying the key steps needed to conduct an fMRI study while ensuring that enough detail is provided to evaluate the methods and results. The outline of an fMRI study consists of four key steps: (1) formulating the research question, (2) designing the fMRI protocol, (3) analyzing fMRI data, and (4) interpreting and reporting fMRI results. These steps are described with an illustrative example of a published fMRI study on trust and distrust in this journal (Dimoka 2010). The paper contributes to the methodological literature by (1) providing a set of guidelines for designing and conducting fMRI studies, (2) specifying methodological details that should be included in fMRI studies in academic venues, and (3) illustrating these practices with an exemplar fMRI study. Future directions for conducting high-quality fMRI studies in the social sciences are discussed.
|keyword = fMRI,decision neuroscience,neuroIS,brain imaging,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''BUILDING MEMBER ATTACHMENT IN ONLINE COMMUNITIES: APPLYING THEORIES OF GROUP IDENTITY AND INTERPERSONAL BONDS'''
{{header}}
{{article
|author= Yuqing Ren,F. Maxwell Harper,Sara Drenner,Loren Terveen,Sara Kiesler,John Riedl,Robert E. Kraut,
|source= MIS QUARTERLY
|year= 2012
|abstract = Online communities are increasingly important to organizations and the general public, but there is little theoretically based research on what makes some online communities more successful than others. In this article, we apply theory from the field of social psychology to understand how online communities develop member attachment, an important dimension of community success. We implemented and empirically tested two sets of community features for building member attachment by strengthening either group identity or interpersonal bonds. To increase identity-based attachment, we gave members information about group activities and intergroup competition, and tools for group-level communication. To increase bond-based attachment, we gave members information about the activities of individual members and interpersonal similarity, and tools for interpersonal communication. Results from a six-month field experiment show that participants' visit frequency and self-reported attachment increased in both conditions. Community features intended to foster identity-based attachment had stronger effects than features intended to foster bond-based attachment. Participants in the identity condition with access to group profiles and repeated exposure to their group's activities visited their community twice as frequently as participants in other conditions. The new features also had stronger effects on newcomers than on old-timers. This research illustrates how theory from the social science literature can be applied to gain a more systematic understanding of online communities and how theory-inspired features can improve their success.
|keyword = Online community,group identity,interpersonal bonds,attachment,participation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A KNOWLEDGE-BASED MODEL OF RADICAL INNOVATION IN SMALL SOFTWARE FIRMS'''
{{header}}
{{article
|author= Jessica Luo Carlo,Kalle Lyytinen,Gregory M. Rose,
|source= MIS QUARTERLY
|year= 2012
|abstract = In this paper, we adopt the lens of absorptive capacity (ACAP), defined by two dimensions the-knowledge base (consisting of knowledge diversity, depth, and linkages) and routines (consisting of sensing and experimentation)-to explain how a software firm's knowledge endowments influence its level of radical information technology innovation during a technological breakthrough. We distinguish three types of IT innovations-base, processes, and service innovation-that form an innovation ecology. We posit that (I) ACAP is a relational construct where the impact of the knowledge base is mediated by routines; (2) IT innovations are either externally adopted or internally generated; and (3) knowledge antecedents associated with different types of innovations differ. We hypothesize a three-step, mediated path (knowledge base -> sensing -> experimentation -> innovation) for external innovation adoption, and a two-step path (knowledge diversity/depth -> experimentation -> innovation)for internal innovation creation to explain the software firm's level of radical innovation across three IT innovation types. We validate the model through a cross-sector study that examined how 121 small software firms innovated with Internet computing. We confirm the mediated nature of ACAP for external base innovations, which are driven by all three knowledge-based factors as follows: (1) knowledge depth (direct positive effect); (2) knowledge diversity (mediated three-step path), (3) knowledge linkages (mediated three step path). Process innovations are externally driven by a three-step mediated path fir knowledge linkages, as well as being directly affected by knowledge diversity, but negatively and directly impeded by knowledge depth. Service innovations are not driven by any mediated influence of ACAP, but driven directly by knowledge diversity. At the same time, both service and process innovations are strongly influenced by prior IT innovations: base and/or service. Several directions for future studies of radical IT innovation are proposed.
|keyword = Absorptive capacity,knowledge base models,routines,organization knowledge base,IT innovation,innovation ecology,Internet computing,mediation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION TECHNOLOGY IMPLEMENTERS' RESPONSES TO USER RESISTANCE: NATURE AND EFFECTS'''
{{header}}
{{article
|author= Suzanne Rivard,Liette Lapointe,
|source= MIS QUARTERLY
|year= 2012
|abstract = User resistance has long been acknowledged as a critical issue during information technology implementation. Resistance can be functional when it signals the existence of problems with the IT or with its effects; it will be dysfunctional when it leads to organizational disruption. Notwithstanding the nature of resistance, the implementers-business managers, functional managers, or IT professionals-have to address it. Although the literature recognizes the importance of user resistance, it has paid little attention to implementers' responses-and their effect-when resistance occurs. Our study focuses on this phenomenon, and addresses two questions: What are implementers' responses to user resistance? What are the effects of these responses on user resistance? To answer these questions, we conducted a case survey, which combines the richness of case studies with the benefits of analyzing large quantities of data. Our case database includes 89 cases with a total of 137 episodes of resistance. In response to our first research question, we propose a taxonomy that includes four categories of implementers' responses to user resistance: inaction, acknowledgment, rectification, and dissuasion. To answer our second question, we adopted a set-theoretic analysis approach, which we enriched with content analysis of the cases. Based on these analyses, we offer a theoretical explanation of how implementers' responses may affect the antecedents that earlier research found to be associated with user resistance behaviors.
|keyword = User resistance,information technology implementation,implementers' response,theory building,case survey,set-theoretic analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''STANDARDS COMPETITION IN THE PRESENCE OF DIGITAL CONVERSION TECHNOLOGY: AN EMPIRICAL ANALYSIS OF THE FLASH MEMORY CARD MARKET'''
{{header}}
{{article
|author= Charles Zhechao Liu,Chris F. Kemerer,Sandra A. Slaughter,Michael D. Smith,
|source= MIS QUARTERLY
|year= 2012
|abstract = Both theoretical and empirical evidence suggest that, in many markets with standards competition, network effects make the strong grow stronger and can "tip" the market toward a single, winner-take-all standard. We hypothesize, however, that low cost digital conversion technologies, which facilitate easy compatibility across competing standards, may reduce the strength of these network effects. We empirically test our hypotheses in the context of the digital flash memory card market. We first test for the presence of network effects in this market and find that network effects, as measured here, are associated with a significant positive price premium for leading flash memory card formats. We then find that the availability of digital converters reduces the price premium of the leading flash card formats and reduces the overall concentration in the flash memory market. Thus, our results suggest that, in the presence of low cost conversion technologies and digital content, the probability of market dominance can be lessened to the point where multiple, otherwise incompatible, standards are viable. Our conclusion that the presence of converters weakens network effects implies that producers of non-dominant digital goods standards benefit from the provision of conversion technology. Our analysis thus aids managers seeking to understand the impact of converters on market outcomes, and contributes to the existing literature on network effects by providing new insights into how conversion technologies can affect pricing strategies in these increasingly important digital settings.
|keyword = Network effects,network externalities,standards competition,conversion technologies,flash memory,digital goods,market competition,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A RESEARCH NOTE ON REPRESENTING PART-WHOLE RELATIONS IN CONCEPTUAL MODELING'''
{{header}}
{{article
|author= Gove N. Allen,Salvatore T. March,
|source= MIS QUARTERLY
|year= 2012
|abstract = Empirical research is an important methodology for the study of conceptual modeling practices. The recently published article "Representing Part-Whole Relations in Conceptual Modeling: An Empirical Evaluation" (Shanks et al. 2008) uses the lens of ontology to study a relatively sophisticated aspect of conceptual modeling practice, the representation of aggregation and composition. It contends that some analysts argue that a composite should be represented as a relationship while others argue that a composite should be represented as an entity. We find no evidence of such a dispute in the data modeling literature. We observe that composites are objects. By definition, all object-types should be represented as entities. Therefore, using the relationship construct to represent composites should not be seen as a viable alternative. Additionally, we found significant conceptual and methodological issues within the study that call its conclusions into question. As a way to offer insight into the requisite methodological procedures for research in this area, we conducted two experiments that both explicate and address the issues raised. Our results call into question the utility of using ontology as a foundation for conceptual modeling practice. Furthermore, they suggest a contrary but at least equally plausible explanation for the results reported by Shanks et al. In conducting this work we hope to encourage dialogue that will be beneficial for future endeavors aimed at identifying developing, and evaluating appropriate foundations for the discipline of conceptual modeling.
|keyword = Conceptual modeling,empirical research,ontology,information systems development,composition,UML,entity-relationship model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE HOLE IN THE WHOLE: A RESPONSE TO ALLEN AND MARCH'''
{{header}}
{{article
|author= Graeme Shanks,Ron Weber,
|source= MIS QUARTERLY
|year= 2012
|abstract = Allen and March provide a critique of one of our papers in which we argue composites should be represented as entities/objects in a conceptual model rather than relationships/associations (Shanks et al. 2008). They contend we have addressed a non-issue. Furthermore, they argue our theoretical rationale and empirical evidence have flaws. In this paper, we provide a response to their arguments. We show that the issue we address is substantive. We show, also, that our theoretical analysis and empirical results are robust. We find, instead, that Allen and March's theoretical arguments and empirical evidence have flaws.
|keyword = Conceptual modeling,empirical research,ontology,information systems development,aggregation,composition,UML,entity-relationship model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DOES PLS HAVE ADVANTAGES FOR SMALL SAMPLE SIZE OR NON-NORMAL DATA?'''
{{header}}
{{article
|author= Dale L. Goodhue,William Lewis,Ron Thompson,
|source= MIS QUARTERLY
|year= 2012
|abstract = There is a pervasive belief in the MIS research community that PLS has advantages over other techniques when analyzing small sample sizes or data with non-normal distributions. Based on these beliefs, major MIS journals have published studies using PLS with sample sizes that would be deemed unacceptably small if used with other statistical techniques. We used Monte Carlo simulation more extensively than previous research to evaluate PLS, multiple regression, and LISREL in terms of accuracy and statistical power under varying conditions of sample size, normality of the data, number of indicators per construct, reliability of the indicators, and complexity of the research model. We found that PLS performed as effectively as the other techniques in detecting actual paths, and not falsely detecting non-existent paths. However, because PLS (like regression) apparently does not compensate for measurement error, PLS and regression were consistently less accurate than LISREL. When used with small sample sizes, PLS, like the other techniques, suffers from increased standard deviations, decreased statistical power,and reduced accuracy. All three techniques were remarkably robust against moderate departures from normality, and equally so. In total, we found that the similarities in results across the three techniques were much stronger than the differences.
|keyword = Partial least squares,PLS,regression,structural equation modeling,statistical power,small sample size,non-normal distributions,Monte Carlo simulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ASSESSING COMMON METHOD BIAS: PROBLEMS WITH THE ULMC TECHNIQUE'''
{{header}}
{{article
|author= Wynne W. Chin,Jason Bennett Thatcher,Ryan T. Wright,
|source= MIS QUARTERLY
|year= 2012
|abstract = Recent work, in journals such as MIS Quarterly and Management Science, has highlighted the importance of evaluating the influence of common method bias (CMB) on the results of statistical analysis. In this research note, we assess the utility of the unmeasured latent method construct (ULMC) approach in partial least squares (PLS), introduced by Liang et al. (2007). Such an assessment of the ULMC approach is important, because it has been employed in 76 studies since it appeared in MIS Quarterly in early 2007. Using data generated via Monte Carlo simulations, we use PLS structural equation modeling (SEM) to demonstrate that the ULMC approach of Liang et al. is neither able to detect, nor control for, common method bias. Method estimates using this approach resulted in negligible estimates, regardless of whether there were some, large, or no method bias introduced in the simulated data. Our study contributes to the IS and research methods literature by illustrating that, and explaining why the ULMC approach does not accurately detect common method bias in PLS. Further, our results build on prior work done using covariance-based SEM questioning the usefulness of the ULMC technique for detecting CMB.
|keyword = Common method bias,unmeasured latent method construct,partial least squares,structural equation modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Novelty-Knowledge Alignment: A Theory of Design Convergence in Systems Development'''
{{header}}
{{article
|author= Amrit Tiwana,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Recent research emphasizing the need for more business knowledge in information technology (IT) units and more technical knowledge in line functions largely overlooks the question of when maintaining either form of such "peripheral" knowledge-a costly endeavor-is valuable. Further application and process novelty are increasingly unavoidable in systems development projects but remain largely overlooked in theory. It is plausible that one type of peripheral knowledge is valuable under one type of novelty but not the other. I develop the idea that discriminating alignment between project novelty and peripheral knowledge is needed for them to enhance systems development performance. Thus, the valuable type of peripheral knowledge depends on whether a project involves novelty in the project concept or in its development processes. Further, we lack an explanation for how such discriminating alignment translates into improved project performance. I develop and test a middle-range theory built around two ideas to address these gaps. First, alignment between project novelty and peripheral knowledge must be discriminating to enhance systems development performance. Second, such discriminating alignment accelerates design convergence, which in turn enhances systems development performance. Tests using data from 159 projects support the proposed ideas. The primary contribution of this paper is therefore explaining when and how alignment between project novelty and peripheral knowledge in IT and client departments enhances systems development performance. The key implication is that greater application domain knowledge in the IT unit (technical knowledge in the client department) enhances performance in projects involving greater application novelty (process novelty).
|keyword = design convergence,iteration,novelty,oscillations,peripheral knowledge,systems development,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Effect of an Initial Budget and Schedule Goal on Software Project Escalation'''
{{header}}
{{article
|author= Jong Seok Lee,Mark Keil,Vijay Kasi,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Software project escalation is a costly problem that leads to significant financial losses. Prior research suggests that setting a publicly announced limit on resources can make individuals less willing to escalate their commitment to a failing course of action. However, the relationship between initial budget and schedule goals and software project escalation remains unexplored. Drawing on goal setting theory as well as sunk cost and mental budgeting perspectives, we explore the effect of goal difficulty and goal specificity on software project escalation. The findings from a laboratory experiment with 349 information technology professionals suggest that both very difficult and very specific goals for budget and schedule can limit software project escalation. Further, the level of commitment to a budget and schedule goal directly affects software project escalation and also interacts with goal difficulty and goal specificity to affect software project escalation. This study makes a theoretical contribution to the existing body of knowledge on software project management by establishing a connection between goal setting theory and software project escalation. The study also contributes to practice by highlighting the potential negative consequences that can result from the nature of initial budget and schedule goals that are established at the outset of a project.
|keyword = escalation of commitment,goal setting theory,mental budgeting,project estimation,software project escalation,software project management,sunk cost,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''What's the Weather Like? The Effect of Team Learning Climate, Empowerment Climate, and Gender on Individuals' Technology Exploration and Use'''
{{header}}
{{article
|author= Likoebe M. Maruping,Massimo Magni,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Given the pervasive use of teams in organizations coupled with high levels of investment in collaboration technology, there is increasing interest in identifying factors that affect the exploration and use of a broader scope of system features so that firms can benefit from the use of such technology. Prior research has called for a deeper understanding of how managers can encourage greater innovation with technology in the workplace. Drawing on the team climate and technology use literatures, we identify team learning climate and team empowerment climate as key factors that affect employees' propensity to explore a new system's features. We develop and test our multilevel model on team climate, team technology exploration, and team technology use in a field study involving 268 employees embedded in 56 work teams. Three main findings come out of this research. First, the results reveal that the two types of team climate differ in their cross-level effects on individual intention to explore, such that team learning climate promotes greater intention to explore, whereas team empowerment climate reduces employees' intention to explore the technology. In addition, we find that team learning climate and team empowerment climate interact in shaping individual intention to explore, such that the presence of a strong learning climate is more effective in promoting intention to explore when teams also have a strong empowerment climate. Second, the findings show that men and women are affected differently by team climate. We find that for men, team empowerment climate has no influence on intention to explore, whereas for women there is a significant negative cross-level effect. Finally, we find that intention to explore has a positive effect on usage scope, suggesting an important link between team climate, individual cognition, and the scope of features used by employees in team settings. Taken together, the model and results highlight the important role of team climate and gender and the interplay between them as drivers of technology feature exploration. Our findings, especially those related to team empowerment climate, are counterintuitive when compared to prior literature and offer useful insights for managers. On the one hand, managers should consider leveraging team learning climate to intrinsically stimulate employees to engage in exploration of technology. On the other hand, managers should be cautious and guard against saddling employees with too many additional responsibilities during the stages of exploration and experimentation with system features. It is possible that through an expanded set of responsibilities and expectations fostered by team empowerment climate, employees may be experiencing work overload, thus reducing their likelihood of exploring a broader set of technology features. Managers should be especially attentive to this based on the gender composition of their teams.
|keyword = collaboration technology,intention to explore,multilevel research,postadoption use,team climate,team technology use,usage scope,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Contract Performance in Offshore Systems Development: Role of Control Mechanisms'''
{{header}}
{{article
|author= Shirish C. Srivastava,Thompson S. H. Teo,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Although control theory has often been invoked to explain the coordination between client and vendor for information systems development (ISD), insights into its moderating effects for explicating ISD contract performance, especially in the offshore context, is rather limited. Such insights would en able better understanding of variables that have complementary or substitutive effects on performance. Further, the control literature talks about different control modes (e.g., formal and informal control modes classified as behavior, outcome, clan, and self-control modes) without adequately distinguishing among the different control mechanisms enacting each of the control modes. In this research, by explicitly classifying the distinctions that exist within each of the control modes, we uncover the key role played by mechanistic governance in outsourced ISD. Grounding our arguments in the information requirement for performance evaluation, the study theorizes the moderating influence of mechanistic governance on the relationships of contract specificity and relational governance with ISD quality and cost performance. We test the theorized model in a field study comprising 160 offshore ISD projects executed by Indian vendors. Our results establish the significant complementary role of mechanistic governance on the relationships of contract specificity with both cost and quality performance variables. Further, mechanistic governance substitutes the impact of relational governance on cost performance. Thus, the study theoretically as well as empirically establishes the need for conceptualizing mechanistic governance as a viable and significant governance mechanism for offshore ISD contracts. The study also teases out the distinctions between the two prime contract types in vogue for managing offshore ISD contracts, namely, fixed price and time and materials contracts. The study thus contributes not only to control theory but also to the stream of literature examining offshore ISD contracts. Further, the study provides insights to managers on having well-specified contracts and acknowledging the role of mechanistic governance for better performance.
|keyword = contract performance,control mechanisms,control modes,control theory,interaction effects,offshoring,outsourcing,project governance,software development,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of Information Technology Investments on Downside Risk of the Firm: Alternative Measurement of the Business Value of IT'''
{{header}}
{{article
|author= Samual Otim,Kevin E. Dow,Varun Grover,Jeffrey A. Wong,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = We examine the effect that investments in information technology (IT) have on downside risk profiles of companies that made public announcements of their investments in technology. Given the limitations of financial and decision theory perspectives on risk, we adopt the strategic management perspective that stresses downside risk as an important alternative measure of firm performance. We examine whether different types of IT investments have a differential impact on firm downside risk. Drawing on the resource-based view of the firm and the real options perspective, we find evidence that IT investments and their timing influence organizational downside risk. Transformational and informational IT investments lead to a reduction in downside risk only if they lead to strategic IT investments in the industry. For competitive necessities such as IT investments that automate business functions, a reduction in downside risk is realized by investing in parity with industry participants. Our study contributes to the literature by offering an alternative perspective on the benefits of IT investments, particularly where no apparent incremental financial results may be evident. It also generates insights on IT investment strategies that may help firms keep up with or stay ahead of the competition.
|keyword = downside risk,IT investment,IT strategic role,real options perspective,resource-based view of the firm,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Vertical Differentiation and a Comparison of Online Advertising Models'''
{{header}}
{{article
|author= Mei Lin,Xuqing Ke,Andrew B. Whinston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Designing business models that take into consideration the role of advertising support is critical to the success of online services. In this paper, we address the challenges of these business model strategies and compare different ad revenue models. We use game theory to model vertical differentiation in both monopoly and duopoly settings, in which online service providers may offer an ad-free service, an ad-supported service, or a combination of these services. Offering both ad-free and ad-supported services is the optimal strategy for a monopolist because ad revenues compensate for the cannibalistic effect of vertical differentiation. In a duopoly equilibrium, exactly one firm offers both services when the ad revenue rate is sufficiently high. Furthermore, we find that a higher ad revenue rate may lead to lower service prices. Consistently across both monopoly and duopoly settings, such price reductions are more severe in the cost-per-thousand-impressions model than in the cost-per-click model. Our findings emphasize the role of advertising revenues in vertical differentiation and offer strategic guidance for monetizing online services.
|keyword = ad-supported business models,e-commerce,economic analysis,game theory,online advertising,vertical differentiation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Differential Effects of Provider Recommendations and Consumer Reviews in E-Commerce Transactions: An Experimental Study'''
{{header}}
{{article
|author= Alexander Benlian,Ryad Titah,Thomas Hess,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Despite the importance of online product recommendations (OPRs) in e-commerce transactions, there is still little understanding about how different recommendation sources affect consumers' beliefs and behavior, and whether these effects are additive, complementary, or rivals for different types of products. This study investigates the differential effects of provider recommendations (PRs) and consumer reviews (CRs) on the instrumental, affective, and trusting dimensions of consumer beliefs and shows how these beliefs ultimately influence continued OPR usage and product purchase intentions. This study tests a conceptual model linking PRs and CRs to four consumer beliefs (perceived usefulness, perceived ease of use, perceived affective quality, and trust) in two different product settings (search products versus experience products). Results of an experimental study show that users of PRs express significantly higher perceived usefulness and perceived ease of use than users of CRs, while users of CRs express higher trusting beliefs and perceived affective quality than users of PRs, resulting in different effect mechanisms toward OPR reuse and purchase intentions in e-commerce transactions. Further, CRs were found to elicit higher perceived usefulness, trusting beliefs, and perceived affective quality for experience goods, while PRs were found to unfold higher effects on all of these variables for search goods.
|keyword = consumer reviews,e-commerce,online product recommendations,perceived affective quality,perceived usefulness,provider recommendations,technology acceptance and usage,trusting beliefs,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Attracted to or Locked In? Predicting Continuance Intention in Social Virtual World Services'''
{{header}}
{{article
|author= Zhongyun (Phil) Zhou,Yulin Fang,Douglas R. Vogel,Xiao-Ling Jin,Xi Zhang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Internet-based social virtual world (SVW) services have aroused extensive interest among academicians and practitioners. The success of SVW services depends heavily on customers' continuance usage, a topic not yet adequately investigated in information systems research. It is unclear to what extent, and how, the existing theories can be extended to explain the continuance usage of such services. In consideration of the distinctive features of these services, this study adapts the dedication-constraint framework of commitment and develops a model of SVW continuance, which is assessed empirically using data collected from 438 experienced users of Second Life, a typical SVW service. Results indicate that SVW customers' continuance intention is jointly determined by two mechanisms: affective commitment (being attracted to) and calculative commitment (being locked in), with the former playing a more central role. Perceived utilitarian value, hedonic value, and relational capital promote affective commitment directly and indirectly through satisfaction, while service-specific investments in personalization and relational capital increase calculative commitment. Theoretical and practical implications and future research directions are subsequently discussed.
|keyword = commitment,continuance intention,dedication-constraint dual model,Second Life,social virtual world services,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Effects of Self-Regulated Learning Processes on E-Learning Outcomes in Organizational Settings'''
{{header}}
{{article
|author= Zeying Wan,Deborah Compeau,Nicole Haggerty,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = This paper focuses on employees' e-learning processes during online job training. A new categorization of self-regulated learning strategies, that is, personal versus social learning strategies, is proposed, and measurement scales are developed. The new measures were tested using data collected from employees in a large company. Our approach provides context-relevant insights into online training providers and employees themselves. The results suggest that learners adopt different self-regulated learning strategies resulting in different e-learning outcomes. Furthermore, the use of self-regulated learning strategies is influenced by individual factors such as virtual competence and goal orientation, and job and contextual factors such as intellectual demand and cooperative norms. The findings can (1) help e-learners obtain better learning outcomes through their active use of varied learning strategies, (2) provide useful information for organizations that are currently using or plan to use e-learning for training, and (3) inform software designers to integrate self-regulated learning strategy support in e-learning system design and development.
|keyword = e-learning,job training,learning outcomes,learning processes,self-regulated learning strategies,social cognitive theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Cost-Sensitive Learning via Priority Sampling to Improve the Return on Marketing and CRM Investment'''
{{header}}
{{article
|author= Geng Cui,Man Leung Wong,Xiang Wan,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Because of the unbalanced class and skewed profit distribution in customer purchase data, the unknown and variant costs of false negative errors are a common problem for predicting the high-value customers in marketing operations. Incorporating cost-sensitive learning into forecasting models can improve the return on investment under resource constraint. This study proposes a cost-sensitive learning algorithm via priority sampling that gives greater weight to the high-value customers. We apply the method to three data sets and compare its performance with that of competing solutions. The results suggest that priority sampling compares favorably with the alternative methods in augmenting profitability. The learning algorithm can be implemented in decision support systems to assist marketing operations and to strengthen the strategic competitiveness of organizations.
|keyword = cost-sensitive learning,customer relationship management,direct marketing,forecasting,priority sampling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Are New IT-Enabled Investment Opportunities Diminishing for Firms?'''
{{header}}
{{article
|author= Brian L. Dos Santos,Zhiqiang (Eric) Zheng,Vijay S. Mookerjee,Hongyu Chen,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Today, few firms could survive for very long without their computer systems. IT has permeated every corner of firms. Firms have reached the current state in their use of IT because IT has provided myriad opportunities for firms to improve performance and, firms have availed themselves of these opportunities. Some have argued, however, that the opportunities for firms to improve their performance through new uses of IT have been declining. Are the opportunities to use TT to improve firm performance diminishing? We sought to answer this question. In this study, we develop a theory and explain the logic behind our empirical analysis; an analysis that employs a different type of event study. Using the volatility of firms' stock prices to news signaling a change in economic conditions, we compare the stock price behavior of firms in the IT industry to firms in the utility and transportation and freight industries. Our analysis of the IT industry as a whole indicates that the opportunities for firms to use TT to improve their performance are not diminishing. However, there are sectors within the TT industry that no longer provide value-enhancing opportunities for firms. We also find that IT products that provided opportunities for firms to create value at one point in time, later become necessities for staying in business. Our results support the key assumption in our work.
|keyword = information technology industry,business value of IT,event study,stock price volatility,financial market evaluation,IT and firm performance, macroeconomic news,IT value,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Blog, Blogger, and the Firm: Can Negative Employee Posts Lead to Positive Outcomes?'''
{{header}}
{{article
|author= Rohit Aggarwal,Ram Gopal,Ramesh Sankaranarayanan,Param Vir Singh,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Consumer-generated media, particularly blogs, can help companies increase the visibility of their products without spending millions of dollars in advertising. Although a number of companies realize the potential of blogs and encourage their employees to blog, a good chunk of them are skeptical about losing control over this new media. Companies fear that employees may write negative things about them and that this may bring significant reputation loss. Overall, companies show mixed response toward negative posts on employee blogs some companies show complete aversion; others allow some negative posts. Such mixed reactions toward negative posts motivated us to probe for any positive aspects of negative posts. In particular, we investigate the relationship between negative posts and readership of an employee blog. In contrast to the popular perception, our results reveal a potential positive aspect of negative posts. Our analysis suggests that negative posts act as catalyst and can exponentially increase the readership of employee blogs, suggesting that companies should permit employees to make negative posts. Because employees typically write few negative posts and largely write positive posts, the increase in readership of employee blogs generally should be enough to offset the negative effect of few negative posts. Therefore, not restraining negative posts to increase readership should be a good strategy. This raises a logical question: what should a firm's policy be regarding employee blogging? For exposition, we suggest an analytical framework using our empirical model.
|keyword = blog,employee blogs,bloggers,attribution theory,nonlinear models,negative posts,influence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Ambidexterity in Agile Distributed Development: An Empirical Investigation'''
{{header}}
{{article
|author= Balasubramaniam Ramesh,Kannan Mohan,Lan Cao,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Distributed software development has become a common reality with the advent of off-shore development and the need to be close to markets. Also, the dynamic nature of the environment in which businesses operate suggests the use of agile development methods. Whereas distributed software development requires the use of formal processes advocated by plan-driven approaches, rapidly changing environments are appropriate candidates for the use of agile development methods. This tension in agile distributed development poses conflicting demands between alignment and adaptability in the software development process. We conducted a multisite case study of three projects that use agile distributed development to examine how these organizations developed contextual ambidexterity the ability to pursue conflicting demands simultaneously. Our findings, presented as a conceptual framework, indicate that conflicting demands between alignment and adaptability posed by agile distributed development can be addressed by a set of balanced practices that shape performance management and social context two important antecedents of contextual ambidexterity.
|keyword = agile development,ambidexterity,distributed development,qualitative case study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Relative Industry Concentration and Customer-Driven IT Spillovers'''
{{header}}
{{article
|author= Zhuo (June) Cheng,Barrie R. Nault,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = We examine how one industry's productivity is affected by the IT capital of its customers and how this effect depends on industries' relative concentration. These customer-driven IT spillovers result from customers' IT investments in various information systems that reduce transaction costs through information sharing and coordination and lead to more efficient production and logistics upstream. The magnitude of IT spillovers depends on relative industry concentration because customers in more concentrated industries relative to those of their suppliers are better able to retain the benefits from their IT investments. We model customer-driven effects based on production theory and empirically test the model using two industry-level data sets covering different and overlapping time periods (1987-1999 and 1998-2005), different scopes of the economy (manufacturing only versus all industries), and different levels of industry aggregation. We find that, given an increase in a downstream industry's IT capital, there is a significant increase in downstream industry output as well as significant increases in upstream industry output. Moreover, the magnitude of IT spillovers is related to relative industry concentration: A 1% decrease in a customer's relative industry concentration increases spillovers by roughly 1%. Thus, further increases in IT capital can be justified along the supply chain, and an industry's relative concentration which can reflect market power in part determines the distribution of productivity benefits.
|keyword = business value of IT,IT-enabled supply chains,economics of IS,spillovers,production function framework,input-output tables,industry concentration,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Cooperative Cashing? An Economic Analysis of Document Duplication in Cooperative Web Caching'''
{{header}}
{{article
|author= Kartik Hosanagar,Yong Tan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Cooperative caching is a popular mechanism to allow an array of distributed caches to cooperate and serve each others' Web requests. Controlling duplication of documents across cooperating caches is a challenging problem faced by cache managers. In this paper, we study the economics of document duplication in strategic and nonstrategic settings. We have three primary findings. First, we find that the optimum level of duplication at a cache is nondecreasing in intercache latency, cache size, and extent of request locality. Second, in situations in which cache peering spans organizations, we find that the interaction between caches is a game of strategic substitutes wherein a cache employs lesser resources towards eliminating duplicate documents when the other caches employs more resources towards eliminating duplicate documents at that cache. Thus, a significant challenge will be to simultaneously induce multiple caches to contribute more resources towards reducing duplicate documents in the system. Finally, centralized decision making, which as expected provides improvements in average latency over a decentralized setup, can entail highly asymmetric duplication levels at the caches. This in turn can benefit one set of users at the expense of the other, and thus will be challenging to implement.
|keyword = Web caching,cooperative caching,duplication in caching,analytical modeling,incentive-centered design,game theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Institutional Contradictions and Loose Coupling: Postimplementation of NASA's Enterprise Information System'''
{{header}}
{{article
|author= Nicholas Berente,Youngjin Yoo,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Through a grounded analysis of the National Aeronautics and Space Administration (NASA's) enterprise information system (IS) implementation in the months immediately following the go-live, we show how NASA can be characterized as an institutionally plural organization, rife with diverse institutional logics, some consistent and some contradictory to each other. The enterprise system is introduced in accordance with the logic of managerial rationalism, but some of the institutional logics that organizational actors draw upon and reproduce contradict the logic of managerial rationalism in certain situations. In these situations, organizational actors loosely couple elements of their practices from the practices implied by the enterprise system, thus satisfying the demands associated with both institutional fields. We identify four generalizable forms of loose coupling that result from these institutional contradictions: temporal, material, procedural, and interpretive, and discuss their effects on both the system implementation and local practices. Further, we show how, through the use of institutional logics, researchers can identify fundamental institutional contradictions that explain regularities in the situated responses to enterprise system implementations regularities that are consistently identified in the literature across a variety of organizational contexts.
|keyword = institutional pluralism,institutional contradiction,institutional logic,institutional theory,loose coupling,loosely coupled,enterprise systems,ERP,NASA,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Modeling Supply-Side Dynamics of IT Components, Products, and Infrastructure: An Empirical Analysis Using Vector Autoregression'''
{{header}}
{{article
|author= Gediminas Adomavicius,Jesse Bockstedt,Alok Gupta,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Prior IS research on technological change has focused primarily on organizational information systems and technology innovation; however, there is a growing need to understand the dynamics of supply-side forces in the introduction of new technologies. In this paper we investigate how the interdependencies among information technology components, products, and infrastructure affect the release of new technologies. Going beyond the ad hoc heuristic approaches applied in previous studies, we empirically validate the existence of several patterns of supply-side technology relationships in the context of wireless networking. We use vector autoregression (VAR) to model the comovements of new component, product, and infrastructure introductions and provide evidence of strong Granger-causal interdependencies. We also demonstrate that substantial improvements in forecasting can be gained by incorporating these cross-level effects into models of technological change. This paper provides some of the first research that empirically demonstrates these cross-level effects and also provides an exposition of VAR methodology for both analysis and forecasting in IS research.
|keyword = information systems and technology trends,supply-side forces,technological change,technology ecosystems,technology forecasting,time series analysis,vector autoregression,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Performance Implications of CRM Technology Use: A Multilevel Field Study of Business Customers and Their Providers in the Telecommunications Industry'''
{{header}}
{{article
|author= Alex R. Zablah,Danny N. Bellenger,Detmar W. Straub,Wesley J. Johnston,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Extant research is equivocal about the organizational performance effects of customer relationship management (CRM) technology use, with some studies reporting positive effects and other studies reporting no effects at all. The present research effort posits that these mixed findings may potentially be explained by two factors: (1) CRM technology use may have different effects on different customers, and (2) different CRM tools may have different performance consequences. This study investigates this possibility by building on relationship marketing and management theory to propose and test a model of the customer- and firm-level consequences of the organizational use of CRM interaction support and customer prioritization tools. The results of data analysis of 295 customer firms nested within 10 provider firms reveal that firm use of CRM interaction support tools is positively related to customers' relationship perceptions, regardless of customer account size. In contrast, the data indicate that use of CRM prioritization tools appears to have positive effects on a firm's larger customers and negative effects on smaller customers. The results also suggest that when considered at an aggregate level, customer perceptions of the exchange relationship are predictive of organizational performance and that the association between these two variables is significant for larger customer accounts but insignificant for smaller accounts. Overall, the study's results help explain some of the inconsistent findings reported in the literature regarding the performance implications of CRM technology use and suggest that use of the technology may serve to enhance organizational performance, at least over the short term.
|keyword = customer relationship management,CRM,CRM technology,relationship investment,relationship marketing and management,multilevel modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Reputation and Uncertainty in Online Markets: An Experimental Study'''
{{header}}
{{article
|author= Sarah C. Rice,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = This paper employs a modified investment game to study how online reputation ratings are assigned, and I thus how electronic reputations are formed in transactions where buyers and sellers interact anonymously. Of particular interest are the important questions of how online reputations evolve and how specific reputation information is interpreted by market participants. We vary the level of uncertainty in the transaction environment, and measure the effects of this manipulation on buyers' trust and their subsequent rating behaviors. We distinguish between a reputation mechanism and specific reputation information, finding the former has an association with the overall decision of whether to transact in the marketplace, while the latter shows significance in purchase decisions regarding specific sellers. We also find that aggregate reputation information is weighted differently than singular reputation information. Finally, we show that when reputations are increasingly noisy, buyers are less likely to react negatively to poor ratings and are more likely to give sellers the benefit of the doubt when seemingly uncooperative outcomes occur.
|keyword = reputation systems,online markets,experimental economics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Managing Data Quality Risk in Accounting Information Systems'''
{{header}}
{{article
|author= Xue Bai,Manuel Nunez,Jayant R. Kalagnanam,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The quality of data contained in accounting information systems has a significant impact on both internal business decision making and external regulatory compliance. Although a considerable body of literature exists on the issue of data quality, there has been little research done at the task level of a business process to develop effective control strategies to mitigate data quality risks. In this paper, we present a methodology for managing the risks associated with the quality of data in accounting information systems. This methodology first models the error evolution process in transactional data flow as a dynamical process; it then finds optimal control policies at the task level to mitigate the data quality-related risks using a Markov decision process model with risk constraints. The proposed Markov decision methodology facilitates the modeling of multiple dimensions of error dependence, captures the correlated impact among control procedures, and identifies an optimal control policy. A revenue realization process of an international production company is used to illustrate this methodology.
|keyword = data quality,risk,audit,control,accounting information systems,constrained Markov decision processes,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Expectation Confirmation in Technology Use'''
{{header}}
{{article
|author= Susan A. Brown,Viswanath Venkatesh,Sandeep Goyal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = We propose a model to study expectation confirmation in information systems. The proposed model is based on the assimilation-contrast model and prospect theory, and suggests that both are needed to account for the magnitude and direction of the deviations between experiences and expectations. Using the technology acceptance model's (TAM) primary construct namely, perceived usefulness expectations and experiences were conceptualized and operationalized to test our model. Data were collected in a field study from 1,113 participants at two points in time. Using polynomial modeling and response surface analysis, we demonstrated that our model offers a good explanation of the relationship among information systems expectations, experiences, and use. We discuss theoretical and practical implications.
|keyword = technology acceptance,TAM,cognitive dissonance theory,polynomial modeling,response surface analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Optimal Software Free Trial Strategy: The Impact of Network Externalities and Consumer Uncertainty'''
{{header}}
{{article
|author= Hsing Kenneth Cheng,Yipeng Liu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Many software firms offer a fully functional version of their products free of charge, for a limited trial period, to ease consumers' uncertainty about the functionalities of their products and to help the diffusion of their new software. This paper examines the trade-off between the effects of reduced uncertainty and demand cannibalization, uncovers the condition under which software firms should introduce the time-locked free trial software, and finds the optimal free trial time. As software firms have the option of providing free trial software with full functionalities but a limited trial time or limited functionalities for an unlimited trial time, we develop a unified framework to provide useful guidelines for deciding which free trial strategy is preferred in the presence of network externalities and consumer uncertainty.
|keyword = software free trial,time-locked free trial,demo software,experience goods,network effect,product trial,product sampling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''SOA Performance Enhancement Through XML Fragment Caching'''
{{header}}
{{article
|author= Anindya Datta,Kaushik Dutta,Qianhui Liang,Debra VanderMeer,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Organizations are increasingly choosing to implement service-oriented architectures to integrate distributed, loosely coupled applications. These architectures are implemented as services, which typically use XML-based messaging to communicate between service consumers and service providers across enterprise networks. We propose a scheme for caching fragments of service response messages to improve performance and service quality in service-oriented architectures. In our fragment caching scheme, we decompose responses into smaller fragments such that reusable components can be identified and cached in the XML routers of an XML overlay network within an enterprise network. Such caching mitigates processing requirements on providers and moves content closer to users, thus reducing bandwidth requirements on the network as well as improving Service times. We describe the system architecture and caching algorithm details for our caching scheme, develop an analysis of the expected benefits of our scheme, and present the results of both simulation and case study-based experiments to show the validity and performance improvements provided by our caching scheme. Our simulation experimental results show an up to 60% reduction in bandwidth consumption and up to 50% response time improvement. Further, our case study experiments demonstrate that when there is no resource bottleneck, the cache-enabled case reduces average response times by 40%-50% and increases throughput by 150% compared to the no-cache and full message caching cases. In experiments contrasting fragment caching and full message caching, we found that full message caching provides benefits when the number of possible unique responses is low while the benefits of fragment caching increase as the number of possible unique responses increases. These experimental results clearly demonstrate the benefits of our approach.
|keyword = caching,XML,SOA,service-oriented architecture,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Lock-In Strategy in Software Competition: Open-Source Software vs. Proprietary Software'''
{{header}}
{{article
|author= Kevin Xiaoguo Zhu,Zach Zhizhong Zhou,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Open-source software poses a serious challenge to proprietary software vendors. "Lock in customers" seems a tempting strategy for proprietary software vendors, who attempt to lock in customers by creating switching costs. This paper examines whether such a lock-in strategy will indeed benefit proprietary software vendors facing competition from open-source software, who can credibly commit future prices. Developing a two-period duopoly model in which software products are differentiated and customers are heterogeneous, we find that the lock-in strategy is actually counterproductive in competing against open-source software. In fact, giving customers the freedom of choice may end up benefiting the proprietary software vendor. In terms of the broader effect, we find that lock-in reduces overall social welfare, but certain customers may actually be better off with it. Finally, we show that the lock-in strategy works differently for different types of customers in the software market (i.e., foresighted versus myopic customers). This suggests that customer behavior could significantly alter the equilibrium strategy of software vendors.
|keyword = software,competition,lock-in,open-source software,proprietary software,game theory,switching cost,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Trust Is in the Eye of the Beholder: A Vignette Study of Postevent Behavioral Controls' Effects on Individual Trust in Virtual Teams'''
{{header}}
{{article
|author= Alan R. Dennis,Jr. Lionel P. Robert,Aaron M. Curtis,Stacy T. Kowalczyk,Bryan K. Hasty,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Research in face-to-face teams shows conflicting results about the impact of behavioral controls on trust; some research shows that controls increase the salience of good behavior, which increases trust while other research shows that controls increase the salience of poor behavior that decreases trust. The only study in virtual teams, which examined poorly functioning teams, found that controls increased the salience of poor behavior, which decreased trust. We argue that in virtual teams behavioral controls amplify the salience of all behaviors (positive and negative) and that an individual's selective perception bias influences how these behaviors are interpreted. Thus the link from behavioral controls to trust is more complex than first thought. We conducted a 2 x 2 experiment, varying the use of behavioral controls (controls, no controls) and individual team member behaviors (reneging behaviors designed to reduce trust beliefs and fulfilling behaviors designed to increase trust beliefs). We found that behavioral controls did amplify the salience of all behaviors; however, contrary to what we expected, this actually weakened the impact of reneging and fulfilling behaviors on trust. We believe that completing a formal evaluation increased empathy and the awareness of context in which the behaviors occurred and thus mitigated extreme perceptions. We also found that behavioral controls increased the selective perception bias which induced participants to see the behaviors their disposition to trust expected rather than the behaviors that actually occurred.
|keyword = virtual teams,trust,controls,disposition to trust,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Generating Shareable Statistical Databases for Business Value: Multiple Imputation with Multimodal Perturbation'''
{{header}}
{{article
|author= Nigel Melville,Michael McQuaid,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Business organizations are generating growing volumes of data about their employees, customers, and suppliers. Much of these data cannot be exploited for business value due to privacy and confidentiality concerns. National statistical agencies share sensitive data collected from individuals and businesses by modifying the data so individuals and firms cannot be identified but statistical utility is preserved. We build on this literature to develop a hybrid approach to data masking for business organizations. We demonstrate the validity of the hybrid approach, which we call multiple imputation with multimodal perturbation (MIMP), using Monte Carlo simulation and illustrate its application in a specific business context. Results of our analysis open new areas of research for information systems scholarship and new potential revenue sources for business organizations.
|keyword = Bayesian bootstrap,business value of information technology,confidentiality,data masking,data safety,data security,decision support systems,disclosure risk,Monte Carlo simulation,multimodal perturbation,multiple imputation,privacy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Online Price Dispersion: A Game-Theoretic Perspective and Empirical Evidence'''
{{header}}
{{article
|author= Sulin Ba,Jan Stallaert,Zhongju Zhang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The existence and persistence of price dispersion for identical products in online markets have been well-documented in the literature. Possible explanations of this price dispersion, derived mainly using hedonic price models, have seen only modest success. In this paper, we propose a competitive model based on online retailers' differentiation mainly in service provided and recognition enjoyed to explain price dispersion. Our exploratory empirical analyses, using cross-sectional data, demonstrate that the competitive model provides a better explanation of the association between prices and online retailers' service and recognition levels. In addition, our competitive model is able to explain observations that are seemingly inconsistent with the hedonic model such as the negative association between service and price. This paper contributes to the literature on price dispersion by offering a differentiation model that provides a good fit with data and by proposing a theory that explains previous counterintuitive observations of prices. Our model also helps an e-tailer to choose a desirable position in the competitive market.
|keyword = online price dispersion,vertical differentiation,e-service,service quality,brand recognition,competitive strategy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''OPEN KNOWLEDGE CREATION: BRINGING TRANSPARENCY AND INCLUSIVENESS TO THE PEER REVIEW PROCESS'''
{{header}}
{{article
|author= Donald E. Hardaway,Richard W. Scamell,
|source= MIS QUARTERLY
|year= 2012
|abstract = The peer review process that has been in place for many years has recognized shortcomings. The Internet provides a means for changing this process. This paper offers a more transparent and inclusive design for peer review referred to as open knowledge creation. The design proposed utilizes Google knol and group services. The open knowledge creation design consists of four stages: creation, review/revision, evaluation/adoption, and publication. It is intended to offer existing or new journals an alternative to the traditional peer review of research.
|keyword = Peer review,communicating research,Google knol and group services,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''STYLE COMPOSITION IN ACTION RESEARCH PUBLICATION'''
{{header}}
{{article
|author= Lars Mathiassen,Mike Chiasson,Matt Germonprez,
|source= MIS QUARTERLY
|year= 2012
|abstract = Examining action research publications in leading Information Systems journals as a particular genre of research communication, we develop the notion of style composition to understand how authors structure their arguments for a research contribution. We define style composition as the activity through which authors select, emphasize, and present elements of their research to establish premises, develop inferences, and present contributions in publications. Drawing on this general notion, we identify a set of styles that is characteristic of how IS action researchers compose their argument. Premise styles relate to the dual goals of action research through practical or theoretical positioning of the argument; inference styles combine insights from the problem-solving and the research cycles through inductive or deductive reasoning; and contribution styles focus on different types of contributions experience report, field study, theoretical development, problem-solving method, and research method. Based on the considered sample, we analyze the styles adopted in selected publications and show that authors have favored certain styles while leaving others underexplored; further, we reveal important strengths and weaknesses in the composition of styles within the IS discipline. Based on these insights, we discuss how action research practices and writing can be improved, as well as how to further develop style compositions to support the publication of engaged scholarship research.
|keyword = Action research,research methodology,style composition,journal publication,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CAN ONLINE WAIT BE MANAGED? THE EFFECTS OF FILLER INTERFACES AND PRESENTATION MODES ON PERCEIVED WAITING TIME ONLINE'''
{{header}}
{{article
|author= Younghwa Lee,Andrew N. K. Chen,Virginia Ilie,
|source= MIS QUARTERLY
|year= 2012
|abstract = Long waits online undermine users' evaluations of Web sites and their providers, triggering abandonment behaviors. Yet e-business researchers and practitioners have not perfected mechanisms to respond to online wait issues. A filler interface that runs during the wait for search results may influence online users perceived waiting time (PWT); however, no scientific investigation has attempted to design effective filler interfaces for managing online waits. By adopting resource allocation theory, cognitive absorption theory, and human computer interaction (HCI) theories (competition for attention, visual search, and motion effect), we design diverse filler interlaces and investigate their effects on antecedents of PWT. The proposed research model considers cognitive absorption factors such as temporal dissociation, focused immersion, and heightened enjoyment as antecedents of PWT, which in turn triggers three outcomes: affective appraisals, cognitive appraisals, and Web site use intention. A multistage, multimethod approach is used to test the research hypotheses. In the first stage, we compare a filler interface condition with a no-filler interface condition, and find the superiority of a filler interface with respect to inducing focused immersion and temporal dissociation. In the second stage, we conduct two controlled experiments to examine whether filler interfaces with various designs (varying the presence and relevance of image. text, and image motion) distinctly influence antecedents of PWT and confirm their distinctive effects on focused immersion, temporal dissociation, and heightened enjoyment. In addition, by conducting a structural equation modeling analysis, we find that our research model explains 51 percent, 51 percent, 44 percent, and 45 percent of the variance in PWT, affective appraisals, cognitive appraisals, and Web site use intention respectively. Theoretical and practical implications of these findings are provided.
|keyword = Filler interface,interface design,online wait management,perceived waiting time,cognitive absorption,motion effect,competition for attention,visual search,resource allocation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ON PRODUCT UNCERTAINTY IN ONLINE MARKETS: THEORY AND EVIDENCE'''
{{header}}
{{article
|author= Angelika Dimoka,Yili Hong,Paul A. Pavlou,
|source= MIS QUARTERLY
|year= 2012
|abstract = Online markets pose a difficulty for evaluating products, particularly experience goods, such as used cars, that cannot be easily described online. This exacerbates product uncertainty, the buyer's difficulty in evaluating product characteristics, and predicting how a product will perform in the future. However, the IS literature has focused on seller uncertainty and ignored product uncertainty. To address this void, this study conceptualizes product uncertainty and examines its effects and antecedents in online markets for used cars (eBay Motors). Extending the information asymmetry literature from the seller to the product, we first theorize the nature and dimensions (description and performance) of product uncertainty. Second, we propose product uncertainty to be distinct from,,yet shaped by, seller uncertainty. Third, we conjecture product uncertainty to negatively affect price premiums in online markets beyond seller uncertainty. Fourth, based on the information signaling literature, we describe how information signals (diagnostic product descriptions and third-party product assurances) reduce product uncertainty. The structural model is validated by a unique dataset comprised of secondary transaction data from used cars on eBay Motors matched with primary data from 331 buyers who bid on these used cars. The results distinguish between product and seller uncertainty, show that product uncertainty has a stronger effect on price premiums than seller uncertainty, and identify the most influential information signals that reduce product uncertainty. The study's implications for the emerging role of product uncertainty in online markets are discussed.
|keyword = Product uncertainty,information signals,price premiums,online auction markets,eBay Motors,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE CAREER PATHS LESS (OR MORE) TRAVELED: A SEQUENCE ANALYSIS OF IT CAREER HISTORIES, MOBILITY PATTERNS, AND CAREER SUCCESS'''
{{header}}
{{article
|author= Damien Joseph,Wai Fong Boh,Soon Ang,Sandra A. Slaughter,
|source= MIS QUARTERLY
|year= 2012
|abstract = This paper examines the objective career histories, mobility patterns, and career success of 500 individuals drawn from the National Longitudinal Survey of Youth (NLSY79), who had worked in the information technology workforce. Sequence analysis of career histories shows that careers of the IT workforce are more diverse than the traditional view of a dual IT career path (technical versus managerial). This study reveals a new career typology comprising three broad, distinct paths: IT careers; professional labor market (PLM) careers; and secondary labor market (SLM) careers. Of the 500 individuals in the IT workforce, 173 individuals pursued IT careers while the remaining 327 individuals left IT for other high-status non-IT professional jobs in PLM or lower-status, non-ITjobs in SLM careers. Findings from this study contribute to refining the concept of "boundaryless" careers. By tracing the diverse trajectories of career mobility, we enrich our understanding of how individuals construct boundaryless careers that span not only organizational hut also occupational boundaries. Career success did not differ in terms of average pay for individuals in IT and PLM careers. By contrast, individuals in SLM careers attained the lowest pay. We conclude this study with implications for future research and for the management of IT professionals' careers.
|keyword = Management of IT human resources,longitudinal,careers,sequence analysis,IT profession boundaryless,mobility,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''UNDERSTANDING USER REVISIONS WHEN USING INFORMATION SYSTEM FEATURES: ADAPTIVE SYSTEM USE AND TRIGGERS'''
{{header}}
{{article
|author= Heshan Sun,
|source= MIS QUARTERLY
|year= 2012
|abstract = Post-adoptive system use is often characterized by cycles of adaptation, in which people actively revise how they use information systems. This paper investigates how and why individual users revise their system use at the feature level. A new concept, adaptive system use (ASU), is conceptualized as a user's revisions of which and how system features are used. This research identifies four specific ASU behaviors that collectively describe how people revise their use of system features. A model of ASU is developed based on Louis and Sutton's (1991) research on how people switch to active thinking from automatic thinking. The model specifies three antecedents of ASU (novel situations, discrepancies, and deliberate initiatives) and two moderators (personal innovativeness in IT and facilitating conditions). An empirical study of 253 Microsoft Office users largely supported the research model. The findings suggest that triggers-including novel situations, discrepancies, and deliberate initiatives are a significant impetus to ASU. This research also confirms moderating effects of personal innovativeness in IT: The findings also show the relationships among triggers: in addition to their direct impact on ASU, novel situations and deliberate initiatives exert their influence on ASU indirectly by giving rise to discrepancies in system use. Moreover, a cluster analysis identifies three heterogeneous triggering conditions and reveals that people engage in different ASU behaviors under different triggering conditions.
|keyword = Post-adoptive system use,adaptive system use,triggers,features in use,formative factor,personal innovativeness in IT,facilitating conditions,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A COST-BASED DATABASE REQUEST DISTRIBUTION TECHNIQUE FOR ONLINE E-COMMERCE APPLICATIONS'''
{{header}}
{{article
|author= Debra VanderMeer,Kaushik Dutta,Anindya Datta,
|source= MIS QUARTERLY
|year= 2012
|abstract = E-commerce is growing to represent an increasing share of overall sales revenue, and online sales are expected to continue growing for the foreseeable future. This growth translates into increased activity on the supporting infrastructure, leading to a corresponding need to scale the infrastructure. This is difficult in an era of shrinking budgets and increasing functional requirements. Increasingly, IT managers are turning to virtualized cloud providers, drawn by the pay-for-use business model. As cloud computing becomes more popular, it is important jar data center managers to accomplish more with fewer dollars (i.e., to increase the utilization of existing resources). Advanced request distribution techniques can help ensure both high utilization and smart request distribution, where requests are sent to the service resources best able to handle them. While such request distribution techniques have been applied to the web and application layers of the traditional online application architecture, request distribution techniques for the data layer have focused primarily on online transaction processing scenarios. However, online applications often have a significant read-intensive workload, where read operations constitute a significant percentage of workloads (up to 95 percent or higher). In this paper, we propose a cost-based database request distribution (C-DBRD) strategy, a policy to distribute requests, across a cluster of commercial, off-the-shelf databases, and discuss its implementation. We first develop the intuition behind our approach, and describe a high-level architecture for database request distribution. We then develop a theoretical model for database load computation, which we use to design a method for database request distribution and build a software implementation. Finally, following a design science methodology, we evaluate our artifact:: through experimental evaluation. Our experiments, in the lab and in production-scale systems, show significant improvement of database layer resource utilization, demonstrating up to a 45 percent improvement over existing request distribution techniques.
|keyword = Database clusters,request distribution,task allocation,design research,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EFFICIENCY OR INNOVATION: HOW DO INDUSTRY ENVIRONMENTS MODERATE THE EFFECTS OF FIRMS' IT ASSET PORTFOLIOS?'''
{{header}}
{{article
|author= Ling Xue,Gautam Ray,Vallabh Sambamurthy,
|source= MIS QUARTERLY
|year= 2012
|abstract = Firms invest in a variety of information technologies and seek to align their IT asset portfolios with two key performance outcomes: efficiency and innovation. Existing research makes the universalistic assumption that both outcomes will always be realized through firms' IT asset portfolios. There has been limited research on the conditions under which firms' IT asset portfolios should be oriented more toward efficiency or innovation. Here, we argue that the nature of the industry where a firm competes will have a significant moderating effect on the link between firms' IT asset portfolios and efficiency or innovation outcomes. Using panel data that covers a wide range of industry environments, we find that at lower levels of dynamism, munificence, and complexity. IT asset portfolios are associated with a greater increase in efficiency. In contrast, in environments with higher levels of complexity, IT asset portfolios are associated with a greater increase in innovation (i.e., development of new products and processes, and exploration of growth opportunities). These results provide insights about how firms could realize strategic alignment by tailoring their IT asset portfolios toward an efficiency or innovation focus.
|keyword = Efficiency,innovation,exploitation,exploration,IT asset portfolio,IT value,competitive environment,dynamism,munificence,complexity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TOWARD A NEW THEORY OF THE CONTRIBUTION OF THE IT FUNCTION IN ORGANIZATIONS'''
{{header}}
{{article
|author= Manon G. Guillemette,Guy Pare,
|source= MIS QUARTERLY
|year= 2012
|abstract = Because changes in organizations and information technology environments are enduring, the alignment of the IT function with business objectives must not only be understood, but constantly renewed and adjusted. This is amply reflected in recent surveys of CIOs, which consistently suggest that the notion of alignment is a top challenge and management priority. Many CIOs face a double challenge when addressing the issue of alignment: they must first clarify, top management's expectations and assumptions about IT, which may be contradictory, and then understand their implications for how the IT department should be managed (i.e., translate the function's strategic mission into an IT management model that adds value to the organization). The characterization of the IT function has constituted a central and growing subject of research in the information systems field. Although the extant literature has much to teach us, knowledge in this area is nevertheless fragmented and has not been properly integrated. In response to these limitations, this study proposes and tests a new theory of the contribution of the IT/function. Specifically, our objective is to offer an explanation of the contribution of the IT function in organizations with a typology of ideal profiles. A field study was conducted in 24 large Canadian companies in order to validate a set of research propositions. Our results first suggest that there are five distinct "ideal" IT management profiles in organizations and each of these profiles tends to focus on specific sources of value. Next, we observed that IT functions that are close to the ideal of any given profile seem to be outperforming those with hybrid profiles. Finally, our findings provide a compelling explanation as to how ideal IT management profiles are adopted in organizations. The article concludes with a discussion of the theoretical and practical implications of the proposed theory.
|keyword = IT function,IT management profile,IT contribution,CIO,theory building,typological theory,field study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE ASYMMETRIC BENEFITS OF RELATIONAL FLEXIBILITY: EVIDENCE FROM SOFTWARE DEVELOPMENT OUTSOURCING'''
{{header}}
{{article
|author= Anandasivam Gopal,Balaji R. Koka,
|source= MIS QUARTERLY
|year= 2012
|abstract = In this paper, the interacting effect of formal contracts and relational governance on vendor profitability and quality in the software outsourcing industry are examined. We focus on a critical manifestation of relational governance the presence of relational flexibility in the exchange relationship and argue that the enacted observation of relational flexibility is driven by perceptions of exchange hazards. In a departure from extant literature, however, we propose that the benefits accruing from it are asymmetric and depend on how the exchange risks are apportioned by the formal contract. Formally, we hypothesize that relational flexibility provides greater benefits to an exchange partner that faces the greater proportion of risk in a project, induced through the contract. In addition, we hypothesize that these benefits manifest on the performance dimensions that are of importance to the risk-exposed partner. We test our hypotheses on 105 software projects completed by a software outsourcing vendor for multiple clients. The results show that relational,flexibility positively affects profitability in only fixed price contracts, where the vendor faces greater risk, while positively affecting quality only in time and materials contracts, where the client is at greater risk. We thus provide evidence for the asymmetric benefits from relational governance, thereby arguing for a more contingent and limited view of the value of relational governance, based on risk-exposure, rather than the more expansive view prevalent in the literature contending that relational governance provides benefits for all parties to an exchange. We conclude with a discussion of the research and managerial implications of our findings.
|keyword = Relational governance,relational flexibility,formal contracts,software development,outsourcing,exchange hazards,regression analysis,quality,profitability,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ENACTING CLAN CONTROL IN COMPLEX IT PROJECTS: A SOCIAL CAPITAL PERSPECTIVE'''
{{header}}
{{article
|author= Cecil Eng Huang Chua,Wee-Kiat Lim,Christina Soh,Siew Kien Sia,
|source= MIS QUARTERLY
|year= 2012
|abstract = The information technology project control literature has documented that clan control is often essential in complex multistakeholder projects for project success. However, instituting clan control in such conditions is challenging as people come to a project with diverse skills and backgrounds. There is often insufficient time for clan control to develop naturally This paper investigates the question, "How can clan control be enacted in complex IT projects?" Recognizing social capital as a resource, we conceptualize a clan as a group with strong social capital (i.e., where its members have developed their structural, cognitive, and relational ties to the point that they share common values and beliefs and are committed to a set of peer norms). We theorize that the enactment of clan control is a dual process of (1) building the clan by developing its social capital dimensions (structural, cognitive, and relational ties) or reappropriating social capital from elsewhere and (2) leveraging the clan by reinforcing project-facilitating shared values, beliefs, and norms, and inhibiting those that impede the achievement of project goals. We explore how clan control was enacted in a large IT project at a major logistics organization in which clan control was quickly instituted to avoid an impending project failure. Our research contributes to theory in three ways: (1) we reconcile the two differing views of clan control into a single framework, (2) we explain the role of controllers in enacting clan control, and (3) we clarify, how formal control can be employed to develop clan control.
|keyword = Behavioral control theory,clan control,formal control,project management,project control,IT projects,social capital,enterprise systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IS EMPLOYEE ATTITUDES AND PERCEPTIONS AT VARYING LEVELS OF SOFTWARE PROCESS MATURITY'''
{{header}}
{{article
|author= Janet K. Ply,Jo Ellen Moore,Clay K. Williams,Jason Bennett Thatcher,
|source= MIS QUARTERLY
|year= 2012
|abstract = Taking a control theory view of software process innovation, we tested prevalent beliefs regarding software process maturity and Information Systems employee attitudes and perceptions by surveying 736 IS professionals in 10 organizations at varying levels of the CMM (capability maturity model). Although anecdotal reports and the scant empirical studies to date suggest job attitudes and perceptions are more positive for employees in organizations at higher levels of software process maturity, we found evidence of a more complex picture. While our data supported expectations that role conflict and perceived work overload were lower for IS professionals in organizations at a level of maturity where software process behavioral controls are implemented, other results were not fully in line with prevalent beliefs. Most notably, IS workers reported significantly lower professional efficacy and lower job satisfaction in organizations at CMM Level 3, where behavioral controls are the dominant form of formal control, than in organizations at Level I, which is relatively free of formal controls. Some anticipated positive attitudes and perceptions surfaced in organizations at the highest rungs of software process maturity (CMM Levels 4/5), where the established behavioral controls are supplemented by substantial outcome controls, as IS professionals reported lower role ambiguity and higher job satisfaction than did their counterparts in organizations at CMM Level 3.
|keyword = Software process improvement,CMM,job satisfaction,role conflict,role ambiguity,work overload,cynicism,professional efficacy,control theory,IS professionals,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ABSORPTIVE CAPACITY AND INFORMATION SYSTEMS RESEARCH: REVIEW, SYNTHESIS, AND DIRECTIONS FOR FUTURE RESEARCH'''
{{header}}
{{article
|author= Nicholas Roberts,Pamela S. Galluch,Michael Dinger,Varun Grover,
|source= MIS QUARTERLY
|year= 2012
|abstract = Absorptive capacity is a firm's ability to identify assimilate, transform, and apply valuable external knowledge. iris considered an imperative for business success. Modern information technologies perform a critical role in the development and maintenance of a firm's absorptive capacity. We provide an assessment of absorptive capacity in the information systems literature. IS scholars have used the absorptive capacity construct in diverse and often contradictory ways. Confusion surrounds how absorptive capacity should be conceptualized, its appropriate level of analysis, and how it can be measured. Our aim in reviewing this construct is to reduce such confusion by improving our understanding of absorptive capacity and guiding its effective use in IS research. We trace the evolution of the absorptive capacity construct in the broader organizational literature and pay special attention to its conceptualization, assumptions, and relationship to organizational learning. Following this, we investigate how absorptive capacity has been conceptualized, measured, and used in IS research. We also examine how absorptive capacity fits into distinct IS themes and facilitates understanding of various IS phenomena. Based on our analysis, we provide a framework through which IS researchers can more fully leverage the rich aspects of absorptive capacity when investigating the role of information technology in organizations.
|keyword = Absorptive capacity,information systems,IT capability,knowledge,organizational learning,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CARROTS AND RAINBOWS: MOTIVATION AND SOCIAL PRACTICE IN OPEN SOURCE SOFTWARE DEVELOPMENT'''
{{header}}
{{article
|author= Georg von Krogh,Stefan Haefliger,Sebastian Spaeth,Martin W. Wallin,
|source= MIS QUARTERLY
|year= 2012
|abstract = Open source software (OSS) is a social and economic phenomenon that raises fundamental questions about the motivations of contributors to information systems development. Some developers are unpaid volunteers who seek to solve their own technical problems, while others create OSS as part of their employment contract. For the past 10 years, a substantial amount of academic work has theorized about and empirically examined developer motivations. We review this work and suggest considering motivation in terms of the values of the social practice in which developers participate. Based on the social philosophy of Alasdair MacIntyre, we construct a theoretical framework that expands our assumptions about individual motivation to include the idea of a long-term, value-informed quest beyond short-term rewards. This motivation practice framework depicts how the social practice and its supporting institutions mediate between individual motivation and outcome. The framework contains three theoretical conjectures that seek to explain how collectively elaborated standards of excellence prompt developers to produce high-quality software, change institutions, and sustain OSS development. From the framework, we derive six concrete propositions and suggest a new research agenda on motivation in OSS.
|keyword = Free software,incentives,MacIntyre,motivation,open source software,innovation,social practice,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Two Rule-Based Natural Language Strategies for Requirements Discovery and Classification in Open Source Software Development Projects'''
{{header}}
{{article
|author= Radu E. Vlas,William N. Robinson,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Open source projects do have requirements; they are, however, mostly informal text descriptions found in requests, forums, and other correspondence. Understanding such requirements provides insight into the nature of open source projects. Unfortunately, manual analysis of natural language requirements is time-consuming, and for large projects, error prone. Automated analysis of natural language requirements, even partial, will be of great benefit. Toward that end, we describe the design and validation of an automated natural language requirements classifier for open source projects. We compare two strategies for recognizing requirements in open forums of software features. Our results suggest that classifying text at the forum post-aggregation and sentence aggregation levels may be effective. Our results suggest that it can reduce the effort required to analyze requirements of open source projects.
|keyword = natural language processing,open source,requirements classification,requirements discovery,software requirements,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Supporting Agile Organizations with a Decision Guidance Query Language'''
{{header}}
{{article
|author= Alexander Brodsky,Nathan E. Egge,X. Sean Wang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Decision optimization is widely used in many decision guidance and support systems (DGSS) to support business decisions such as procurement, scheduling, and planning. In spite of rapid changes in users' requirements, the implementation of DGSS is typically rigid, expensive, and not easily extensible, which is in stark contrast to the agile implementation of management information systems (MIS) based on the database management systems (DBMS) and SQL technologies. This paper focuses on the Decision Guidance Query Language (DGQL) designed to (re-)use SQL programs for decision optimization with the goals of making DGSS implementation agile and intuitive and leveraging existing investment in SQL-implemented MIS. The paper addresses two related technical issues with DGQL: (1) how to annotate existing queries to precisely express the optimization semantics, and (2) how to translate the annotated queries into equivalent mathematical programming formulations that can be solved efficiently.
|keyword = agile organizations,decision guidance,decision support,optimization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding Technology Support for Organizational Transactive Memory: Requirements, Application, and Customization'''
{{header}}
{{article
|author= Dorit Nevo,Izak Benbasat,Yair Wand,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Transactive memory is an effective mechanism for locating and coordinating expertise in small groups and has been shown to hold numerous benefits for groups and organizations. To extend transactive memory beyond the scope of small groups, researchers have proposed the use of information technology (IT). This paper provides an integrated discussion of our knowledge from three studies concerning IT support in transactive memory in organizations. Focusing on meta-memory, which is at the heart of transactive memory systems, we examine what meta-memory is maintained by members of transactive memory systems, whether providing this meta-memory in a technology-mediated environment can lead to transactive memory development, whether IT can realistically provide this meta-memory, and whether different requirements exist for different users and in different stages of transactive memory development. We discuss the implications of these studies to both research and practice.
|keyword = expertise location,meta-memory,social media,transactive memory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Theory-Informed Design and Evaluation of an Advanced Search and Knowledge Mapping System in Nanotechnology'''
{{header}}
{{article
|author= Yan Dang,Yulei Zhang,Hsinchun Chen,Susan A. Brown,Paul Jen-Hwa Hu,Jr. Jay F. Nunamaker,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Effective search support is an important tool for helping individuals deal with the problem of information overload. This is particularly true in the field of nanotechnology, where information from patents, grants, and research papers is growing rapidly. Guided by cognitive fit and cognitive load theories, we develop an advanced Web-based system, Nano Mapper, to support users' search and analysis of nanotechnology developments. We perform controlled experiments to evaluate the functions of Nano Mapper. We examine users' search effectiveness, efficiency, and evaluations of system usefulness, ease of use, and satisfaction. Our results demonstrate that Nano Mapper enables more effective and efficient searching, and users consider it to be more useful and easier to use than the benchmark systems. Users are also more satisfied with Nano Mapper and have higher intention to use it in the future. User evaluations of the analysis functions are equally positive.
|keyword = cognitive fit,cognitive load,information system evaluation,knowledge mapping,searching,visualization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Facilitation Roles and Responsibilities for Sustained Collaboration Support in Organizations'''
{{header}}
{{article
|author= Gwendolyn L. Kolfschoten,Fred Niederman,Robert O. Briggs,Gert-Jan De Vreede,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Research shows that under certain conditions, groups using collaboration technologies such as group support systems (GSS) can gain substantial improvements in the effectiveness and efficiency of their work processes. GSS, however, have been slow to develop self-sustaining communities of users in the workplace. Organizations that use collaboration technology may require two kinds of support: process support and technology support. Both types of support involve (1) design tasks (e.g., designing a work process and designing the technology to support the process), (2) application tasks (to apply the process and to use the technology), and (3) management tasks (to monitor and control the process and to oversee the maintenance of the technology). This paper explores how these tasks and associated roles can be anchored in organizations, and the relationship of task allocation patterns to the sustained use of collaboration technology in organizations.
|keyword = collaboration engineering,collaboration support,facilitation,group support systems,group work,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Going Concerns: The Governance of Interorganizational Coordination Hubs'''
{{header}}
{{article
|author= M. Lynne Markus,Quang Neo Bui,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Business-to-business interactions are increasingly conducted through interorganizational coordination hubs, in which standardized information technology-based platforms provide data and business process interoperability for interactions among the organizations in particular industrial communities. Because the governance of interorganizational arrangements is believed to affect their efficiency and effectiveness, this paper explores how and why interorganizational coordination hubs are governed. Analysis of relevant prior theory and case examples shows that coordination hub governance is designed to balance the sometimes conflicting needs for capital to invest in new technology, for participation of industry members, and for the protection of data resources. Findings suggest that the governance of interorganizational coordination hubs is not the starkly categorical choice between collective (member-owned) and investor-owned forms as suggested by prior theory. Instead, many hybrid arrangements are observed in the five examined cases. Future theoretical development and empirical research are needed to understand the increasingly important phenomenon of coordination hub governance.
|keyword = case study,coordination hubs,corporate governance,interorganizational relationships,IT investment,IT standards,trust,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Effect of Information Feedback on the Outcomes and Dynamics of Multisourcing Multiattribute Procurement Auctions'''
{{header}}
{{article
|author= Gediminas Adomavicius,Alok Gupta,Pallab Sanyal,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Electronic auctions are increasingly being used to facilitate the procurement of goods and services in organizations. Multiattribute auctions, which allow bids on multiple dimensions of the product and not just price, are information technology-enabled sourcing mechanisms that can increase the efficiency of procurement for configurable goods and services compared to price-only auctions. Given the strategic nature of procurement auctions, the amount of information concerning the buyer's preferences that is disclosed to the suppliers has implications on the profits of the buyer and the suppliers and, consequently, on the long-term relationship between them. This study explores novel feedback schemes for multisourcing multiattribute auctions that require limited exchange of strategic information between the buyer and the suppliers. To study the impact of feedback on the outcomes and dynamics of the auctions, we conduct laboratory experiments wherein we analyze bidder behavior and economic outcomes under three different treatment conditions with different types of information feedback. Our results indicate that, in contrast to winner-take-all multiattribute auctions, multisourcing multiattribute auctions, with potentially multiple winners, allow bidders (i.e., suppliers) to extract more profit when greater transparency in terms of provisional allocations and prices is provided. We develop several insights for mechanism designers toward developing sustainable procurement auctions that efficiently allocate multiple units of an asset with multiple negotiable attributes among multiple suppliers.
|keyword = bidder behavior,experimental economics,information feedback,multiattribute auction,procurement,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Leveraging Information Technology Infrastructure to Facilitate a Firm's Customer Agility and Competitive Activity: An Empirical Investigation'''
{{header}}
{{article
|author= Nicholas Roberts,Varun Grover,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = This paper investigates how information technology (IT) facilitates a firm's customer agility and, in turn, competitive activity. Customer agility captures the extent to which a firm is able to sense and respond quickly to customer-based opportunities for innovation and competitive action. Drawing from the dynamic capability and IT business value research streams, we propose that IT plays an important role in facilitating a "knowledge creating" synergy derived from the interaction between a firm's Web-based customer infrastructure and its analytical ability. This will enhance the firm's ability to sense customer-based opportunities. IT also plays an important role in "process enhancing" synergy obtained from the interaction between a firm's coordination efforts and its level of information systems integration, which facilitates the firm's ability to respond to those opportunities. We also leverage the competitive dynamics and strategic alignment literature to propose that the alignment between customer-sensing capability and customer-responding capability will impact the firm's competitive activity. We test our model with a two-stage research design in which we survey marketing executives of high-tech firms. Our results show that a Web-based customer infrastructure facilitates a firm's customer-sensing capability; furthermore, analytical ability positively moderates this relationship. We also find that internal systems integration positively moderates the relationship between interfunctional coordination and a firm's customer-responding capability. Finally, our results show that agility alignment affects the efficacy of a firm's competitive actions. In particular, action efficacy is higher when sensing and responding capabilities are both high.
|keyword = alignment,competitive dynamics,customer agility,dynamic capability,IT infrastructure,IT value,open innovation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Methodology Mashups: An Exploration of Processes Used to Maintain Software'''
{{header}}
{{article
|author= Dana Edberg,Polina Ivanova,William Kuechler,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = The majority of studies of software development processes explore initial development rather than ongoing software maintenance, yet the majority of the systems development budget in many organizations is devoted to maintenance. Software maintenance projects differ significantly from original development projects, indicating a need for more research specifically concerning maintenance processes. This study uses a grounded theory research method to explore how information technology professionals define and select a methodology to maintain existing software. We found that in-use maintenance methodologies are composed of components from multiple formal methodologies. We developed a factor model describing how these components are chosen. The findings contribute to a better understanding of how standard methodologies are applied in software practice and the critical factors used by professionals when choosing an appropriate methodology for software maintenance activities. This research underscores the need for incorporating the full software life cycle in information systems development research and education.
|keyword = grounded theory,maintenance methodology,software development,software maintenance,software process,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Patch Release Behaviors of Software Vendors in Response to Vulnerabilities: An Empirical Analysis'''
{{header}}
{{article
|author= Orcun Temizkan,Ram L. Kumar,SungJune Park,Chandrasekar Subramaniam,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2012
|abstract = Software vulnerabilities have become a serious concern because unpatched software runs the risk of being exploited by hackers. There is a need for software vendors to make software patches available in a timely manner for vulnerabilities in their products. We develop a survival analysis model of software vendors' patch release behavior and test it using a data set compiled from the National Vulnerability Database, United States Computer Emergency Readiness Team, and vendor Web sites. This model helps to understand how factors specific to vulnerabilities, patches, software vendors, and software affect the patch release behavior of software vendors based on their cost structure. This study also analyzes the impact of the presence of multiple vendors and type of vendor on the patch release behavior of software vendors. Our results indicate that vulnerabilities with high confidentiality impact or high integrity impact are patched faster than vulnerabilities with high availability impact. Interesting differences in the patch release behavior of software vendors based on software type (new release versus update) and type of vendor (open source versus proprietary) are found. Our results illustrate that when there are legislative pressures, vendors react faster in patching vulnerabilities. Thus, appropriate regulations can be an important policy tool to influence vendor behavior toward socially desirable security outcomes.
|keyword = patch quality,patch release time,patch types,software vendor types,software vulnerability characteristics,survival analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Moving Beyond the Single Site Implementation Study: How (and Why) We Should Study the Biography of Packaged Enterprise Solutions'''
{{header}}
{{article
|author= Robin Williams,Neil Pollock,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The single site implementation study is an invaluable tool for studying the large-scale enterprise solution. Together with constructivist frameworks and ethnographic approaches it has allowed the development of rich local pictures of the immediate and adaptive response by user organizations to the take-up of what are, today, often generic packaged systems. However, to view the packaged enterprise solution principally at the place where the user encounters it also has limitations. It produces somewhat partial understandings of these complex artifacts. In particular, it downplays important influences from other sites and time frames. This paper argues that if we are to understand the full implications of enterprise solutions for organizations then we should study their "biography." This idea points to how the career of workplace technology is often played out over multiple time frames and settings. To understand its shaping therefore requires scholars to go beyond the study of technology at a single locale or moment and, rather, attempt to follow it through space and time. The paper develops two ideas to aid this kind of study. We discuss better spatial metaphors that might help us explore the hybrid and extended spaces in which packaged software systems develop and evolve. We also review improved temporal understandings that may capture the multiple contemporary and historical time frames at play. The paper concludes by discussing some possible research directions that a focus on the biography of a technology might allow.
|keyword = implementation,biography,ethnography,enterprise resource planning,sociology,actor network theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Social Networks and the Diffusion of User-Generated Content: Evidence from YouTube'''
{{header}}
{{article
|author= Anjana Susarla,Jeong-Ha Oh,Yong Tan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = This paper is motivated by the success of YouTube, which is attractive to content creators as well as corporations for its potential to rapidly disseminate digital content. The networked structure of interactions on YouTube and the tremendous variation in the success of videos posted online lends itself to an inquiry of the role of social influence. Using a unique data set of video information and user information collected from YouTube, we find that social interactions are influential not only in determining which videos become successful but also on the magnitude of that impact. We also find evidence for a number of mechanisms by which social influence is transmitted, such as (i) a preference for conformity and homophily and (ii) the role of social networks in guiding opinion formation and directing product search and discovery. Econometrically, the problem in identifying social influence is that individuals' choices depend in great part upon the choices of other individuals, referred to as the reflection problem. Another problem in identification is to distinguish between social contagion and user heterogeneity in the diffusion process. Our results are in sharp contrast to earlier models of diffusion, such as the Bass model, that do not distinguish between different social processes that are responsible for the process of diffusion. Our results are robust to potential self-selection according to user tastes, temporal heterogeneity and the reflection problem. Implications for researchers and managers are discussed.
|keyword = diffusion,user-generated content,YouTube,social networks,reflection problem,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Technology and Intangible Output: The Impact of IT Investment on Innovation Productivity'''
{{header}}
{{article
|author= Landon Kleis,Paul Chwelos,Ronald V. Ramirez,Iain Cockburn,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Prior research concerning IT business value has established a link between firm-level IT investment and tangible returns such as output productivity. Research also suggests that IT is vital to intermediate processes such as those that produce intangible output. Among these, the use of IT in innovation and knowledge creation processes is perhaps the most critical to a firm's long-term success. However, little is known about the relationship between IT, knowledge creation, and innovation output. In this study, we contribute to the literature by comprehensively examining the contribution of IT to innovation production across multiple contexts using a quality-based measure of innovation output. Analyzing annual information from 1987 to 1997 for a panel of large U. S. manufacturing firms, we find that a 10% increase in IT input is associated with a 1.7% increase in innovation output for a given level of innovation-related spending. This relationship between IT, research and development (R&D), and innovation production is robust across multiple econometric methodologies and is found to be particularly strong in the mid to late 1990s, a period of rapid technological innovation. Our results also demonstrate the importance of IT in creating value at an intermediate stage of production, in this case, through improved innovation productivity. However, R&D and its related intangible factors (skill, knowledge, etc.) appear to play a more crucial role in the creation of breakthrough innovations.
|keyword = information technology,productivity,knowledge production function,innovation,patents,research and development,IT business value,breakthrough innovation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Competitive Behavior-Based Price Discrimination for Software Upgrades'''
{{header}}
{{article
|author= Amit Mehra,Ram Bala,Ramesh Sankaranarayanan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The introduction of product upgrades in a competitive environment is commonly observed in the software industry. When introducing a new product, a software vendor may employ behavior-based price discrimination (BBPD) by offering a discount over its market price to entice existing customers of the competitor. This type of pricing is referred to as competitive upgrade discount pricing and is possible because the vendor can use proof of purchase of a competitor's product as credible evidence to offer the discount. At the same time, the competitor may offer a discount to its own previous customers in order to induce them to buy its upgrade. We formulate a game-theoretic model involving an incumbent and entrant where both firms can offer discounts to existing customers of the incumbent. Although several equilibrium possibilities exist, we establish that an equilibrium with competitive upgrade discount pricing is observed only for a unique market structure and a corresponding unique set of prices. In this equilibrium, instead of leveraging its first mover advantage, the incumbent cedes market share to the entrant. Furthermore, the profits of both the incumbent and the entrant reduce with switching costs. This implies that the use of BBPD has product design implications because firms may influence the switching costs between their products by making appropriate compatibility decisions. In addition, lower switching costs result in reduced consumer surplus. Hence, a social planner may want to increase switching costs. The resulting policy implications are different from those prevalent in other industries such as mobile telecommunications where the regulators reduced switching costs by enforcing number portability.
|keyword = behavior-based pricing,software upgrades,competitive strategy,switching costs,forward-looking customers,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Effects of Information Revelation Policies Under Cost Uncertainty'''
{{header}}
{{article
|author= Karthik N. Kannan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The paper presents insights regarding the key learning-related factors a buyer should consider when deciding the extent to which information about bids is revealed in a procurement auction context. It offers the insights by analyzing the following two first-price sealed-bid policies in a private-value sequential auction with no winner dropouts: (i) IIS, where only the winner's bid is revealed, and (ii) CIS, where all bids are revealed. Our analysis identifies two important learning effects-the extraction and the deception effects-as having significant welfare implications. Both these effects arise because of a bidder's desire to gain an informational advantage relative to his competitors, but their manifestations are different. The extraction effect occurs because of a bidder's incentive to learn about his competitors, and the deception effect is a consequence of the incentive to prevent an opponent from gaining the information. Both effects lead to higher bid prices, and either may be dominant from a procurer surplus standpoint. With the deception effect, social welfare can decrease even when the number of suppliers increases, a result that is counterintuitive. The paper also discusses how insights regarding the learning effects might apply to other policies.
|keyword = information revelation,electronic markets,economics of information systems,perfect Bayesian Nash equilibrium,auctions,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Switching Costs, Network Effects, and Competition in the European Mobile Telecommunications Industry'''
{{header}}
{{article
|author= Lucio Fuentelsaz,Juan Pablo Maicas,Yolanda Polo,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = This paper empirically analyzes the joint effect of switching costs and network effects in determining the level of competition in the European mobile communications industry. Theoretical reasoning argues that switching costs and network effects may confer some market power that firms can strategically exploit to reduce competition and thus increase profits. Theoretical predictions are completely confirmed by the empirical evidence and important asymmetries between the market structures in the different European countries can be observed. These asymmetries are clearly related to the levels of switching costs and network effects-the greater their importance, the lower the rivalry in the market. This suggests that the recent efforts of policymakers to reduce the negative consequences of switching costs and network effects have not been successful enough and these efforts must be strengthened, at least in several countries.
|keyword = network effects,switching costs,mobile telecommunications industry,competition,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Modeling Spatial and Temporal Set-Based Constraints During Conceptual Database Design'''
{{header}}
{{article
|author= Faiz Currim,Sudha Ram,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = From a database perspective, business constraints provide an accurate picture of the real world being modeled and help enforce data integrity. Typically, rules are gathered during requirements analysis and embedded in code during the implementation phase. We propose that the rules be explicitly modeled during conceptual design, and develop a framework for understanding and classifying spatiotemporal set-based (cardinality) constraints and an associated syntax. The constraint semantics are formally specified using first-order logic. Modeling rules in conceptual design ensures they are visible to designers and users and not buried in application code. The rules can then be semiautomatically translated into logical design triggers yielding productivity gains. Following the principles of design science research, we evaluate the framework's expressiveness and utility with a case study.
|keyword = data modeling,conceptual design,spatiotemporal cardinality constraints,data management spatiotemporal databases,design science research,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IT Outsourcing Contracts and Performance Measurement'''
{{header}}
{{article
|author= David Fitoussi,Vijay Gurbaxani,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Companies that outsource information technology (IT) services usually focus on achieving multiple objectives. Correspondingly, outsourcing contracts typically specify a variety of metrics to measure and reward (or penalize) vendor performance. The specific types of performance metrics included in a contract strongly affect its incentive content and ultimately its outcome. One specific challenge is the measurement of performance when an outsourcing arrangement has a mix of objectives, some that are highly measurable and others that are not. Recent advances in contract theory suggest that the design of incentives for a given objective is affected by the characteristics of other objectives. However, there is little empirical work that demonstrates how relevant these "multitask" concerns are in real-world contracts. We apply contract theory to examine how objectives and incentives are related in IT outsourcing contracts that include multiple objectives with varying measurement costs. In our context, contracts generally share the objective of reducing IT costs but vary in the importance of increasing IT quality. We establish empirical results about performance measurement in IT outsourcing contracts that are consistent with recent theoretical propositions. We find that the use of strong direct incentives for a given measurable objective is negatively correlated with the presence of less measurable objectives in the contract. We show that outsourcing contracts that emphasize goals with high measurement costs employ more performance metrics than initiatives whose objectives have a lower measurement cost profile. Surprisingly, as the number of performance metrics increases, satisfactory outcomes decrease, which we explain within a multitask theory framework. Overall, our results provide empirical support for multitask principal-agent theory and important guidance in designing outsourcing contracts for complex IT services.
|keyword = IT outsourcing,multitask,contract theory,performance measurement,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''How Peripheral Developers Contribute to Open-Source Software Development'''
{{header}}
{{article
|author= Pankaj Setia,Balaji Rajagopalan,Vallabh Sambamurthy,Roger Calantone,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Open-source software development is the next stage in the evolution of product development, particularly software products. Compared with the prevailing proprietary approaches, open-source software products are developed by co-opting external developers and prospective users. Although a core group of developers might still play a key role in the initial design and development, a notable aspect of the open-source software paradigm is the role of peripheral developers in the enhancement and popularization of the product. Peripheral developers are not formal members of the core development team. They voluntarily contribute their time and creative talent in improving the quality of the product or in popularizing the product through word-of-mouth advocacy. As volunteers, they are not subject to the traditional hierarchical controls, nor are they contractually obligated. Peripheral developers represent a novel and unique aspect of open-source software development, and there is a greater interest in tapping their potential. However, there has been limited evidence about how and when their participation has beneficial impacts. We examine how peripheral developers contribute to product quality and diffusion by utilizing longitudinal data on 147 open-source software products. Hierarchical linear modeling analysis indicates that peripheral developers make significant contributions to product quality and diffusion, especially on projects that are in the more mature stages of product development.
|keyword = open source,diffusion,quality,new product development,adoption,software development,peripheral developers,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Online and Offline Demand and Price Elasticities: Evidence from the Air Travel Industry'''
{{header}}
{{article
|author= Nelson Granados,Alok Gupta,Robert J. Kauffman,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The Internet has brought consumers increased access to information to make purchase decisions. One of the expected consequences is an increase in the price elasticity of demand, or the percent change in demand caused by a percent change in price, because consumers are better able to compare offerings from multiple suppliers. In this paper, we analyze the impact of the Internet on demand, by comparing the demand functions in the Internet and traditional air travel channels. We use a data set that contains information for millions of records of airline ticket sales in both online and offline channels. The results suggest that consumer demand in the Internet channel is more price elastic for both transparent and opaque online travel agencies (OTAs), in part, because of more leisure travelers self-selecting the online channel, relative to business travelers. Yet, after controlling for this channel self-selection effect, we still find differences in price elasticity across channels. We find that the opaque OTAs are more price elastic than the transparent OTAs, which suggests that product information can mitigate the price pressures that arise from Internet-enabled price comparisons. We discuss the broader implications for multichannel pricing strategy and for the transparency-based design of online selling mechanisms.
|keyword = air travel industry,economics of information systems,electronic markets,market transparency,mechanism design,multichannel strategy,price elasticity,online travel agencies,self-selection,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of External Word-of-Mouth Sources on Retailer Sales of High-Involvement Products'''
{{header}}
{{article
|author= Bin Gu,Jaehong Park,Prabhudev Konana,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Online word-of-mouth (WOM) such as consumer opinions, user experiences, and product reviews has become a major information source in consumer purchase decisions. Prior research on online WOM effect has focused mostly on low-involvement products such as books or CDs. For these products, retailer-hosted (internal) WOM is shown to influence sales overwhelmingly. Numerous surveys, however, suggest consumers often conduct pre-purchase searches for high-involvement products (e. g., digital cameras) and visit external WOM websites during the search process. In this study, we analyze the relative impact of external and internal WOMs on retailer sales for high-involvement products using a panel of sales and WOM data for 148 digital cameras from Amazon.com and three external WOM websites (Cnet, DpReview, and Epinions) over a four-month period. The results suggest that a retailer's internal WOM has a limited influence on its sales of high-involvement products, while external WOM sources have a significant impact on the retailer's sales. The findings imply that external WOM sources play an important role in the information search process.
|keyword = user generated content,word-of-mouth,consumer information search,product involvement,electronic commerce,digital cameras,Amazon,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Online Users' Switching Costs: Their Nature and Formation'''
{{header}}
{{article
|author= Soumya Ray,Sung S. Kim,James G. Morris,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = The highly competitive and rapidly changing market for online services is becoming increasingly effective at locking users in through the coercive effects of switching costs. Although the information systems field increasingly recognizes that switching costs plays a big part in enforcing loyalty, little is known about what factors users regard as switching costs or why they perceive these costs. Consequently, it is hard for online services to know what lock-in strategies to use and when to apply them. We address this problem by first developing a theory-driven structure of online users' perceived switching costs that distinguishes between vendor-related and user-related factors. We then propose that important antecedent influences on switching costs from economic value, technical self-efficacy, and past investments are more complex and intertwined than previously thought. We empirically validated the proposed model using data collected from home users of Internet service providers. Our findings demonstrate that an online service's economic value more heavily influences users' perceptions of vendor-related switching costs than does technical self-efficacy. However, users' technical abilities outweigh economic value in influencing user-related switching costs. Furthermore, although we confirmed the commonly held notion that deeply invested users are generally more vulnerable to lock-in, we also found that this relationship is contingent on users' technical abilities. Finally, we found that our multidimensional measure of switching costs is a valid predictor of user loyalty and is more powerful than previous global measures. Overall, this study uncovered a finer network of switching-cost production than had been previously established and suggests a new approach to modeling and exploiting online users' perceived switching costs.
|keyword = switching costs,online consumer behavior,survey data,partial least squares,structural equation modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Multilevel Analysis of the Effect of Group Appropriation on Collaborative Technologies Use and Performance'''
{{header}}
{{article
|author= Sora Kang,Kai H. Lim,Min Soo Kim,Hee-Dong Yang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = This study develops a comprehensive model to predict and explain the use of collaborative technologies (CT) and the task performance of individual users as a result of using CT. The integrated model attempts to capture how the individual user's extent of use of CT is a function of both the technical features and the structures embedded within or created by the interactions among the technology, group, and organization. The model developed is tested using data collected from a national bank with 279 members working in 40 different workgroups. A hierarchical linear model (HLM) is used to test the hypotheses generated from the model. Results show that our integrated model provides a more complete explanation of the use of CT and task performance beyond those of the individual-level factors. The study is an early effort to develop an integrated theory to provide comprehensive insight into individual use of CT in a group or organizational context.
|keyword = IT diffusion and adoption,IT use,questionnaire surveys,adaptive structuration theory,collaborative technologies,consensus of appropriation,faithfulness of appropriation,social comparison theory,multilevel analysis,hierarchical linear model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Halo Effect in Multicomponent Ratings and Its Implications for Recommender Systems: The Case of Yahoo! Movies'''
{{header}}
{{article
|author= Nachiketa Sahoo,Ramayya Krishnan,George Duncan,Jamie Callan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Collaborative filtering algorithms learn from the ratings of a group of users on a set of items to find personalized recommendations for each user. Traditionally they have been designed to work with one-dimensional ratings. With interest growing in recommendations based on multiple aspects of items, we present an algorithm for using multicomponent rating data. The presented mixture model-based algorithm uses the component rating dependency structure discovered by a structure learning algorithm. The structure is supported by the psychometric literature on the halo effect. This algorithm is compared with a set of model-based and instance-based algorithms for single-component ratings and their variations for multicomponent ratings. We evaluate the algorithms using data from Yahoo! Movies. Use of multiple components leads to significant improvements in recommendations. However, we find that the choice of algorithm depends on the sparsity of the training data. It also depends on whether the task of the algorithm is to accurately predict ratings or to retrieve relevant items. In our experiments a model-based multicomponent rating algorithm is able to better retrieve items when training data are sparse. However, if the training data are not sparse, or if we are trying to predict the rating values accurately, then the instance-based multicomponent rating collaborative filtering algorithms perform better. Beyond generating recommendations we show that the proposed model can fill in missing rating components. Theories in psychometric literature and the empirical evidence suggest that rating specific aspects of a subject is difficult. Hence, filling in the missing component values leads to the possibility of a rater support system to facilitate gathering of multicomponent ratings.
|keyword = collaborative filtering,multicomponent rating,halo effect,Bayesian network,mixture model,expectation maximization,recommender system,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''To Continue Sharing or Not to Continue Sharing? An Empirical Analysis of User Decision in Peer-to-Peer Sharing Networks'''
{{header}}
{{article
|author= Mu Xia,Yun Huang,Wenjing Duan,Andrew B. Whinston,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Peer-to-peer sharing networks have seen explosive growth recently. In these networks, sharing files is completely voluntary, and there is no financial reward for users to contribute. However, many users continue to share despite the massive free-riding by others. Using a large-scale data set of individual activities in a peer-to-peer music-sharing network, we seek to understand users' continued-sharing behavior as a private contribution to a public good. We find that the more benefit users "get from" the network, in the form of downloads, browses, and searches, the more likely they are to continue sharing. Also, the more value users "give to" the network, in the form of downloads by other users and recognition by the network, the more likely they are to continue sharing. Moreover, our findings suggest that, overall, "getting from" is a stronger force for the continued-sharing decision than "giving to."
|keyword = peer-to-peer networks,music sharing,IRC, voluntary contribution,sharer,free rider,public good,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Codiffusion of Wireless Voice and Data Services: An Empirical Analysis of the Japanese Mobile Telecommunications Market'''
{{header}}
{{article
|author= Marius F. Niculescu,Seungjin Whang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2012
|abstract = Wireless telecommunications have become over time a ubiquitous tool that not only sustains our increasing need for flexibility and efficiency, but also provides new ways to access and experience both utilitarian and hedonic information goods and services. This paper explores the parallel market evolution of the two main categories of wireless services-voice and data-in leading technology markets, inspecting the differences and complex interactions between the associated adoption processes. We propose a model that addresses specific individual characteristics of these two services and the stand-alone/add-on relationship between them. In particular, we acknowledge the distinction between the nonoverlapping classes of basic consumers, who only subscribe to voice plans, and sophisticated consumers, who adopt both services. We also account for the fact that, unlike voice services, data services rapidly evolved over time due to factors such as interface improvement, gradual technological advances in data transmission speed and security, and the increase in volume and diversity of the content and services ported to mobile Internet. Moreover, we consider the time gap between the market introduction of these services and allow for different corresponding consumer learning curves. We test our model on the Japanese wireless market. The empirical analysis reveals several interesting results. In addition to an expected one-way effect of voice on data adoption at the market potential level, we do find two-way codiffusion effects at the speed of adoption level. We also observe that basic consumers impact the adoption of wireless voice services in a stronger way compared to sophisticated consumers. This, in turn, leads to a decreasing average marginal network effect of voice subscribers on the adoption of wireless voice services. Furthermore, we find that the willingness of voice consumers to consider adopting data services is positively related to both time and penetration of 3G-capable handsets among voice subscribers.
|keyword = wireless telecommunication markets,mobile Internet,stand-alone and add-on services,network and imitation effects,codiffusion of contingent IT products and services,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE ENDS OF INFORMATION SYSTEMS RESEARCH: A PRAGMATIC FRAMEWORK'''
{{header}}
{{article
|author= Panos Constantinides,Mike W. Chiasson,Lucas D. Introna,
|source= MIS QUARTERLY
|year= 2012
|abstract = In this paper, we argue that any effort to understand the state of the Information Systems field has to view IS research as a series of normative choices and value judgments about the ends of research. To assist a systematic questioning of the various ends of IS research, we propose a pragmatic framework that explores the choices IS researchers make around theories and methodologies, ethical methods of conduct, desirable outcomes, and the long-term impact of the research beyond a single site and topic area. We illustrate our framework by considering and questioning the explicit and implicit choices of topics, design and execution, and the representation of knowledge in experimental research-research often considered to be largely beyond value judgments and power relations. We conclude with the implications of our pragmatic framework by proposing practical questions for all IS researchers to consider in making choices about relevant topics, design and execution, and representation of findings in their research.
|keyword = IS research practice,rigor and relevance,pragmatism,ethics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''SHACKLED TO THE STATUS QUO: THE INHIBITING EFFECTS OF INCUMBENT SYSTEM HABIT, SWITCHING COSTS, AND INERTIA ON NEW SYSTEM ACCEPTANCE'''
{{header}}
{{article
|author= Greta L. Polites,Elena Karahanna,
|source= MIS QUARTERLY
|year= 2012
|abstract = Given that adoption of a new system often implies Ally or partly replacing an incumbent system, resistance is often manifested as failure of a user to switch from an incumbent technology to a newly introduced one. Thus, a potential source of resistance to adopting a new system lies in the use of an incumbent system. Using the status quo bias and habit literatures as theoretical lenses, the study explains how use of an incumbent system negatively impacts new system perceptions and usage intentions. We argue that habitual use of an incumbent system, rationalization due to perceived transition costs, and psychological commitment due to perceived sunk costs all encourage development of inertia. Inertia in turn filly mediates the impact of these incumbent system constructs on constructs related to acceptance of the new system via psychological commitment based on cognitive consistency and by increasing the importance of normative pressures. Specifically, we hypothesize that inertia leads to decreased perceptions of the ease of use and relative advantage of a newly introduced system and has a negative impact on intentions to use the new system, above and beyond its impact through perceptions. Finally, we hypothesize that inertia moderates the relationship between subjective norm and intention, such that normative pressures to use a new system become more important in the presence of inertia. Empirical results largely support the hypothesized relationships showing the inhibiting effect of incumbent-system habit, transition and sunk costs, and inertia on acceptance of a new system. Our study thus extends theoretical understanding of the role of incumbent system constructs such as habit and inertia in technology acceptance, and lays the foundations for further study of the interplay between perceptions and cognition with respect to the incumbent system and those with respect to a new system.
|keyword = IS habit,technology acceptance,inhibitors,inertia,switching costs,status quo bias,subjective norm,sunk costs,transition costs,incumbent system,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ARE MARKETS FOR VULNERABILITIES EFFECTIVE?'''
{{header}}
{{article
|author= Sam Ransbotham,Sabyaschi Mitra,Jon Ramsey,
|source= MIS QUARTERLY
|year= 2012
|abstract = Current reward structures in security vulnerability disclosure may be skewed toward benefiting nefarious usage of vulnerability information rather than responsible disclosure. Recently suggested market-based mechanisms offer incentives to responsible security researchers for discovering and reporting vulnerabilities. However, concerns exist that any benefits gained through increased incentives for responsible discovely may be lost through information leakage. Using perspectives drawn from the diffusion of innovations literature, we examine the effectiveness of market-based vulnerability disclosure mechanisms. Empirical examination of two years of security alert data finds that market-based disclosure restricts the diffusion of vulnerability exploitations, reduces the risk of exploitation, and decreases the volume of exploitation attempts.
|keyword = Information security,vulnerability disclosure,information technology policy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''RECOMMENDATION NETWORKS AND THE LONG TAIL OF ELECTRONIC COMMERCE'''
{{header}}
{{article
|author= Gal Oestreicher-Singer,Arun Sundararajan,
|source= MIS QUARTERLY
|year= 2012
|abstract = It has been conjectured that the peer-based recommendations associated with electronic commerce lead to a redistribution of demand from popular products or "blockbusters" to less popular or "niche" products, and that electronic markets will therefore be characterized by a "long tail" of demand and revenue. We test this conjecture using the revenue distributions of books in over 200 distinct categories on Amazon. corn and detailed daily snapshots of co-purchase recommendation networks in which the products of these categories are situated. We measure how much a product is influenced by its position in this hyperlinked network of recommendations using a variant of Google's PageRank measure of centrality. We then associate the average influence of the network on each category with the inequality in the distribution of its demand and revenue, quantifying this inequality using the Gini coefficient derived from the category's Lorenz curve. We establish that categories whose products are influenced more by the recommendation network have significantly flatter demand and revenue distributions, even after controlling for variation in average category demand, category size, and price differentials. Our empirical findings indicate that doubling the average network influence on a category is associated with an average increase of about 50 percent in the relative revenue for the least popular 20 percent of products, and with an average reduction of about 15 percent in the relative revenue for the most popular 20 percent of products. We also show that this effect is enhanced by higher assortative mixing and lower clustering in the network, and is greater in categories whose products are more evenly influenced by recommendations. The direction of these results persists over time, across both demand and revenue distributions, and across both daily and weekly demand aggregations. Our work illustrates how the microscopic economic data revealed by online networks can be used to define and answer new kinds of research questions, offers a fresh perspective on the influence of networked IT artifacts on business outcomes, and provides novel empirical evidence about the impact of visible recommendations on the long tail of electronic commerce.
|keyword = Networks,social networks,electronic commerce,recommender systems,Gini coefficient,long tail,influence,social media,Web 2.0,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE IMPACT OF ANALYST-INDUCED MISINFORMATION ON THE REQUIREMENTS ELICITATION PROCESS'''
{{header}}
{{article
|author= Radha Appan,Glenn J. Browne,
|source= MIS QUARTERLY
|year= 2012
|abstract = Information requirements determination (IRD) is concerned with developing accurate requirements for a proposed system, primarily by eliciting information from users and other organizational stakeholders. In this paper we build and test theory concerning a significant threat to the accuracy of information requirements, termed the misinformation effect. Misinformation is distorted, false, or other erroneous or misleading information that does not reflect the true state of the world or state of mind of the person communicating the information. The misinformation effect refers to the tendency of people to recall misleading or false information introduced to them following an event instead of original material learned or observed at the time the event occurred. During user analyst communication in the IRD process, analysts may introduce misinformation in their discussions with users. We use the misinformation effect literature to hypothesize that in such circumstances users are likely to recall misinformation introduced by analysts rather than their true beliefs and knowledge of facts. Additionally, we use literature in social psychology to hypothesize that the misinformation effect will be stronger when misinformation is introduced using a social technique rather than a nonsocial technique. We conducted an experiment to test the misinformation effect in the requirements elicitation process. Results indicated that (I) introduction of misinformation reduces the accuracy of requirements provided by users, and (2) social techniques (interviews) are more vulnerable to the misinformation effect than nonsocial techniques (surveys). Our research contributes to the information systems literature by identifying an important reason that requirements provided by users may be inaccurate, and to IRD practice by identifying important dilemmas caused by the misinformation effect as well as potential solutions. We also contribute to the psychology literature by demonstrating the existence of the misinformation effect with users' experiential factual knowledge and beliefs in a business context, and by aiding in understanding the underlying causes of the misinformation effect. We discuss implications of our findings and directions for future research to address challenges resulting from the misinformation effect.
|keyword = Information requirements determination,misinformation effect,user-analyst communication,user participation,elicitation techniques,systems development,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''HUMAN CAPITAL DEVELOPMENT FOR PROGRAMMERS USING OPEN SOURCE SOFTWARE'''
{{header}}
{{article
|author= Amit Mehra,Vijay Mookerjee,
|source= MIS QUARTERLY
|year= 2012
|abstract = A firm can upgrade relevant skills of its programmers by ensuring their participation in carefully chosen open source projects. Highly skilled programmers are more valuable for the firm but participating in open source projects reduces the time they spend doing the firm's projects. This tradeoff determines the optimal extent of programmer participation in open source for the firm. The extent of open source participation may also be influenced by the minimum compensation that must be paid to hire a programmer in the labor market. This is because providing better skills is a way of compensating the programmers by improving their future market value. Hence the firm may want to increase open source participation to keep direct wage payments in check. We develop an analytical model based on optimal control theory to characterize the employment contract that features the best mix of open source participation and wage payments. We also find that the firm benefits more from the presence of open source in a tight labor market (i.e., when programmers have good options besides the employment offered by the firm). On the other hand, programmers are compensated better in the presence of open source opportunities when they have few outside options. This benefit is more for less skilled programmers.
|keyword = Human capital,open source software,employment contracts,training,skill development incentives,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''REVISITING BIAS DUE TO CONSTRUCT MISSPECIFICATION: DIFFERENT RESULTS FROM CONSIDERING COEFFICIENTS IN STANDARDIZED FORM'''
{{header}}
{{article
|author= Miguel I. Aguirre-Urreta,George M. Marakas,
|source= MIS QUARTERLY
|year= 2012
|abstract = Researchers in a number of disciplines, including Information Systems, have argued that much of past research may have incorrectly specified the relationship between latent variables and indicators as reflective when an understanding of a construct and its measures indicates that a formative specification would have been warranted. Coupled with the posited severe biasing effects of construct misspecification on structural parameters, these two assertions would lead to concluding that an important portion of our literature is largely invalid. While we do not delve into the issue of when one specification should be employed over another, our work here contends that construct misspecification, but with a particular exception, does not lead to severely biased estimates. We argue, and show through extensive simulations, that a lack of attention to the metric in which relationships are expressed is responsible for the current belief in the negative effects of misspecification.
|keyword = Construct specification,formative,reflective,simulations,standardized coefficients,unstandardized coefficients,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE CRITICAL IMPORTANCE OF CONSTRUCT MEASUREMENT SPECIFICATION: A RESPONSE TO AGUIRRE-URRETA AND MARAKAS'''
{{header}}
{{article
|author= Stacie Petter,Arun Rai,Detmar Straub,
|source= MIS QUARTERLY
|year= 2012
|abstract = Aguirre-Urreta and Marakas (A&M) suggest in their simulation "Revisiting Bias Due to Construct Misspecification: Different Results from Considering Coefficients in Standardized Form," that, like Jarvis et al. (2003), MacKenzie et al. (2005), and Petter et al. (2007) before them, bias does occur when formative constructs are misspecified as reflective. But A&M argue that the level of bias in prior simulation studies has been exaggerated. They parameterize their simulation models using standardized coefficients in contrast to Jarvis et al., MacKenzie et al., and Petter et al., who parameterize their simulation models using unstandardized coefficients. Thus, across these four simulation studies, biases in parameter estimates are likely to result in misspecified measurement models (i.e., using either unstandardized or standardized coefficients); yet, the biases are greater in magnitude when unstandardized coefficients are used to parameterize the misspecified model. We believe that regardless of the extent of the bias, it is critically important for researchers to achieve correspondence between the measurement specification and the conceptual meaning of the construct so as to not alter the theoretical meaning of the construct at the operational layer of the model. Such alignment between theory and measurement will safeguard against threats to construct and statistical conclusion validity.
|keyword = Formative measurement,construct misspecification,standardized coefficients,unstandardized coefficients,simulation,construct validity,statistical conclusion validity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CONSUMER ACCEPTANCE AND USE OF INFORMATION TECHNOLOGY: EXTENDING THE UNIFIED THEORY OF ACCEPTANCE AND USE OF TECHNOLOGY'''
{{header}}
{{article
|author= Viswanath Venkatesh,James Y. L. Thong,Xin Xu,
|source= MIS QUARTERLY
|year= 2012
|abstract = This paper extends the unified theory of acceptance and use of technology (UTAUT) to study acceptance and use of technology in a consumer context. Our proposed UTAUT2 incorporates three constructs into UTAUT: hedonic motivation, price value, and habit. Individual differences-namely, age, gender, and experience-are hypothesized to moderate the effects of these constructs on behavioral intention and technology use. Results from a two-stage online survey, with technology use data collected four months after the first survey, of 1,512 mobile Internet consumers supported our model. Compared to UTA UT, the extensions proposed in UTAUT2 produced a substantial improvement in the variance explained in behavioral intention (56 percent to 74 percent) and technology use (40 percent to 52 percent). The theoretical and managerial implications of these results are discussed.
|keyword = Unified theory of acceptance and use of technology (UTAUT),UTAUT2,habit,hedonic motivation,price value,mobile Internet,consumer,technology adoption,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE CONSEQUENCES OF INFORMATION TECHNOLOGY CONTROL WEAKNESSES ON MANAGEMENT INFORMATION SYSTEMS: THE CASE OF SARBANES-OXLEY INTERNAL CONTROL REPORTS'''
{{header}}
{{article
|author= Chan Li,Gary F. Peters,Vernon J. Richardson,Marcia Weidenmier Watson,
|source= MIS QUARTERLY
|year= 2012
|abstract = In this article, the association between the strength of information technology controls over management information systems and the subsequent forecasting ability of the information produced by those systems is investigated. The Sarbanes-Oxley Act of 2002 highlights the importance of information system controls by requiring management and auditors to report on the effectiveness of internal controls over the financial reporting component of the firm's management information systems. We hypothesize and find evidence that management forecasts are less accurate for firms with information technology material weaknesses in their financial reporting system than the forecasts for firms that do not have information technology material weaknesses. In addition, we examine three dimensions of information technology material weaknesses: data processing integrity, system access and security, and system structure and usage. We find that the association with forecast accuracy appears to be strongest for IT control weaknesses most directly related to data processing integrity. Our results support the contention that information technology controls, as apart of the management information system, affect the quality of the information produced by the system. We discuss the complementary nature of our findings to the information and systems quality literature.
|keyword = Sarbanes-Oxley,internal controls,information quality,management forecast,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION TECHNOLOGY AND FIRM PROFITABILITY: MECHANISMS AND EMPIRICAL EVIDENCE'''
{{header}}
{{article
|author= Sunil Mithas,Ali Tafti,Indranil Bardhan,Jie Mein Goh,
|source= MIS QUARTERLY
|year= 2012
|abstract = Do information technology investments improve firm profitability? Ifs, is this effect because such investments help improve sales, or is it because they help reduce overall operating expenses? How does the effect of IT on profitability compare with that of advertising and of research and development? These are important questions because investments in IT constitute a large part of firms discretionary expenditures, and managers need to understand the likely impacts and mechanisms to justify and realize value from their IT and related resource allocation processes. The empirical evidence in this paper, derived using archival data from 199810 2003 for more than 400 global firms, suggests that IT has a positive impact on profitability. Importantly, the effect of IT investments on sales and profitability is higher than that of other discretionary investments, such as advertising and R&D. A significant portion of the impact of IT on firm profitability is accounted for by IT-enabled revenue growth, but there is no evidence for the effect of IT on profitability through operating cost reduction. Taken together, these findings suggest that firms have had greater success in achieving higher profitability through IT-enabled revenue growth than through IT-enabled cost reduction. They also provide important implications for managers to make allocations among discretionary expenditures such as IT, advertising, and R&D. With regard to IT expenditures, the results imply that firms should accord higher priority to IT projects that have revenue growth potential over those that focus mainly on cost savings.
|keyword = Information technology,profitability,revenue growth,cost reduction,firm performance,discretionary expenditures,advertising,research and development,resource-based view,profitability paradox,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COCREATING IT VALUE: NEW CAPABILITIES AND METRICS FOR MULTIFIRM ENVIRONMENTS'''
{{header}}
{{article
|author= Varun Grover,Rajiv Kohli,
|source= MIS QUARTERLY
|year= 2012
|abstract = Most research on IT value has been from the vantage point of a single firm. Multifirm studies have largely been dyadic and emphasize transaction costs over cocreation of value. Contemporary environments involve IT investments being made by multiple companies in cooperative, platform-based, and relational arrangements where the objective is to cocreate value. If IT serves as a tool, an output. or is instrumental in generating this cocreated value, then it falls within the cocreation domain of this special issue. In this introductory article, we frame the discussion of cocreating IT value through four layers of relational arrangement between firms, describe the papers in the special issue with respect to this framework, and briefly describe an agenda for research in this important area.
|keyword = Information technology value,cocreation of value,multifirm environments,IT-based relationship value,IT-based platforms,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INTERFIRM IT CAPABILITY PROFILES AND COMMUNICATIONS FOR COCREATING RELATIONAL VALUE: EVIDENCE FROM THE LOGISTICS INDUSTRY'''
{{header}}
{{article
|author= Arun Rai,Paul A. Pavlou,Ghiyoung Im,Steve Du,
|source= MIS QUARTERLY
|year= 2012
|abstract = This study seeks to identify the means by which information technology helps cocreate relational value in the context of interfirm relationships in the logistics industry-a large and information-intensive industry. We identify a set of IT functionalities-single-location shipping, multilocation shipping, supply chain visibility, and financial settlement-that can be used to manage the flows of physical goods, information, and finances across locations in interfirm logistics processes. Progressively more advanced sets of IT functionalities, when implemented and used in the interfirm relationship to execute logistics processes, are proposed to form four distinct IT capability profiles of increased sophistication. Interfirm IT capability profiles of higher sophistication are proposed to help cocreate greater relational value by facilitating the flows of physical goods, information, and finances across locations in the interfirm logistics process. Besides their direct role in helping cocreate relational value, these interfirm IT capability profiles are proposed to further enhance relational value cocreation when complemented by interfirm communications for business development and IT development. Our empirical study was situated in one of the world's largest logistics suppliers and over 2,000 of its interfirm relationships with buyers across industries. Integrated data from four archival sources on the IT functionalities implemented and used in interfirm logistics relationships, interfirm communications, relational value (share of wallet and loyalty), and multiple control variables were collected. The results show that the proposed interfirm IT capability profiles and interfirm communications have both a direct and an interaction effect on relational value. Implications for cocreating relational value in interfirm relationships with the aid of IT are discussed.
|keyword = Relational value,relational view,share of wallet,interfirm relationships,IT capability profiles,IT functionalities,contact streams,interfirm communications,complementarities,logistics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COCREATION OF VALUE IN A PLATFORM ECOSYSTEM: THE CASE OF ENTERPRISE SOFTWARE'''
{{header}}
{{article
|author= Marco Ceccagnoli,Chris Forman,Peng Huang,D. J. Wu,
|source= MIS QUARTERLY
|year= 2012
|abstract = It has been argued that platform technology owners cocreate business value with other firms in their platform ecosystems by encouraging complementary invention and exploiting indirect network effects. In this study, we examine whether participation in an ecosystem partnership improves the business performance of small independent software vendors (ISVs) in the enterprise software industry and how appropriability mechanisms influence the benefits of partnership. By analyzing the partnering activities and performance indicators of a sample of 1,210 small ISVs over the period 1996-2004, we find that joining a major platform owner's platform ecosystem is associated with an increase in sales and a greater likelihood of issuing an initial public offering (IPO). In addition, we show that these impacts are greater when ISVs have greater intellectual property rights or stronger downstream capabilities. This research highlights the value of inter-operability between software products, and stresses that value cocreation and appropriation are not mutually exclusive strategies in interfirm collaboration.
|keyword = Platform ecosystem,partnership,business value,sales,IPO,intellectual property rights,downstream capabilities,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''VALUE COCREATION AND WEALTH SPILLOVER IN OPEN INNOVATION ALLIANCES'''
{{header}}
{{article
|author= Kunsoo Han,Wonseok Oh,Kun Shin Im,Ray M. Chang,Hyelim Oh,Alain Pinsonneault,
|source= MIS QUARTERLY
|year= 2012
|abstract = In this study, we investigate the economic and strategic value of open innovation alliances (OIAs), in which collaborators and competitors integrate in the pursuit of the codevelopment of technological innovations. Given that OIAs differ substantially from traditional, closed alliances in many aspects, including their strategic scope and scale, governing mechanisms, and member composition, it is important to understand and assess the potential value inherent in these new modes of collaboration. Furthermore, OIAs evolve over time as the participating members are free to enter and leave at will. Therefore, we also examine the on-going value creation and wealth spillover that result from changes in membership. Moreover, we investigate how a firm's participation in an IT-based open alliance alters the market value of its rivals operating within the same marketplace. To gain additional insight into the factors that moderate the market valuation of OIA participation, several contextual factors, including the degree of partner heterogeneity, innovation type, and degree of openness of the OIAs are used to account for variability in abnormal returns. Based on 194 observations, we found that allying firms realize significant positive abnormal returns when their entry into an OIA is made public. The results also suggest that substantial excessive returns accrue to the allying firms with the belated entry of a market leader firm. Furthermore, we discovered that a firm's entry into an OIA increases, rather than decreases, the market valuation of its rivals. Interestingly, an incumbent rival that did not participate in the alliance appears to gain greater "free-riding" benefits from the OIA, as compared to peer rivals. Innovation type and openness were significantly associated with the amount of abnormal returns accruing to allying firms, while no significance was found for partner heterogeneity. Finally, we conclude with a discussion of the implications of our findings for research and practice with respect to value cocreation in multifirm environments.
|keyword = Open innovation,open innovation alliances,value cocreation,wealth spillover,event study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EXPLORING VALUE COCREATION IN RELATIONSHIPS BETWEEN AN ERP VENDOR AND ITS PARTNERS: A REVELATORY CASE STUDY'''
{{header}}
{{article
|author= Suprateek Sarker,Saonee Sarker,Arvin Sahaym,Niels Bjorn-Andersen,
|source= MIS QUARTERLY
|year= 2012
|abstract = Contemporary business organizations are increasingly turning their attention to jointly creating value with a variety of stakeholders. such as individual customers and other business organizations. However, a review of the literature reveals that very few studies have systematically examined value cocreation within business-to-business (B2B) contexts. Using a revelatory case study of the relationship between an ERP vendor with a global reputation and its partners, and informed by the resource-based view of the firm and related theoretical perspectives, we develop an understanding of value cocreation in B2B alliances associated with selling, extending, and implementing packaged software, specifically ERP systems. Our study reveals that there are different mechanisms underlying value cocreation within B2B alliances, and also points to several categories of contingency Actors that influence these mechanisms. In addition to providing insights about the phenomenon of cocreation itself the study contributes to the stream of packaged software literature, where the implications of value cocreation in alliances between packaged software vendors and their partners for the client organizations have not been sufficiently explored.
|keyword = Value creation,cocreation,business-to-business alliance,ERP systems,SME market,vendor-partner relationship,information technology characteristics,case study,interpretive study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Value Chain Linkages and the Spillover Effects of Strategic Information Technology Alignment: A Process-Level View'''
{{header}}
{{article
|author= Paul P. Tallon,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = The alignment of information technology (IT) and business strategy is a perennial challenge for corporate executives. While earlier studies confirm the value of alignment, there is still some question as to how alignment creates value and the level at which value is created. In this research, we use a series of theoretical arguments based on the interconnected structure of the value chain to consider the extended effects of alignment at the process level. Since processes are often linked to create a complex chain of activities, the absence or presence of alignment in any process could have implications for business performance elsewhere in the value chain. Minimally aligned processes can not only disrupt performance within the focal process, but their effects may also be felt further downstream in the form of bottlenecks and a diminution in the business value of IT. Using a simplified form of the value chain and data from matched surveys of business and IT executives at 317 U. S. and EU firms, we examine how the effects of alignment on a given process spill over into processes further downstream, creating higher IT business value in those downstream processes. We also show that these spillover effects continue along the length of the value chain and do not diminish based on distance from the focal process. Our results reinforce the call for firms to improve the fit between business and IT strategy by showing how efforts to improve alignment in a given process can deliver a stream of benefits along the value chain. This research provides a fresh perspective on the value of alignment, facilitating a deeper understanding and appreciation of the link between strategic IT alignment and firm performance.
|keyword = IT business value,process bottlenecks,profile deviation,spillover effects,strategic IT alignment,value chain,value disciplines,value flows,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Path Dependence of Dynamic Information Technology Capability: An Empirical Investigation'''
{{header}}
{{article
|author= Jee-Hae Lim,Theophanis C. Stratopoulos,Tony S. Wirjanto,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Organizations seek to differentiate themselves in the marketplace by deploying information technology (IT) to develop dynamic IT capabilities and resist competitors' attempts to imitate or improve these capabilities. While this strategy has been justified on the grounds that dynamic IT capabilities are durably heterogeneous, there does not seem to be empirical evidence supporting or refuting this assumption. This study empirically validates the assumption of durable heterogeneity of dynamic organizational IT capability (ITC) due to path dependence. We capture ITC heterogeneity by introducing a framework in which firms try to achieve ITC leadership in their industry and we propose that durable ITC heterogeneity can be attributed to path dependence, and hence, it can be tested using Heckman's true state dependence of ITC leadership status. Using random and fixed effect dynamic logit models, we investigate true state dependence of ITC leadership on a sample of large U. S. firms. The results, which are robust to alternative sample, dependent, and control variable specifications, show that achieving ITC leadership is a true state-dependent process, suggesting durable heterogeneity of ITC due to path dependence. The study contributes to the dynamic capabilities literature and has important managerial implications. The proposed framework for conceptualizing durable resource heterogeneity due to path dependence is general and versatile, thus providing a foundation for future research on dynamic capabilities. The findings provide empirical evidence to confirm that ITC is durably heterogeneous and should be managed as a potential source of competitive advantage.
|keyword = dynamic organizational IT capability,dynamic random effects,fixed effects logit models,IT business value,path dependence,true state dependence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Service Quality in Software-as-a-Service: Developing the SaaS-Qual Measure and Examining Its Role in Usage Continuance'''
{{header}}
{{article
|author= Alexander Benlian,Marios Koufaris,Thomas Hess,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Despite the need to better understand how customers of software-as-a-service (SaaS) solutions perceive the quality of these software services and how these perceptions influence SaaS adoption and use, there is no extant measure that comprehensively captures service quality evaluations in SaaS. Based on previous SERVQUAL and SaaS literature, field interviews and focus groups, a card-sorting exercise, and two surveys of SaaS using companies, we develop, refine, and test SaaS-Qual, a zones-of-tolerance (ZOT)-based service quality measurement instrument specifically for SaaS solutions. Besides validating already established service quality dimensions (i.e., rapport, responsiveness, reliability, and features), we identify two new factors (i.e., security and flexibility) that are essential for the evaluation of service quality of SaaS solutions. SaaS-Qual demonstrates strong psychometric properties and shows high nomological validity within a framework that predicts the continued use of SaaS solutions by existing customers. In addition to developing a validated instrument that provides a fine-grained measurement of SaaS service quality, we also enrich existing research models on information systems continuance. Moreover, the SaaS-Qual instrument can be used as a diagnostic tool by SaaS providers and users alike to spot strengths and weaknesses in the service delivery of SaaS solutions.
|keyword = IS continuance,SaaS-Qual,service quality,SERVQUAL,software-as-a-service,zones of tolerance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Benchmarking Model for Management of Knowledge-Intensive Service Delivery Networks'''
{{header}}
{{article
|author= Su Dong,Monica S. Johar,Ram L. Kumar,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Effective management of information technology (IT) and IT-enabled services is becoming increasingly important due to the growing complexity of their context. These services are often delivered by employees who work at widely dispersed locations and interact with each other to constitute knowledge-intensive service delivery networks (KISDNs). This paper contributes to the effective design and management of KISDNs by presenting a mixed-integer programming model that integrates disparate streams of research. This model facilitates analysis and managerial benchmarking of KISDN performance. It captures how the performance of such networks depends on the interaction between workflow decisions, structure of information flow networks (IFNs), and knowledge management decisions. We propose that knowledge about IFNs and worker competence can be effectively used to make workflow decisions. Our results, based on the study of different IFN archetypes, illustrate practices for effective management of KISDNs. Managers can enhance business value by recognizing existing IFNs, increasing randomness in IFNs, nurturing weak or performative ties depending on the archetype, assigning tasks based on effective worker competence, and selectively delaying assignment of tasks to workers. In addition, our results illustrate the impact of training and network density on KISDN performance.
|keyword = benchmarking,IT services,knowledge-based services,knowledge management,OR models,service delivery,service science,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Value of Information Integration to Supply Chain Management: Roles of Internal and External Contingencies'''
{{header}}
{{article
|author= Christina W. Y. Wong,Kee-Hung Lai,T. C. E. Cheng,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = While integrating information flows between internal organizational functions and across partner firms is widely acknowledged as a contributor to organizational competitiveness, there is little empirical research on the effects of situational factors on the success of information integration. Based on contingency theory, we address the following question: Under what circumstances does information integration contribute to better performance outcomes in supply chain management (SCM)? Our results provide a contingency perspective of information integration, which highlights that the performance outcomes of information integration are contingent on both external environmental conditions and internal operational characteristics. We find that information integration improves firms' ability to perform, particularly when they operate under favorable environmental conditions-a highly munificent and a less uncertain environment-and when they offer durable and complex products. Our findings advance contingency research on the performance outcomes of information integration for SCM. Our study provides managers with empirical insights on the effects of information integration on the cost and customer-oriented operational performance of SCM under favorable and unfavorable environmental conditions.
|keyword = business environment,information integration,IT-enabled supply chain,IT value,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Influence of Individual, Contextual, and Social Factors on Perceived Behavioral Control of Information Technology: A Field Theory Approach'''
{{header}}
{{article
|author= Christophe Elie-Dit-Cosaque,Jesie Pallud,Michel Kalika,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Organizations are increasingly concerned about ensuring that workers have sufficient sense of control over the information technology (IT) that they use. However, we know little about the antecedents of the end user's perceived behavioral control (PBC) with respect to IT. Drawing on Kurt Lewin's field theory, the present study responds to this concern by formulating and testing a model whereby individual, contextual, and social forces influence PBC directly and indirectly via computer anxiety. In order to test the model, a survey was conducted in France with IT end users enrolled in professional training programs. The results show that increasing autonomy, offering appropriate managerial support, reducing work overload, and perceived innovativeness with IT can together reduce computer anxiety and increase PBC. These findings emphasize the forces that managers can manipulate in order to foster users' feelings of control with respect to IT in the workplace. Following this, the paper makes three main contributions to research. First, it increases our knowledge of the nomological net surrounding PBC by shedding light on the joint influences of internal, external, and social forces on this variable. Second, it reveals the role of computer anxiety, emphasizing that it is an important conduit through which these forces influence workers' PBC. Third, the paper shows how Lewin's field theory can help to create richer and less fragmented models in order to capture more fully the determinants of IT adoption and adaptation. The practical implications regarding the actions that managers can take in order to increase workers' PBC are discussed.
|keyword = autonomy,computer anxiety,control over IT,demand-control model,field theory,managerial support,perceived behavioral control,personal innovativeness with IT,work environment,work overload,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Seller Strategies for Differentiation in Highly Competitive Online Auction Markets'''
{{header}}
{{article
|author= Jese Bockstedt,Kim Huat Goh,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = We explore the issue of seller differentiation in competitive auction environments, where most sellers have a high percentage of positive feedback. Analyzing a set of eBay auction listings for identical products, we find evidence that the use of visibility-enhancing and quality-signaling discretionary auction attributes affects auction outcomes throughout the auction process (i.e., listing views, bids, and price premiums). We also find strong evidence that the number of reputable sellers in an auction marketplace moderates the effects of these discretionary attributes on auction outcomes. Specifically, as auction environments become more competitive, these attributes become more effective tools for differentiation, whereas seller feedback scores become less effective. Furthermore, sellers appear to select their strategies for employing these discretionary attributes based on both their prior experience and the number of experienced reputable sellers in the market. These findings suggest that in addition to relying on feedback scores, online sellers must take a more strategic approach in the selection of discretionary attributes in their auction listings.
|keyword = differentiation,e-auctions,online auctions,seller differentiation,signaling theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Usability Design and Psychological Ownership of a Virtual World'''
{{header}}
{{article
|author= Younghwa Lee,Andrew N. K. Chen,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Virtual worlds, immersive three-dimensional virtual spaces where users interact with projected identities of other users (avatars) and objects, are becoming increasingly popular and continue to grow as highly interactive, collaborative, and commercial cyberspaces. However, extant research in this context has not paid much attention to usability design of a virtual world and corresponding effects on users' psychological desire to own and control the space and objects within it and subsequent behavior intention. In this study, we apply concepts of Web site usability and psychological ownership to develop a model that illustrates the relationships between seven usability factors (legibility, firmness, coherence, variety, mystery, classic, and expressive visual aesthetics), four antecedents of psychological ownership (cognitive appraisals, perceived control, affective appraisals, and self-investment), psychological ownership, and use intention. A cross-sectional study with 239 Second Life users was conducted. The results demonstrate that designing a usable virtual world that induces strong psychological ownership is crucial to attract users to spend more time, participate in more activities, and revisit the virtual world. This is an important finding for forward-looking e-business managers looking to invest their limited resources in designing a usable virtual world. In addition, by using our model and corresponding survey items, designers can benchmark and evaluate the usability of their current virtual worlds, compare the results to the designs of competitors, and upgrade the offerings of virtual worlds, as needed, by allocating available resources to the most influential design factors to suit their specific needs.
|keyword = architectural quality model,human-computer interaction,landscape preference model,psychological ownership,usability,virtual worlds,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Factors Affecting Bloggers' Knowledge Sharing: An Investigation Across Gender'''
{{header}}
{{article
|author= Sangmi Chai,Sanjukta Das,H. Raghav Rao,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Blogs have emerged as an innovative tool for sharing information and knowledge, and they command significant interest from information technology (IT) users as well as providers. Our study establishes a research framework to provide an understanding of the factors affecting knowledge sharing among bloggers in online social networks. The research results indicate that bloggers' trust, strength of social ties, and reciprocity all have a positive effect on their knowledge-sharing behavior. Further, the impact of each factor on such behavior varies by gender. Our results provide evidence that offline expected social norms tend to persist in the online blogosphere and that gender differences need to be considered as a significant factor in understanding the IT usage behavior in the context of social capital theory. For IT managers and blog service providers, our results also highlight the importance of being gender aware in an effort to elicit participation from all constituent members for the successful adoption and usage of blogs as a knowledge-sharing mechanism.
|keyword = bloggers,blogs,gender,information privacy,knowledge sharing,trust,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Same Coin, Different Sides: Differential Impact of Social Learning on Two Facets of Music Piracy'''
{{header}}
{{article
|author= Jingguo Wang,Zhiyong Yang,Sudip Bhattacharjee,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = We demonstrate that two intertwined activities of music piracy, unauthorized obtaining and unauthorized sharing, are differentially influenced by the same social learning environment. We develop a structural model and test it using survey data from a prime demographic set of respondents who engage in music piracy. Considering behavioral heterogeneity, we employ a factor mixture modeling technique to classify respondents into different groups that highlight distinct patterns of social learning influences. We find that the differential effects of social learning factors on obtaining and sharing persist across these groups. We further utilize demographic variables to profile members in each group for segmentation insights. From a theoretical perspective, our findings advance the understanding of music piracy and suggest the importance of separating obtaining from sharing activities when studying piracy. From a managerial perspective, our research provides new avenues for managers and policymakers to design targeted incentives to curtail music piracy.
|keyword = intellectual property infringement,latent class analysis,music piracy,partial least squares regression,social learning theory,unauthorized obtaining,unauthorized sharing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''NeuroIS: The Potential of Cognitive Neuroscience for Information Systems Research'''
{{header}}
{{article
|author= Angelika Dimoka,Paul A. Pavlou,Fred D. Davis,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = This paper introduces the idea of drawing upon the cognitive neuroscience literature to inform IS research (herein termed "NeuroIS"). Recent advances in cognitive neuroscience are uncovering the neural bases of cognitive, emotional, and social processes, and they offer new insights into the complex interplay between IT and information processing, decision making, and behavior among people, organizations, and markets. The paper reviews the emerging cognitive neuroscience literature to propose a set of seven opportunities that IS researchers can use to inform IS phenomena, namely (1) localizing the neural correlates of IS constructs, (2) capturing hidden mental processes, (3) complementing existing sources of IS data with brain data, (4) identifying antecedents of IS constructs, (5) testing consequences of IS constructs, (6) inferring the temporal ordering among IS constructs, and (7) challenging assumptions and enhancing IS theories. The paper proposes a framework for exploring the potential of cognitive neuroscience for IS research and offers examples of potentially fertile intersections of cognitive neuroscience and IS research in the domains of design science and human-computer interaction. This is followed by an example NeuroIS study in the context of e-commerce adoption using fMRI, which spawns interesting new insights. The challenges of using functional neuroimaging tools are also discussed. The paper concludes that there is considerable potential for using cognitive neuroscience theories and functional brain imaging tools in IS research to enhance IS theories.
|keyword = cognitive neuroscience,functional brain imaging,NeuroIS,neuroeconomics,neuromarketing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Cross-Business Information Technology Integration and Acquirer Value Creation in Corporate Mergers and Acquisitions'''
{{header}}
{{article
|author= Hueseyin Tanriverdi,Vahap Buelent Uysal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = This study develops and tests the idea that the cross-business information technology integration (CBITI) capability of an acquirer creates significant value for shareholders of the acquirer in mergers and acquisitions (M&A). In M&A, integrating the IT systems and IT management processes of acquirer and target could generate benefits such as (a) the consolidation of IT resources and the reduction of overall IT costs of the combined firm, (b) the development of an IT-based coordination mechanism and the realization of cross-firm business synergies, (c) the minimization of potential disruptions to business operations, and (d) greater ability to comply with relevant laws and regulations and the reduction of regulatory compliance costs. We test these ideas in a sample of 141 acquisitions conducted by 86 Fortune 1000 firms. In the short run, acquirers that have high levels of CBITI capabilities receive positive and significant cumulative abnormal returns to their M&A announcements. Announcement period returns indicate that the capital markets value CBITI similarly in same-industry and different-industry acquisitions. In the long run, acquirers with high levels of CBITI capabilities obtain significantly higher abnormal operating performance. They create significantly greater value in complementary acquisitions from different industries than in related acquisitions from the same industry. The findings have important implications for M&A research and practice.
|keyword = corporate mergers and acquisitions,cross-business IT integration,short-run abnormal stock returns,long-run abnormal operating performance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Pricing Digital Goods: Discontinuous Costs and Shared Infrastructure'''
{{header}}
{{article
|author= Ke-Wei Huang,Arun Sundararajan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = In this paper, we analyze a model of usage pricing for digital products with discontinuous supply functions. This model characterizes a number of information technology-based products and services for which variable increases in demand are fulfilled by the addition of blocks of computing or network infrastructure. Such goods are often modeled as information goods with zero variable costs; in fact, the actual cost structure resembles a mixture of zero marginal costs and positive periodic fixed costs. This paper discusses the properties of a general solution for the optimal nonlinear pricing of such digital goods. We show that the discontinuous cost structure can be accrued as a virtual constant variable cost. This paper applies the general solution to solve two related extensions by first investigating the optimal technology capacity planning when the cost function is both discontinuous and declining over time, and then characterizing the optimal costing for the discontinuous supply when it is shared by several business profit centers. Our findings suggest that the widely adopted full cost recovery policies are typically suboptimal.
|keyword = pricing digital goods,nonlinear pricing,infrastructure cost,IT chargeback,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Usercentric Operational Decision Making in Distributed Information Retrieval'''
{{header}}
{{article
|author= Kartik Hosanagar,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Information specialists in enterprises regularly use distributed information retrieval (DIR) systems that query a large number of information retrieval (IR) systems, merge the retrieved results, and display them to users. There can be considerable heterogeneity in the quality of results returned by different IR servers. Further, because different servers handle collections of different sizes and have different processing and bandwidth capacities, there can be considerable heterogeneity in their response times. The broker in the DIR system has to decide which servers to query, how long to wait for responses, and which retrieved results to display based on the benefits and costs imposed on users. The benefit of querying more servers and waiting longer is the ability to retrieve more documents. The costs may be in the form of access fees charged by IR servers or user's cost associated with waiting for the servers to respond. We formulate the broker's decision problem as a stochastic mixed-integer program and present analytical solutions for the problem. Using data gathered from FedStats-a system that queries IR engines of several U.S. federal agencies-we demonstrate that the technique can significantly increase the utility from DIR systems. Finally, simulations suggest that the technique can be applied to solve the broker's decision problem under more complex decision environments.
|keyword = distributed information retrieval (IR),personalization,utility theory,optimal operational decisions,source selection,query termination,stochastic modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Risk Management and Optimal Pricing in Online Storage Grids'''
{{header}}
{{article
|author= Sanjukta Das,Anna Ye Du,Ram Gopal,R. Ramesh,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Online storage service providers grant a way for companies to avoid spending resources on maintaining their own in-house storage infrastructure and thereby allowing them to focus on their core business activities. These providers, however, follow a fixed, posted pricing strategy that charges the same price in each time period and thus bear all the risk arising out of demand uncertainties faced by their client companies. We examine the effects of providing a spot market with dynamic prices and forward contracts to hedge against future revenue uncertainty. We derive revenue-maximizing spot and forward prices for a single seller facing a known set of buyers. We perform a simulation study using publicly available traffic data regarding Amazon S3 clients from Alexa.com to validate our analytical results. Our field study supports our analysis and indicates that spot markets alone can enhance revenues to Amazon, but this comes at the cost of increased risks due to the increased market share in the spot markets. Furthermore, adding a forward contract feature to the spot markets can reduce risks while still providing the benefits of enhanced revenues. Although the buyers incur an increase in costs in the spot market, adding a forward contract does not cause any additional cost increase while transferring the risk to the buyers. Thus, storage grid providers can greatly benefit by applying a forward contract alongside the spot market.
|keyword = online storage,grid computing,forward contracts,market mechanism design,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Protecting Privacy Against Record Linkage Disclosure: A Bounded Swapping Approach for Numeric Data'''
{{header}}
{{article
|author= Xiao-Bai Li,Sumit Sarkar,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Record linkage techniques have been widely used in areas such as antiterrorism, crime analysis, epidemiologic research, and database marketing. On the other hand, such techniques are also being increasingly used for identity matching that leads to the disclosure of private information. These techniques can be used to effectively reidentify records even in deidentified data. Consequently, the use of such techniques can lead to individual privacy being severely eroded. Our study addresses this important issue and provides a solution to resolve the conflict between privacy protection and data utility. We propose a data-masking method for protecting private information against record linkage disclosure that preserves the statistical properties of the data for legitimate analysis. Our method recursively partitions a data set into smaller subsets such that data records within each subset are more homogeneous after each partition. The partition is made orthogonal to the maximum variance dimension represented by the first principal component in each partitioned set. The attribute values of a record in a subset are then masked using a double-bounded swapping method. The proposed method, which we call multivariate swapping trees, is nonparametric in nature and does not require any assumptions about statistical distributions of the original data. Experiments conducted on real-world data sets demonstrate that the proposed approach significantly outperforms existing methods in terms of both preventing identity disclosure and preserving data quality.
|keyword = privacy,record linkage,data partitioning,data swapping,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Hidden Markov Model of Developer Learning Dynamics in Open Source Software Projects'''
{{header}}
{{article
|author= Param Vir Singh,Yong Tan,Nara Youn,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = This study develops a stochastic model to capture developer learning dynamics in open source software projects (OSS). A hidden Markov model (HMM) is proposed that allows us to investigate (1) the extent to which individuals learn from their own experience and from interactions with peers, (2) whether an individual's ability to learn from these activities varies as she evolves/learns over time, and (3) to what extent individual learning persists over time. We calibrate the model based on six years of detailed data collected from 251 developers working on 25 OSS projects hosted at Sourceforge. Using the HMM, three latent learning states (high, medium, and low) are identified, and the marginal impact of learning activities on moving the developer between these states is estimated. Our findings reveal different patterns of learning in different learning states. Learning from peers appears to be the most important source of learning for developers across the three states. Developers in the medium learning state benefit the most through discussions that they initiate. On the other hand, developers in the low and the high states benefit the most by participating in discussions started by others. While in the low state, developers depend entirely upon their peers to learn, whereas in the medium or high state, they can also draw upon their own experiences. Explanations for these varying impacts of learning activities on the transitions of developers between the three learning states are provided. The HMM is shown to outperform the classical learning curve model. The HMM modeling of this study contributes to the development of a theoretically grounded understanding of learning behavior of individuals. Such a theory and associated findings have important managerial and operational implications for devising interventions to promote learning in a variety of settings.
|keyword = hidden Markov model,learning curve,productivity,learning by doing,learning from peers,open source software,dynamic models,structural models,regime switching models,behavior dynamics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Identifying and Testing the Inhibitors of Technology Usage Intentions'''
{{header}}
{{article
|author= Ronald T. Cenfetelli,Andrew Schwarz,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = An important area of information systems (IS) research has been the identification of the individual-level beliefs that enable technology acceptance such as the usefulness, reliability, and flexibility of a system. This study posits the existence of additional beliefs that inhibit usage intentions and thus foster technology rejection rather than acceptance. We theorize that these inhibitors are more than just the antipoles of enablers (e.g., the opposite of usefulness or reliability) and so are distinct constructs worthy of their own investigation. Inhibitors are proposed to have effects on usage intentions beyond that of enablers as well as effects on enablers themselves. We report on a series of empirical studies designed to test the existence and effects of inhibitors. A candidate set of six inhibitors is shown to be distinct from enablers. These inhibitors are subsequently tested in a field study of 387 individuals nested within 32 different websites. Effects at both individual and website unit levels of analysis are tested using multilevel modeling. We find that inhibitors have negative effects on usage intentions, as well as on enablers, and these effects vary contingent upon individual or website unit levels of analysis. The overall results support the existence and importance of inhibitors in explaining individual intent to use-or not use-technology.
|keyword = usage intentions,inhibitors,nonacceptance,technology rejection,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Returns to Information Technology Outsourcing'''
{{header}}
{{article
|author= Kunsoo Han,Robert J. Kauffman,Barrie R. Nault,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = This study extends existing information technology (IT) productivity research by evaluating the contributions of spending in IT outsourcing using a production function framework and an economywide panel data set from 60 industries in the United States over the period from 1998 to 2006. Our results demonstrate that IT outsourcing has made a positive and economically meaningful contribution to industry output and labor productivity. It has not only helped industries produce more output, but it has also made their labor more productive. Moreover, our analysis of split data samples reveals systematic differences between high and low IT intensity industries in terms of the degree and impact of IT outsourcing. Our results indicate that high IT intensity industries use more IT outsourcing as a percentage of their output, but less as a percentage of their own IT capital, and they achieve higher returns from IT outsourcing. This finding suggests that to gain greater value from IT outsourcing, firms need to develop IT capabilities by intensively investing in IT themselves. By comparing the results from subperiods and analyzing a separate data set for the earlier period of 1987-1999, we conclude that the value of IT outsourcing has been stable from 1998 to 2006 and consistent over the past two decades. The high returns we find for IT outsourcing also suggest that firms may be underinvesting in IT outsourcing.
|keyword = economic analysis,industry analysis,information technology,IT impacts,IT intensity,IT outsourcing,output elasticity,production function,production theory,productivity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of Community Commitment on Participation in Online Communities'''
{{header}}
{{article
|author= Patrick J. Bateman,Peter H. Gray,Brian S. Butler,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Online discussion communities have become a widely used medium for interaction, enabling conversations across a broad range of topics and contexts. Their success, however, depends on participants' willingness to invest their time and attention in the absence of formal role and control structures. Why, then, would individuals choose to return repeatedly to a particular community and engage in the various behaviors that are necessary to keep conversation within the community going? Some studies of online communities argue that individuals are driven by self-interest, while others emphasize more altruistic motivations. To get beyond these inconsistent explanations, we offer a model that brings dissimilar rationales into a single conceptual framework and shows the validity of each rationale in explaining different online behaviors. Drawing on typologies of organizational commitment, we argue that members may have psychological bonds to a particular online community based on (a) need, (b) affect, and/or (c) obligation. We develop hypotheses that explain how each form of commitment to a community affects the likelihood that a member will engage in particular behaviors (reading threads, posting replies, moderating the discussion). Our results indicate that each form of community commitment has a unique impact on each behavior, with need-based commitment predicting thread reading, affect-based commitment predicting reply posting and moderating behaviors, and obligation-based commitment predicting only moderating behavior. Researchers seeking to understand how discussion-based communities function will benefit from this more precise theorizing of how each form of member commitment relates to different kinds of online behaviors. Community managers who seek to encourage particular behaviors may use our results to target the underlying form of commitment most likely to encourage the activities they wish to promote.
|keyword = online communities,virtual communities,discussion groups,commitment,online behavior,Web 2.0,social media,social technologies,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Knowledge Exploration and Exploitation: The Impacts of Psychological Climate and Knowledge Management System Access'''
{{header}}
{{article
|author= Alexandra Durcikova,Kelly J. Fadel,Brian S. Butler,Dennis F. Galletta,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Firms need to balance efficiency gains obtained through exploiting existing knowledge assets with long-term competitive viability achieved through exploring new knowledge resources. Because the use of knowledge management systems (KMSs) continues to expand, understanding how these systems affect exploration and exploitation practices at the individual level is important to advance both knowledge management theory and practice. This study reports the results of a multi-industry survey investigating how psychological climate and KMS access influence solution reuse (exploitation) and solution innovation (exploration) in the context of technical support work. Our results show that KMS access does not directly determine solution innovation or solution reuse. Instead, KMS access strengthens the positive relationship between a climate for innovation and solution innovation and reverses the positive relationship between a climate for autonomy and solution innovation. The implications for knowledge management research and practice are discussed.
|keyword = knowledge management systems,exploration,exploitation,psychological climate,technical support,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Influence of Trade-off Difficulty Caused by Preference Elicitation Methods on User Acceptance of Recommendation Agents Across Loss and Gain Conditions'''
{{header}}
{{article
|author= Young Eun Lee,Izak Benbasat,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Prior studies on product recommendation agents (RAs) have been based on the effort-accuracy perspective in which the amount of effort required to make a decision and the accuracy of such decisions are two dominant antecedents of user acceptance of RAs. The current study extends the effort-accuracy perspective by considering trade-off difficulty, a type of negative emotion that arises when attainment of one's goals is blocked by the attainment of other goals; consequently, one must make trade-offs among the conflicting goals. Many product purchase choices for which RAs are used require users to make trade-offs among conflicting product attributes. A key feature of RAs, the preference elicitation method (PEM), often compels users to make explicit trade-offs. We examine whether an RA's PEM generates trade-off difficulty, which, in turn, affects users' evaluations (i.e., perceived amount of effort and perceived accuracy of recommendations) and the resultant acceptance of the RA. Trade-off difficulty influences users' evaluations of an RA via perceived control over execution of the RA PEM. In addition, the decision context in which users employ a PEM moderates the degree to which that PEM generates trade-off difficulty. Specifically, a PEM generates a greater degree of trade-off difficulty in a choice context that leads to a loss than in a choice context that leads to a gain. Consequently, users exert more effort to cope with trade-off difficulty in a loss condition. Because users voluntarily spend more effort, the negative influence of perceived effort on users' acceptance of an RA-which is supported in prior studies-decreases in a loss condition. A laboratory experiment was conducted using two between-subject factors: two RAs, one that employed a trade-off-compelling PEM and the other a trade-off-hiding PEM, and two decision contexts, one of which was a loss condition and the other a gain condition. The results supported all of the hypotheses.
|keyword = product recommendation agent,effort-accuracy framework,decision context,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''NETWORK EFFECTS: THE INFLUENCE OF STRUCTURAL CAPITAL ON OPEN SOURCE PROJECT SUCCESS'''
{{header}}
{{article
|author= Param Vir Singh,Yong Tan,Vijay Mookerjee,
|source= MIS QUARTERLY
|year= 2011
|abstract = What determines the success of open source projects? In this study, we investigate the impact of network social capital on open source project success. We define network social capital as the benefits open source developers secure from their membership in developer collaboration networks. We focus on one specific type of success as measured by the rate of knowledge creation in an open source project. Specific hypotheses are developed and tested using a longitudinal panel of 2,378 projects hosted at Source Forge. We find that network social capital is not equally accessible to or appropriated by all projects. Our main results are as follows. First, projects with greater internal cohesion (that is, cohesion among the project members) are more successful. Second, external cohesion (that is, cohesion among the external contacts of a project) has an inverse U-shaped relationship with the project's success; moderate levels of external cohesion are best for a project's success rather than very low or very high levels. Third, the technological diversity of the external network of a project also has the greatest benefit when it is neither too low nor too high. Fourth, the number of direct and indirect external contacts positively affects a project's success such that the effect of the number of direct contacts is moderated by the number of indirect contacts. These results are robust to several control variables and alternate model specifications. Several theoretical and managerial implications are provided.
|keyword = Social networks,open source software development,cohesion,project success,team composition,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TECHNOSTRESS: TECHNOLOGICAL ANTECEDENTS AND IMPLICATIONS'''
{{header}}
{{article
|author= Ramakrishna Ayyagari,Varun Grover,Russell Purvis,
|source= MIS QUARTERLY
|year= 2011
|abstract = With the proliferation and ubiquity of information and communication technologies (ICTs), it is becoming imperative for individuals to constantly engage with these technologies in order to get work accomplished. Academic literature, popular press, and anecdotal evidence suggest that ICTs are responsible for increased stress levels in individuals (known as technostress). However, despite the influence of stress on health costs and productivity, it is not very clear which characteristics of ICTs create stress. We draw from IS and stress research to build and test a model of technostress. The person-environment fit model is used as a theoretical lens. The research model proposes that certain technology characteristics-like usability (usefulness, complexity, and reliability), intrusiveness (presenteeism, anonymity), and dynamism (pace of change)-are related to stressors (work overload, role ambiguity, invasion of privacy, work home conflict, and job insecurity). Field data from 661 working professionals was obtained and analyzed. The results clearly suggest the prevalence of technostress and the hypotheses from the model are generally supported. Work overload and role ambiguity are found to be the two most dominant stressors, whereas intrusive technology characteristics are found to be the dominant predictors of stressors. The results open up new avenues for research by highlighting the incidence of technostress in organizations and possible interventions to alleviate it.
|keyword = Technostress,ICTs,information and communication technologies,stress,technology characteristics,strain,stressors,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE VALUE OF IT-ENABLED RETAILER LEARNING: PERSONALIZED PRODUCT RECOMMENDATIONS AND CUSTOMER STORE LOYALTY IN ELECTRONIC MARKETS'''
{{header}}
{{article
|author= Tongxiao (Catherine) Zhang,Ritu Agarwal,Jr. Henry C. Lucas,
|source= MIS QUARTERLY
|year= 2011
|abstract = Recent research has acknowledged the key role of information technology in helping build stronger and more enduring customer relationships. Personalized product recommendations (PPRs) adapted to individual customers' preferences and tastes are one IT-enabled strategy that has been widely adopted by online retailers to enhance customers' shopping experience. Although many online retailers have implemented PPRs on their electronic storefronts to improve customer retention, empirical evidence for the effects of PPRs on retention is sparse, and the limited anecdotal evidence is contradictory. We draw upon the household production function model in the consumer economics literature to develop a theoretical framework that explains the mechanisms through which PPRs influence customer store loyalty in electronic markets. We suggest that retailer learning that occurs as a result of customer knowledge obtained to enable personalization influences the efficiency of the online product brokering activity. Data collected from a two-phase lab experiment with 253 student subjects where the quality of PPRs was manipulated are used to empirically test the predictions of the theoretical model. Empirical analyses of the data indicate that retailer learning reflected in higher quality PPRs is associated with lower product screening cost, but higher product evaluation cost. We further find that higher quality PPRs are associated with greater value derived by consumers from the online product brokering activity in terms of higher decision making quality, which is positively associated with repurchase intention. The paper presents the implications, limitations, and contributions of this study along with areas for future research.
|keyword = Personalized product recommendations,recommender systems,household production function,retailer learning,laboratory experiment,online product brokering,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''GUIDELINES FOR DESIGNING VISUAL ONTOLOGIES TO SUPPORT KNOWLEDGE IDENTIFICATION'''
{{header}}
{{article
|author= Palash Bera,Andrew Burton-Jones,Yair Wand,
|source= MIS QUARTERLY
|year= 2011
|abstract = Organizations often provide workers with knowledge management systems to help them obtain knowledge they need. A significant constraint on the effectiveness of such systems is that they assume workers know what knowledge they need (they know what they don't know) when, in fact, they often do not know what knowledge they need (they don't know what they don't know). A way to overcome this problem is to use visual ontologies to help users learn relevant concepts and relationships in the knowledge domain, enabling them to search the knowledge base in a more educated manner. However, no guidelines exist for designing such ontologies. To fill this gap, we draw on theories of philosophical ontology and cognition to propose guidelines for designing visual ontologies for knowledge identification. We conducted three experiments to compare the effectiveness of guided ontologies, visual ontologies that followed our guidelines, to unguided ontologies, visual ontologies that violated our guidelines. We found that subjects performed considerably better with the guided ontologies, and that subjects could perceive the benefits of using guided ontologies, at least in some circumstances. On the basis of these results, we conclude that the way visual ontologies are presented makes a difference in knowledge identification and that theories of philosophical ontology and cognition can guide the construction of more effective visual representations. Furthermore, we propose that the principles we used to create the guided visual ontologies can be generalized for other cases where visual models are used to inform users about application domains.
|keyword = Knowledge work,knowledge identification,visual ontologies,knowledge management system,ontology,cognition,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A MULTILEVEL MODEL FOR MEASURING FIT BETWEEN A FIRM'S COMPETITIVE STRATEGIES AND INFORMATION SYSTEMS CAPABILITIES'''
{{header}}
{{article
|author= Tim S. McLaren,Milena M. Head,Yufei Yuan,Yolande E. Chan,
|source= MIS QUARTERLY
|year= 2011
|abstract = To compete in a highly dynamic marketplace, firms must frequently adapt and align their competitive strategies and information systems. The dominant literature on the strategic fit of a firm's information systems focuses primarily on high-level measures of the strategic fit of a firm's overall IS portfolio and the impact of fit on business performance. This paper addresses the need for a more fine-grained approach for assessing the specific areas of misfit between a firm's competitive strategies and IS capabilities. We describe the design and evaluation of a multilevel strategic fit (MSF) measurement model that enables researchers and practitioners to measure the strategic fit of a firm's information systems at both an overall and a detailed level. The steps in the model include identifying the relevant IS capabilities according to the type of system; measuring the current level of support for each capability using a capabilities instrument; identifying the ideal level of support for each capability using an adaptation of Conant et al.'s (1990) instrument to assess strategic archetype; and comparing the ideal and realized level of support for each capability. Evidence from a multiple case study analysis indicates that the fine-grained assessment of strategic fit can strengthen the validity, utility, and ease of corroboration of the strategic fit measurement outputs. The paper also demonstrates how an iterative design science research approach, with its emphasis on evaluating the utility of prototype artifacts, is well suited to developing field-tested and theoretically grounded measurement models and instruments that are accessible to practitioners. This focus on practical utility in turn provides researchers with results that can be more readily corroborated, thus improving the quality and usefulness of the research findings.
|keyword = Strategic alignment,information systems capabilities,configurational theory,strategic archetypes,design science,research methods,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''UNDERSTANDING THE LINK BETWEEN INFORMATION TECHNOLOGY CAPABILITY AND ORGANIZATIONAL AGILITY: AN EMPIRICAL EXAMINATION'''
{{header}}
{{article
|author= Ying Lu,K. (Ram) Ramamurthy,
|source= MIS QUARTERLY
|year= 2011
|abstract = Information technology is generally considered an enabler of a firm's agility. A typical premise is that greater IT investment enables a firm to be more agile. However, it is not uncommon that IT can also hinder and sometimes even impede organizational agility. We propose and theorize this frequently observed but understudied IT-agility contradiction by which IT may enable or impede agility. We develop the premise that organizations need to develop superior firm-wide IT capability to successfully manage their IT resources to realize agility. We refine the conceptualization and measurement of IT capability as a latent construct reflected in its three dimensions: IT infrastructure capability, IT business spanning capability, and IT proactive stance. We also conceptualize two types of organizational agility: market capitalizing agility and operational adjustment agility. We then conduct a matched-pair field survey of business and information systems executives in 128 organizations to empirically examine the link between a firm's IT capability and agility. Business executives responded to measurement scales of the two types of agility and organizational context variables, and IS executives responded to measurement scales of IT capabilities and IS context variables. The results show a significant positive relationship between IT capability and the two types of organizational agility. We also find a significant positive joint effect of IT capability and IT spending on operational adjustment agility but not on market capitalizing agility. The findings suggest a possible resolution to the contradictory effect of IT on agility: while more IT spending does not lead to greater agility, spending it in such a way as to enhance and foster IT capabilities does. Our study provides initial empirical evidence to better understand essential IT capabilities and their relationship with organizational agility. Our findings provide a number of useful implications for research and managerial practices.
|keyword = Organizational agility,IT-agility contradiction,information technology capability,second-order latent multidimensional construct,IT spending,theory development,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''FREEDOM OF CHOICE, EASE OF USE, AND THE FORMATION OF INTERFACE PREFERENCES'''
{{header}}
{{article
|author= Kyle B. Murray,Gerald Haeubl,
|source= MIS QUARTERLY
|year= 2011
|abstract = How does users' freedom of choice, or the lack thereof affect interface preferences? The research reported in this article approaches this question from two theoretical perspectives. The first of these argues that an interface with a dominant market share benefits from the absence of competition because users acquire skills that are specific to that particular interface, which in turn reduces the probability that they will switch to a new competitor interface in the future. By contrast, the second perspective proposes that the advantage that a market leader has in being able to install a set of non-transferable skills in its user base is offset by a psychological force that causes humans to react against perceived constraints on their freedom of choice. We test a research model that incorporates the key predictions of these two theoretical perspectives in an experiment involving consequential interface choices. We find strong support for the second perspective, which builds upon the theory of psychological reactance.
|keyword = Interface preferences,ease of use,usability,user skills,consumer choice,psychological reactance,human capital,user based learning,psychological theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''STATE OF THE INFORMATION PRIVACY LITERATURE: WHERE ARE WE NOW AND WHERE SHOULD WE GO?'''
{{header}}
{{article
|author= Paul A. Pavlou,
|source= MIS QUARTERLY
|year= 2011
|abstract = While information privacy has been studied in multiple disciplines over the years, the advent of the information age has both elevated the importance of privacy in theory and practice, and increased the relevance of information privacy literature for Information Systems, which has taken a leading role in the theoretical and practical study of information privacy. There is an impressive body of literature on information privacy in IS, and the two Theory and Review articles in this issue of MIS Quarterly review this literature. By integrating these two articles, this paper evaluates the current state of the IS literature on information privacy (where are we now?) and identifies promising research directions for advancing IS research on information privacy (where should we go?). Additional thoughts on further expanding the information privacy research in IS by drawing on related disciplines to enable a multidisciplinary study of information privacy are discussed.
|keyword = Information privacy,personal information,information privacy concerns,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION PRIVACY RESEARCH: AN INTERDISCIPLINARY REVIEW'''
{{header}}
{{article
|author= H. Jeff Smith,Tamara Dinev,Heng Xu,
|source= MIS QUARTERLY
|year= 2011
|abstract = To date, many important threads of information privacy research have developed, but these threads have not been woven together into a cohesive fabric. This paper provides an interdisciplinary review of privacy-related research in order to enable a more cohesive treatment. With a sample of 320 privacy articles and 128 books and book sections, we classify previous literature in two ways: (1) using an ethics-based nomenclature of normative, purely descriptive, and empirically descriptive, and (2) based on their level of analysis: individual, group, organizational, and societal. Based upon our analyses via these two classification approaches, we identify three major areas in which previous research contributions reside: the conceptualization of information privacy, the relationship between information privacy and other constructs, and the contextual nature of these relationships. As we consider these major areas, we draw three overarching conclusions. First, there are many theoretical developments in the body of normative and purely descriptive studies that have not been addressed in empirical research on privacy. Rigorous studies that either trace processes associated with, or test implied assertions from, these value-laden arguments could add great value. Second, some of the levels of analysis have received less attention in certain contexts than have others in the research to date. Future empirical studies-both positivist and interpretive-could profitably be targeted to these under-researched levels of analysis. Third, positivist empirical studies will add the greatest value if they focus on antecedents to privacy concerns and on actual outcomes. In that light, we recommend that researchers be alert to an overarching macro model that we term APCO (Antecedents -> Privacy Concerns -> Outcomes).
|keyword = Information privacy,multi-theory,regulation,society,interdisciplinary,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PRIVACY IN THE DIGITAL AGE: A REVIEW OF INFORMATION PRIVACY RESEARCH IN INFORMATION SYSTEMS'''
{{header}}
{{article
|author= France Belanger,Robert E. Crossler,
|source= MIS QUARTERLY
|year= 2011
|abstract = Information privacy refers to the desire of individuals to control or have some influence over data about themselves. Advances in information technology have raised concerns about information privacy and its impacts, and have motivated Information Systems researchers to explore information privacy issues, including technical solutions to address these concerns. In this paper, we inform researchers about the current state of information privacy research in IS through a critical analysis of the IS literature that considers information privacy as a key construct. The review of the literature reveals that information privacy is a multilevel concept, but rarely studied as such. We also find that information privacy research has been heavily reliant on student-based and USA-centric samples, which results in findings of limited generalizability. Information privacy research focuses on explaining and predicting theoretical contributions, with few studies in journal articles focusing on design and action contributions. We recommend that future research should consider different levels of analysis as well as multilevel effects of information privacy. We illustrate this with a multilevel framework for information privacy concerns. We call for research on information privacy to use a broader diversity of sampling populations, and for more design and action information privacy research to be published in journal articles that can result in IT artifacts for protection or control of information privacy.
|keyword = Information privacy,privacy,level of analysis,information privacy framework,information privacy concerns,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INTEGRATING TECHNOLOGY ADDICTION AND USE: AN EMPIRICAL INVESTIGATION OF ONLINE AUCTION USERS'''
{{header}}
{{article
|author= Ofir Turel,Alexander Serenko,Paul Giles,
|source= MIS QUARTERLY
|year= 2011
|abstract = Technology addiction is a relatively new mental condition that has not yet been well integrated into mainstream MIS models. This study bridges this gap and incorporates technology addiction into technology use processes in the context of online auctions. It examines how user cognition and ultimately usage intentions toward an information technology are distorted by addiction to the technology. The findings from two empirical studies of 132 and 223 eBay users, using three different operationalizations of addiction, indicate that the level of online auction addiction distorts the way the IT artifact is perceived. Informing a range of cognition-modification processes, addiction to online auctions augments user perceptions of enjoyment, usefulness, and ease of use attributed to the technology, which in turn influence usage intentions. Overall, consistent with behavioral addiction models, the findings indicate that users' levels of online auction addiction influence their reasoned IT usage decisions by altering users' belief systems. The formation of maladaptive perceptions is driven by a combination of memory-, learning-, and bias-based cognition modification processes. Implications of the,findings are discussed.
|keyword = Technology addiction,addiction,online auction,IT continuance,enjoyment,user behavior,obsessive-compulsive behavior,intrinsic and extrinsic motivation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CENTRALITY-IS PROFICIENCY ALIGNMENT AND WORKGROUP PERFORMANCE'''
{{header}}
{{article
|author= Gerald C. Kane,Stephen P. Borgatti,
|source= MIS QUARTERLY
|year= 2011
|abstract = Virtually all of the extensive previous research investigating the effect of information systems proficiency on performance has been conducted at the individual level. Little research has investigated the relationship between IS proficiency and performance at the group level. In this paper, we argue that IS proficiency at the group level may be more than the simple sum or average of the IS proficiency of individual group members. Rather, effective group-level IS proficiency may also be afiinction of how a group's IS proficiency is distributed across its members. Relying on concepts associated with social network analysis (SNA), we introduce the concept of centrality-IS proficiency alignment. We argue that groups will perform better if their more proficient members are highly central in the group's communication and workflows network. Data from 468 employees in 32 workgroups show that centrality-IS proficiency alignment is significantly and positively related to performance across multiple systems examined individually and with the portfolio of systems examined as a whole. This approach effectively integrates the structural and resource perspectives of SNA, providing a roadmap so that others may follow a similar approach to address broader questions of group-level user system interactions in the IS literature and more general questions of central resource alignment in the broader organizational literature.
|keyword = Social network analysis,IS proficiency,centrality,multimodal networks,healthcare delivery,performance,collective use,multilevel analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''VIRTUAL SPACE AND PLACE: THEORY AND TEST'''
{{header}}
{{article
|author= Carol Saunders,Anne F. Rutkowski,Michiel van Genuchten,Doug Vogel,Julio Molina Orrego,
|source= MIS QUARTERLY
|year= 2011
|abstract = Little is known about how individuals come to relate to settings in virtual worlds (VWs), which are defined as digital environments in which individuals, groups, and even organizations interact in virtual (that is to say, nonphysical) spaces. This research develops a theory of virtual space and place (VSP), specifically relating this to the setting of Second Life (SL), a prominent social virtual world. We explore how three-dimensional space, as perceived by users, is able to provide them with an interactive experience with virtual objects, as well as with other VW denizens. To test our theory, we build interactive work tools in SL that are designed to reflect various degrees of motion range and to influence presence. The three information technology tools are evaluated by 150 business professionals who are either familiar or unfamiliar with SL. Implications for practice and directions for future research are discussed.
|keyword = Virtual worlds,Second Life,virtual space,place,cognition,perception,familiarity,presence,social presence,focused immersion,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Measuring Information Diffusion in an Online Community'''
{{header}}
{{article
|author= Rajiv Garg,Michael D. Smith,Rahul Telang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Measuring peer influence in social networks is an important business and policy question that has become increasingly salient with the development of globally interconnected information and communication technology networks. However, in spite of the new data sources available today, researchers still face many of the same measurement challenges that have been present in the literature for over four decades: homophily, reflection and selection problems, identifying the source of influence, and determining preexisting knowledge. The goal of this paper is to develop an empirical approach for measuring information diffusion and discovery in online social networks that have these measurement challenges. We develop such an approach and apply it to data collected from 4,000 users of an online music community. We show that peers on such networks significantly increase music discovery. Moreover, we demonstrate how future research can use this method to measure information discovery and diffusion using data from other online social networks.
|keyword = data mining,empirical research,information diffusion,new content discovery,online music community,peer influence,social influence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Decommoditization, Resonance Marketing, and Information Technology: An Empirical Study of Air Travel Services amid Channel Conflict'''
{{header}}
{{article
|author= Nelson F. Granados,Robert J. Kauffman,Hsiangchu Lai,Huang-Chi Lin,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Digital intermediaries and Internet search technologies have commoditized many products, resulting in intense price competition and channel conflict. Firms use decommoditization strategies to regain control over distribution channels, as well as to implement resonance marketing and hyperdifferentiation, which allows them to improve margins through differentiation. We test two hypotheses: the decommoditization hypothesis and the resonance marketing hypothesis. We use data from an airline with a new a la carte pricing mechanism, which allows consumers to tailor airline ticket bundles to suit their individual preferences. We compare a la carte ticket pricing, whose features can be modified by the purchaser, and fixed (bundled offer) sales, which cannot be modified. We found that a significant number of travelers do use a la carte pricing, which allows the airlines to regain some control over distribution. We find that travelers customized standard bundles when it was possible for them to make a la carte ticket bookings, but mainly for low-feature standard bundles. Frequent-flyer members purchased higher-feature bundles more often when they had the opportunity. The findings support the proposed hypotheses. We discuss the implications for distribution strategy and channel conflict management.
|keyword = air travel services,a la carte pricing,channel conflict,commoditization,decommoditization,disintermediation,information transparency,intermediaries,reintermediation,resonance marketing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Through a Glass Clearly: Standards, Architecture, and Process Transparency in Global Supply Chains'''
{{header}}
{{article
|author= Charles Steinfield,M. Lynne Markus,Rolf T. Wigand,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Despite evidence that a lack of interoperable information systems results in enormous costs, development, implementation, and effective use of interorganizational systems (IOS) remain an elusive goal for many companies. Lack of interoperability across systems is especially problematic for manufacturers dependent on global supply chains. We develop propositions about the characteristics of IOS that affect information transparency in supply chains. Specifically, we propose that data and process standards are necessary, but not sufficient, to solve such information transparency problems. Instead, standards need to be complemented by hub-type information technology architectures that are shared by organizations participating in an industrial field, not just by the participants in one manufacturer's supply chain. These arguments are supported by an automotive industry case study involving data and process standardization and a shared, cloud-based architecture. We conclude with additional aspects of the case that may be relevant to addressing information transparency problems in global supply chains.
|keyword = automotive industry,case study,data standards,EDI,industry study,information transparency,interorganizational systems,software as a service,supply chain,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''R&D Versus Acquisitions: Role of Diversification in the Choice of Innovation Strategy by Information Technology Firms'''
{{header}}
{{article
|author= Rajiv D. Banker,Sunil Wattal,Jose M. Plehn-Dujowich,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = This research examines the role of diversification on incumbent firms' response to the threat of new entry. When faced with threats posed by new technologies, incumbent firms in the information technology (IT) industry can either perform research and development (R&D), or acquire the new entrants who are successful at innovating. We use a two-stage game-theoretic framework to model the relation between diversification and the decision to acquire versus perform R&D. We also collect data on financial indicators for firms in the IT industry using the Compustat database to empirically test the propositions from the analytical model. Our results suggest that firms with a higher degree of diversification are more likely to innovate through acquisition than through R&D. Moreover, diversification has a positive effect on investment in acquisitions, as well as a negative effect on investment in R&D.
|keyword = diversification,firm acquisition,game theory,innovation,R&D,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Study of Sourcing Channels for Electronic Business Transactions'''
{{header}}
{{article
|author= Byungjoon Yoo,Vidyanand Choudhary,Tridas Mukhopadhyay,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = There are two popular forms of business-to-business (B2B) marketplaces: public marketplaces and private channels. We study why firms choose either or both of these sourcing channels. Using a framework of decision making under uncertainty, we explain firms' choice of B2B channels as a hedging strategy and as a method of obtaining greater managerial flexibility for the future. We show that greater uncertainty can lead to higher investment with firms more likely to invest in both public and private channels. We find that the level of information technology (IT) capability and spending is an important factor in firms' decision making. When a firm chooses its level of IT investment simultaneously with the decision about which sourcing channels to use, the firm choosing both channels selects the highest level of IT capability and the firm implementing only one channel selects lower levels of IT capability.
|keyword = analytical modeling,B2B e-commerce,decision making under uncertainty,economic theory,IT capabilities,managerial decision making,private channels,public marketplaces,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Innovation and Price Competition in a Two-Sided Market'''
{{header}}
{{article
|author= Mei Lin,Shaojin Li,Andrew B. Whinston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = We examine a platform's optimal two-sided pricing strategy while considering seller-side innovation decisions and price competition. We model the innovation race among sellers in both finite and infinite horizons. In the finite case, we analytically show that the platform's optimal seller-side access fee fully extracts the sellers' surplus, and that the optimal buyer-side access fee mitigates price competition among sellers. The platform's optimal strategy may be to charge or subsidize buyers depending on the degree of variation in the buyers' willingness to pay for quality; this optimal strategy induces full participation on both sides. Furthermore, a wider quality gap among sellers' products lowers the optimal buyer-side fee but leads to a higher optimal seller-side fee. In the infinite innovation race, we perform computations to find the stationary Markov equilibrium of sellers' innovation rate. Our results show that when all sellers innovate, there exists a parameterization under which a higher seller-side access fee stimulates innovation.
|keyword = innovation,price competition,two-sided markets,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding Nonmalicious Security Violations in the Workplace: A Composite Behavior Model'''
{{header}}
{{article
|author= Ken H. Guo,Yufei Yuan,Norman P. Archer,Catherine E. Connelly,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = End users are said to be "the weakest link" in information systems (IS) security management in the workplace. They often knowingly engage in certain insecure uses of IS and violate security policies without malicious intentions. Few studies, however, have examined end user motivation to engage in such behavior. To fill this research gap, in the present study we propose and test empirically a nonmalicious security violation (NMSV) model with data from a survey of end users at work. The results suggest that utilitarian outcomes (relative advantage for job performance, perceived security risk), normative outcomes (workgroup norms), and self-identity outcomes (perceived identity match) are key determinants of end user intentions to engage in NMSVs. In contrast, the influences of attitudes toward security policy and perceived sanctions are not significant. This study makes several significant contributions to research on security-related behavior by (1) highlighting the importance of job performance goals and security risk perceptions on shaping user attitudes, (2) demonstrating the effect of workgroup norms on both user attitudes and behavioral intentions, (3) introducing and testing the effect of perceived identity match on user attitudes and behavioral intentions, and (4) identifying nonlinear relationships between constructs. This study also informs security management practices on the importance of linking security and business objectives, obtaining user buy-in of security measures, and cultivating a culture of secure behavior at local workgroup levels in organizations.
|keyword = information systems security,nonlinear construct relationships,nonmalicious security violation,perceived identity match,perceived security risk,relative advantage for job performance,workgroup norms,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Moderated Online Communities and Quality of User-Generated Content'''
{{header}}
{{article
|author= Jianqing Chen,Hong Xu,Andrew B. Whinston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Online communities provide a social sphere for people to share information and knowledge. While information sharing is becoming a ubiquitous online phenomenon, how to ensure information quality or induce quality content remains a challenge because of the anonymity of commentators. This paper introduces moderation into reputation systems. We show that moderation directly affects strategic commentators' incentive to generate useful information, and moderation is generally desirable to improve information quality. We find that when being moderated with different probabilities based on their reputations, commentators might display a pattern of reputation oscillation, in which they generate useful content to build up high reputation and then exploit their reputation. As a result, the expected performance from high-reputation commentators can be inferior to that from low-reputation commentators (reverse reputation). We then investigate the optimal moderation resource allocation and conclude that the seemingly abnormal reverse reputation could arise as an optimal result. Our study underscores the importance of moderation and highlights that the frequency of moderation should be properly chosen for better performance of online communities.
|keyword = knowledge management,moderation,online community,reputation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''System Design Features and Repeated Use of Electronic Data Exchanges'''
{{header}}
{{article
|author= Andreas I. Nicolaou,D. Harrison McKnight,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Oftentimes researchers may not only generalize across a population, but may also extrapolate research findings across time. While either assumption can introduce difficulties, generalizing results in one time frame to another time frame may be especially perilous. We study a data exchange, and find that interventions designed to improve exchange features at two points in time have markedly varying effects, from an initial transaction use (time one) to a second transaction occurring two weeks later (time two). Our research objective is to test whether two system design features have the same effects on the intent to continue using an exchange in time two as they had in time one. The two features are control transparency (the availability of information cues) and interim shipping outcome feedback. These effects are mediated, in varying degrees, by perceived information quality. We use social exchange theory and social cognition theory to develop hypotheses regarding changes between time one (the first user transaction) and time two (the second transaction). These are tested using a combined experiment and survey. Supporting the theory, outcome feedback matters at time two even though it did not matter at time one. While control transparency has direct effects on a user's intent to continue use of the exchange in time one, its effects are reduced in time two if negative outcome feedback is communicated to the user. Outcome feedback's effects grow stronger from time one to time two vis-a-vis control transparency's effects. This underscores how critical it is to examine such phenomena at more than one period of time. The study also suggests different strategies for managing data exchanges based on the time frame of use. At the initial transaction use, the exchange should make transparent high-quality information cues to its user. At the next transaction, it should provide feedback showing properly fulfilled orders. These findings have implications for both future research examining effective data exchange design and for professionals who wish to enrich electronic data exchange interactions.
|keyword = control transparency,electronic data exchanges,outcome feedback,perceived information quality,system modifications,two-period model,usage continuance intention,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''What Motivates Firms to Contribute to Consortium-Based E-Business Standardization?'''
{{header}}
{{article
|author= Kexin Zhao,Mu Xia,Michael J. Shaw,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = E-business standards are a key infrastructure for electronic commerce. In many industries, they are collaboratively developed by firms in an open and neutral industry consortium. It is imperative to understand what drives firms' resource investments in such consortia, as they are critical for the success of e-business standardization. Based on collective action theory, we propose a research model to investigate the drivers of standard development within consortia. We test the model through a data set of 232 firms from 7 consortia. Consistent with collective action theory, our results demonstrate that firms' interests, resource availability, and consortium management effectiveness jointly determine their resource expenditures within the consortium. However, our exploratory investigation indicates differences between vendors and users, as vendors are more motivated by perceived standard benefits whereas users are more motivated by perceived process benefits. Our research provides a deeper understanding of firms' behaviors within consortia and factors driving their standard making.
|keyword = collective action theory,e-business standards,IT vendors,motivations to contribute,standard consortia,user organizations,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of Automation of Systems on Medical Errors: Evidence from Field Research'''
{{header}}
{{article
|author= Ravi Aron,Shantanu Dutta,Ramkumar Janakiraman,Praveen A. Pathak,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = We use panel data from multiple wards from two hospitals spanning a three-year period to investigate the impact of automation of the core error prevention functions in hospitals on medical error rates. Although there are studies based on anecdotal evidence and self-reported data on how automation impacts medical errors, no systematic studies exist that are based on actual error rates from hospitals. Further, there is no systematic evidence on how incremental automation over time and across multiple wards impacts the rate of medical errors. The primary objective of our study is to fill this gap in the literature by empirically examining how the automation of core error prevention functions affects two types of medical errors. We draw on the medical informatics literature and principal-agency theory and use a unique panel data set of actual documented medical errors from two major hospitals to analyze the interplay between automation and medical errors. We hypothesize that the automation of the sensing function (recording and observing agent actions) will have the greatest impact on reducing error rates. We show that there are significant complementarities between quality management training imparted to hospital staff and the automation of control systems in reducing interpretative medical errors. We also offer insights to practitioners and theoreticians alike on how the automation of error prevention functions can be combined with training in quality management to yield better outcomes. Our results suggest an optimal implementation path for the automation of error prevention functions in hospitals.
|keyword = medical errors,automation,procedural errors,information technology,hospital performance,hospital information systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Managing Emerging Infectious Diseases with Information Systems: Reconceptualizing Outbreak Management Through the Lens of Loose Coupling'''
{{header}}
{{article
|author= Yi-Da Chen,Susan A. Brown,Paul Jen-Hwa Hu,Chwan-Chuen King,Hsinchun Chen,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Increasing global connectivity makes emerging infectious diseases (EID) more threatening than ever before. Various information systems (IS) projects have been undertaken to enhance public health capacity for detecting EID in a timely manner and disseminating important public health information to concerned parties. While those initiatives seemed to offer promising solutions, public health researchers and practitioners raised concerns about their overall effectiveness. In this paper, we argue that the concerns about current public health IS projects are partially rooted in the lack of a comprehensive framework that captures the complexity of EID management to inform and evaluate the development of public health IS. We leverage loose coupling to analyze news coverage and contact tracing data from 479 patients associated with the severe acute respiratory syndrome (SARS) outbreak in Taiwan. From this analysis, we develop a framework for outbreak management. Our proposed framework identifies two types of causal circles-coupling and decoupling circles-between the central public health administration and the local capacity for detecting unusual patient cases. These two circles are triggered by important information-centric activities in public health practices and can have significant influence on the effectiveness of EID management. We derive seven design guidelines from the framework and our analysis of the SARS outbreak in Taiwan to inform the development of public health IS. We leverage the guidelines to evaluate current public health initiatives. By doing so, we identify limitations of existing public health IS, highlight the direction future development should consider, and discuss implications for research and public health policy.
|keyword = public health information systems,emerging infectious disease,outbreak management,loose coupling,SARS outbreak,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Digitization of Healthcare: Boundary Risks, Emotion, and Consumer Willingness to Disclose Personal Health Information'''
{{header}}
{{article
|author= Catherine L. Anderson,Ritu Agarwal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = As healthcare becomes increasingly digitized, the promise of improved care enabled by technological advances inevitably must be traded off against any unintended negative consequences. There is little else that is as consequential to an individual as his or her health. In this context, the privacy of one's personal health information has escalated as a matter of significant concern for the public. We pose the question: under what circumstances will individuals be willing to disclose identified personal health information and permit it to be digitized? Using privacy boundary theory and recent developments in the literature related to risk-as-feelings as the core conceptual foundation, we propose and test a model explicating the role played by type of information requested (general health, mental health, genetic), the purpose for which it is to be used (patient care, research, marketing), and the requesting stakeholder (doctors/hospitals, the government, pharmaceutical companies) in an individual's willingness to disclose personal health information. Furthermore, we explore the impact of emotion linked to one's health condition on willingness to disclose. Results from a nationally representative sample of over 1,000 adults underscore the complexity of the health information disclosure decision and show that emotion plays a significant role, highlighting the need for re-examining the timing of consent. Theoretically, the study extends the dominant cognitive-consequentialist approach to privacy by incorporating the role of emotion. It further refines the privacy calculus to incorporate the moderating influence of contextual factors salient in the healthcare setting. The practical implications of this study include an improved understanding of consumer concerns and potential impacts regarding the electronic storage of health information that can be used to craft policy.
|keyword = privacy calculus,healthcare,empathy gap,emotion,communication privacy management,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Analysis of the Adoption of Digital Health Records Under Switching Costs'''
{{header}}
{{article
|author= Zafer Ozdemir,Jack Barron,Subhajyoti Bandyopadhyay,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = We investigate the incentive issues that surround the adoption and sharing of electronic health records (EHR) and the potential role of a personal health record (PHR) platform in facilitating data sharing. Through our analysis, we find evidence that health-care providers may not have an incentive to share patients' records electronically even though EHR systems will increase consumer surplus, especially in the presence of provider heterogeneity and myopic consumers. In this context, we find that an independent PHR platform can create incentives for the providers to share their patients' records electronically with other providers by selectively subsidizing them. In a pluralistic health-care system like that in the United States, where health-care providers have varying incentives to implement electronic health records, an online PHR platform can provide a proxy for a "national health information network,'" wherein consumers can freely exchange their health records among competing providers.
|keyword = electronic health records,personal health records,switching costs,national health information network,technology adoption,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IS Avoidance in Health-Care Groups: A Multilevel Investigation'''
{{header}}
{{article
|author= Gerald C. Kane,Giuseppe (Joe) Labianca,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = The information systems (IS) literature has focused considerable research on IS resistance, particularly in the health-care industry. Most of this attention has focused on the impact of IS resistance on systems' initial implementation, but little research has investigated whether and how post-adoption resistance affects performance. We focus on a particular type of post-adoption resistance, which we call IS avoidance, to identify situations in which individuals avoid working with adopted IS despite the need and opportunity to do so. We examine the effects of IS avoidance on patient care delivered by health-care groups across three levels of analysis: the individual level, the shared group level, and the configural group level. We find that IS avoidance is significantly and negatively related to patient care only at the configural group level, which suggests that patient care is not degraded by the number of doctors and/or nurses in a group avoiding a system, but rather by their locations in the group's workflow network configuration. We use qualitative data collected over 16 months at the research site to help explain these results. Implications for theory and practice are discussed.
|keyword = IS use,IS avoidance,IS resistance,multilevel analysis,multimodal networks,multimethod study,social networks,centrality,configural use,healthcare,performance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Doctors Do Too Little Technology: A Longitudinal Field Study of an Electronic Healthcare System Implementation'''
{{header}}
{{article
|author= Viswanath Venkatesh,Xiaojun Zhang,Tracy A. Sykes,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = With the strong ongoing push toward investment in and deployment of electronic healthcare (e-healthcare) systems, understanding the factors that drive the use of such systems and the consequences of using such systems is of scientific and practical significance. Elaborate training in new e-healthcare systems is not a luxury that is typically available to healthcare professionals-i.e., doctors, paraprofessionals (e.g., nurses) and administrative personnel-because of the 24 x 7 nature and criticality of operations of healthcare organizations, especially hospitals, thus making peer interactions and support a key driver of or barrier to such e-healthcare system use. Against this backdrop, using social networks as a theoretical lens, this paper presents a nomological network related to e-healthcare system use. A longitudinal study of an e-healthcare system implementation, with data gathered from doctors, paraprofessionals, administrative personnel, patients, and usage logs lent support to the hypotheses that: (1) ingroup and outgroup ties to doctors negatively affect use in all user groups; (2) ingroup and outgroup ties to paraprofessionals and administrative personnel positively affect use in both those groups, but have no effect on doctors' use; and (3) use contributes positively to patient satisfaction mediated by healthcare quality variables-i.e., technical quality, communication, interpersonal interactions, and time spent. This work contributes to the theory and practice related to the success of e-healthcare system use in particular, and information systems in general.
|keyword = IT diffusion and adoption,healthcare and IT,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Unity in Diversity: Electronic Patient Record Use in Multidisciplinary Practice'''
{{header}}
{{article
|author= Eivor Oborn,Michael Barrett,Elizabeth Davidson,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = In this paper we examine the use of electronic patient records (EPR) by clinical specialists in their development of multidisciplinary care for diagnosis and treatment of breast cancer. We develop a practice theory lens to investigate EPR use across multidisciplinary team practice. Our findings suggest that there are oppositional tendencies towards diversity in EPR use and unity which emerges across multidisciplinary work, and this influences the outcomes of EPR use. The value of this perspective is illustrated through the analysis of a yearlong, longitudinal case study of a multidisciplinary team of surgeons, oncologists, pathologists, radiologists, and nurse specialists adopting a new EPR. Each group adapted their use of the EPR to their diverse specialist practices, but they nonetheless orientated their use of the EPR to each others' practices sufficiently to support unity in multidisciplinary teamwork. Multidisciplinary practice elements were also reconfigured in an episode of explicit negotiations, resulting in significant changes in EPR use within team meetings. Our study contributes to the growing literature that questions the feasibility and necessity of achieving high levels of standardized, uniform health information technology use in healthcare.
|keyword = multidisciplinary,practice theory,electronic patient record,unity,IT adoption,information systems and organizational change,case study,longitudinal research,diversity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Evolving Work Routines: Adaptive Routinization of Information Technology in Healthcare'''
{{header}}
{{article
|author= Jie Mein Goh,Guodong (Gordon) Gao,Ritu Agarwal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Despite the significant potential for performance gains from health IT (HIT), there has been limited study of the mechanisms underlying successful HIT implementations. We conducted an extensive longitudinal field study to gain an understanding of the interplay between technology and patterns of clinical work embodied in routines. We use the analytical device of narrative networks to identify where and how HIT influences patterns of work. We further draw upon adaptive structuration theory to conceptualize HIT as an intervention that alters the flow of events in a narrative network. Our findings suggest that the key to successful implementation is to manage the co-evolution process between routines and HIT and to actively orchestrate a virtuous cycle through agentic action. We propose a dynamic process model of adaptive routinization of HIT that delineates the major channels through which HIT and routines interact, identifies the different stages in the dynamic co-evolution process, and isolates the pivotal role of two forms of agency in enabling the virtuous cycle of co-evolution. This is one of the first studies to offer a processual, microlevel analysis of HIT implementation in a clinical setting.
|keyword = health information technology,routines,narrative network,adaptive structuration theory,affordances,hospital routines,technological change,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Learning Curves of Agents with Diverse Skills in Information Technology-Enabled Physician Referral Systems'''
{{header}}
{{article
|author= Tridas Mukhopadhyay,ParamVir Singh,Seung Hyun Kim,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = To improve operational efficiencies while providing state of the art healthcare services, hospitals rely on information technology enabled physician referral systems (IT-PRS). This study examines learning curves in an IT-PRS setting to determine whether agents achieve performance improvements from cumulative experience at different rates and how information technologies transform the learning dynamics in this setting. We present a hierarchical Bayes model that accounts for different agent skills (domain and system) and estimate learning rates for three types of referral requests: emergency (EM), nonemergency (NE), and nonemergency out of network (NO). Furthermore, the model accounts for learning spillovers among the three referral request types and the impact of system upgrade on learning rates. We estimate this model using data from more than 80,000 referral requests to a large IT-PRS. We find that: (1) The IT-PRS exhibits a learning rate of 4.5% for EM referrals, 7.2% for NE referrals, and 12.3% for NO referrals. This is slower than the learning rate of manufacturing (on average 20%) and more comparable to other service settings (on average, 8%). (2) Domain and system experts are found to exhibit significantly different learning behaviors. (3) Significant and varying learning spillovers among the three referral request types are also observed. (4) The performance of domain experts is affected more adversely in comparison to system experts immediately after system upgrade. (5) Finally, the learning rate change subsequent to system upgrade is also higher for system experts in comparison to domain experts. Overall, system upgrades are found to have a long-term positive impact on the performance of all agents. This study contributes to the development of theoretically grounded understanding of learning behaviors of domain and system experts in an IT-enabled critical healthcare service setting.
|keyword = domain experts,system experts,healthcare IT,learning curves,IT-enabled call centers,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''When Hackers Talk: Managing Information Security Under Variable Attack Rates and Knowledge Dissemination'''
{{header}}
{{article
|author= Vijay Mookerjee,Radha Mookerjee,Alain Bensoussan,Wei T. Yue,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = This paper analyzes interactions between a firm that seeks to discriminate between normal users and hackers that try to penetrate and compromise the firm's information assets. We develop an analytical model in which a variety of factors are balanced to best manage the detection component within information security management. The approach not only considers conventional factors such as detection rate and false-positive rate, but also factors associated with hacker behavior that occur in response to improvements in the detection system made by the firm. Detection can be improved by increasing the system's discrimination ability (i.e., the ability to distinguish between attacks and normal usage) through the application of maintenance effort. The discrimination ability deteriorates over time due to changes in the environment. Also, there is the possibility of sudden shocks that can sharply degrade the discrimination ability. The firm's cost increases as hackers become more knowledgeable by disseminating security knowledge within the hacker population. The problem is solved to reveal the presence of a steady-state solution in which the level of system discrimination ability and maintenance effort are held constant. We find an interesting result where, under certain conditions, hackers do not benefit from disseminating security knowledge among one another. In other situations, we find that hackers benefit because the firm must lower its detection rate in the presence of knowledge dissemination. Other insights into managing detection systems are provided. For example, the presence of security shocks can increase or decrease the optimal discrimination level as compared to the optimal level without shocks.
|keyword = optimal security management,variable attack rates,hacker learning,security shocks,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Determining Optimal CRM Implementation Strategies'''
{{header}}
{{article
|author= Seung Hyun Kim,Tridas Mukhopadhyay,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Although companies have spent a great deal of money to adopt CRM (customer relationship management) technologies, many have not seen satisfactory returns on their CRM implementations. We study optimal CRM implementation strategies and the impact of CRM investments on profitability. For our analysis, we classify CRM technologies into two broad categories: targeting-related and support-related technologies. While targeting CRM improves the success rate of distinguishing between nonloyal and loyal customers, support CRM increases the probability of retaining the loyalty of existing customers. We also consider the costs of implementing each CRM type separately as well as both types simultaneously. We show that the optimal CRM implementation strategy depends on the initial mass of loyal customers and diseconomies of scale in simultaneous implementation. We also find that the two types of CRM technologies are substitutive rather than complementary in generating revenue. We discuss why it is difficult to avoid overinvestments in CRM when the nature of the investments is misunderstood. We study the optimal CRM implementation scope and the impact of different types of CRM on customers. We develop a model that not only considers both the revenue and costs sides but is also helpful in determining the deployment of right CRM technology in the right scope.
|keyword = customer relationship management,IT investments,CRM costs,consumer surplus,complementarity,substitutability,economics of IS,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Putting Yourself in the Picture: An Evaluation of Virtual Model Technology as an Online Shopping Tool'''
{{header}}
{{article
|author= Stephen P. Smith,Robert B. Johnston,Steve Howard,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = The electronic gulf between shoppers and products makes evaluating a physical product on offer at an e-store a potentially problematic activity. We propose that the outcome of the product evaluation task is determined by the fit between the type of information provided and the type of information sought by the consumer and that this, in turn, influences a consumer's attitude toward an e-store. An experiment to compare the impact of one type of advanced evaluation support technology, the virtual model, with a more basic online catalog, is then described. Results indicate that virtual models are potentially valuable when a customer is concerned with self-image and considerably less valuable when concerned with functionality. In more general terms, variation in end-user attitudes toward the object of the task (evaluative attitude) influenced how informed consumers felt about a product when using different technologies. Feeling informed, in turn, had a strong effect on consumer attitudes toward the store. Our results highlight two important issues for online stores: (1) a consumer's information requirements depend on his or her attitude to a product rather than product attributes; and (2) meeting or not meeting these information requirements affects perceptions of the store. Business success in this context therefore appears to hinge on addressing the specific functional and image-related information needs of customers rather than simply providing more interactivity or technical functionality.
|keyword = dual methods,e-store evaluation,electronic commerce,consumer attitude,virtual model,product information,empirical evaluation,value expressive,functional theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Timing of Adaptive Web Personalization and Its Effects on Online Consumer Behavior'''
{{header}}
{{article
|author= Shuk Ying Ho,David Bodoff,Kar Yan Tam,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Web personalization allows online merchants to customize Web content to serve the needs of individual customers. Using data mining and clickstream analysis techniques, merchants can now adapt website content in real time to capture the current preferences of online customers. Though the ability to offer adaptive content in real time opens up new business opportunities for online merchants, it also raises questions of timing. One question is when to present personalized content to consumers. Consumers prefer early presentation that eases their selection process, whereas adaptive systems can make better personalized content if they are allowed to collect more consumers' clicks over time. A review of personalization research confirms that little work has been done on these timing issues in the context of personalized services. The current study aims to fill that gap. Drawing on consumer search theory, we develop hypotheses about consumer responses to differences in presentation timing and recommendation type and the interaction between the two. The findings establish that quality improves over the course of an online session but the probability of considering and accepting a given recommendation diminishes over the course of the session. These effects are also shown to interact with consumer expertise, providing insights on the interplay between the different design elements of a personalization strategy.
|keyword = Web personalization,timing,consumer search theory,online shopping,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION SYSTEMS RESEARCH BEHAVIORS: WHAT ARE THE NORMATIVE STANDARDS?'''
{{header}}
{{article
|author= Gove N. Allen,Nicholas L. Ball,H. Jeff Smith,
|source= MIS QUARTERLY
|year= 2011
|abstract = Information systems researchers frequently face quandaries in their professional lives. We present the results of a study of academic IS researchers that assesses their judgments and the prevalence of 29 questionable research-related behaviors. We find that the focus and stages of researchers' careers influence their judgments of these behaviors. Membership in the Association for Information Systems (A IS) and adherence to the AIS Code of Research Conduct are also associated with IS researchers' judgments. There is strong evidence to suggest that IS researchers expect to engage in questionable behaviors more in the future than they report having done in the past. As a result of the study, we recommend that the IS community revisit the A IS Code of Research Conduct on a regular basis and take active steps to both educate its members on professional normative standards and to uphold the standards of our community.
|keyword = Normative standards,information systems research,Code of Research Conduct,survey,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PREDICTIVE ANALYTICS IN INFORMATION SYSTEMS RESEARCH'''
{{header}}
{{article
|author= Galit Shmueli,Otto R. Koppius,
|source= MIS QUARTERLY
|year= 2011
|abstract = This research essay highlights the need to integrate predictive analytics into information systems research and shows several concrete ways in which this goal can be accomplished. Predictive analytics include empirical methods (statistical and other) that generate data predictions as well as methods for assessing predictive power. Predictive analytics not only assist in creating practically useful models, they also play an important role alongside explanatory modeling in theory building and theory testing. We describe six roles for predictive analvtics: new theory generation, measurement development, comparison of competing theories, improvement of existing models, relevance assessment, and assessment of the predictability of empirical phenomena. Despite the importance of predictive analytics, we find that they are rare in the empirical IS literature. Extant IS literature relies nearly exclusively on explanatory statistical modeling, where statistical inference is used to test and evaluate the explanatory power of underlying causal models, and predictive power is assumed to follow automatically from the explanatory model. However, explanatory power does not imply predictive power and thus predictive analytics are necessary for assessing predictive power and for building empirical models that predict well. To show that predictive analytics and explanatory statistical modeling are fundamentally disparate, we show that they are different in each step of the modeling process. These differences translate into different final models, so that a pure explanatory statistical model is best tuned for testing causal hypotheses and a pure predictive model is best in terms of predictive power. We convert a well-known explanatory paper on TAM to a predictive context to illustrate these differences and show how predictive analytics can add theoretical and practical value to IS research.
|keyword = Prediction,causal explanation,theory building,theory testing,statistical model,data mining,modeling process,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AN EXPLORATION OF ORGANIZATIONAL LEVEL INFORMATION SYSTEMS DISCONTINUANCE INTENTIONS'''
{{header}}
{{article
|author= Brent Furneaux,Michael Wade,
|source= MIS QUARTERLY
|year= 2011
|abstract = Limited attention has been directed toward examining post-adoption stages of the information system life cycle. In particular, the final stages of this life cycle have been largely ignored despite the fact that most systems eventually reach the end of their useful life. This oversight is somewhat surprising given that end-of-life decisions can have significant implications for user effectiveness, the value extracted from IS investments, and organizational performance. Given this apparent gap, a multi-method empirical study was undertaken to improve our understanding of organizational level information system discontinuance. Research commenced with the development of a broad theoretical framework consistent with the technology organization environment (TOE) paradigm. The resulting framework was then used to guide a series of semi-structured interviews with organizational decision makers in an effort to inductively identify salient influences on the formation of IS discontinuance intentions. A set of research hypotheses were formulated based on the understanding obtained during these interviews and subsequently tested via a random survey of senior IS decision makers at U.S. and Canadian organizations. Data obtained from the survey responses was analyzed using partial least squares (PLS). Results of this analysis suggest that system capability shortcomings, limited availability of system support, and low levels of technical integration were key determinants of increased intentions to replace an existing system. Notably, investments in existing systems did not appear to significantly undermine organizational replacement intentions despite support for this possibility from both theory and our semi-structured interviews.
|keyword = Information systems discontinuance,obsolescence,abandonment,replacement,life cycle management,technology-organization-environment (TOE) framework,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE EFFECTS OF DIGITAL TRADING PLATFORMS ON COMMODITY PRICES IN AGRICULTURAL SUPPLY CHAINS'''
{{header}}
{{article
|author= Rajiv Banker,Sabyasachi Mitra,V. Sambamurthy,
|source= MIS QUARTERLY
|year= 2011
|abstract = Digital platforms for buying and selling agricultural commodities have generated significant interest in the trade literature as a way to link rural communities to the Internet. Yet, the extent to which these digital platforms actually translate into higher commodity prices for producers remains an open research question. We investigate this question by comparing transaction data on trading various grades of coffee from a recently implemented digital platform in India with similar transactions from a physical commodity auction held weekly, and firm-gate prices in the coffee producing regions of India. Although the digital platform prices closely track the physical commodity auction prices, producers obtain significantly higher prices when they sell the commodity through the digital platform rather than at the farm-gate through brokers who operate in their regions. However, coffee grades with higher price volatility and premium coffee grades that require face-to-face interactions to verify quality obtain lower prices on the digital platform. Our results also indicate that market participants who control the transaction obtain better prices. We discuss the implications of our findings for governments and platform providers.
|keyword = Digital divide,digital platforms,global IT,commodity auctions,bargaining power,commodity trading,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''MEMBERSHIP TURNOVER AND COLLABORATION SUCCESS IN ONLINE COMMUNITIES: EXPLAINING RISES AND FALLS FROM GRACE IN WIKIPEDIA'''
{{header}}
{{article
|author= Sam Ransbotham,Gerald C. Kane,
|source= MIS QUARTERLY
|year= 2011
|abstract = Firms increasingly turn to online communities to create valuable information. These communities are empowered by new information technology-enabled collaborative tools, tools such as blogs, wikis, and social networks. Collaboration on these platforms is characterized by considerable membership turnover, which could have significant effects on collaborative outcomes. We hypothesize that membership retention relates in a curvilinear fashion to effective collaboration: positively up to a threshold and negatively thereafter. The longitudinal history of 2,065 featured articles on Wikipedia offers support for this hypotheses: Contributions from a mixture of new and experienced participants both increases the likelihood that an article will be promoted to featured article status and decreases the risk it will be demoted after having been promoted. These findings imply that, contrary to many of the assumptions in previous research, participant retention does not have a strictly positive effect on emerging collaborative environments. Further analysis of our data provides empirical evidence that knowledge creation and knowledge retention are actually distinct phases of community-based peer production, and that communities may on average experience more turnover than ideal during the knowledge retention phase.
|keyword = Online communities,collaboration,longitudinal study,membership turnover,information generation,information retention,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INNOVATION IMPACTS OF USING SOCIAL BOOKMARKING SYSTEMS'''
{{header}}
{{article
|author= Peter H. Gray,Salvatore Parise,Bala Iyer,
|source= MIS QUARTERLY
|year= 2011
|abstract = Many organizational innovations can be explained by the movement of ideas and information from one social context to another, "from where they are known to where they are not" (Hargadon 2002, p. 41). A relatively new technology, social bookmarking, is increasingly being used in many organizations (McAfee 2006), and may enhance employee innovativeness by providing a new, socially mediated channel for discovering information. Users of such systems create publicly viewable lists of bookmarks (each being a hyperlink to an information resource) and often assign searchable keywords ("tags") to these bookmarks. We explore two different perspectives on how accessing others' bookmarks could enhance how innovative an individual is at work. First, we develop two hypotheses around the idea that quantity may be a proxy for diversity, following a well established literature that holds that the more information obtained and the larger the number of sources consulted, the higher the likelihood an individual will come across novel ideas. Next, we offer two hypotheses adapted from social network research that argue that the shape of the network of connections that is created when individuals access each others' bookmarks can reflect information novelty, and that individuals whose networks bridge more structural holes and have greater effective reach are likely to be more innovative. An analysis of bookmarking system use in a global professional services firm provides strong support for the social diversity of information sources as a predictor of employee innovativeness, but no support that the number of bookmarks accessed matters. By extending the social networks literature to theorize the functionalities offered by social bookmarking systems, this research establishes structural holes theory as a valuable lens through which social technologies may be understood.
|keyword = Social tagging systems,social bookmarking systems,social technologies,Web 2.0 technologies,Social network analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CONTROL OVER VIRTUAL WORLDS BY GAME COMPANIES: ISSUES AND RECOMMENDATIONS'''
{{header}}
{{article
|author= Christophe Roquilly,
|source= MIS QUARTERLY
|year= 2011
|abstract = Game companies use five components four core components and one complementary one in a 5Cs model to ensure the control and development of virtual worlds. A multidisciplinary review of the literature reveals that game companies make use of copyright, codes, creativity, and community to do this. They use the contract as a complementary component to reinforce their control over the four basic components and to compensate for the lacunae they present. In order to examine the extent to which game companies use the contract in this way, an analysis is performed of all contractual documents from a sample of 20 virtual worlds, providing evidence of general trends and emphasizing any differences between the virtual worlds in terms of the business and gaming models sought by each game company. An explanation is provided of why these contracts do not constitute a sustainable model for the game companies, given the high level of legal insecurity they present. Some basic recommendations can be made in order to improve the sustainability of the 5Cs model by modifying these contracts in such away that they are enforceable and by matching their content with appropriate business and gaming models. This could lead to further studies aimed at providing answers to some of the intriguing issues affecting scholars and practitioners.
|keyword = Community,computer codes,contract,control,copyright,creativity,EULA,property rights,virtual world,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DESIGN PRINCIPLES FOR VIRTUAL WORLDS'''
{{header}}
{{article
|author= Alok R. Chaturvedi,Daniel R. Dolk,Paul L. Drnevich,
|source= MIS QUARTERLY
|year= 2011
|abstract = In this research note, we examine the design, development, validation, and use of virtual worlds. Our purpose in doing so is to extend the design science paradigm by developing a set of design principles applicable to the context of virtual environments, particularly those using agent-based simulation as their underlying technology. Our central argument is that virtual worlds comprise a new class of information system, one that combines the structural aspects of traditional modeling and simulation systems in concert with emergent user dynamics of systems supporting emergent knowledge processes. Our approach involves two components. First, we review the characteristics of agent-based virtual worlds (ABVWs) to discern design requirements that may challenge current design theory. From this review, we derive a set of design principles based on deep versus emergent structures where deep structures reflect conventional modeling and simulation system architectures and emergent structures capture the unpredictable user system dynamics inherent in emergent knowledge processes, which increasingly characterize virtual worlds. We illustrate how these design challenges are addressed with an exemplar of a complex mirror world, a large-scale ABVW we developed called Sentient World. Our contribution is the insight of partitioning ABVW architectures into deep and emergent structures that mirror modeling systems and emergent knowledge processes respectively, while developing extended design principles to facilitate their integration. We conclude with a discussion of the implications of our design principles for informing and guiding future research and practice.
|keyword = IS Design theory,virtual world systems,emergent knowledge processes,agent-based simulation,deep structure,platform as a methodology (PaaM),user-developed content (UDC),
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ARGUING THE VALUE OF VIRTUAL WORLDS: PATTERNS OF DISCURSIVE SENSEMAKING OF AN INNOVATIVE TECHNOLOGY'''
{{header}}
{{article
|author= Nicholas Berente,Sean Hansen,Jacqueline C. Pike,Patrick J. Bateman,
|source= MIS QUARTERLY
|year= 2011
|abstract = With the rapid pace of technological development, individuals are frequently challenged to make sense of equivocal innovative technology while being given limited information. Virtual worlds are a prime example of such an equivocal innovative technology, and this affords researchers an opportunity to study sensemaking and the construction of perspectives about the organizational value of virtual worlds. This study reports on an analysis of the written assessments of 59 business professionals who spent an extended period of time in Second Life, a popular virtual world, and discursively made sense of the organizational value of virtual worlds. Through a Toulminian analysis of the claims, grounds, and warrants used in the texts they generated, we identify 12 common patterns of sensemaking and indicate that themes of confirmation, open-ended rhetoric, demographics, and control are evident in the different types of claims that were addressed. Further, we assert that the Toulminian approach we employ is a useful methodology for the study of sensemaking and one that is not bound to any particular theoretical perspective.
|keyword = Virtual worlds,Second Life,sensemaking,discourse,argument,Toulmin,organizational value,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WHAT IF YOUR AVATAR LOOKS LIKE YOU? DUAL-CONGRUITY PERSPECTIVES FOR AVATAR USE'''
{{header}}
{{article
|author= Kil-Soo Suh,Hongki Kim,Eung Kyo Suh,
|source= MIS QUARTERLY
|year= 2011
|abstract = As broadband Internet access and virtual reality technology rapidly expand, virtual worlds and three-dimensional avatars will become more pervasive and widely adopted. In virtual worlds, people assume an identity as an avatar and interact with each other. The objective of this study is to theorize how users form attitudes and intentions regarding avatars in realistic, task-focused virtual world settings. To investigate these effects, this study proposes a conceptual framework based on dual-congruity perspectives (self-congruity and functional congruity). The results show that the more closely an avatar resembles its user, the more the user is likely to have positive attitudes (e.g., affection, connection, and passion) toward the avatar, and the better able to evaluate the quality and performance of apparel products. In the end, these positive attitudes toward an avatar and its usefulness positively affect users' intentions to use the avatar. Based on this study, we propose that avatars representing users' actual appearance may be helpful in experiencing and evaluating some business areas related to users' lives in the real world (e.g., virtual apparel shopping, matchmaking, plastic surgery, fitness clubs, etc.); utilization of such avatars may be a new business opportunity likely to thrive in virtual worlds.
|keyword = Virtual worlds,self-concept,self-congruity,functional congruity,avatar similarity,avatar identification,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ENHANCING BRAND EQUITY THROUGH FLOW AND TELEPRESENCE: A COMPARISON OF 2D AND 3D VIRTUAL WORLDS'''
{{header}}
{{article
|author= Fiona Fui-Hoon Nah,Brenda Eschenbrenner,David DeWester,
|source= MIS QUARTERLY
|year= 2011
|abstract = This research uses theories of flow, telepresence, positive emotions, and brand equity to examine the effect of using two-dimensional versus three-dimensional virtual world environments on telepresence, enjoyment, brand equity, and behavioral intention. The findings suggest that the 3D virtual world environment produces both positive and negative effects on brand equity when compared to the 2D environment. The positive effect of the 3D virtual world environment on brand equity occurs through telepresence, a specific aspect of flow, as well as enjoyment. The negative effect on brand equity can be explained using distraction conflict theory in which attentional conflicts faced by users of a highly interactive and rich medium resulted in distractions from attending to the brand. Brand equity, in turn, has a positive effect on behavioral intention. The results suggest that although the 3D virtual world environment has the potential to increase brand equity by offering an immersive and enjoyable virtual product experience, the rich environment can also be a distraction. Therefore, developers of virtual world branding sites need to take into account limitations in the information processing capacity and attention span of users when designing their sites in order to avoid cognitive overload, which can lead to users being distracted from branding information. This paper not only provides a theoretical foundation for explaining users' experience with 2D versus 3D virtual world branding sites, but also provides insights to practitioners for designing 3D virtual world sites to enhance brand equity and intentions through user engagement.
|keyword = Virtual worlds,telepresence,flow,enjoyment,brand equity,behavioral intention,2D,3D,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''FROM SPACE TO PLACE: PREDICTING USERS' INTENTIONS TO RETURN TO VIRTUAL WORLDS'''
{{header}}
{{article
|author= Lakshmi Goel,Norman A. Johnson,Iris Junglas,Blake Ives,
|source= MIS QUARTERLY
|year= 2011
|abstract = Virtual worlds have received considerable attention as platforms for entertainment, education, and commerce. But organizations are experiencing failures in their early attempts to lure customers, employees, or partners into these worlds. Among the more grievous problems is the inability to attract users back into a virtual environment. In this study, we propose and test a model to predict users 'intentions to return to a virtual world. Our model is based on the idea that users intend to return to a virtual world having conceived of it as a "place" in which they have had meaningful experiences. We rely on the interactionist theory of place attachment to explain the links among the constructs of our model. Our model is tested via a lab experiment. We find that users' intentions to return to a virtual world is determined by a state of deep involvement (termed cognitive absorption) that users experience as they perform an activity and tend to lose track of time. In turn, cognitive absorption is determined by users' awareness of whom they interact with and how they interact within a virtual world, what they interact about, and where, in a virtual sense, such interaction occurs. Our work contributes to theory in the following ways: it identifies state predictors of cognitive absorption, it conceives of virtual worlds in such a way as to account for users' experiences through the notion of place, and it explains how the properties of a virtual world contribute to users' awareness.
|keyword = Virtual worlds,cognitive absorption,intention to return,social awareness,location awareness,task awareness,sense of place,place attachment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CO-CREATION IN VIRTUAL WORLDS: THE DESIGN OF THE USER EXPERIENCE'''
{{header}}
{{article
|author= Thomas Kohler,Johann Fueller,Kurt Matzler,Daniel Stieger,
|source= MIS QUARTERLY
|year= 2011
|abstract = Emerging virtual worlds, such as the prominent Second Life, offer unprecedented opportunities for companies to collaborate with co-creating users. However, pioneering corporate co-creation systems fail to attract a satisfying level of participation and engagement. The experience users have with the co-creation system is the key to making virtual places a vibrant source of great connections, creativity, and co-creation. While prior research on co-creation serves as a foundation for this work, it does not provide adequate guidance on how to design co-creation systems in virtual worlds. To address this shortcoming, a 20-month action research project was conducted to study the user's experience and to identify design principles for virtual co-creation systems. In two action research cycles, a virtual co-creation system called Ideation Quest was created, deployed, evaluated, and improved. The study reveals how to design co-creation systems and enriches research on co-creation to fit the virtual world context. Practitioners receive a helpful framework to leverage virtual worlds for co-creation.
|keyword = Virtual worlds,Second Life,co-creation,action research,experience design,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AN ODYSSEY INTO VIRTUAL WORLDS: EXPLORING THE IMPACTS OF TECHNOLOGICAL AND SPATIAL ENVIRONMENTS ON INTENTION TO PURCHASE VIRTUAL PRODUCTS'''
{{header}}
{{article
|author= Animesh Animesh,Alain Pinsonneault,Sung-Byung Yang,Wonseok Oh,
|source= MIS QUARTERLY
|year= 2011
|abstract = Although research on three-dimensional virtual environments abounds, little is known about the social and business aspects of virtual worlds. Given the emergence of large-scale social virtual worlds, such as Second Life, and the dramatic growth in sales of virtual goods, it is important to understand the dynamics that govern the purchase of virtual goods in virtual worlds. Employing the stimulus organism response (S-O-R) framework, we investigate how technological (interactivity and sociability) and spatial (density and stability) environments in virtual worlds influence the participants' virtual experiences (telepresence, social presence, and low), and how experiences subsequently affect their response (intention to purchase virtual goods). The results of our survey of 354 Second Life residents indicate that interactivity, which enhances the interaction with objects, has a significant positive impact on telepresence and flow. Also, sociability, which fosters interactions with participants, is significantly associated with social presence, although no such significant impact was observed on flow. Furthermore, both density and stability are found to significantly influence participants' virtual experiences; stability helps users to develop strong social bonds, thereby increasing both social presence and flow. However, contrary to our prediction of curvilinear patterns, density is linearly associated with flow and social presence. Interestingly, the results exhibit two opposing effects of density: while it reduces the extent of flow, density increases the amount of social presence. Since social presence is found to increase flow, the net impact of density on flow depends heavily on the relative strength of the associations involving these three constructs. Finally, we find that flow mediates the impacts of technological and spatial environments on intention to purchase virtual products. We conclude the paper with a discussion of the theoretical and practical contributions of our findings.
|keyword = Virtual worlds,technological environment,spatial environment,virtual experience,intention to purchase virtual products,S-O-R framework,Second Life,interactivity,sociability,density,stability,symbolic consumption,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Embodied Conversational Agent-Based Kiosk for Automated Interviewing'''
{{header}}
{{article
|author= Jr. Jay E. Nunamaker,Douglas C. Derrick,Aaron C. Elkins,Judee K. Burgoon,Mark W. Patton,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = We have created an automated kiosk that uses embodied intelligent agents to interview individuals and detect changes in arousal, behavior, and cognitive effort by using psychophysiological information systems. In this paper, we describe the system and propose a unique class of intelligent agents, which are described as Special Purpose Embodied Conversational Intelligence with Environmental Sensors (SPECIES). SPECIES agents use heterogeneous sensors to detect human physiology and behavior during interactions, and they affect their environment by influencing human behavior using various embodied states (i.e., gender and demeanor), messages, and recommendations. Based on the SPECIES paradigm, we present three studies that evaluate different portions of the model, and these studies are used as foundational research for the development of the automated kiosk. The first study evaluates human computer interaction and how SPECIES agents can change perceptions of information systems by varying appearance and demeanor. Instantiations that had the agents embodied as males were perceived as more powerful, while female embodied agents were perceived as more likable. Similarly, smiling agents were perceived as more likable than neutral demeanor agents. The second study demonstrated that a single sensor measuring vocal pitch provides SPECIES with environmental awareness of human stress and deception. The final study ties the first two studies together and demonstrates an avatar-based kiosk that asks questions and measures the responses using vocalic measurements.
|keyword = avatars,deception detection,embodied conversational agents,NeuroIS,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Global Model of Technological Utilization Based on Governmental, Business-Investment, Social, and Economic Factors'''
{{header}}
{{article
|author= James B. Pick,Rasool Azari,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = This exploratory paper presents a conceptual model of the factors of governmental support and openness, business and technology investment, and socioeconomic level that are posited to influence technological utilization. The conceptual model and conjectures are developed inductively based on logic and prior research about the relationship among variables related to the factors. Structural equation modeling (SEM) is applied to operationalize and test the model. The SEM analysis tests five points of investigation on a large sample of country data from the World Bank and the World Economic Forum. Findings indicate a critical pathway of associations between the factors of government support and openness, investment in business and technology, socioeconomic level, and technology utilization. The paper presents two country case examples of the model and suggests policy steps for national governments of developed and developing countries to prioritize information and communications technology, create openness, strengthen research and development and technology investment, and enhance education and information technology training.
|keyword = global digital divide,government investment,societal openness,socioeconomic factors,structural equation modeling,technological utilization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Changing the Perspective: Using a Cognitive Model to Improve thinkLets for Ideation'''
{{header}}
{{article
|author= Stefan Werner Knoll,Graham Horton,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = In the field of collaboration engineering, thinkLets describe reusable and transferable collaborative activities to reproduce known patterns of collaboration. This paper focuses on thinkLets of the pattern Generate, which define collaboration activities to produce and share new contributions by a group. We address the question whether the small number of published Generate thinkLets can adequately represent the various approaches contained in published idea generation techniques. We used a cognitive model to analyze 101 idea generation techniques with regard to the underlying mental principles that stimulate the ideation process by deliberately activating larger areas of the knowledge network. We present three changes of perspective based on these principles, which can be used to formalize the underlying mechanisms of idea generation techniques. The paper shows how these three principles can be used to improve Generate thinkLets and discusses how this formalization can improve the applicability of information systems for ideation processes.
|keyword = change of perspective,cognitive model of ideation,collaboration engineering,idea generation,thinkLet,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Technology Spillover and Productivity: The Role of Information Technology Intensity and Competition'''
{{header}}
{{article
|author= Kuns Han,Young Bong Chang,Jungpil Hahn,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = We study interindustry information technology (IT) spillover wherein IT investments made by supplier industries increase the productivity of downstream industries. Using data from U.S. manufacturing industries, we find that industries receive significant IT spillover benefits in terms of total factor productivity growth through economic transactions with their respective supplier industries. More importantly, we find that two characteristics of downstream industries, namely, IT intensity and competitiveness, which have been shown to moderate the effect of internal IT investments, play an important role in IT spillovers as well. Our results suggest that IT intensity as well as competitiveness of the downstream industry moderate the effect of IT spillovers industries that are more IT intensive and more competitive benefit more from IT spillovers. Finally, our results suggest that the long-term effects of spillovers are greater than short-term effects, suggesting that learning periods are required to reap the benefits from the IT spillovers.
|keyword = competition,industry analysis,industry characteristics,IT effects,IT intensity,IT spillover,productivity,total factor productivity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Cultural Signifiers of Web Site Images'''
{{header}}
{{article
|author= Fatemeh Mariam Zahedi,Gaurav Bansal,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Web sites rely on pictures and animation to convey subtle messages that are more effectively communicated nonverbally. We argue that such messages could have strong cultural content, which should be understood in developing Web sites. Hence, this paper explores the cultural content of Web site images and develops a theory for Web-image signifiers. This is done in two phases. Phase I has an interpretive qualitative approach that uses Grounded Theory to identify signifiers and to develop the Web-image signifiers (WIS) theory. Phase II quantitatively tests the WIS theory. Together, these two phases identify and validate signifiers of cultural dimensions in Web site images. More interestingly, the results uncover that cultural dimensions are signified in five categories, of which two, humans and buildings categories, are the most prominent. The contribution of this paper is in developing a comprehensive theory for the cultural content of Web images, identifying 48 signifiers in Web images, discovering new categories of signifiers, and providing insights into the nature of cultural signification by testing the theory. Such knowledge could heighten our sensitivity and awareness of hidden cultural messages in Web site images. The WIS theory could provide a novel approach to the cultural studies of Web images and other artifacts with cultural content. The results of this work have immediate application in the design of Web sites for a multicultural audience.
|keyword = cultural signifiers,Grounded Theory,Hofstede's cultural dimensions,semiology,Web-image signifiers theory,Web site images,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Effects of Automated and Participative Decision Support in Computer-Aided Credibility Assessment'''
{{header}}
{{article
|author= Matthew L. Jensen,Paul Benjamin Lowry,Jeffrey L. Jenkins,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Historically, inaccurate credibility assessments have resulted in tremendous costs to businesses and to society. Recent research offers unobtrusive credibility assessment aids as a solution; however, the accuracy of these decision aids is inadequate, and users often resist accepting the aids' recommendations. We follow the principles of signal detection theory to improve the accuracy of recommendations in computer-aided credibility assessment by combining automated and participatory decision support. We also leverage participation in decision-making theory to explain and predict an increased acceptance of assessment aid recommendations when perceptual cues are elicited from users. Based on these two theories, we design and test a hybrid decision aid to perform automated linguistic analysis and to elicit and analyze perceptual cues from an observer. Results from a laboratory experiment indicate that decision aids that use linguistic and perceptual cues offer more accurate recommendations than aids that use only one type of cue. Automatic analysis of linguistic cues improved both the decision aid's recommendations and the users' credibility assessment accuracy. Challenging the generalizability of past findings, the elicitation of perceptual cues did not improve the decision aid's recommendations or the users' assessment accuracy. Elicitation of perceptual cues, however, did improve user acceptance of the decision aid's recommendations. These findings provide guidance for future development of credibility assessment decision aids.
|keyword = credibility assessment,decision support systems,indirect cues elicitation,linguistic analysis,signal detection theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''User Acceptance of Agile Information Systems: A Model and Empirical Test'''
{{header}}
{{article
|author= Weiyin Hong,James Y. L. Thong,Lewis C. Chasalow,Gurpreet Dhillon,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = In response to the rapid changes in users' requirements, a new generation of information systems (IS), namely, agile IS, has emerged. Agile IS, defined as information systems developed using agile methods, are characterized by frequent upgrades with a small number of new features released periodically. The existing research on agile IS has mainly focused on the developers' perspective with little research into end users' responses to these agile IS. Drawing upon the tripartite model of attitude, the status quo and the omission bias theories, and the availability heuristic, we propose a model that utilizes constructs from the unified theory of acceptance and use of technology, the IS continuance model, habit, and individual differences to examine the drivers of user acceptance of agile IS. Further, we investigate not only users' intentions to continue using the agile IS but also their intentions to use new features when they are released, which is a surrogate for the ultimate success of agile IS. Data from 477 users of an agile IS showed that users' level of comfort with constant changes, the facilitating conditions provided, and users' habit are predictors of both types of intentions, with users' level of comfort with constant changes being the strongest predictor. Users' intentions to continue using agile IS are also determined by users' satisfaction with and perceived usefulness of the past upgrades. Finally, users who are innovative are more likely to use future releases of new features. The present work fills a gap in the software engineering literature and contributes a technology acceptance model specific to agile IS, which are becoming a mainstay of companies' IT portfolio in a fast-changing business environment.
|keyword = agile methods,agile systems,availability heuristic,comfort with change,habit,information systems continuance,omission bias,personal innovativeness,status quo bias,unified theory of acceptance and use of technology (UTAUT),
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Role of Communication and Trust in Global Virtual Teams: A Social Network Perspective'''
{{header}}
{{article
|author= Saonee Sarker,Manju Ahuja,Suprateek Sarker,Sarah Kirkeby,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = The importance of communication and trust in the context of global virtual teams has been noted and reiterated in the information systems (IS) literature. Yet precisely how communication and trust influence certain outcomes within virtual teams remains unresolved. In this study, we seek to contribute some clarity to the understanding of the theoretical linkages among trust, communication, and member performance in virtual teams. To this end, we identify and test three proposed models (additive, interaction, and mediation) describing the role of trust in its relationship with communication to explain performance. In testing the relationships, we note that the concepts of communication and trust are inherently relational and not properties of individuals. Thus, we argue that a social network approach is potentially more appropriate than attribute-based approaches that have been utilized in prior research. Our results indicate that the "mediating" model best explains how communication and trust work together to influence performance. Overall, the study contributes to the existing body of knowledge on virtual teams by empirically reconciling conflicting views regarding the interrelationships between key constructs in the literature. Further, the study, through its adoption of the social network analysis approach, provides awareness within the IS research community of the strengths of applying network approaches in examining new organizational forms.
|keyword = communication,distributed teams,global virtual teams,hybrid teams,individual performance,mediation,networked individualism,social network analysis,trust,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Cognitive Conflict and Consensus Generation in Virtual Teams During Knowledge Capture: Comparative Effectiveness of Techniques'''
{{header}}
{{article
|author= Ananth Chiravuri,Derek Nazareth,K. (Ram) Ramamurthy,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Effective knowledge management has been increasingly cited as critical for businesses to compete successfully. Knowledge acquisition/capture, the first step in knowledge management, continues to be a bottleneck and is exacerbated when experts are geographically distributed. Furthermore, knowledge from multiple experts is likely to generate inconsistent knowledge for a given problem domain. There is thus a compelling need to generate consensus by resolving inconsistencies and conflicts that may occur among experts during the process of knowledge acquisition. This process is more challenging when dealing with virtual teams of experts. This study addresses task-based or cognitive conflicts among experts. A key objective of this study is to examine the effectiveness of two cognitive techniques the repertory grid (or RepGrid) and Delphi in generating consensus among experts during the knowledge capture process. A field experiment with geographically distributed real-world network experts involving multiple rounds of interaction over an extended period of time was conducted. Findings from this research indicate that, in the short run, Delphi works better than the RepGrid in reducing conflict and generating consensus. However, the RepGrid technique appears to perform better in the long run. We find similar results for satisfaction with the process and outcome. Our findings also indicate that experts using the RepGrid technique elicited more knowledge as well as higher-quality knowledge than experts using the Delphi technique. To sum up, our study indicates that RepGrid is superior to Delphi, and therefore managers should seriously consider the use of RepGrid in capturing knowledge from multiple and distributed experts when dealing with complex real-world issues.
|keyword = cognitive conflict,conflict resolution,consensus generation,Delphi technique,knowledge capture,knowledge management,repertory grid technique,virtual teams,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Influence of Virtuality on Social Networks Within and Across Work Groups: A Multilevel Approach'''
{{header}}
{{article
|author= Ayoung Suh,Kyung-Shik Shin,Manju Ahuja,Min Soo Kim,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = We examine how the virtuality of work context influences individuals' social networks within and across work groups. Given this purpose, we develop a multilevel research framework that explores the effects of different levels of virtuality on one's intra-group tie strength and extra-group network range based on the computer-mediated communication theory, the proximity theory, and the social network theory. The results of the hierarchical linear modeling indicate that the individual-level virtuality (use of personal and communal communication technologies) significantly influences one's intra-group tie strength and extra-group network range. Moreover, the results show that the effects of individual-level virtuality on social networks vary depending on the group-level virtuality, such as geographic/temporal dispersion and technological support. By illuminating how individuals' social networks can be developed through the appropriate use of personal and communal communication technologies in the context of a virtual group, this study provides useful insights into the mechanics that underlie effective virtual work.
|keyword = computer-mediated communication,hierarchical linear modeling,multilevel analysis,social networks,virtuality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''MEASUREMENT AND MEANING IN INFORMATION SYSTEMS AND ORGANIZATIONAL RESEARCH: METHODOLOGICAL AND PHILOSOPHICAL FOUNDATIONS'''
{{header}}
{{article
|author= Richard P. Bagozzi,
|source= MIS QUARTERLY
|year= 2011
|abstract = Despite renewed interest and many advances in methodology in recent years, information systems and organizational researchers face confusing and inconsistent guidance on how to choose amongst, implement, and interpret findings from the use of different measurement procedures. In this article, the related topics of measurement and construct validity are summarized and discussed, with particular focus on formative and reflective indicators and common method bias, and, where relevant, a number of allied issues are considered. The perspective taken is an eclectic and holistic one and attempts to address conceptual and philosophical essentials, raise salient questions, and pose plausible solutions to critical measurement dilemmas occurring in the managerial, behavioral, and social sciences.
|keyword = Construct validity,common method bias,reflective indicators,formative indicators,measurement,structural equation models,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CONSTRUCT MEASUREMENT AND VALIDATION PROCEDURES IN MIS AND BEHAVIORAL RESEARCH: INTEGRATING NEW AND EXISTING TECHNIQUES'''
{{header}}
{{article
|author= Scott B. MacKenzie,Philip M. Podsakoff,Nathan P. Podsakoff,
|source= MIS QUARTERLY
|year= 2011
|abstract = Despite the fact that validating the measures of constructs is critical to building cumulative knowledge in MIS and the behavioral sciences, the process of scale development and validation continues to be a challenging activity. Undoubtedly, part of the problem is that many of the scale development procedures advocated in the literature are limited by the fact that they (1) fail to adequately discuss how to develop appropriate conceptual definitions of the focal construct, (2) often fail to properly specify the measurement model that relates the latent construct to its indicators, and (3) under utilize techniques that provide evidence that the set of items used to represent the focal construct actually measures what it purports to measure. Therefore, the purpose of the present paper is to integrate new and existing techniques into a comprehensive set of recommendations that can be used to give researchers in MIS and the behavioral sciences a frame work for developing valid measures. First, we briefly elaborate upon some of the limitations of current scale development practices. Following this, we discuss each of the steps in the scale development process while paying particular attention to the differences that are required when one is attempting to develop scales for constructs with formative indicators as opposed to constructs with reflective indicators. Finally, we discuss several things that should be done after the initial development of a scale to examine its generalizability and to enhance its usefulness.
|keyword = Construct validation procedures,Scale development and validation,content, convergent, discriminant and nomological validity,formative and reflective indicator models,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INCORPORATING FORMATIVE MEASURES INTO COVARIANCE-BASED STRUCTURAL EQUATION MODELS'''
{{header}}
{{article
|author= Adamantios Diamantopoulos,
|source= MIS QUARTERLY
|year= 2011
|abstract = Formatively measured constructs have been increasingly used in information systems research. With few exceptions, however, extant studies have been relying on the partial least squares (PLS) approach to specify; and estimate structural models involving constructs measured wit h formative indicators. This paper highlights the benefits of employing covariance structure analysis (CSA) when investigating such models and illustrates its application with the LISREL program. The aim is to provide practicing IS researchers with an understanding of key issues and potential problems associated with formatively measured constructs within a covariance-based modeling framework and encourage them to consider using CSA in their future research endeavors.
|keyword = Formative measurement,formative indicators,covariance structure analysis,PLS,MIMIC models,identification,scaling options,model evaluation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EVALUATING EFFECT, COMPOSITE, AND CAUSAL INDICATORS IN STRUCTURAL EQUATION MODELS'''
{{header}}
{{article
|author= Kenneth A. Bollen,
|source= MIS QUARTERLY
|year= 2011
|abstract = Although the literature on alternatives to effect indicators is growing, there has been little attention given to evaluating causal and composite (formative) indicators. This paper provides an overview of this topic by contrasting ways of assessing the validity of effect and causal indicators in structural equation models (SEMs). It also draws a distinction between composite (formative) indicators and causal indicators and argues that validity is most relevant to the latter. Sound validity assessment of indicators is dependent on having an adequate overall model fit and on the relative stability of the parameter estimates for the latent variable and indicators as they appear in different models. If the overall fit and stability of estimates are adequate, then a researcher can assess validity using the unstandardized and standardized validity coefficients and the unique validity variance estimate. With multiple causal indicators or with effect indicators influenced by multiple latent variables, collinearity diagnostics are useful. These results are illustrated with a number of correctly and incorrectly specified hypothetical models.
|keyword = Causal indicators,effect indicators,formative indicators,reflective indicators,measurement,validity,structural equation models,scale construction,composites,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WHAT SIGNAL ARE YOU SENDING? HOW WEBSITE QUALITY INFLUENCES PERCEPTIONS OF PRODUCT QUALITY AND PURCHASE INTENTIONS'''
{{header}}
{{article
|author= John D. Wells,Joseph S. Valacich,Traci J. Hess,
|source= MIS QUARTERLY
|year= 2011
|abstract = An electronic commerce marketing channel is fully mediated by information technology, stripping away much of a product's physical informational cues, and creating information asymmetries (i.e., limited information). These asymmetries may impede consumers' ability to effectively assess certain types of products, thus creating challenges for online sellers. Signaling theory provides a framework for understanding how extrinsic cues signals can be used by sellers to convey product quality information to consumers, reducing uncertainty and facilitating a purchase or exchange. This research proposes a model to investigate website quality as a potential signal of product quality and consider the moderating effects of product information asymmetries and signal credibility. Three experiments are reported that examine the efficacy of signaling theory as a basis for predicting online consumer behavior with an experience good. The results indicate that website quality influences consumers' perceptions of product quality, which subsequently affects online purchase intentions. Additionally, website quality was found to have a greater influence on perceived product quality when consumers had higher information asymmetries. Likewise, signal credibility was found to strengthen the relationship between website quality and product quality perceptions for a high quality website. Implications for future research and website design are examined.
|keyword = Signaling theory,signals,cues,website quality,eCommerce,perceived quality,credibility,information asymmetries,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CORRELATED FAILURES, DIVERSIFICATION, AND INFORMATION SECURITY RISK MANAGEMENT'''
{{header}}
{{article
|author= Pei-yu Chen,Gaurav Kataria,Ramayya Krishnan,
|source= MIS QUARTERLY
|year= 2011
|abstract = The increasing dependence on information networks for business operations has focused managerial attention on managing risks posed by failure of these networks. In this paper, we develop models to assess the risk of failure on the availability of an information network due to attacks that exploit software vulnerabilities. Software vulnerabilities arise from software installed on the nodes of the network. When the same software stack is installed on multiple nodes on the network, software vulnerabilities are shared among them. These shared vulnerabilities can result in correlated failure of multiple nodes resulting in longer repair times and greater loss of availability of the network. Considering positive network effects (e.g., compatibility) alone without taking the risks of correlated failure and the resulting downtime into account would lead to over-investment in homogeneous software deployment. Exploiting characteristics unique to information networks, we present a queuing model that allows us to quantify downtime loss faced by arm as a function of (1) investment in security technologies to avert attacks, (2) software diversification to limit the risk of correlated failure under attacks, and (3) investment in IT resources to repair failures due to attacks. The novelty of this method is that we endogenize the failure distribution and the node correlation distribution, and show how the diversification strategy and other security measures/investments may impact these two distributions, which in turn determine the security loss faced by the firm. We analyze and discuss the effectiveness of diversification strategy under different operating conditions and in the presence of changing vulnerabilities. We also take into account the benefits and costs of a diversification strategy. Our analysis provides conditions under which diversification strategy is advantageous.
|keyword = Security,diversification,downtime loss,software allocation,network effects,risk management,correlated failures,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''MANAGING CONSUMER PRIVACY CONCERNS IN PERSONALIZATION: A STRATEGIC ANALYSIS OF PRIVACY PROTECTION'''
{{header}}
{{article
|author= Dong-Joo Lee,Jae-Hyeon Ahn,Youngsok Bang,
|source= MIS QUARTERLY
|year= 2011
|abstract = Advances in information technology and e-commerce enable firms to make personalized offers to individual consumers based on information about the consumers. However, the collection and use of private information have caused serious concerns about privacy invasion by consumers, creating a personalization privacy tradeoff The key approach to address privacy concerns is via the protection of privacy through the implementation of fair information practices, a set of standards governing the collection and use of personal information. In this paper, we take a game-theoretic approach to explore the motivation of firms for privacy protection and its impact on competition and social welfare in the context of product and price personalization. We find that privacy protection can work as a competition-mitigating mechanism by generating asymmetry in the consumer segments to which firms offer personalization, enhancing the profit extraction abilities of the firms. In equilibrium, both symmetric and asymmetric choices of privacy protection by the firms can result, depending on the size of the personalization scope and the investment cost of protection. Further, as consumers become more concerned about their privacy, it is more likely that all firms adopt privacy protection. In the perspective of welfare, we show that autonomous choices of privacy protection by personalizing firms can improve social welfare at the expense of consumer welfare. We further find that regulation enforcing the implementation of fair information practices can be efficient from the social welfare perspective mainly by limiting the incentives of the firms to exploit the competition-mitigation effect.
|keyword = Information privacy,consumer privacy concerns,personalization,privacy protection,fair information practices,game theory,competitive analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE MORE, THE MERRIER? HOW THE NUMBER OF PARTNERS IN A STANDARD-SETTING INITIATIVE AFFECTS SHAREHOLDER'S RISK AND RETURN'''
{{header}}
{{article
|author= Nitin Aggarwal,Qizhi Dai,Eric A. Walden,
|source= MIS QUARTERLY
|year= 2011
|abstract = Firms often collaborate with other firms to set information technology standards in order to decrease each firm's individual risk. But does this work? We propose that, in a capital market setting, establishing standards in a group does not decrease the total risk laced by an individual firm's shareholders. However, the market risky its investors lace decrease and idiosyncratic risks increase, changing the risk profiles of the group members. We collected data on standard-setting events from 1996 to 2005. In our dataset, a firm obtained a 4.07 percent, three-day cumulative risk-adjusted return on stock price when engaging in a standard-setting initiative, after controlling event year, firm size, and group size. More importantly, we found that an increase in the number of firms in the group decreased the risk-adjusted abnormal return and the market risk (as measured by beta) of each firm, but increased the idiosyncratic risk (as measured by the variance of firm returns). Our findings suggest that firms electing to participate in a large standardization group obtain a reduction in abnormal returns on stocks on the days of the standard-setting events. They also expect to reduce market risks but increase idiosyncratic risks after the standard-setting events, as compared to firms choosing to participate in a smaller group or attempting to standardize their products unilaterally. This study contributes to the literature on IT standards and standardization, and expands our understanding of the implications of standardization strategy on shareholder risks.
|keyword = Standard,standardization,standard-setting,event study,returns on IT investment,risk of IT investment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COMPETING PERSPECTIVES ON THE LINK BETWEEN STRATEGIC INFORMATION TECHNOLOGY ALIGNMENT AND ORGANIZATIONAL AGILITY: INSIGHTS FROM A MEDIATION MODEL'''
{{header}}
{{article
|author= Paul P. Tallon,Alain Pinsonneault,
|source= MIS QUARTERLY
|year= 2011
|abstract = Strategic information technology alignment remains a top priority for business and IT executives. Yet with a recent rise in environmental volatility, firms are asking how to be more agile in identifying and responding to market-based threats and opportunities. Whether alignment helps or hurts agility is an unresolved issue. This paper presents a variety of arguments from the literature that alternately predict a positive or negative relationship between alignment and agility. This relationship is then tested using a model in which agility mediates the link between alignment and firm performance under varying conditions of IT infrastructure flexibility and environmental volatility. Using data from a matched survey of IT and business executives in 241 firms, we uncover a positive and significant link between alignment and agility and between agility and firm performance. We also show that the effect of alignment on performance is fully mediated by agility, that environmental volatility positively moderates the link between agility and firm performance, and that agility has a greater impact on firm performance in more volatile markets. While IT infrastructure flexibility does not moderate the link between alignment and agility, except in a volatile environment, we reveal that IT infrastructure flexibility has a positive and significant main effect on agility. In fact, the effect of IT infrastructure flexibility on agility is as strong as the effect of alignment on agility. This research extends and integrates the literature on strategic IT alignment and organizational agility at a time when both alignment and agility are recognized as critical and concurrent organizational goals.
|keyword = Agility,strategic IT alignment,environmental change,volatility,IT infrastructure flexibility,IT rigidity traps,industry clockspeed,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CIO REPORTING STRUCTURE, STRATEGIC POSITIONING, AND FIRM PERFORMANCE'''
{{header}}
{{article
|author= Rajiv D. Banker,Nan Hu,Paul A. Pavlou,Jerry Luftman,
|source= MIS QUARTERLY
|year= 2011
|abstract = Almost 30 years after the introduction of the CIO position, the ideal CIO reporting structure (whether the CIO should report to the CEO or the CFO) is yet to be identified There is an intuitive assumption among some proponents of IT that the CIO should always report to the CEO to promote the importance of IT and the CIO's clout in the firm, while some adversaries of IT call for a CIO CFO reporting structure to keep a tab on IT spending. However, we challenge these two ad hoc prescriptions by arguing that neither CIO reporting structure is necessarily optimal, and that the CIO reporting structure should not be used to gauge the strategic role of IT in the firm. First, extending the strategy structure paradigm, we propose that a firm's strategic positioning (differentiation or cost leadership) should be a primary determinant of its CIO reporting structure. We hypothesize that differentiators are more likely to have their CIO report to the CEO in order to pursue IT initiatives that help the firm's differentiation strategy. We also hypothesize that cost leaders are more likely to have their CIO report to the CFO to lead IT initiatives to facilitate the firm's cost leadership strategy. Second, extending the alignment fit view, we propose that firms that align their CIO reporting structure with their strategic positioning (specifically, differentiation with a CIO CEO reporting structure and cost leadership with a CIO CFO reporting structure) will have superior future performance. Longitudinal data from two periods (1990-1993 and 2006) support the proposed hypotheses, validating the relationship between a firm's strategic positioning and its CIO reporting structure, and also the positive impact of their alignment on firm performance. These results challenge the ad hoc prescriptions about the CIO reporting structure, demonstrating that a CIO CEO reporting structure is only superior for differentiators and a CIO CFO reporting structure is superior only for cost leaders. The CIO reporting structure must, therefore, be designed to align with the firm's strategic positioning, independent of whether IT plays a key strategic role in the firm.
|keyword = Chief information officer (CIO),CIO reporting structure,strategic positioning,Porter's generic strategies,product/service differentiation,cost leadership,firm performance,abnormal stock returns,cash flows from operations,chief executive officer (CEO),chief financial officer (CFO),
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CAPTURING BOTTOM-UP INFORMATION TECHNOLOGY USE PROCESSES: A COMPLEX ADAPTIVE SYSTEMS MODEL'''
{{header}}
{{article
|author= Ning Nan,
|source= MIS QUARTERLY
|year= 2011
|abstract = Although information systems researchers have long recognized the possibility for collective-level information technology use patterns and outcomes to emerge from individual-level IT use behaviors, few have explored the key properties and mechanisms involved in this bottom-up IT use process. This paper seeks to build a theoretical framework drawing on the concepts and the analytical tool of complex adaptive systems (CAS) theory. The paper presents a CAS model of IT use that encodes a bottom-up IT use process into three interrelated elements: agents that consist of the basic entities of actions in an IT use process, interactions that refer to the mutually adaptive behaviors of agents, and an environment that represents the social organizational contexts of IT use. Agent-based modeling is introduced as the analytical tool for computationally representing and examining the CAS model of IT use. The operationability of the CAS model and the analytical tool are demonstrated through a theory-building exercise translating an interpretive case study of IT use to a specific version of the CAS model. While Orlikowski (1996) raised questions regarding the impacts of employee learning, IT flexibility, and workplace rigidity on IT-based organization transformation, the CAS model indicates that these factors in individual-level actions do not have a direct causal linkage with organizational-level IT use patterns and outcomes. This theory-building exercise manifests the intriguing nature of the bottom-up IT use process: collective-level IT use patterns and outcomes are the logical and yet often unintended or unforeseeable consequences of individual-level behaviors. The CAS model of IT use offers opportunities for expanding the theoretical and methodological scope of the IT use literature.
|keyword = Bottom-up IT use,complex adaptive systems,agent-based modeling,individual-level IT use,collective-level IT use,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Analysis of Incentives for Network Infrastructure Investment Under Different Pricing Strategies'''
{{header}}
{{article
|author= Alok Gupta,Boris Jukic,Dale O. Stahl,Andrew B. Whinston,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = The Internet is making a significant transition from primarily a network of desktop computers to a network variety of connected information devices such as personal digital assistants and global positioning system-based devices. On the other hand, new paradigms such as overlay networks are defining service-based logical architecture for the network services that make locating content and routing more efficient. Along with Internet2's proposed service-based routing, overlay networks will create a new set of challenges in the provision and management of content over the network. However, a lack of proper infrastructure investment incentive may lead to an environment where network growth may not keep pace with the service requirements. In this paper, we present an analysis of investment incentives for network infrastructure owners under two different pricing strategies: congestion-based negative externality pricing and the prevalent flat-rate pricing. We develop a theoretically motivated gradient-based heuristic to compute maximum capacity that a network provider will be willing to invest in under different pricing schemes. The heuristic appropriates different capacities to different network components based on demand for these components. We then use a simulation model to compare the impact of dynamic congestion-based pricing with flat-rate pricing on the choice of capacity level by the infrastructure provider. The simulation model implements the heuristic and ensures that near-optimal level of capacity is allocated to each network component by checking theoretical optimality conditions. We investigate the impact of a variety of factors, including the per unit cost of capacity of a network resource, average value of the users' requests, average level of users' tolerance for delay, and the level of exogenous demand for services on the network. Our results indicate that relationships between these factors are crucial in determining which of the two pricing schemes results in a higher level of socially optimal network capacity. The simulation results provide a possible explanation for the evolution of the Internet pricing from time-based to flat-rate pricing. The results also indicate that regardless of how these factors are related, the average stream of the net benefits realized under congestion-based pricing tends to be higher than the average net benefits realized under flat-rate pricing. These central results point to the fallacy of the arguments presented by the supporters of net neutrality that do not consider the incentives for private investment in network capacity.
|keyword = Internet pricing,infrastructure investment,simulation,investment incentives,net neutrality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Addressing Digital Inequality for the Socioeconomically Disadvantaged Through Government Initiatives: Forms of Capital That Affect ICT Utilization'''
{{header}}
{{article
|author= J. J. Po-An Hsieh,Arun Rai,Mark Keil,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Digital inequality, or unequal access to and use of information and communication technologies (ICT), is a severe problem preventing the socioeconomically disadvantaged (SED) from participating in a digital society. To understand the critical resources that contribute to digital inequality and inform public policy for stimulating initial and continued ICT usage by the SED, we drew on capital theories and conducted a field study to investigate: (1) the forms of capital for using ICT and how they differ across potential adopters who are SED and socioeconomically advantaged (SEA); (2) how these forms of capitals are relatively impacted for the SEA and the SED through public policy for ICT access; and (3) how each form of capital influences the SED's intentions to use initially and to continue to use ICT. The context for our study involved a city in the southeastern United States that offered its citizens free ICT access for Internet connectivity. Our results show that SED potential adopters exhibited lower cultural capital but higher social capital relative to the SEA. Moreover, the SED who participated in the city's initiative realized greater positive gains in cultural capital, social capital, and habitus than the SEA. In addition, we find that the SED's initial intention to use ICT was influenced by intrinsic motivation for habitus, self-efficacy for cultural capital, and important referents' expectations and support from acquaintances for social capital. Cultural capital and social cultural capital also complemented each other in driving the SED's initial use intention. The SED's continued use intention was affected by both intrinsic and extrinsic motivations for habitus and both knowledge and self-efficacy for cultural capital but was not affected by social capital. We also make several recommendations for future research on digital inequality and ICT acceptance to extend and apply the proposed capital framework.
|keyword = capital theory,habitus,cultural capital,social capital,economic capital,digital divide,digital inequality,ICT policy,socioeconomic inequality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Effect of Online Privacy Information on Purchasing Behavior: An Experimental Study'''
{{header}}
{{article
|author= Janice Y. Tsai,Serge Egelman,Lorrie Cranor,Alessandro Acquisti,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Although online retailers detail their privacy practices in online privacy policies, this information often remains invisible to consumers, who seldom make the effort to read and understand those policies. This paper reports on research undertaken to determine whether a more prominent display of privacy information will cause consumers to incorporate privacy considerations into their online purchasing decisions. We designed an experiment in which a shopping search engine interface clearly and compactly displays privacy policy information. When such information is made available, consumers tend to purchase from online retailers who better protect their privacy. In fact, our study indicates that when privacy information is made more salient and accessible, some consumers are willing to pay a premium to purchase from privacy protective websites. This result suggests that businesses may be able to leverage privacy protection as a selling point.
|keyword = privacy,information systems,economics,experimental economics,e-commerce,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Using Transaction Prices to Re-Examine Price Dispersion in Electronic Markets'''
{{header}}
{{article
|author= Anindya Ghose,Yuliang Yao,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Price dispersion is an important indicator of market efficiency. Internet-based electronic markets have the potential to reduce transaction and search costs, thereby creating more efficient, "frictionless" markets, as predicted by theories in information economics. However, earlier work has reported significant levels of price dispersion on the Internet, which is in contrast to theoretical predictions. A key feature of the existing stream of work has been its use of posted prices to estimate price dispersion. In theory, this can lead to an overestimation of price dispersion because a sale may not have occurred at the posted price. In this research, we use a unique data set of actual transaction prices collected from both the electronic and offline markets of buyers in a business-to-business market to evaluate the extent of price dispersion. We find that price dispersion in the electronic market is as low as 0.22%, which is substantially less than that reported in the existing literature. This near-zero price dispersion suggests that in some electronic markets the "law of one price" can prevail when we consider transaction prices, instead of posted prices. We further develop a theoretical framework that identifies several new drivers of price dispersion using transaction data. In particular, we focus on four product-level and market-level attributes-product cost, order cycle time, own price elasticity, and transaction quantity, and we estimate their impact on price dispersion. We also examine the electronic market's moderating role in the relationship between these drivers and price dispersion. Finally, we estimate the efficiency gains that accrue from transactions in the relatively friction-free market and find that the electronic market can enhance consumer surplus by as much as $97.92 million per year.
|keyword = electronic markets,Internet commerce,price dispersion,transaction prices,demand estimation,consumer surplus,econometrics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Vendor and Client Interaction for Requirements Assessment in Software Development: Implications for Feedback Process'''
{{header}}
{{article
|author= Rajiv Jayanth,Varghese S. Jacob,Suresh Radhakrishnan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = We study agency problems that arise when prototypes are used for requirements assessment. The precision with which the prototype helps a client assess his requirements depends on (a) the type of prototype provided by the vendor and (b) the client's feedback effort. The vendor can provide either a neutral or nonneutral prototype: The nonneutral prototype influences the client towards one particular set of requirements that may not be the true requirement, and the neutral prototype allows the client to assess his true requirements. This leads to the vendor's moral hazard problem. The client chooses to exert either the high or low feedback effort after the vendor provides the prototype. Because the effort is unobservable to the vendor, it can lead to the client exerting the low feedback effort: the client's commitment problem. In this paper we develop and discuss the role of the contract payment to provide the vendor with incentives to supply the neutral prototype, as well as for the client to commit to the high feedback effort. In this setting, we also examine the "anchoring" effect, wherein even a high-feedback effort can influence the client more toward a particular set of requirements with the nonneutral prototype. Our results highlight the interplay among the feedback effort, anchoring, and vendor payments.
|keyword = requirements assessment,anchoring,software prototyping,game theory,double moral hazard,incentives,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Contracting Efficiency and New Firm Survival in Markets Enabled by Information Technology'''
{{header}}
{{article
|author= Anjana Susarla,Anitesh Barua,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Application service providers (ASP), who host and maintain information technology (IT) applications across the Internet, emerged as an innovation in the way IT services are delivered to client firms. In spite of many potential benefits of this model, ASPs experienced business failure and high rates of exit. Drawing on agency theory, we argue that the efficiency of contracting arrangements between ASPs and client organizations is an important determinant of ASP survival. We test this prediction using a unique data set combining multiple sources that allows us to track an ASP from the year of founding through the beginning of 2006. Contractual misalignment, or adopting contracts mismatched with the underlying agency costs, significantly lowers the probability of survival of service providers in the ASP marketplace. The impact of misalignment is particularly severe when coupled with adjustment costs that impede the transition to aligned contracts. To account for potential heterogeneity in ASPs' knowledge of contracting, we test for endogenous self-selection of ASPs in the relationship between contractual misalignment and survival. Our results are robust to a variety of model specifications as well as alternate explanations of survival from multiple theoretical domains.
|keyword = agency theory,contractual misalignment,firm survival,propensity score matching,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Analyzing Sharing in Peer-to-Peer Networks Under Various Congestion Measures'''
{{header}}
{{article
|author= Monica Johar,Syam Menon,Vijay Mookerjee,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Historically, the use of peer-to-peer (P2P) networks has been limited primarily to user-initiated exchanges of (mostly music) files over the Internet. This traditional view of P2P networks is changing, however, and the use of P2P networks has been suggested for delivering general-purpose content over the Web (or corporate intranets), even in real time. We analyze sharing in a P2P community in this new context under three different congestion measures: delay, jitter, and packet loss. Sharing is important to study in the presence of congestion because most existing research on P2P networks views congestion in the network as a relatively insignificant criterion. However, when delivering general-purpose content, congestion and its relationship to sharing is a critical factor that influences end-user performance. This paper looks at P2P networks from this new perspective by explicitly considering the effects of congestion on user incentives for sharing. We also propose a simple incentive mechanism that induces socially optimal sharing.
|keyword = peer-to-peer networks,congestion,sharing,socially optimal sharing,free-riders,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Experimental Comparison of Linear and Nonlinear Price Combinatorial Auctions'''
{{header}}
{{article
|author= Tobias Scheffel,Alexander Pikovsky,Martin Bichler,Kemal Guler,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Combinatorial auctions are used for the efficient allocation of heterogeneous goods and services. They require appropriate software platforms that provide automated winner determination and decision support for bidders. Several promising ascending combinatorial auction formats have been developed throughout the past few years based on primal-dual algorithms and linear programming theory. The ascending proxy auction and iBundle result in Vickrey payoffs when the coalitional value function satisfies buyer submodularity conditions and bidders bid their best responses. These auction formats are based on nonlinear and personalized ask prices. In addition, there are a number of designs with linear prices that have performed well in experiments, the approximate linear prices auction, and the combinatorial clock auction. In this paper, we provide the results of lab experiments that tested these different auction formats in the same setting. We analyze aggregate metrics such as efficiency and auctioneer revenue for small-and medium-sized value models. In addition, we provide a detailed analysis not only of aggregate performance metrics but also of individual bidding behaviour under alternative combinatorial auction formats.
|keyword = laboratory experiments,electronic markets and auctions,decision support systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Technology and Firm Boundaries: Impact on Firm Risk and Return Performance'''
{{header}}
{{article
|author= Sanjeev Dewan,Fei Ren,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = In this paper, we empirically investigate the impact of information technology (IT) investment on firm return and risk financial performance, emphasizing the moderating role of the firm boundary strategies of diversification and vertical integration. Our results indicate a sharp contrast between the direct and interactive effects of IT on both the return (profitability) and risk (variability of returns) dimensions. Although the direct effect of IT capital is to increase firm risk for a given level of return, we find that suitable boundary strategies can moderate the impact of IT on firm performance in a way that increases return and decreases risk, at the margin. This interaction effect is strongest in service firms, in firms with high levels of IT investment intensity, and in more recent time periods. Our results are robust to alternative proxies for firm risk, including an ex ante risk measure (variability of analysts' earnings estimates), and alternative risk-return specifications. Put together, our results provide new insights into how IT and firm boundary strategies interact to affect the risk and return performance of firms.
|keyword = IT investments,risk and return,firm boundaries,diversification,vertical integration,strategic use of IT,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Environmental Uncertainty and IT Infrastructure Governance: A Curvilinear Relationship'''
{{header}}
{{article
|author= Ling Xue,Gautam Ray,Bin Gu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Extant research considers the IT governance choice to be a trade-off between the cost-efficiency of centralization and the responsiveness provided by local information processing. This view predicts that firms tend to decentralize IT governance in more uncertain environments. We investigate this issue by studying the relationship between environmental uncertainty and IT infrastructure governance in a sample of business units from Fortune 1000 companies. The key proposition in this paper is that the relationship between environmental uncertainty and decentralization in IT infrastructure governance is best characterized as a curvilinear relationship. That is, when environmental uncertainty increases from low to high, firms tend to first decentralize their IT infrastructure decisions to the business units to enhance their responsiveness; and then centralize their IT infrastructure decisions to the headquarters as uncertainty increases further, to achieve the benefits of coordination and to mitigate the potential agency problem in uncertain environments. Moreover, the study proposes that business unrelatedness between business units and their headquarters moderates the curvilinear relationship between environmental uncertainty and IT infrastructure governance. We find that both the propositions are supported by the data.
|keyword = IT infrastructure governance,environmental uncertainty,agency theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Punishment, Justice, and Compliance in Mandatory IT Settings'''
{{header}}
{{article
|author= Yajiong Xue,Huigang Liang,Liansheng Wu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = This paper aims to understand the influence of punishment and perceived justice on user compliance with mandatory information technology (IT) policies. Drawing on punishment research and justice theory, a research model is developed. Data collected from a field survey of enterprise resource planning (ERP) users are analyzed to test the proposed hypotheses. The results indicate that IT compliance intention is strongly influenced by perceived justice of punishment, which is negatively influenced by actual punishment. When perceived justice of punishment is considered, the effect of satisfaction on compliance intention decreases and that of perceived usefulness becomes insignificant. This paper contributes to information systems (IS) research and practice by drawing attention to the importance of punishment, particularly perceived justice of punishment, in mandatory IT settings. It delineates the relationships among actual punishment, punishment expectancy, perceived justice of punishment, and IT compliance intention, and thus provides a better understanding of user compliance behavior in mandatory IT settings.
|keyword = punishment,punishment expectancy,distributive justice,procedural justice,informational justice,fairness,mandatory context,compliance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Product Reviews and Competition in Markets for Repeat Purchase Products'''
{{header}}
{{article
|author= Xinxin Li,Lorin M. Hitt,Z. John Zhang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = This paper examines how information provided by online reviews influences firms' pricing strategy for repeat purchase products. It is commonly understood that online reviews can reduce consumer uncertainty about product characteristics and, therefore, have the potential to increase product demand and firm profits. However, when considering repeat purchase products, online reviews have an additional effect in that they can alter consumers' propensity to switch among products, which can intensify price competition and lead to lower profits. The strength of these potentially offsetting effects depends on the informativeness of consumer reviews, which is a function of both objective review accuracy and the ability of consumers to obtain information from reviews when their idiosyncratic preferences over product characteristics might differ from the preferences of reviewers. The interplay of these competing effects results in an S-shaped relationship between the quality of reviews and firm profits. There exists an optimal level of consumer informedness from the firms' perspective, and competing firms may have incentives to facilitate consumer reviews in some markets but not in others. Given firms' strategic pricing, consumers may also be worse off as review informativeness increases.
|keyword = game-theoretic model,installed customer base,online product reviews,price competition,repeat purchase products,review informativeness,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Drivers of the Long Tail Phenomenon: An Empirical Analysis'''
{{header}}
{{article
|author= Oliver Hinz,Jochen Eckert,Bernd Skiera,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = The Internet makes it easy to offer large assortments of products, tempting managers to chase the "long tail" that is, the phenomenon in which niche products gain a significant share of demand among all products. Yet few studies empirically examine the existence and drivers of this long tail phenomenon. This study uses a unique data set with 843,922 purchases from 143,939 customers that a monopolistic video-on-demand operator observed over 111 weeks after its launch of the service. The current analysis centers on the effects of increasing assortment sizes and improved search technologies on measures of the long tail, such as per customer demand, the share of products purchased from the assortment, the distribution of demand across products, and the concentration of demand. Increases in assortment sizes and better assortment quality lead to increases in demand per customer and a longer tail. The length of the tail (i.e., share of purchased products) is also driven by new customers and seasonal effects, such as school vacations, whereas the presence of high-quality blockbuster products shortens the tail. Different search technologies can shift demand toward niche products as well as toward blockbuster products.
|keyword = electronic commerce,long tail,recommendation systems,search technology,video-on-demand,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Quality in Wikipedia: The Effects of Group Composition and Task Conflict'''
{{header}}
{{article
|author= Ofer Arazy,Oded Nov,Raymond Patterson,Lisa Yeo,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = The success of Wikipedia demonstrates that self-organizing production communities can produce high-quality information-based products. Research on Wikipedia has proceeded largely atheoretically, focusing on (I) the diversity in members' knowledge bases as a determinant of Wikipedia's content quality, (2) the task-related conflicts that occur during the collaborative authoring process, and (3) the different roles members play in Wikipedia. We develop a theoretical model that explains how these three factors interact to determine the quality of Wikipedia articles. The results from the empirical study of 96 Wikipedia articles suggest that (I) diversity should be encouraged, as the creative abrasion that is generated when cognitively diverse members engage in task-related conflict leads to higher-quality articles, (2) task conflict should be managed, as conflict notwithstanding its contribution to creative abrasion can negatively affect group output, and (3) groups should maintain a balance of both administrative- and content-oriented members, as both contribute to the collaborative process.
|keyword = co-creation,cognitive diversity,collaboration,community-based production,group composition,information quality,task conflict,Wikipedia,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Influence of Industry Characteristics on Information Technology Outsourcing'''
{{header}}
{{article
|author= Wen Guang Qu,Alain Pinsonneault,Wonseok Oh,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Despite the extensive research on information technology (IT) outsourcing, our knowledge and understanding of how industry characteristics impact the use of IT outsourcing remain limited. Drawing upon theories from organization behavior and industrial economics, this study identifies four major industry characteristics (i.e., munificence, dynamism, concentration, and capital intensity) and investigates how each of these factors affects the use of IT outsourcing. Specifically, we postulate that the extent of industry munificence is positively related to the utilization of IT outsourcing. Since timely strategic actions are the crucial aspects of leveraging munificent resources, IT outsourcing, which can be implemented in short periods of time, is considered to be a preferred option in such environments. Furthermore, industry dynamism is also positively associated with IT outsourcing, given that firms in dynamically evolving industries tend to look for flexibility and avoid a large amount of fixed investments (e.g., IT development in-house). In contrast to these hypotheses, we predict that industry concentration is negatively related to IT outsourcing. Firms in concentrated industries are likely to develop their own IT infrastructures, as they are not constrained by institutional pressures or cost-driven strategic actions. Finally, because firms in capital-intensive industries tend to conform to long-standing traditional practices, and do not highly value novel and risky practices, they will be less likely to use IT outsourcing than firms in industries with low capital intensity. The data from the U.S. Bureau of Economic Analysis along with Compustat empirically validated all of the proposed hypotheses; however, only marginal support was found for the association between industry concentration and IT outsourcing. Our findings offer business executives and IT service providers strategic and managerial insights into the dynamics and complexities involved in the diverse aspects of industry environments and IT outsourcing decisions.
|keyword = capital intensity,industry concentration,industry dynamism,industry environments,industry munificence,IT outsourcing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Productivity and Performance Effects of Business Process Reengineering: A Firm-Level Analysis'''
{{header}}
{{article
|author= Kemal Altinkemer,Yasin Ozcelik,Zafer D. Ozdemir,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = We empirically investigate whether business process reengineering (BPR), which requires substantial investment in information technology to integrate separate tasks into complete cross-functional processes, is associated with enhanced firm productivity and performance. We analyze firm-level panel data covering the period 1987-2008 using fixed effects and first differencing, standard methods that account for unobservable firm-level effects. We find that return on assets drops significantly during the project initiation year. According to fixed effects results, the performance and productivity measures improve in a decreasing manner after project initiation, suggesting that BPR indeed positively affects firm performance on average. We also find that enterprise-wide BPR projects are associated with more negative returns during project initiation than functionally focused projects. However, there is no clear evidence regarding their superiority over functionally focused BPR projects in terms of performance improvements after project initiation, perhaps because grand projects are risky and sometimes lead to grand failures.
|keyword = business process reengineering,business value of information technology,panel regression,productivity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Privacy Concerns Versus Desire for Interpersonal Awareness in Driving the Use of Self-Disclosure Technologies: The Case of Instant Messaging in Two Cultures'''
{{header}}
{{article
|author= Paul Benjamin Lowry,Jinwei Cao,Andrea Everard,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Social computing technologies typically have multiple features that allow users to reveal their personal information to other users. Such self-disclosure (SD) behavior is generally considered positive and beneficial in interpersonal communication and relationships. Using a newly proposed model based on social exchange theory, this paper investigates and empirically validates the relationships between SD technology use and culture. In particular, we explore the effects of culture on information privacy concerns and the desire for online interpersonal awareness, which influence attitudes toward, intention to use, and actual use of SD technologies. Our model was tested using arguably the strongest social computing technology for online SD instant messaging (IM) with users from China and the United States. Our findings reveal that cross-cultural dimensions are significant predictors of information privacy concerns and desire for online awareness, which are, in turn, found to be predictors of attitude toward, intention to use, and actual use of IM. Overall, our proposed model is applicable to both cultures. Our findings enhance the theoretical understanding of the effects of culture and privacy concerns on SD technologies and provide practical suggestions for developers of SD technologies, such as adding additional control features to applications.
|keyword = instant messaging,privacy,self-disclosure,self-disclosure technologies,social computing technologies,social exchange theory,theory of reasoned action,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of Network Externalities on the Competition Between Open Source and Proprietary Software'''
{{header}}
{{article
|author= Hsing Kenneth Cheng,Yipeng Liu,Qian (Candy) Tang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = In this paper, we build analytical models to examine the impact of network externalities on the competition between open source software (OSS) and proprietary software. We investigate the competing OSS and proprietary software products with comparable functionalities in four different scenarios depending on whether they are compatible with each other and whether the underlying market is fully covered (i.e., all consumers adopt one of the two products). Furthermore, we study which party has the most incentive to make its product compatible with its counterpart. When the market is fully covered, the installed base and the profit of proprietary software increase at the expense of a decreasing user base for OSS in the presence of network externalities. This competitive imbalance becomes more pronounced when OSS and proprietary software are incompatible and the market is partially covered. Finally, we find that in the presence of network externalities, being compatible with its rival is not desirable for the proprietary software, but highly beneficial to the OSS community.
|keyword = competition,network externalities,open source software,software compatibility,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Consumer Acceptance of Recommendations by Interactive Decision Aids: The Joint Role of Temporal Distance and Concrete Versus Abstract Communications'''
{{header}}
{{article
|author= Clemens F. Koehler,Els Breugelmans,Benedict G. C. Dellaert,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Interactive decision aids (IDAs) typically use concrete, feature based approaches to interact with consumers. Recently, however, interaction designs that focus on communicating abstract consumer needs have been suggested as a promising alternative. This paper investigates how temporal distance moderates the effectiveness of these two competing IDA communication designs by its effect on consumers' mental representation of the product decision problem. Temporal distance is inherently connected to IDAs in two ways. Congruency between consumption timing (immediate versus distant) and IDA communication design (concrete versus abstract, respectively) increases the likelihood to accept the IDA's advice. This effect is also achieved by congruency between IDA process timing (immediate versus delayed delivery of recommendations) and IDA communication design (concrete versus abstract, respectively). We further show that this process is mediated by the perceived transparency of the IDA process. Managers and researchers need to take into account the importance of congruency between the user and the interface through which companies interact with their users and can further optimize IDAs so that they better match consumers' mental representations.
|keyword = construal level theory,consumer behavior,e-commerce,interactive decision aids,recommenders,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Mitigating Vendor Silence in Offshore Outsourcing: An Empirical Investigation'''
{{header}}
{{article
|author= Radhika P. Jain,Judith C. Simon,Robin S. Poston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = The tendency to remain silent about project-related issues can contribute to suboptimal project performance or project failure. Prior research in offshore outsourcing suggests that client managers should play a critical role to induce offshore vendors' employees not only to report project problems in a timely fashion but also to brainstorm and contribute ideas to a project. Also, the extant research on cross-cultural teams has emphasized the importance of cultural adaptation in the smooth functioning of these teams, but the role of cultural adaptation in silence mitigation has been largely underdeveloped in the literature. In this research, we bring these concepts of vendor silence and cultural adaptation in cross-cultural teams together and develop a process framework that illustrates how vendor silence may be mitigated in offshore outsourcing through various silence mitigation mechanisms. We then develop three propositions for organizational action toward mitigating vendor silence, which highlight the mediating role of cultural adaptation.
|keyword = collaboration effectiveness,IT outsourcing,mum effect,offshore outsourcing,offshore project management,organizational silence,silence mitigation,vendor silence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Individual Virtual Competence and Its Influence on Work Outcomes'''
{{header}}
{{article
|author= Yinglei Wang,Nicole Haggerty,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2011
|abstract = Witnessing both opportunities and challenges in virtual work arrangements, researchers have explored a number of technological, social, and organizational factors in order to improve virtual work effectiveness. However, there is limited understanding of an important element of virtual work the individuals. Our review of the literature indicates that the composition of individual knowledge, skills, and abilities (KSAs) required to work virtually would benefit from further research. In this study, we theoretically and empirically develop the construct of individual virtual competence that captures the key KSAs required to perform effectively in today's virtualized workplace, within a parsimonious nomological network. Substantiated by its explanatory power on individual perceived performance and satisfaction, individual virtual competence contributes to the literature by acknowledging a distinct workplace competency that can be incorporated in future individual-level studies of virtual phenomena. This research provides managers with a lens to understand differences in individual work outcomes and provides a lever to developing individuals' capabilities so as to improve work outcomes.
|keyword = individual virtual competence,individual work outcomes,virtual organization,virtual work,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Managing the Versions of a Software Product Under Variable and Endogenous Demand'''
{{header}}
{{article
|author= Kutsal Dogan,Yonghua Ji,Vijay S. Mookerjee,Suresh Radhakrishnan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Software product versioning (i.e., upgrading the product after its initial release) is a widely adopted practice followed by leading software providers such as Microsoft, Oracle, and IBM. Unlike conventional durable goods, software products are relatively easy to upgrade, making upgrades a strategic consideration in commercial software production. We consider a two-period model with a monopoly software provider who develops and releases a software product to the market. Unlike previous research, we consider demand variability and endogeneity to determine the functionality of the software in the first and second periods. Demand endogeneity is the impact of the word-of-mouth effect that positively relates the features in the initial release of the product to its demand in the second period. We also determine the design effort that should be spent in the first period to prepare for upgrading the product in the second period-upgrade design effort-to tap into the possible future demand. Results show that the upgrade design effort can be lower or higher when there is more market demand uncertainty. We also show that the features of the product in its initial release and upgrade design effort can be complements as well as substitutes, depending on the strength of the word-of-mouth effect. The results in this paper provide insights into how demand-side factors (market demand variability or demand endogeneity) can influence supply-side decisions (initial features and upgrade design effort). A key insight of the analysis is that a high word-of-mouth effect helps manage the product in the face of demand variability.
|keyword = software upgrades,demand endogeneity,upgrade design effort,demand variability,upgrade strategy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Firms as Incubators of Open-Source Software'''
{{header}}
{{article
|author= Amit Mehra,Rajiv Dewan,Marshall Freimer,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Many successful open-source projects have been developed by programmers who were employed by firms but worked on open-source projects on the side because of economic incentives like career improvement benefits. Such side work may be a good thing for the employing firms, too, if they get some strategic value from the open-source software and if the productivity of the programmers on these projects improves through learning-by-doing effects. However, the programmers may work more or less on these projects than what is best for the firms. To manage the programmers' efforts, the firms set appropriate employment policies and incentives. These policies and career concerns then together govern the programmers' effort allocation between the open-source and proprietary projects. We examine this relationship using a variant of the principal/agent model. We derive and characterize optimal employment contracts and show that firms either offer a bonus for only one of the two projects or do not offer any bonuses. However, if attractive alternate employment opportunities are available, they change their strategy and may offer bonuses for both projects simultaneously.
|keyword = open-source software,programmer incentives,programmer compensation,learning by doing,principal/agent,signalling,game theory,business models,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Examining the Strategic Alignment and Implementation Success of a KMS: A Subculture-Based Multilevel Analysis'''
{{header}}
{{article
|author= M. N. Ravishankar,Shan L. Pan,Dorothy E. Leidner,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Two important gaps exist in the information systems (IS) alignment research. First, there is scant research on the potential of organizational culture, and specifically subcultures to influence the strategic alignment of IS and organizations. Second, there is a dearth of literature that considers the relationship between alignment and implementation success. In this paper, we address both of these gaps by considering the influence of organizational subcultures on the alignment of a specific IS-a knowledge management system (KMS)-with organizational strategy. Our analysis demonstrates the important roles played by three different subcultures-enhancing, countercultural, and chameleon-in the alignment of the KMS. The analysis also underscores the complementary nature of the alignment and implementation literatures and suggests that they should be used in concert to explain the success of an IS. Drawing on our analysis, we build a subculture model, which depicts the intersection of alignment and implementation. From a managerial perspective, the subculture model highlights three different approaches to managing alignment and implementation. From a theoretical perspective, our paper highlights the need for IS alignment models to be modified, so that subunit-level analyses are incorporated. It also illustrates that organizations confront challenges of alignment and implementation simultaneously rather than sequentially.
|keyword = strategic alignment,information systems implementation,knowledge management systems,organizational subcultures,case study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Debate on Net Neutrality: A Policy Perspective'''
{{header}}
{{article
|author= Hsing Kenneth Cheng,Subhajyoti Bandyopadhyay,Hong Guo,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = The status quo of prohibiting broadband service providers from charging websites for preferential access to their customers-the bedrock principle of net neutrality (NN)-is under fierce debate. We develop a game-theoretic model to address two critical issues of NN: (1) Who are gainers and losers of abandoning NN? (2) Will broadband service providers have greater incentive to expand their capacity without NN? We find that if the principle of NN is abolished, the broadband service provider stands to gain from the arrangement, as a result of extracting the preferential access fees from content providers. Content providers are thus left worse off, mirroring the stances of the two sides in the debate. Depending on parameter values in our framework, consumer surplus either does not change or is higher in the short run. When compared to the baseline case under NN, social welfare in the short run increases if one content provider pays for preferential treatment but remains unchanged if both content providers pay. Finally, we find that the incentive to expand infrastructure capacity for the broadband service provider and its optimal capacity choice under NN are higher than those under the no-net-neutrality (NNN) regime, except in some specific cases. Under NN, the broadband service provider always invests in broadband infrastructure at the socially optimal level but either under-or overinvests in infrastructure capacity in the absence of NN.
|keyword = net neutrality,economics of net neutrality,broadband service providers,content providers,consumer surplus,social welfare,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Price Formats as a Source of Price Dispersion: A Study of Online and Offline Prices in the Domestic US Airline Markets'''
{{header}}
{{article
|author= Ramnath K. Chellappa,Raymond G. Sin,S. Siddarth,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = A large body of research in economics, information systems, and marketing has sought to understand sources of price dispersion. Previous empirical work has mainly offered consumer- and/or product-based explanations for this phenomenon. In contrast, our research explores the key role played by vendors' price-format adoption in explaining price dispersion. We empirically analyze over a half-million online and offline prices offered by major U. S. airlines in the top 500 domestic markets. Our study shows that a vendor's price format remains an important source of price dispersion in both channels even after accounting for other factors known to impact dispersion in airline ticket prices. Importantly, this finding is true for both transacted and posted tickets. We document several other interesting empirical findings. First, the lower variance in the prices of "everyday low price" (EDLP) firms serves to reduce the market-level dispersion in prices when such firms are present. Moreover, the price variance of non-EDLP firms in these markets is also lower than in those markets in which EDLP competitors are absent. Second, we also find that dispersion in offered prices increases closer to the departure date, which is consistent with theoretical assertion that price dispersion increases with reservation prices. Finally, we continue to observe dispersion of online prices even after accounting for vendor strategy and other known sources of dispersion, suggesting that the prices are unlikely to converge even in the presence of sophisticated online search mechanisms.
|keyword = online markets,price dispersion,airline industry,EDLP,hierarchical linear modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''REQUEST: A Query Language for Customizing Recommendations'''
{{header}}
{{article
|author= Gediminas Adomavicius,Alexander Tuzhilin,Rong Zheng,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Initially popularized by Amazon.com, recommendation technologies have become widespread over the past several years. However, the types of recommendations available to the users in these recommender systems are typically determined by the vendor and therefore are not flexible. In this paper, we address this problem by presenting the recommendation query language REQUEST that allows users to customize recommendations by formulating them in the ways satisfying personalized needs of the users. REQUEST is based on the multidimensional model of recommender systems that supports additional contextual dimensions besides traditional User and Item dimensions and also OLAP-type aggregation and filtering capabilities. This paper also presents the recommendation algebra RA, shows how REQUEST recommendations can be mapped into this algebra, and analyzes the expressive power of the query language and the algebra. This paper also shows how users can customize their recommendations using REQUEST queries through a series of examples.
|keyword = personalization,recommender systems,recommendation query language,multidimensional recommendations,contextual recommendations,recommendation algebra,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Finite Mixture Logit Model to Segment and Predict Electronic Payments System Adoption'''
{{header}}
{{article
|author= Ravi Bapna,Paulo Goes,Kwok Kee Wei,Zhongju Zhang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Despite much hype about electronic payments systems (EPSs), a 2004 survey establishes that close to 80% of between-business payments are still made using paper-based formats. We present a finite mixture logit model to predict likelihood of EPS adoption in business-to-business (B2B) settings. Our model simultaneously classifies firms into homogeneous segments based on firm-specific characteristics and estimates the model's coefficients relating predictor variables to EPS adoption decisions for each respective segment. While such models are increasingly making their presence felt in the marketing literature, we demonstrate their applicability to traditional information systems (IS) problems such as technology adoption. Using the finite mixture approach, we predict the likelihood of EPS adoption using a unique data set from a Fortune 100 company. We compare the finite mixture model with a variety of traditional approaches. We find that the finite mixture model fits the data better, controlling for the number of parameters estimated; that our explicit model-based segmentation leads to a better delineation of segments; and that it significantly improves the predictive accuracy in holdout samples. Practically, the proposed methodology can help business managers develop actionable segment-specific strategies for increasing EPS adoption by their business partners. We discuss how the methodology is potentially applicable to a wide variety of IS research.
|keyword = finite mixture model,logistic regression,market segmentation,clustering analysis,hierarchical logit regression,electronic payments systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Profiting from Knowledge Management: The Impact of Time and Experience'''
{{header}}
{{article
|author= Dong-Gil Ko,Alan R. Dennis,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Although many organizations are implementing knowledge management systems (KMS), there is little empirical evidence about whether KMS use can improve individual performance, and how time and experience influence the value derived from KMS use. Using hierarchical linear modeling (HLM) statistical analysis, we examined the impact of using a codification-based KMS on the sales performance of 2,154 sales representatives in a pharmaceutical firm over a 24-month period. We found that KMS had significant positive impacts on individual performance and that these performance benefits grew over time. Moreover, experience moderated the relationship between KMS use and individual performance. Knowledge workers with more experience were able to more quickly absorb and apply the knowledge from the KMS than were those with less experience, who took longer to benefit from KMS use. However, over time experience played a diminishing role in leveraging performance gains from KMS use, and knowledge workers with less experience eventually derived similar performance benefits as those of their more experienced counterparts.
|keyword = knowledge management systems use,performance improvement,time,job experience,longitudinal study,hierarchical linear modeling (HLM),
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Competing "Creatively" in Sponsored Search Markets: The Effect of Rank, Differentiation Strategy, and Competition on Performance'''
{{header}}
{{article
|author= Animesh Animesh,Siva Viswanathan,Ritu Agarwal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = Although efficiency-enhancing features of online markets have been well studied, much less is known about firms' differentiation strategies in these competitive markets or the outcomes of such differentiation. This study examines competition among firms in online sponsored search markets-one of the fastest growing and most competitive of online markets. We develop and test a model that predicts the clickthrough rate (CTR) of a seller's listing in a sponsored search setting. Drawing on consumer search theory and competitive positioning strategies, we theorize that CTR is jointly driven by a seller's positioning strategy as reflected by the unique selling proposition (USP) in its "ad creative," by its rank in a sponsored search listing, and by the nature of competition around the focal firm's listing. We use data from a field experiment conducted by a leading firm in the mortgage industry where the firm varied its rank and USP dynamically. Results suggest that sponsored search listings can act as effective customer segmentation mechanisms, consistent with a model of consumer search in directional markets. We further find that the effect on CTR of a firm's positioning strategy and its rank in a listing is strongly moderated by its ability to differentiate itself from adjacent rivals. We discuss the implications of our findings for sellers' strategies in sponsored search markets and for extending the understanding of consumer search behavior in directional markets.
|keyword = online competition,online differentiation,e-commerce,Internet marketing,online search behavior,sponsored search,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Conceptualizing and Testing a Social Cognitive Model of the Digital Divide'''
{{header}}
{{article
|author= Kwok-Kee Wei,Hock-Hai Teo,Hock Chuan Chan,Bernard C. Y. Tan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = The digital divide has loomed as a public policy issue for over a decade. Yet, a theoretical account for the effects of the digital divide is currently lacking. This study examines three levels of the digital divide. The digital access divide (the first-level digital divide) is the inequality of access to information technology (IT) in homes and schools. The digital capability divide (the second-level digital divide) is the inequality of the capability to exploit IT arising from the first-level digital divide and other contextual factors. The digital outcome divide (the third-level digital divide) is the inequality of outcomes (e. g., learning and productivity) of exploiting IT arising from the second-level digital divide and other contextual factors. Drawing on social cognitive theory and computer self-efficacy literature, we developed a model to show how the digital access divide affects the digital capability divide and the digital outcome divide among students. The digital access divide focuses on computer ownership and usage in homes and schools. The digital capability divide and the digital outcome divide focus on computer self-efficacy and learning outcomes, respectively. This model was tested using data collected from over 4,000 students in Singapore. The results generate insights into the relationships among the three levels of the digital divide and provide a theoretical account for the effects of the digital divide. While school computing environments help to increase computer self-efficacy for all students, these factors do not eliminate knowledge the gap between students with and without home computers. Implications for theory and practice are discussed.
|keyword = digital divide,social cognitive theory,computer ownership,school IT environment,computer self-efficacy,learning outcomes,adoption and impact of IT,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Compatibility and Proprietary Standards: The Impact of Conversion Technologies in IT Markets with Network Effects'''
{{header}}
{{article
|author= Charles Zhechao Liu,Esther Gal-Or,Chris F. Kemerer,Michael D. Smith,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2011
|abstract = In markets that exhibit network effects, the presence of digital conversion technologies provides an alternative mechanism to achieve compatibility. This study examines the impact of conversion technologies on market equilibrium in the context of sequential duopoly competition and proprietary technology standards. We analyze this question by departing from the extant literature to endogenize the decision to provide a converter and incorporate explicit negotiations between firms concerning the extent of conversion. We argue that these choices better reflect the environment facing firms in digital goods industries and find that these decisions change some of the established results in the literature. Specifically, we find that unless network effects are very large, the subgame-perfect equilibrium (SPNE) involves firms' agreeing to provide digital converters at a sufficiently low price to all consumers. At this equilibrium, both the entrant and the incumbent are better off because the provision of converters alleviates price competition in the market and leads to both higher product revenues and higher proceeds from the sale of converters. Moreover, under some circumstances, the provision of converters is welfare enhancing. These findings have important implications for research and practice in the adoption of new digital goods as the introduction of conversion technologies can reduce the social costs of standardization without compromising the benefits of network effects.
|keyword = network effects,conversion technologies,compatibility,technology standards,digital goods,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PROFILING THE RESEARCH PRODUCTIVITY OF TENURED INFORMATION SYSTEMS FACULTY AT US INSTITUTIONS'''
{{header}}
{{article
|author= Douglas L. Dean,Paul Benjamin Lowry,Sean Humpherys,
|source= MIS QUARTERLY
|year= 2011
|abstract = How many articles in highly rated journals do Information Systems research faculty publish to earn tenure? Which journals are highly rated outlets? Tenure candidates, promotion and tenure committees, and those who are asked to write external letters are frequently called upon to answer such questions. When Dennis et al. (2006) examined all IS Ph.D. graduates entering academic careers, few faculty had published enough articles in 20 "elite" journals in six years to meet tenure research expectations at research-intensive schools. Our study builds on the dialog started by Dennis et al. In our study, we counted the number of journal articles at the point of tenure for faculty who earned tenure within five to seven years after their Ph.D. graduation date. We also examined the effect of acknowledging different sets of journals as highly rated on the publication rates of faculty who earned tenure. Specifically, we examined the effects of expanding on Dennis et al. by including MIS Quarterly, Information Systems Research, Journal of Management Information Systems, Journal of the AIS, Information Systems Journal, European Journal of Information Systems, Journal of Information Technology, and Journal of Strategic Information Systems in the journal basket. We also looked at the effect of acknowledging highly rated non-IS business journals and highly rated computer science and engineering journals. Finally, we present journal publication benchmarks based on these findings for different types of research institutions.
|keyword = Tenure standards,publication standards,publication benchmarks,faculty productivity,scientometrics,Carnegie classification,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A SET OF PRINCIPLES FOR CONDUCTING CRITICAL RESEARCH IN INFORMATION SYSTEMS'''
{{header}}
{{article
|author= Michael D. Myers,Heinz K. Klein,
|source= MIS QUARTERLY
|year= 2011
|abstract = While criteria or principles for conducting positivist and interpretive research have been widely discussed in the IS research literature, criteria or principles for critical research are lacking. Therefore, the purpose of this paper is to propose a set of principles for the conduct of critical research in information systems. We examine the nature of the critical research perspective, clarify; its significance, and review its major discourses, recognizing that its mission and methods cannot be captured by a fixed set of criteria once and for all, particularly as multiple approaches are still in the process of defining their identity However, we suggest it is possible to formulate a set of principles capturing some of the commonalities of those approaches that have so far become most visible in the IS research literature. The usefulness of the principles is illustrated by analyzing three critical field studies in information systems. We hope that this paper will further reflection and debate on the important subject of grounding critical research methodology.
|keyword = Research methods,critical research,interpretive perspective,critical perspective,ethics,values,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ACTION DESIGN RESEARCH'''
{{header}}
{{article
|author= Maung K. Sein,Ola Henfridsson,Sandeep Purao,Matti Rossi,Rikard Lindgren,
|source= MIS QUARTERLY
|year= 2011
|abstract = Design research (DR) positions information technology artifacts at the core of the Information Systems discipline. However, dominant DR thinking takes a technological view of the IT artifact, paying scant attention to its shaping by the organizational context. Consequently, existing DR methods focus on building the artifact and relegate evaluation to a subsequent and separate phase. They value technological rigor at the cost of organizational relevance, and fail to recognize that the artifact emerges from interaction with the organizational context even when its initial design is guided by the researchers' intent. We propose action design research (ADR) as a new DR method to address this problem. ADR reflects the premise that IT artifacts are ensembles shaped by the organizational context during development and use. The method conceptualizes the research process as containing the inseparable and inherently interwoven activities of building the IT artifact, intervening in the organization, and evaluating it concurrently. The essay describes the stages of A DR and associated principles that encapsulate its underlying beliefs and values. We illustrate ADR through a case of competence management at Volvo IT.
|keyword = Action design research,action research,design research,emergence,ensemble artifact,organizational intervention,research method,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DO ONTOLOGICAL DEFICIENCIES IN MODELING GRAMMARS MATTER?'''
{{header}}
{{article
|author= Jan Recker,Michael Rosemann,Peter Green,Marta Indulska,
|source= MIS QUARTERLY
|year= 2011
|abstract = Conceptual modeling grammars are a fundamental means for specifying information systems requirements. However, the actual usage of these grammars is only poorly understood. In particular, little is known about how properties of these grammars inform usage beliefs such as usefulness and ease of use. In this paper, we use an ontological theory to describe conceptual modeling grammars in terms of their ontological deficiencies, and formulate two propositions in regard to how these ontological deficiencies influence primary usage beliefs. Using BPMN OS an example modeling grammar, we surveyed 528 modeling practitioners to test the theorized relationships. Our results show that users of conceptual modeling grammars perceive ontological deficiencies to exist, and that these deficiency perceptions are negatively associated with usefulness and ease of use of these grammars. With our research, we provide empirical evidence in support of the predictions of the ontological theory of modeling grammar expressiveness, and we identify previously unexplored links between conceptual modeling grammars and grammar usage beliefs. This work implies fur practice a much closer coupling of the act of (re-)designing modeling grammars with usage-related success metrics.
|keyword = Conceptual modeling,perception measurement,usage behavior,ontology,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PRICE DISCRIMINATION IN E-COMMERCE? AN EXAMINATION OF DYNAMIC PRICING IN NAME-YOUR-OWN PRICE MARKETS'''
{{header}}
{{article
|author= Oliver Hinz,Ii-Horn Hann,Martin Spann,
|source= MIS QUARTERLY
|year= 2011
|abstract = The enhanced abilities of online retailers to learn about their customers' shopping behaviors have increased fears of dynamic pricing, a practice in which a seller sets prices based on the estimated buyer's willingness-to-pay. However, among online retailers, a deviation from a one-price-for-all policy is the exception. When price discrimination is observed, it is often in the context of customer outrage about unfair pricing. One setting where pricing varies is the name-your-own-price (NYOP) mechanism, hi contrast to a typical retail setting, in NYOP markets, it is the buyer who places an initial offer. This offer is accepted if it is above some threshold price set by the seller. If the initial offer is rejected, the buyer can update her offer in subsequent rounds. By design, the final purchase price is opaque to the public; the price paid depends on the individual buyer's willingness-to-pay and offer strategy. Further, most forms of NYOP employ a fixed threshold price policy. In this paper, we compare a fixed threshold price setting with an adaptive threshold price setting. A seller who considers an adaptive threshold price has to weigh potentially greater profits against customer objections about the perceived fairness of such a policy. We first derive the optimal strategy for the seller. We analyze the effectiveness of an adaptive threshold price vis-a-vis a fixed threshold price on seller profit and customer satisfaction. Further, we evaluate the moderating effect of revealing the threshold price policy (adaptive versus fixed) to buyers. We test our model in a series of laboratory experiments and in a large field experiment at a prominent NYOP seller involving real purchases. Our results show that revealing the usage of an adaptive mechanism yields higher profits and more transactions than not revealing this information. In the field experiment, we find that applying a revealed adaptive threshold price can increase profits by over 20 percent without lowering customer satisfaction.
|keyword = Name-your-own-price,bargaining games,dynamic pricing,electronic commerce,customer satisfaction,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''STUCK IN THE CONFLICTED MIDDLE: A ROLE-THEORETIC PERSPECTIVE ON B2B E-MARKETPLACES'''
{{header}}
{{article
|author= Hope Koch,Ulrike Schultze,
|source= MIS QUARTERLY
|year= 2011
|abstract = Over the years, research on the implications of information technology on network governance structures has explored the "move to the market" and the "move to the middle" hypotheses. The middle is a space in which the logic and modalities of markets and hierarchies are intermingled. There is increasing evidence that most network relations reflect mixed-mode or hybrid logic. Despite the apparent advantages that make the middle so populous or "swollen" (Hennart 1993, p. 472), Kambil et al. (1999) highlight that it is riddled with uncertainty and high transaction costs. They label it "the conflicted middle" and propose that online marketplaces, specifically all-in-one markets, are capable of resolving this conflict. Unfortunately, however, Kambil et al. provide limited insight into both the nature of the conflict that plagues the middle and the ability of all-in-one markets to resolve it. To address these questions, this paper applies a role-theoretic perspective to the study of an e-marketplace that served the energy industry and evolved into an all-in-one market. Relying on an interpretive case study, this paper addresses the following research questions: (I) What is the nature of the conflict that characterizes the conflicted middle? (2) How do e-marketplaces, specifically all-in-one markets, help resolve this conflict? Our research highlights that brokers, trading partners, and agents who operate in the middle (where the contradictory logic of markets and hierarchies are mixed) experience goal, behavior, and identity conflict. All-in-one markets can help resolve these conflicts by supporting role integration at the group level and role segmentation at the individual level.
|keyword = B2B e-marketplace,all-in-one markets,network governance structures,market,hierarchy,move to the middle,role theory,role conflict,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WHEN FLEXIBLE ROUTINES MEET FLEXIBLE TECHNOLOGIES: AFFORDANCE, CONSTRAINT, AND THE IMBRICATION OF HUMAN AND MATERIAL AGENCIES'''
{{header}}
{{article
|author= Paul M. Leonardi,
|source= MIS QUARTERLY
|year= 2011
|abstract = Employees in many contemporary organizations work with flexible routines and flexible technologies. When those employees find that they are unable to achieve their goals in the current environment, how do they decide whether they should change the composition of their routines or the materiality of the technologies with which they work? The perspective advanced in this paper suggests that the answer to this question depends on how human and material agencies-the basic building blocks common to both routines and technologies-are imbricated. Imbrication of human and material agencies creates infrastructure in the form of routines and technologies that people use to cam, out their work. Routine or technological infrastructure used at any given moment is the result of previous imbrications of human and material agencies. People draw on this infrastructure to construct a perception that a technology either constrains their ability to achieve their goals, or that the technology affords the possibility of achieving new goals. The case of a computer simulation technology for automotive design used to illustrate this framework suggests that perceptions of constraint lead people to change their technologies while perceptions of affordance lead people to change their routines. This imbrication metaphor is used to suggest how a human agency approach to technology can usefully incorporate notions of material agency into its explanations of organizational change.
|keyword = Affordances,agency,materiality,routines,organizational change,technological change,perception,imbrication,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PRODUCT-RELATED DECEPTION IN E-COMMERCE: A THEORETICAL PERSPECTIVE'''
{{header}}
{{article
|author= Bo Xiao,Izak Benbasat,
|source= MIS QUARTERLY
|year= 2011
|abstract = With the advent of e-commerce, the potential of new Internet technologies to mislead or deceive consumers has increased considerably. This paper extends prior classifications of deception and presents a typology of product-related deceptive information practices that illustrates the various ways in which online merchants can deceive consumers via e-commerce product websites. The typology can be readily used as educational material to promote consumer awareness of deception in e-commerce and as input to establish benchmarks for good business practices :for online companies. In addition, the paper develops an integrative model and a set of theory-based propositions addressing why consumers are deceived by the various types of deceptive information practices and what factors contribute to consumer success (or failure,) in detecting such deceptions. The model not only enhances our conceptual understanding of the phenomenon of product-based deception and its outcomes in e-commerce but also serves as a foundation further theoretical and empirical investigations. Moreover, a better understanding of the factors contributing to or inhibiting deception detection can also help government agencies and consumer organizations design more effective solutions to fight online deception.
|keyword = Product-based information practices,electronic commerce,typology,stimulus-organism-response framework,model of deception detection,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TRANSDISCIPLINARY PERSPECTIVES ON ENVIRONMENTAL SUSTAINABILITY: A RESOURCE BASE AND FRAMEWORK FOR IT-ENABLED BUSINESS TRANSFORMATION'''
{{header}}
{{article
|author= Steve Elliot,
|source= MIS QUARTERLY
|year= 2011
|abstract = The quality and future of human existence are directly related to the condition of our natural environment, but we are damaging the environment. Scientific evidence has mounted a compelling case that human behavior is responsible for deterioration in the Earth's natural environment, with the rate of deterioration predicted to increase in the future. Acknowledging this evidence, the governments of 192 countries have formally agreed to take action to resolve problems with the climate system, one of the most highly stressed parts of the natural environment. While the intention is clear, the question of how best to proceed is not. The research reported here undertook a three-phase approach of selecting, analyzing, and synthesizing relevant literature to develop a holistic, transdisciplinary, integrative framework for IT-enabled business transformation. The focus on business transformation is because business is recognized as being a critical contributor in realizing the challenges of environmental sustainability due to its potential capacity for innovation and change locally, nationally, and globally This article also serves as a resource base for researchers to begin to undertake significant information systems and multidisciplinary work toward the goal of environmental sustainability. Through selection and analysis of illustrative examples of current work from 12 academic disciplines across 6 core categories, the framework addresses the key issues of uncertainty: (1) What is meant by environmental sustainability? (2) What are its major challenges? (3) What is being done about these challenges? (4) What needs to be done?
|keyword = Environmental sustainability,IT-enabled business transformation,literature review,transdisciplinary framework,technology,information systems (IS),information technology (IT),
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''HOW INFORMATION MANAGEMENT CAPABILITY INFLUENCES FIRM PERFORMANCE'''
{{header}}
{{article
|author= Sunil Mithas,Narayan Ramasubbu,V. Sambamurthy,
|source= MIS QUARTERLY
|year= 2011
|abstract = How do information technology capabilities contribute to firm performance? This study develops a conceptual model linking IT-enabled information management capability with three important organizational capabilities (customer management capability, process management capability, and performance management capability). We argue that these three capabilities mediate the relationship between information management capability and firm performance. We use a rare archival data set from a conglomerate business group that had adopted a model of performance excellence for organizational transformation based on the Baldrige criteria. This data set contains actual scores from high quality assessments of firms and intraorganizational units of the conglomerate, and hence provides unobtrusive measures of the key constructs to validate our conceptual model. We find that information management capability plays an important role in developing other firm capabilities for customer management, process management, and performance management. In turn, these capabilities favorably influence customer, financial, human resources, and organizational effectiveness measures of firm performance. Among key managerial implications, senior leaders must focus on creating necessary conditions for developing IT infrastructure and information management capability because they play a foundational role in building other capabilities far improved firm performance. The Baldrige model also needs some changes to more explicitly acknowledge the role and importance of information management capability so that senior leaders know where to begin in their journey toward business excellence.
|keyword = Information management capability,information technology,IT capability,customer management capability,process management capability,performance management capability,organizational capital,firm performance,performance excellence,business excellence,resource-based view,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE EFFECTS OF TREE-VIEW BASED PRESENTATION ADAPTATION ON MOBILE WEB BROWSING'''
{{header}}
{{article
|author= Boonlit Adipat,Dongsong Zhang,Lina Zhou,
|source= MIS QUARTERLY
|year= 2011
|abstract = Accessing the Web from mobile handheld devices has become increasingly common. However, accomplishing that task remains challenging mainly due to the physical constraints of handheld devices and the static presentation of Web pages. Adapting the presentation of Web pages is, therefore, critical to enabling effective mobile Web browsing and information searching. Based on cognitive fit theory and information foraging theory, we propose a novel hybrid approach to adapting Web page presentation that integrates three types of adaptation techniques, namely tree-view, hierarchical text summarization, and colored keyword highlighting. By following the design science research framework, we implemented the proposed approach on handheld devices and empirically evaluated the effects of presentation adaptation on mobile Web browsing. The results show that presentation adaptation significantly improves user performance and perception of mobile Web browsing. We also discover that the positive impact of presentation adaptation is moderated by the complexity of an information search task. The findings have significant theoretical and practical implications for the design and implementation of mobile Web applications.
|keyword = Presentation adaptation,mobile handheld device,Web browsing and searching,interface design,usability testing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Sponsored Search and Market Efficiency'''
{{header}}
{{article
|author= Vasant Dhar,Anindya Ghose,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Sponsored search is the mechanism whereby advertisers pay a fee to Internet search engines to be displayed alongside organic (nonsponsored) web search results. Based on prior literature, we draw an analogy between these markets and financial markets. We use the analogy as well as the key differences to present a theoretical framework consisting of a set of research questions about the pricing of keywords and design choices available to firms in sponsored search markets. These questions define an agenda for future research in sponsored search markets. They also have practical implications for advertisers and online marketplaces such as search engines and social media sites that support advertising.
|keyword = social media,social commerce,sponsored search,financial markets,user-generated content,market efficiency,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Cooperation, Coordination, and Governance in Multisourcing: An Agenda for Analytical and Empirical Research'''
{{header}}
{{article
|author= Ravi Bapna,Anitesh Barua,Deepa Mani,Amit Mehra,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Multisourcing, the practice of stitching together best-of-breed IT services from multiple, geographically dispersed service providers, represents the leading edge of modern organizational forms. While major strides have been achieved in the last decade in the information systems (IS) and strategic management literature in improving our understanding of outsourcing, the focus has been on a dyadic relationship between a client and a vendor. We demonstrate that a straightforward extrapolation of such a dyadic relationship falls short of addressing the nuanced incentive-effort-output linkages that arise when multiple vendors, who are competitors, have to cooperate and coordinate to achieve the client's business objectives. We suggest that when multiple vendors have to work together to deliver end-to-end services to a client, the choice of formal incentives and relational governance mechanisms depends on the degree of interdependence between the various tasks as well as the observability and verifiability of output. With respect to cooperation, we find that a vendor must not only put effort in a "primary" task it is responsible for but also cooperate through "helping" effort in enabling other vendors perform their primary tasks. In the context of coordination, we find that task redesign for modularity, OLAs, and governance structures such as the guardian vendor model represent important avenues for further research. Based on the analysis of actual multisourcing contract details over the last decade, interviews with leading practitioners, and a review of the single-sourcing literature, we lay a foundation for normative theories of multisourcing and present a research agenda in this domain.
|keyword = multisourcing,offshore outsourcing,cooperation,coordination,output verifiability,observability,relational governance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Virtual Worlds: A Performative Perspective on Globally Distributed, Immersive Work'''
{{header}}
{{article
|author= Ulrike Schultze,Wanda J. Orlikowski,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Virtual worlds are immersive, simulated, persistent, and dynamic environments that include rich graphical three dimensional spaces, high fidelity audio, motion, viewpoint, and interactivity. Initially dismissed as environments of play, virtual worlds have gained legitimacy in business and educational settings for their application in globally distributed work, project management, online learning, and real-time simulation. Understanding the emergent aspects of these virtual worlds and their implications for organizations will require both new theories and new methods. We propose that a performative perspective may be particularly useful as it challenges the existence of independent objects with fixed or given properties and boundaries, and focuses instead on situated and relational practices that enact entangled and contingent boundaries, entities, identities, and effects.
|keyword = virtual worlds,boundaries,identity,presence,performativity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Seeking the Configurations of Digital Ecodynamics: It Takes Three to Tango'''
{{header}}
{{article
|author= Omar A. El Sawy,Arvind Malhotra,YoungKi Park,Paul A. Pavlou,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = This paper starts from the premise that the simultaneous increase in environmental turbulence, the requisite speed of organizational change, and the intensified ubiquity of digital technologies are spawning a phenomenon that is messy, complex, and chaotic. Accordingly, we need to change the way we examine how information technology (IT) can help organizations build a strategic advantage in turbulent environments. We propose a more systemic and holistic perspective to theory building and testing in the information system (IS) strategy area and correspondingly appropriate methods that capture the complexity of this phenomenon. We term this phenomenon digital ecodynamics, defined as the holistic confluence among environmental turbulence, dynamic capabilities, and IT systems-and their fused dynamic interactions unfolding as an ecosystem. We believe that a more holistic understanding of digital ecodynamics will fuel the next leap in knowledge in the IS strategy area. First, extending the strategic management literature that has mainly focused on two-way interactions between environmental turbulence and dynamic capabilities, we foreground IT systems as a third central element. We use a "threesome tango" analogy(1) with strong mutual interdependence to accentuate our view of digital ecodynamics-while also stressing the emerging role of IT systems in triggering environmental turbulence and shaping dynamic capabilities to build a strategic advantage. Second, we propose a different paradigmatic lens (configuration theories) as an appropriate inquiring system to better understand the complexity of digital ecodynamics. The paper articulates the key aspects of configuration theories as inquiring systems, compares them with the more common variance theories and process theories, and illustrates the power of recent advances in configurational methods. Third, we create a preliminary roadmap for IS researchers to better examine digital ecodynamics using novel structural properties afforded by configuration theories (i.e., mutual causality, discontinuity, punctuated equilibria, nonlinear change). Fourth, we reflect on the broader opportunities that the configurational perspective of digital ecodynamics can create for IS strategy research. The paper ends by highlighting the double-barreled opportunity that digital ecodynamics renders, both as an energizing vision for IS strategy research and also as a reshaper of strategic management research and practice in a turbulent and digitized world.
|keyword = digital ecodynamics,information systems strategy,digital disruption,configuration theory,holistic perspective,environmental turbulence,dynamic capabilities,IT systems,ecosystem dynamics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Let's Shop Online Together: An Empirical Investigation of Collaborative Online Shopping Support'''
{{header}}
{{article
|author= Lei Zhu,Izak Benbasat,Zhenhui Jiang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Prior studies investigating business-to-consumer e-commerce have focused predominantly on online shopping by individuals on their own, although consumers often desire to conduct their shopping activities with others. This study explores the important, but seldom studied, topic of collaborative online shopping. It investigates two design components that are pertinent to collaborative online shopping support tools, namely, navigation support and communication support. Results from a laboratory experiment indicate that compared to separate navigation, shared navigation effectively reduces uncoupling (i.e., the loss of coordination with one's shopping partner) incidents per product discussed and leads to fewer communication exchanges dedicated to resolving each uncoupling incident, thereby enhancing coordination performance. Compared to text chat, voice chat does not help reduce the occurrence of uncoupling, but likely increases the efficiency in resolving uncoupling. The results further show that shared navigation and voice chat can significantly enhance the collaborative shoppers' perceptions of social presence derived from their online shopping experiences. The interaction effect on social presence implies that the benefit of shared navigation is higher in the presence of text chat than in the presence of voice chat.
|keyword = collaborative online shopping,shared navigation,common ground,media richness,uncoupling,social presence,electronic commerce,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Interaction Between Knowledge Codification and Knowledge-Sharing Networks'''
{{header}}
{{article
|author= De Liu,Gautam Ray,Andrew B. Whinston,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Current knowledge management (KM) technologies and strategies advocate two different approaches: knowledge codification and knowledge-sharing networks. However, the extant literature has paid limited attention to the interaction between them. This research draws on the literature on formal modeling of networks to examine the interaction between knowledge codification and knowledge-sharing networks. The analysis suggests that an increase in codification may damage existing network-sharing ties. Anticipating that, individuals may hoard their knowledge to protect their network ties, even when there are nontrivial rewards for codification. We find that despite the aforementioned tension between the codification and the network approach, a firm may still benefit from combining the two approaches. Specifically, when the future sharing potential between knowledge workers is high, a combination of the two approaches may outperform a codification-only or a network-only approach because the codification reward causes fewer network ties to break down, and the benefit from increased codification can offset the loss of some network ties. However, when the future sharing potential is low, an increase in codification reward can quickly break down the whole network. Thus, firms may be better off by pursuing a codification-only or a network-only strategy.
|keyword = knowledge management,codification,knowledge-sharing network,sharing potential,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Organizational Learning and Capabilities for Onshore and Offshore Business Process Outsourcing'''
{{header}}
{{article
|author= Jonathan Whitaker,Sunil Mithas,M. S. Krishnan,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = This paper identifies and analyzes firm-level characteristics that facilitate onshore and offshore business process outsourcing (BPO). We use organizational learning and capabilities to develop a conceptual model. We test the conceptual model with archival data on a broad cross section of U.S. firms. Our empirical findings indicate that firms with experience in onshore information technology (IT) outsourcing and capabilities related to IT coordination applications and process codification are more likely to engage in BPO, and firms with experience in internationalization are more likely to engage in offshore BPO. We also find that IT coordination applications have a greater impact on onshore BPO than on offshore BPO, and the effect of process codification is partly mediated through IT outsourcing.
|keyword = business process outsourcing,offshoring,organizational capabilities,organizational learning,outsourcing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Disruptive Effect of Open Platforms on Markets for Wireless Services'''
{{header}}
{{article
|author= Atanu Lahiri,Rajiv M. Dewan,Marshall Freimer,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Application-based pricing is common in telecommunications. Wireless carriers charge consumers more per byte of traffic for text messages than they do for wireless surfing or voice calls. Such pricing is possible because carriers and handset manufacturers have the ability to tag and meter each application. While tagging and metering are possible in the case of closed platforms such as iPhone, they are not in the case of open platforms such as Android. Android is open source with open application programming interfaces, and anyone can develop applications for it. Because the carriers have little control over applications, Android is inherently disruptive of differential pricing across applications. Users and neutrality advocates support Android, believing that it can increase consumer surplus by disrupting differential pricing. However, we show that the equilibrium under differential pricing is different from the equilibrium under open platforms, and it is particularly so with regard to the sets of consumers served and the quantities consumed. With open platforms, certain consumers are either not served or they are served a quantity that is less than what they would be served under differential pricing. Consequently, the consumer surplus and the social surplus are often lower with open platforms. Similarly, firms are expected to prefer differential pricing. We show that this expectation is also not true under certain circumstances in which open platforms and neutral pricing work like a quasi-bundle.
|keyword = net neutrality,nonlinear pricing,open platforms,quasi-bundling,wireless services,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Oligopolistic Pricing with Online Search'''
{{header}}
{{article
|author= Lizhen Xu,Jianqing Chen,Andrew Whinston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = In this paper, we set up a game-theoretic model to examine oligopolistic price competition, considering two features of online search: the existence of a common search ordering and shoppers who have nonpositive search cost. We find that in equilibrium firms set their prices probabilistically rather than deterministically, and different firms follow different price distributions. The equilibrium pricing pattern exhibits an interesting local-competition feature in which direct price competition occurs only between firms adjacent to each other. Further, we incorporate consumers' search strategies into the model so that both search order and stopping rules are determined rationally by consumers. We show that similar patterns may continue to hold in the fully rational framework when consumers have higher inspection costs for inferior positions.
|keyword = local competition,oligopolistic competition,online search,price dispersion,pricing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Asymmetry in Information Systems Consulting: Toward a Theory of Relationship Constraints'''
{{header}}
{{article
|author= Gregory S. Dawson,Richard T. Watson,Marie-Claude Boudreau,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Opportunism, or self-interest seeking with guile, is often witnessed in human behavior, and it bedevils human interactions and relationships. Organizations expend considerable effort to reduce opportunism. Agency theory espouses formal contracts as effective constraints on opportunism; however, a consultant's use of tacit knowledge subjects clients to information asymmetry that is not amenable to formal contracts. The principal professional lens was developed to accommodate the presence of tacit knowledge, but it ignores formal contracts and, like agency theory, ignores the existence of principal opportunism. This examination of information systems (IS) consulting notes that when information asymmetry is present, both clients and consultants sometimes behave opportunistically. The level of information asymmetry, the type of knowledge, and the level of contract specificity in an IS consulting engagement determine the mixture of legal and social constraints that are efficacious. Based on these revelations and the inadequacy of other theories, a theoretical model of relationship constraints is developed to explain the interplay between signaling and screening, knowledge type, contract specificity, and the levels of information asymmetry in predicting adopted constraint mechanisms. For researchers, this new model offers a lens to study opportunism from a knowledge-based perspective, whereas for practitioners it offers the possibility of forestalling a decline in markets due to rampant opportunism.
|keyword = agency theory,information asymmetry,information systems consulting,opportunism,principal-agent relationship,screening,signaling,tacit knowledge,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Developer Heterogeneity and Formation of Communication Networks in Open Source Software Projects'''
{{header}}
{{article
|author= Param Vir Singh,Yong Tan,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Over the past few years, open source software (OSS) development has gained a huge popularity and has attracted a large variety of developers. According to software engineering folklore, the architecture and the organization of software depend on the communication patterns of the contributors. Communication patterns among developers influence knowledge sharing among them. Unlike in a formal organization, the communication network structures in an OSS project evolve unrestricted and unplanned. We develop a non-cooperative game-theoretic model to investigate the network formation in an OSS team and to characterize the stable and efficient structures. Developer heterogeneity in the network is incorporated based on their informative value. We find that there may exist several stable structures that are inefficient and there may not always exist a stable structure that is efficient. The tension between the stability and efficiency of structures results from developers acting in their self-interest rather than the group interest. Whenever there is such tension, the stable structure is either underconnected across types or overconnected within type of developers from an efficiency perspective. We further discuss how an administrator can help evolve a stable network into an efficient one. Empirically, we use the latent class model and analyze two real-world OSS projects hosted at Source Forge. For each project, different types of developers and a stable structure are identified, which fits well with the predictions of our model. Overall, our study sheds light on how developer abilities and incentives affect communication network formation in OSS projects.
|keyword = analytical modeling,economics of IS,network formation,software development,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Task and Social Information Seeking: Whom Do We Prefer and Whom Do We Approach?'''
{{header}}
{{article
|author= Yunjie (Calvin) Xu,Hee-Woong Kim,Atreyi Kankanhalli,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Employee information-seeking behavior shapes the formation of organizational communication networks and affects performance. However, it is not easy to facilitate, particularly through information technology, and its motivations are not well understood. Recognizing two broad categories of information-that is, task and social information-this study investigates and compares the antecedents of task and social information seeking. Deriving from the relational communication perspective, informational and relational motivations are modeled as the two main antecedents of source preference and sourcing frequency in dyadic information seeking. Through a survey of employee dyads, our findings indicate that perceived information relevance is a significant antecedent of source preference for both task and social information seeking, whereas perceived relational benefit is significant in the context of task information. The results also show that perceived relational benefit has a stronger effect on source preference in task information seeking than in social information seeking. Furthermore, preference for a source is a significant antecedent of the frequency of sourcing in both contexts. This study provides an explanation of the formation of organizational communication networks. It suggests that organizational information and communication technologies not only need to support information delivery but must also facilitate relationship management for the seeker.
|keyword = perceived information relevance,perceived relational benefit,preference for source,social information seeking,sourcing frequency,task information seeking,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Bidding Patterns, Experience, and Avoiding the Winner's Curse in Online Auctions'''
{{header}}
{{article
|author= Robert F. Easley,Charles A. Wood,Sharad Barkataki,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = The design and implementation of online auctions has given rise to a unique set of bidding strategies that has stimulated a growing body of research. We make use of a theoretically grounded, well-understood, and empirically observable bidder behavior-the winner's curse adjustment for the expected number of bidders in an auction-to examine the relationships between bidder experience, bidding patterns, and the winner's curse adjustment in rare coin online auctions. We also examine the impact of uncertainty on the winner's curse adjustment, both by using precise measures of uncertainty and by considering seller and bidder strategies for reducing that uncertainty. We analyze a complete record of all auctions in a three-month period for rare U.S. coins, examining 284,681 bids from 62,625 auctions hosted by eBay, the market leader in online auctions. One of the main contributions of this paper is to demonstrate that the bidding patterns associated with different bidders are strongly related to whether they calculate their bids to take into account the number of competing bidders, as predicted for common-value auctions. This is a substantial extension and empirical confirmation of prior work that has explored the implications of different observed patterns of bidding. We also explore new territory by examining the relationships between bidder experience, bidding patterns observed, and the economic outcomes for bidders. We are able to show that bidders with more domain-specific experience (rather than general auction experience) make better adjustments for the winner's curse, that experience has an effect on the type of bidding strategy, and that the type of bidding strategy has a significant effect on the economic outcomes for the bidders.
|keyword = bidder experience,bidder strategies,bidding patterns,online auctions,winner's curse,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Entertainment Without Borders: The Impact of Digital Technologies on Government Cultural Policy'''
{{header}}
{{article
|author= Hsing Kenneth Cheng,Juan Feng,Gary J. Koehler,Sean Marston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Many countries limit the influence of foreign entertainment products, such as music, film, and television programs, to protect their domestic cultural industry. Commonly observed policy tools include quotas, tariffs, and subsidies. However, advances in digital technology enable consumers to access digital versions of foreign entertainment programs via the Internet, a leakage channel that bypasses government protection methods. This calls for a reexamination of the effectiveness of these traditional tools. We build a unified analytical framework to study the impact of digital technology on cultural protection policies. We find that in the presence of Internet leakage, imposing a quota is the least effective protection policy to maximize the total domestic social welfare, but using either a tariff or subsidy policy is optimal, depending on the quality difference between domestic and foreign entertainment programs via the traditional channel and the Internet. Using quotas remains the least effective policy when we extend the analyses to consider the presence of piracy. In addition to the quality difference between foreign and domestic entertainment, the proportion of unethical consumers and the cost of piracy determine whether using tariffs or subsidies is the optimal policy.
|keyword = cultural protection policy,digital entertainment,quotas,subsidies,tariffs,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Platform Evolution: Coevolution of Platform Architecture, Governance, and Environmental Dynamics'''
{{header}}
{{article
|author= Amrit Tiwana,Benn Konsynski,Ashley A. Bush,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = The emergence of software-based platforms is shifting competition toward platform-centric ecosystems, although this phenomenon has not received much attention in information systems research. Our premise is that the coevolution of the design, governance, and environmental dynamics of such ecosystems influences how they evolve. We present a framework for understanding platform-based ecosystems and discuss five broad research questions that present significant research opportunities for contributing homegrown theory about their evolutionary dynamics to the information systems discipline and distinctive information technology-artifact-centric contributions to the strategy, economics, and software engineering reference disciplines.
|keyword = platforms,ecosystem,architecture,modularity,environment,evolutionary dynamics,coevolution,governance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Designing Smart Markets'''
{{header}}
{{article
|author= Martin Bichler,Alok Gupta,Wolfgang Ketter,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Electronic markets have been a core topic of information systems (IS) research for last three decades. We focus on a more recent phenomenon: smart markets. This phenomenon is starting to draw considerable interdisciplinary attention from the researchers in computer science, operations research, and economics communities. The objective of this commentary is to identify and outline fruitful research areas where IS researchers can provide valuable contributions. The idea of smart markets revolves around using theoretically supported computational tools to both understand the characteristics of complex trading environments and multiechelon markets and help human decision makers make real-time decisions in these complex environments. We outline the research opportunities for complex trading environments primarily from the perspective of design of computational tools to analyze individual market organization and provide decision support in these complex environments. In addition, we present broad research opportunities that computational platforms can provide, including implications for policy and regulatory research.
|keyword = auctions,design,decision support systems,experimentation,smart markets,software agents,platforms,preferences,trading agent competition,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Design, Use, and Consequences of Virtual Processes'''
{{header}}
{{article
|author= Eric Overby,Sandra A. Slaughter,Benn Konsynski,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Process virtualization occurs when a process that relies upon physical interaction between people and/or objects is transitioned to a virtual environment. Process virtualization is having profound effects on society, as an increasing number of both business and nonbusiness processes such as those related to education, medicine, and dating are being migrated to virtual environments. There is a vast literature that relates to process virtualization topics, but it is fragmented across different domains. The purpose of this paper is to propose a research agenda to develop high-level theories and frameworks that inform the general process virtualization phenomenon. Developing these theories and frameworks will synthesize existing knowledge and provide a theoretical foundation upon which to add new knowledge as it is created. This will help policy makers maximize the substantial benefits of virtual processes while minimizing the risks. Given the background, interests, and skills of IS scholars, the IS discipline is well suited to lead in this endeavor.
|keyword = process virtualization,virtual,physical,theory construction,electronic commerce,online dating,distance learning,telemedicine,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Digital Natives and Ubiquitous Information Systems'''
{{header}}
{{article
|author= Shahper Vodanovich,David Sundaram,Michael Myers,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Most information systems research until now has focused on information systems in organizations and their use by digital immigrants. Digital immigrants are those who were not born into the digital world-they learnt to use information systems at some stage in their adult lives. An underlying assumption of much of this research is that users "resist" technology or at least have some difficulty in accepting it. Digital natives, conversely, are those who have grown up in a world where the use of information and communications technology is pervasive and ubiquitous. These ubiquitous technologies, networks, and associated systems have proliferated and have woven themselves into the very fabric of everyday life. This article suggests that the rise of the digital native, along with the growth of ubiquitous information systems (UIS), potentially represents a fundamental shift in our "paradigm" for IS research. We propose a research agenda that focuses on digital natives and UIS.
|keyword = digital native,digital immigrant,ubiquitous information systems,pervasive computing,interorganizational information systems,IT diffusion and adoption,user acceptance of IT,mobile computing,enterprise systems,IT and new organizational forms,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The New Organizing Logic of Digital Innovation: An Agenda for Information Systems Research'''
{{header}}
{{article
|author= Youngjin Yoo,Ola Henfridsson,Kalle Lyytinen,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = In this essay, we argue that pervasive digitization gives birth to a new type of product architecture: the layered modular architecture. The layered modular architecture extends the modular architecture of physical products by incorporating four loosely coupled layers of devices, networks, services, and contents created by digital technology. We posit that this new architecture instigates profound changes in the ways that firms organize for innovation in the future. We develop (1) a conceptual framework to describe the emerging organizing logic of digital innovation and (2) an information systems research agenda for digital strategy and the creation and management of corporate information technology infrastructures.
|keyword = digitization,digital innovation,product architecture,layered modular architecture,organizing logic,doubly distributed networks,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Long Tails vs. Superstars: The Effect of Information Technology on Product Variety and Sales Concentration Patterns'''
{{header}}
{{article
|author= Erik Brynjolfsson,Yu (Jeffrey) Hu,Michael D. Smith,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = The Internet and related information technologies are transforming the distribution of product sales across products, and these effects are likely to grow in coming years. Both the Long Tail and the Superstar effect are manifestations of these changes, yet researchers lack consistent metrics or models for integrating and extending their insights and predictions. In this paper, we begin with a taxonomy of the technological and nontechnological drivers of both Long Tails and Superstars and then define and compare the key metrics for analyzing these phenomena. The core of the paper describes a large and promising set of questions forming a research agenda. Important opportunities exist for understanding future changes in sales concentration patterns; the impact on supply chains (including cross-channel competition, competition within the Internet channel, implications for the growth of firms, and the balance of power within the supply chain); implications for pricing, promotion, and product design; and, ultimately, the potential effects on society in general. Our approach provides an introduction to some of the relevant research findings and allows us to identify opportunities for cross-pollination of methods and insights from related research topics.
|keyword = Long Tail,Superstar,product variety,sales concentration,information technology,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Digital Infrastructures: The Missing IS Research Agenda'''
{{header}}
{{article
|author= David Tilson,Kalle Lyytinen,Carsten Sorensen,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Since the inauguration of information systems research (ISR) two decades ago, the information systems (IS) field's attention has moved beyond administrative systems and individual tools. Millions of users log onto Facebook, download iPhone applications, and use mobile services to create decentralized work organizations. Understanding these new dynamics will necessitate the field paying attention to digital infrastructures as a category of IT artifacts. A state-of-the-art review of the literature reveals a growing interest in digital infrastructures but also confirms that the field has yet to put infrastructure at the centre of its research endeavor. To assist this shift we propose three new directions for IS research: (1) theories of the nature of digital infrastructure as a separate type of IT artifact, sui generis; (2) digital infrastructures as relational constructs shaping all traditional IS research areas; (3) paradoxes of change and control as salient IS phenomena. We conclude with suggestions for how to study longitudinal, large-scale sociotechnical phenomena while striving to remain attentive to the limitations of the traditional categories that have guided IS research.
|keyword = generativity,digital infrastructure,control points,IT artifact,IS research agenda,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Vigilant Interaction in Knowledge Collaboration: Challenges of Online User Participation Under Ambivalence'''
{{header}}
{{article
|author= Sirkka L. Jarvenpaa,Ann Majchrzak,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Online participation engenders both the benefits of knowledge sharing and the risks of harm. Vigilant interaction in knowledge collaboration refers to an interactive emergent dialogue in which knowledge is shared while it is protected, requiring deep appraisals of each others' actions in order to determine how each action may influence the outcomes of the collaboration. Vigilant interactions are critical in online knowledge collaborations under ambivalent relationships where users collaborate to gain benefits but at the same time protect to avoid harm from perceived vulnerabilities. Vigilant interactions can take place on discussion boards, open source development, wiki sites, social media sites, and online knowledge management systems and thus is a rich research area for information systems researchers. Three elements of vigilant interactions are described: trust asymmetry, deception and novelty. Each of these elements challenges prevailing theory-based assumptions about how people collaborate online. The study of vigilant interaction, then, has the potential to provide insight on how these elements can be managed by participants in a manner that allows knowledge sharing to proceed without harm.
|keyword = online participation,knowledge collaboration,vigilance,trust,distrust,deception,novelty,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Digital Transformation of Healthcare: Current Status and the Road Ahead'''
{{header}}
{{article
|author= Ritu Agarwal,Guodong (Gordon) Gao,Catherine DesRoches,Ashish K. Jha,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = As the United States expends extraordinary efforts toward the digitization of its health-care system, and as policy makers across the globe look to information technology (IT) as a means of making health-care systems safer, more affordable, and more accessible, a rare and remarkable opportunity has emerged for the information systems research community to leverage its in-depth knowledge to both advance theory and influence practice and policy. Although health IT (HIT) has tremendous potential to improve quality and reduce costs in healthcare, significant challenges need to be overcome to fully realize this potential. In this commentary, we survey the landscape of existing studies on HIT to provide an overview of the current status of HIT research. We then identify three major areas that warrant further research: (1) HIT design, implementation, and meaningful use; (2) measurement and quantification of HIT payoff and impact; and (3) extending the traditional realm of HIT. We discuss specific research questions in each domain and suggest appropriate methods to approach them. We encourage information systems scholars to become active participants in the global discourse on health-care transformation through IT.
|keyword = health information technology,health-care transformation,electronic health records,meaningful use,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Reframing the Dominant Quests of Information Systems Strategy Research for Complex Adaptive Business Systems'''
{{header}}
{{article
|author= Hueseyin Tanriverdi,Arun Rai,N. Venkatraman,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = We review and reframe three main quests of research on information systems (IS) strategy: (1) the strategic alignment quest, (2) the integration quest, and (3) the sustained competitive advantage quest. The assumptions and logic of these quests have become less relevant in increasingly complex adaptive business systems (CABS), where the competitive performance landscapes of products and services are highly dynamic and co-evolve. We revise the strategic alignment quest to propose a co-evolution quest that addresses not only competitive strategy questions of a firm but also corporate strategy questions. The co-evolution quest seeks to increase a firm's agility and dynamism in repositioning itself, identifying profitable product-market positions as the evolving competitive landscape erodes the profitability of the firm's existing positions. To support the co-evolution quest, we revise the integration quest and propose a reconfiguration quest that encompasses not only business processes but also products and services, as well as the contracts, resources, and transactions associated with them. As the firm makes repositioning moves to co-evolve with the competitive landscape, the reconfiguration quest seeks to increase the firm's agility in disintegrating its existing nexus of contracts, resources, and transactions that support the old positions and in reconfiguring new ones that support the new positions. Finally, we revise the sustained competitive advantage quest to propose a renewal quest that recognizes the temporary nature of competitive advantage in CABS. The renewal quest seeks to destabilize the firm's old sources of competitive advantage when competitive dynamics erode their utility, rapidly create new sources of competitive advantage, and concatenate a series of temporary advantages over time. The three reframed quests provide the foundation for a research agenda on IS strategy in CABS.
|keyword = information systems strategy,complex adaptive business systems,emergence,strategic alignment,integration,sustained advantage,temporary advantage,co-evolution,reconfiguration,renewal,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Alliances, Rivalry, and Firm Performance in Enterprise Systems Software Markets: A Social Network Approach'''
{{header}}
{{article
|author= Ramnath K. Chellappa,Nilesh Saraf,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Enterprise systems software (ESS) is a multibillion dollar industry that produces systems components to support a variety of business functions for a widerange of vertical industry segments. Even if it forms the core of an organization's information systems (IS) infrastructure, there is little prior IS research on the competitive dynamics in this industry. Whereas economic modeling has generally provided the methodological framework for studying standards-driven industries, our research employs social network methods to empirically examine ESS firm competition. Although component compatibility is critical to organizational end users, there is an absence of industry-wide ESS standards and compatibility is ensured through interfirm alliances. First, our research observes that this alliance network does not conform to the equilibrium structures predicted by economics of network evolution supporting the view that it is difficult to identify dominant standards and leaders in this industry. This state of flux combined with the multifirm multicomponent nature of the industry limits the direct applicability of extant analytical models. Instead, we propose that the relative structural position acquired by a firm in its alliance network is a reasonable proxy for its standards dominance and is an indicator of its performance. In lieu of structural measures developed mainly for interpersonal networks, we develop a measure of relative firm prominence specifically for the business software network where benefits of alliances may accrue through indirect connections even if attenuated. Panel data analyses of ESS firms that account for over 95% of the industry revenues, show that our measure provides a superior model fit to extant social network measures. Two interesting counterintuitive findings emerge from our research. First, unlike other software industries compatibility considerations can trump rivalry concerns. We employ quadratic assignment procedure to show that firms freely form alliances even with their rivals. Second, we find that smaller firms enjoy a greater value from acquiring a higher structural position as compared to larger firms.
|keyword = technology standards,software industry,enterprise resource planning (ERP),software architecture,partnerships,social network theory,standards competition,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding Willingness-to-Pay Formation of Repeat Bidders in Sequential Online Auctions'''
{{header}}
{{article
|author= Paulo B. Goes,Gilbert G. Karuga,Arvind K. Tripathi,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = A growing number of vendors are using a sequence of online auctions to sell large inventories of identical items. Although bidding strategies and bidder behavior in single auctions have been extensively studied, limited research exists on bidding in sequential auctions. We seek to explain how bidders in such an environment learn from the information, and form and update their willingness to pay (WTP). Using a large data set from an online auction retailer, we analyze the evolution of the bidders' WTP as well as the effect of auction design on bidders' WTP in sequential auctions. We see our study in the context of a longitudinal field experiment, in which we were able to track actions of repeat bidders over an extended period of time. Our results show that bidders' WTP in sequential auctions can be explained from their demand characteristics, their participation experience in previous auctions, outcomes in previous auctions, and auction design parameters. We also observe, characterize, and measure what we call a modified demand reduction effect exhibited across different auctions, over time, by multiunit demand bidders. Our findings are important to enable better auction mechanism design, and more sophisticated bidding tools that explore the rich information environment of sequential auctions.
|keyword = sequential online auctions,bidding behavior,willingness to pay,demand reduction,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Complementarities in the Diffusion of Personal Computers and the Internet: Implications for the Global Digital Divide'''
{{header}}
{{article
|author= Sanjeev Dewan,Dale Ganley,Kenneth L. Kraemer,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = This paper studies the cross-country diffusion of personal computers (PCs) and the Internet, and examines how the diffusive interactions across these technologies affect the evolution of the global digital divide. We adopt a generalized diffusion model that incorporates the impact of one technology's installed base on the diffusion of the other technology. We estimate the model on data from 26 developing and developed countries between 1991 and 2005. We find that the codiffusion effects between PCs and the Internet are complementary in nature and the impact of PCs on Internet diffusion is substantially stronger in developing countries as compared to developed ones. Furthermore, our results suggest that these codiffusive effects are a significant driver of the narrowing of the digital divide. We also examine the policy implications of our results, especially with respect to how complementarities in the diffusion of PC and Internet technologies might be harnessed to further accelerate the narrowing of the global digital divide.
|keyword = IT penetration,IT diffusion,digital divide,global IT,diffusion model,codiffusion,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Applying the Randomized Response Technique to Elicit Truthful Responses to Sensitive Questions in IS Research: The Case of Software Piracy Behavior'''
{{header}}
{{article
|author= Samuel S. K. Kwan,Mike K. P. So,Kar Yan Tam,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Research on software piracy often relies on self-reports by individual users and thus suffers from possible response distortion attributable to a variety of human motivations. Conclusions drawn directly from distorted self-reports may misguide managerial and policy decisions. The randomized response technique (RRT) was proposed as a remedy to response distortion. In this paper, a model based on RRT was used to illustrate how truthful responses to sensitive questions can be empirically estimated. The model was tested in two empirical studies on software piracy. Consistent with our expectations, respondents responding to RRT were more willing to disclose sensitive information about their attitudes, intentions, and behaviors on software piracy. Nontrivial distortions were demonstrated in causal relationships involving sensitive and nonsensitive variables. The study extends RRT to multivariate analysis and illustrates the feasibility and usefulness of the method in studying sensitive behavioral issues in the information systems (IS) domain.
|keyword = response distortion,software piracy,randomized response technique,unrelated question design,method of moments,socially desirable responding,structural equation modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Role of Organizational Controls and Boundary Spanning in Software Development Outsourcing: Implications for Project Performance'''
{{header}}
{{article
|author= Anandasivam Gopal,Sanjay Gosain,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Past research has studied how the selection and use of control portfolios in software projects is based on environmental and task characteristics. However, little research has examined the consequences of control mode choices on project performance. This paper reports on a study that addresses this issue in the context of outsourced software projects. In addition, we propose that boundary-spanning activities between the vendor and the client enable knowledge sharing across organizational and knowledge domain boundaries. This is expected to lead to facilitation of control through specific incentives and performance norms that are suited to client needs as well as the vendor context. Therefore, we argue that boundary spanning between the vendor and client moderates the relationship between formal controls instituted by the vendor on the development team and project performance. We also hypothesize the effect of collaboration as a clan control on project performance. We examine project performance in terms of software quality and project efficiency. The research model is empirically tested in the Indian software industry setting on a sample of 96 projects. The results suggest that formal and informal control modes have a significant impact on software project outcomes, but need to be finely tuned and directed toward appropriate objectives. In addition, boundary-spanning activities significantly improve the effectiveness of formal controls. Finally, we find that collaborative culture has provided mixed benefits by enhancing quality but reducing efficiency.
|keyword = software outsourcing,organizational control,software quality,project overruns,boundary spanning,partial least squares,surveys,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Mapping the Field of Virtual Work: A Cocitation Analysis'''
{{header}}
{{article
|author= Sumita Raghuram,Philipp Tuertscher,Raghu Garud,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Interest in the area of virtual work continues to increase with articles being written from different disciplinary perspectives-e. g., information systems (IS), management, psychology, and transportation. In this paper, we map research on virtual work to (a) understand the intellectual base from which this field has emerged, (b) explore how this field has evolved over time, and (c) identify clusters of research themes that have emerged over time and the relationships between them. Specifically, we use cocitation analysis of research published in all social science disciplines to map the field at three points in time-1995, 2000, and 2006. Our results show that the field has grown from 9 research clusters in 1995 to 16 in 2006. A comparison across these maps suggests that research in the cluster of "virtual teams" has gained significance even as research in some earlier clusters such as "urban planning and transportation" has lost ground. Our longitudinal analysis identifies relevant concepts, theories, and methodologies that have emerged in the field of virtual work. This analysis can help interested researchers identify how they may want to contribute to the field of virtual work-by adding to popular clusters, by enriching emerging smaller clusters, or by acting as bridges across clusters.
|keyword = virtual work,virtual teams,bibliometric analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Regulation of Digital Businesses with Natural Monopolies or Third-Party Payment Business Models: Antitrust Lessons from the Analysis of Google'''
{{header}}
{{article
|author= Eric K. Clemons,Nehal Madhani,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Some digital business models may be so innovative that they overwhelm existing regulatory mechanisms, both legislation and historical jurisprudence, and require extension to or modification of antitrust law. Regulatory policies that were developed in response to nineteenth- or twentieth-century antitrust concerns dealt principally with economies of scale leading to monopoly power and may not be well suited to the issues of network effects or third-party payer online business models such as sponsored search. From the perspective of information systems economics, we investigate if such third-party payer digital systems require intervention as profound as the government's innovative approach to the problems posed by AT&T in the 1913 Kingsbury Commitment, establishing the first private regulated monopoly. Google provides an example of a company whose innovative digital business model is difficult to fit into current regulatory frameworks, and may provide examples of the issues that might require an extension to regulatory policy.
|keyword = antitrust,bundling and tying,contestability,deterred market entry,digital business strategies,essential facilities doctrine,Google,key word auctions,online search,relevant market share,sponsored search,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Impact of Technostress on End-User Satisfaction and Performance'''
{{header}}
{{article
|author= Monideepa Tarafdar,Qiang Tu,T. S. Ragu-Nathan,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Organizational use of information and communications technologies (ICT) is increasingly resulting in negative cognitions in individuals, such as information overload and interruptions. Recent literature has encapsulated these cognitions in the concept of technostress, which is stress caused by an inability to cope with the demands of organizational computer usage. Given the critical role of the user in organizational information processing and accomplishing application-enabled workflows, understanding how these cognitions affect users' satisfaction with ICT and their performance in ICT-mediated tasks is an important step in appropriating benefits from current computing environments. The objective of this paper is to (1) understand the negative effects of technostress on the extent to which end users perceive the applications they use to be satisfactory and can utilize them to improve their performance at work and (2) identify mechanisms that can mitigate these effects. Specifically, we draw from the end-user computing and technostress literature to develop and validate a model that analyzes the effects of factors that create technostress on the individual's satisfaction with, and task performance using, ICT. The model also examines how user involvement in ICT development and support mechanisms for innovation can be used to weaken technostress-creating factors and their outcomes. The results, based on survey data analysis from 233 ICT users from two organizations, show that factors that create technostress reduce the satisfaction of individuals with the ICT they use and the extent to which they can utilize ICT for productivity and innovation in their tasks. Mechanisms that facilitate involvement of users, and encourage them to take risks, learn, explore new ideas, and experiment in the context of ICT use, diminish the factors that create technostress and increase satisfaction with the ICT they use. These mechanisms also have a positive effect on users' appropriation of ICT for productivity and innovation in their tasks. The paper contributes to emerging literature on negative outcomes of ICT use by (1) highlighting the influence of technostress on users' satisfaction and performance (i.e., productivity and innovation in ICT-mediated tasks) with ICT, (2) extending the literature on technostress, which has so far looked largely at the general behavioral and psychological domains, to include the domain of end-user computing, and (3) demonstrating the importance of user involvement and innovation support mechanisms in reducing technostress-creating conditions and their ICT use related outcomes.
|keyword = end-user performance,end-user satisfaction,ICT use,information overload,survey research,technostress,user involvement,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''FOCUS AND DIVERSITY IN INFORMATION SYSTEMS RESEARCH: MEETING THE DUAL DEMANDS OF A HEALTHY APPLIED DISCIPLINE'''
{{header}}
{{article
|author= Hazel Taylor,Stuart Dillon,Melinda Van Wingen,
|source= MIS QUARTERLY
|year= 2010
|abstract = Drawing on sociology of science foundations, we argue that, in order to survive and prosper, healthy applied disciplines must meet the dual demands of academic and practitioner audiences by demonstrating both focus and diversity in their research. First, we use this concomitant modality to explain why previous studies into the structure of the Information Systems discipline have reported contradictory results, with some finding a focused field while others conclude that the field is diverse. In support of our argument, we then present the results of a longitudinal, author co-citation analysis, looking across the full range of journals in which IS research is published. Our results suggest that the IS field has sustained a focus on research within three subfields over a 20-year period from 1986 to 2005: (I) a thematic miscellany of research on development, implementation, and use of systems in various application domains; (2) IS strategy and business outcomes; and (3) group work and decision support. At the same time, the field has demonstrated considerable diversity within and around these core subfields, with researchers responding flexibly to the rapidly changing field by investigating these areas with new paradigms and in new contexts, and by exploring new topics including inter-business and Internet applications, computer-supported collaborative work, virtual teams, and knowledge management. Finally, we demonstrate that, over the 20-year period from 1986 to 2005, the discipline has shifted from fragmented adhocracy to a polycentric state, which is particularly appropriate to an applied discipline such as IS that must address the dual demands of focus and diversity in a rapidly changing technological context.
|keyword = IS discipline,IS research,author co-citation analysis,focus,diversity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WEB 2.0 AND POLITICS: THE 2008 US PRESIDENTIAL ELECTION AND AN E-POLITICS RESEARCH AGENDA'''
{{header}}
{{article
|author= Sunil Wattal,David Schuff,Munir Mandviwalla,Christine B. Williams,
|source= MIS QUARTERLY
|year= 2010
|abstract = The Internet was a major factor in the 2008 U.S. presidential campaign and has become an important tool for political communication and persuasion. Yet, information systems research is generally silent on the role of the Internet in politics. In this paper, we argue that IS is positioned to enhance understanding of the influence of the Internet on politics, and, more specifically, the process of election campaigning using Internet-based technologies such as Web 2.0. In this paper, we discuss how these technologies can change the nature of competition in politics and replace or complement traditional media. Our empirical study on how Web 2.0 technologies were used by the candidates leading up to the 2008 U.S. presidential primaries sheds light on how these technologies influenced candidate performance. Finally, we outline a research agenda highlighting where IS can contribute to the academic discourse on e-politics.
|keyword = New media,Web 2.0,politics,digital democracy,e-politics,elections,online,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE OTHER SIDE OF ACCEPTANCE: STUDYING THE DIRECT AND INDIRECT EFFECTS OF EMOTIONS ON INFORMATION TECHNOLOGY USE'''
{{header}}
{{article
|author= Anne Beaudry,Alain Pinsonneault,
|source= MIS QUARTERLY
|year= 2010
|abstract = Much ado has been made regarding user acceptance of new information technologies. However, research has been primarily based on cognitive models and little attention has been given to emotions. This paper argues that emotions are important drivers of behaviors and examines how emotions experienced early in the implementation of new IT applications relate to IT use. We develop a framework that classifies emotions into four distinct types: challenge, achievement, loss, and deterrence emotions. The direct and indirect relationships between four emotions (excitement, happiness, anger, and anxiety) and IT use were studied through a survey of 249 bank account managers. Our results indicate that excitement was positively related to IT use through task adaptation. Happiness was directly positively related to IT use and, surprisingly, was negatively associated with task adaptation, which is a facilitator of IT use. Anger was not related to IT use directly, but it was positively related to seeking social support, which in turn was positively related to IT use. Finally, anxiety was negatively related to IT use, both directly and indirectly through psychological distancing. Anxiety was also indirectly positively related to IT use through seeking social support, which countered the original negative effect of anxiety. Post hoc ANOVAs were conducted to compare IT usage of different groups of users experiencing similar emotions but relying on different adaptation behaviors. The paper shows that emotions felt by users early in the implementation of a new IT have important effects on IT use. As such, the paper provides a complementary perspective to understanding acceptance and antecedents of IT use. By showing the importance and complexity of the relationships between emotions and IT use, the paper calls for more research on the topic.
|keyword = Emotions,IT use,acceptance,adaptation behaviors,appraisal theory,user reaction,IT-related behaviors,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AFFECT IN WEB INTERFACES: A STUDY OF THE IMPACTS OF WEB PAGE VISUAL COMPLEXITY AND ORDER'''
{{header}}
{{article
|author= Liqiong Deng,Marshall Scott Poole,
|source= MIS QUARTERLY
|year= 2010
|abstract = This research concentrates on visual complexity and order as central factors in the design of webpages that enhance users' positive emotional reactions and facilitate desirable psychological states and behaviors. Drawing on existing theories and empirical findings in the environmental psychology, human computer interaction, and marketing research literatures, a research model is developed to explain the relationships among visual complexity and order design features of a webpage, induced emotional responses in users, and users' approach behaviors toward the website as moderated by users' metamotivational states. A laboratory experiment was conducted to test the model and its associated hypotheses. The results of the study suggested that a web user's initial emotional responses (i.e., pleasantness and arousal), evoked by the visual complexity and order design features of a webpage when first encountered, will have carry-over effects on subsequent approach behavior toward the website. The results also revealed how webpage visual complexity and order influence users' emotions and behaviors differently when users are in different metamotivational states. The salience and importance of webpage visual complexity and order for users' feelings of pleasantness were largely dependent on users' metamotivational states.
|keyword = Webpage visual design,webpage visual complexity,webpage order,emotional response,approach behavior,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''UNDERSTANDING ORGANIZATION-ENTERPRISE SYSTEM FIT: A PATH TO THEORIZING THE INFORMATION TECHNOLOGY ARTIFACT'''
{{header}}
{{article
|author= Diane M. Strong,Olga Volkoff,
|source= MIS QUARTERLY
|year= 2010
|abstract = Packaged software applications such as enterprise systems are designed to support generic rather than specific requirements, and hence are likely to be an imperfect fit in any particular instance. Using critical realism as our philosophical perspective, we conducted a three-year qualitative study of misfits that arose from an enterprise system (ES) implementation. A detailed analysis of the observed misfits resulted in a richer understanding of the concept of fit and of the ES artifact itself Specifically, we found six misfit domains (functionality, data, usability, role, control and organizational culture) and within each, two types of misfit (deficiencies and impositions). These misfit types correspond to two newly defined types of fit: fit as coverage and fit as enablement. Our analysis of fit also revealed a new conceptualization of the ES artifact, with implications for IT artifacts in general.
|keyword = Fit,misfits,enterprise systems,IT artifact,critical realism,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IMPROVING EMPLOYEES' COMPLIANCE THROUGH INFORMATION SYSTEMS SECURITY TRAINING: AN ACTION RESEARCH STUDY'''
{{header}}
{{article
|author= Petri Puhakainen,Mikko Siponen,
|source= MIS QUARTERLY
|year= 2010
|abstract = Employee noncompliance with information systems security policies is a key concern for organizations. If users do not comply with IS security policies, security solutions lose their efficacy. Of the different IS security policy compliance approaches, training is the most commonly suggested in the literature. Yet, few of the existing studies about training to promote IS policy compliance utilize theory to explain what learning principles affect user compliance with IS security policies, or offer empirical evidence of their practical effectiveness. Consequently, there is a need for IS security training approaches that are theory-based and empirically evaluated. Accordingly, we propose a training program based on two theories: the universal constructive instructional theory and the elaboration likelihood model. We then validate the training program for IS security policy compliance training through an action research project. The action research intervention suggests that the theory-based training achieved positive results and was practical to deploy. Moreover, the intervention suggests that information security training should utilize contents and methods that activate and motivate the learners to systematic cognitive processing of information they receive during the training. In addition, the action research study made clear that a continuous communication process was also required to improve user IS security policy compliance. The findings of this study offer new insights for scholars and practitioners involved in IS security policy compliance.
|keyword = IS security,IS security training,employees' compliance with security policies,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AN ALTERNATIVE TO METHODOLOGICAL INDIVIDUALISM: A NON-REDUCTIONIST APPROACH TO STUDYING TECHNOLOGY ADOPTION BY GROUPS'''
{{header}}
{{article
|author= Saonee Sarker,Joseph S. Valacich,
|source= MIS QUARTERLY
|year= 2010
|abstract = Studies on groups within the MIS discipline have largely been based on the paradigm of methodological individualism. Commentaries on methodological individualism within the reference disciplines suggest that studies embracing this paradigm can lead to potentially misleading or incorrect conclusions. This study illustrates the appropriateness of the alternate non-reductionist approach to investigating group-related phenomenon, specifically in the context of technology adoption. Drawing on theories of group influence, prior research on conflict, technology characteristics, task technology fit, group communication media, and recent theoretical work surrounding group technology adoption, the paper proposes and empirically tests a new non-reductionist model for conceptualizing technology adoption by groups. Further, the study also empirically compares this non-reductionist model with a (hypothetical) methodological individualist model of technology adoption by groups. Results strongly support most of the assertions of the non-reductionist model and highlight that this model provides a more robust explanation of technology adoption by groups than a methodological individualist view. Further, the study also highlights some conditions wherein the methodological individualist view fails to provide correct explanations. The implications of the study's findings for future research are discussed.
|keyword = Methodological individualism,non-reductionist view,multilevel theory,group technology adoption,valence,task-technology fit,technology characteristics,PLS analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PRICE EFFECTS IN ONLINE PRODUCT REVIEWS: AN ANALYTICAL MODEL AND EMPIRICAL ANALYSIS'''
{{header}}
{{article
|author= Xinxin Li,Lorin M. Hitt,
|source= MIS QUARTERLY
|year= 2010
|abstract = Consumer reviews may reflect not only perceived quality but also the difference between quality and price (perceived value). In markets where product prices change frequently, these price-influenced reviews may be biased as a signal of product quality when used by consumers possessing no knowledge of historical prices. In this paper, we develop an analytical model that examines the impact of price-influenced reviews on firm optimal pricing and consumer welfare. We quantify the price effects in consumer reviews for different formats of review systems using actual market prices and on-line consumer ratings data collected for the digital camera market. Our empirical results suggest that unidimensional ratings, commonly used in most review systems, can be substantially biased by price effects. In fact, unidimensional ratings are more closely correlated with ratings of product value than ratings of product quality. Our findings suggest the importance for firms to account for these price effects in their overall marketing strategy and suggest that review systems could better serve consumers by explicitly expanding review dimensions to separate perceived value and perceived quality.
|keyword = Online product reviews,review bias,price effects,empirical analysis,optimal pricing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TOWARD ETHICAL INFORMATION SYSTEMS: THE CONTRIBUTION OF DISCOURSE ETHICS'''
{{header}}
{{article
|author= John Mingers,Geoff Walsham,
|source= MIS QUARTERLY
|year= 2010
|abstract = Ethics is important in the Information Systems field as illustrated by the direct effect of the Sarbanes-Oxley Act on the work of IS professionals. There is a substantial literature on ethical issues surrounding computing and information technology in the contemporary world, but much of this work is not published nor widely cited in the mainstream IS literature. The purpose of this paper is to offer one contribution to an increased emphasis on ethics in the IS field. The distinctive contribution is a focus on Habermas's discourse ethics. After outlining some traditional theories of ethics and morality, the literature on IS and ethics is reviewed, and then the paper details the development of discourse ethics. Discourse ethics is different from other approaches to ethics as it is grounded in actual debates between those affected by decisions and proposals. Recognizing that the theory could be considered rather abstract, the paper discusses the need to pragmatize discourse ethics for the IS field through, for example, the use of existing techniques such as soft systems methodology. In addition, the practical potential of the theory is illustrated through a discussion of its application to specific IS topic areas including Web 2.0, open source software, the digital divide, and the UK biometric identity card scheme. The final section summarizes ways in which the paper could be used in IS research, teaching, and practice.
|keyword = Ethics and IS,ethical theories,Habermas,discourse ethics,deliberative democracy,soft systems methodology,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE IMPACT OF INFORMATION TECHNOLOGY AND TRANSACTIVE MEMORY SYSTEMS ON KNOWLEDGE SHARING, APPLICATION, AND TEAM PERFORMANCE: A FIELD STUDY'''
{{header}}
{{article
|author= Sue Young Choi,Heeseok Lee,Youngjin Yoo,
|source= MIS QUARTERLY
|year= 2010
|abstract = In contemporary knowledge-based organizations, teams often play an essential role in leveraging knowledge resources. Organizations make significant investments in information technology to support knowledge management practices in teams. At the same time, recent studies show that the transactive memory system (TMS) the specialized division of cognitive labor among team members that relates to the encoding, storage, and retrieval of knowledge is an important factor that affects a team's performance. Yet little is known of how IT support for knowledge management practices in organizations affects the development of TMS. Furthermore, the precise role of TMS on knowledge sharing and knowledge application, which in turn influences team performance, has not been fully explored. In order to close this gap in the literature, we conducted a field study that involved 139 on-going teams of 743 individuals from two major firms in South Korea. Our results show that IT support in organizations has a positive impact on the development of TMS in teams, and that both TMS and IT support have a positive impact on knowledge sharing and knowledge application. Furthermore, we found that knowledge sharing has a positive impact on knowledge application, which in turn has a direct impact on team performance. However, contrary to our expectation, knowledge sharing does not have a direct impact on team performance and its impact on team performance was fully mediated by knowledge application. Our research shows that organizations can improve team members' meta-knowledge of who knows what through the careful investment in information technology. Finally, our results show that sharing knowledge alone is not enough. Organizations must ensure that shared knowledge is in fact applied in order to improve team performance.
|keyword = Transactive memory system,knowledge management,team performance,field study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Safe Contexts for Interorganizational Collaborations Among Homeland Security Professionals'''
{{header}}
{{article
|author= Ann Majchrzak,Sirkka L. Jarvenpaa,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = In many domains of increased turbulence and volatility, interorganizational ad hoc collaborations are common. One such domain is homeland security in which security professionals collaborate virtually with individuals outside of their own organizations in response to a security threat. In such a domain, a safe context is needed to ensure that interactions with collaborators not only help to solve the immediate threat but also avoid the improper use by outside parties of information released during these collaborations. We use the heuristic systematic model of information processing to hypothesize that the relationship between different safe context factors and a security professional's perceptions of collaboration success will be contingent on differences in geographic proximity of the collaborating parties differences in proximity that are not related to differences in physical face-to-face contact but to differences in social proximity. Our exploratory empirical investigation finds support for the hypothesized interaction effect: safe contexts that require deeper processing are related to higher levels of perceived success when the parties are geographically proximal (with no differences in face-to-face contact), whereas safe contexts that involve heuristic-based processing are related to success when parties are geographically less proximal. Our findings suggest that the utility of safe context factors is contextualized based on the proximity of interacting parties, that geographical proximity's social space dimension plays a key role independent of differences in physical face-to-face contact, and that, practically, to be successful, ad hoc collaborators should have access to a range of safe context factors, using them in different combinations depending on the proximity of network members.
|keyword = dual process theories,geographic proximity,knowledge protection,personal networks,safe contexts,security professionals,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Systems Development Ambidexterity: Explaining the Complementary and Substitutive Roles of Formal and Informal Controls'''
{{header}}
{{article
|author= Amrit Tiwana,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Although formal and informal control mechanisms are often simultaneously used to govern systems development projects, considerable disagreement exists about whether the use of one strengthens or diminishes the benefits of the other. In other words, are they complements or substitutes? Competing theoretical perspectives favor both sides of the argument, and neither the information systems (IS) controls literature nor the information technology (IT) outsourcing literature has addressed this issue. This study theoretically develops the idea that these competing perspectives are mutually compatible rather than contradictory because informal and formal control mechanisms can simultaneously be complements and substitutes. Using data from 120 outsourced systems development projects, it is shown that informal control mechanisms strengthen the influence of formal behavior control mechanisms on systems development ambidexterity (complementary effects) but weaken the influence of formal outcome control mechanisms (substitutive effects). The key contribution of the paper therefore lies in exploring interactions among control mechanisms in a project's control portfolio to reconcile the competing theoretical perspectives on whether formal and informal controls are complements or substitutes. The findings provide managers guidance on how to carefully combine formal and informal control mechanisms in a project. Combining informal with formal process-based control mechanisms can simultaneously enhance the fulfillment of project goals and development flexibility. However, combining informal with formal outcome-based control mechanisms can instead impair these objectives.
|keyword = ambidexterity,control mechanisms,interaction effects,outsourcing,project governance,signaling,software project control,systems development,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''No Free Lunch: Price Premium for Privacy Seal-Bearing Vendors'''
{{header}}
{{article
|author= Bin Mai,Nirup M. Menon,Sumit Sarkar,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Privacy is a significant concern of customers in the business-to-consumer online environment. Several technical, economic, and regulatory mechanisms have been proposed to address online privacy. A current market-based mechanism is the privacy seal, under which a third party assures adherence by a vendor to its posted privacy policy. In this paper, we present empirical evidence of the effect of displaying a privacy seal on the product prices of online vendors of electronic books, downloadable audiobooks, and textbooks. Using data collected on these relatively homogeneous products sold by online vendors, we find that while controlling for vendor-specific characteristics, vendors bearing privacy seals charge a premium for such products compared to vendors not bearing a seal. The paper provides empirical evidence of the economic value of privacy assurance from the customers' perspective as measured by the price premium charged for products. The research has implications for researchers and policymakers by providing evidence that privacy is another factor that creates friction in e-commerce, and that prices on the Internet for homogeneous products need not converge.
|keyword = partial least squares,price dispersion,privacy assurance,risk premium,trust,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Donor-to-Nonprofit Online Marketplace: An Economic Analysis of the Effects on Fund-Raising'''
{{header}}
{{article
|author= Zafer D. Ozdemir,Kemal Altinkemer,Prabuddha De,Yasin Ozcelik,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Online intermediaries have recently started offering database services to donors and certification services to nonprofit organizations through the Internet. We conceptualize a donor-to-nonprofit (D2N) marketplace as an online intermediary that offers these two services and examine its effect on fund-raising strategies of nonprofit organizations using an analytical model based on spatial competition under incomplete information with donor search. We characterize the signaling equilibria where certification of quality conveys information about organizational effectiveness in generating socially valuable services. Interestingly, the emergence of the D2N marketplace may lead to a drop in total net fund-raising revenues in the market, despite the fact that the intermediary's database service eliminates search costs for some donors. We also explain why such a marketplace may deliberately lower the accuracy of its certification process.
|keyword = fund-raising,nonprofit organizations,online marketplaces,online search,quality certification,seal of approval,signaling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Impact of Internal Open Source Development on Reuse: Participatory Reuse in Action'''
{{header}}
{{article
|author= Padmal Vitharana,Julie King,Helena Shih Chapman,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Adoption of open source software (OSS) principles to internal software development has gained considerable momentum. Often labeled as "internal open source" (IOS), several large firms have started to implement these programs. Research to date has mostly focused on facilitating IOS adoption. In the present research, we focus on how IOS affects reuse. Employing a qualitative case study, we examine the IOS program at IBM called "Community Source." Analyzing data gathered from multiple sources reveals that IOS adoption facilitates participatory reuse by enhancing information sharing and leveraging of broader community skills. Participatory reuse manifests itself when potential reusers participate in the entire development process leading to the creation of reusable assets. Based on data, we develop a theoretical model to illustrate how IOS affects reuse. While furthering research on IOS and reuse, the model informs managers wishing to foster participatory reuse that they are wise to adopt IOS as a vehicle to promote greater openness of the software development infrastructure for leveraging broader community skills and enhancing information sharing among projects' stakeholders.
|keyword = closed source,internal open source,open source,open source software,participatory reuse,software reuse,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Balancing IT with the Human Touch: Optimal Investment in IT-Based Customer Service'''
{{header}}
{{article
|author= Sulin Ba,Jan Stallaert,Zhongju Zhang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = To cut costs, companies have chosen to deliver a variety of service offerings online. However, the digital systems providing such services (e-service) have always been complemented with or supported by human-based service (h-service). Whereas h-service has total costs that increase with the demand for services, e-service mainly requires a fixed investment upfront, which can be amortized over the totality of customers served. Considering the different nature of the costs of h-service and e-service and the heterogeneity of customer preferences for services, we derive the optimal mix of h-service and e-service for a service-providing company vis-a-vis its competitor. Our theoretical analysis finds the subgame-perfect Nash equilibria that determines the optimal positions in a duopoly setting. We further study the competitive dynamics of the system to examine how firms stay on the equilibrium paths. Using simulation, we investigate the effects of starting positions, small adjustments in h-service and/or e-service, and monotonic expansions of e-service on the final positioning and profits of the firms. Our results demonstrate that when firms follow a local best-reply strategy, they may end up in a position of low profitability, and when only monotonic expansions of e-service are allowed, both firms may end up overinvesting in e-service.
|keyword = e-service quality,customer service,price competition,service differentiation,competitive strategy,competitive dynamics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The "Third Hand": IT-Enabled Competitive Advantage in Turbulence Through Improvisational Capabilities'''
{{header}}
{{article
|author= Paul A. Pavlou,Omar A. El Sawy,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Organizations are increasingly engaged in competitive dynamics that are enabled or induced by information technology (IT). A key competitive dynamics question for many organizations is how to build a competitive advantage in turbulence with digital IT systems. The literature has focused mostly on developing and exercising dynamic capabilities for planned reconfiguration of existing operational capabilities in fairly stable environments with patterned "waves," but this may not always be possible, or even appropriate, in highly turbulent environments with unexpected "storms." We introduce improvisational capabilities as an alternative means for managing highly turbulent environments; we define this as the ability to spontaneously reconfigure existing resources to build new operational capabilities to address urgent, unpredictable, and novel environmental situations. In contrast to the planned role of dynamic and operational capabilities and the ambidexterity that they jointly offer, improvisational capabilities are proposed to operate distinctly as a "third hand" that facilitates reconfiguration and change in highly turbulent environments. First, the paper develops the notion of improvisational capabilities and articulates the key differences between the two "reconfiguration"-improvisational and dynamic-capabilities. Second, the paper compares the relative effects of improvisational and dynamic capabilities in the context of new product development in different levels of environmental turbulence. Third, the paper shows how IT-leveraging capability in new product development is decomposed into its three digital IT systems: project and resource management systems, organizational memory systems (OMS), and cooperative work systems-and how each of these IT systems enhances improvisational capabilities, an effect that is accentuated in highly turbulent environments. The results show that although dynamic capabilities are the primary predictor of competitive advantage in moderately turbulent environments, improvisational capabilities fully dominate in highly turbulent environments. Besides discriminant validity, the distinction between improvisational and dynamic capabilities is evidenced by the differential effects of IT-leveraging capability on improvisational and dynamic capabilities. The results show that the more the IT-leveraging capability is catered toward managing resources (through project and resource management systems) and team collaboration (through cooperative work systems) rather than relying on past knowledge and procedures (through organizational memory systems), the more it is positively associated with improvisational capabilities, particularly in more turbulent environments. The paper draws implications for how different IT systems can influence improvisational capabilities and competitive advantage in turbulent environments, thereby enhancing our understanding of the role of IT systems on reconfiguration capabilities. The paper discusses the theoretical and practical implications of building and exercising the " third hand" of improvisational capabilities for IT-enabled competitive dynamics in turbulence.
|keyword = improvisation,improvisational capabilities,dynamic capabilities,environmental turbulence,digital systems,IT-leveraging capability,new product development,competitive advantage,competitive dynamics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Changing the Competitive Landscape: Continuous Innovation Through IT-Enabled Knowledge Capabilities'''
{{header}}
{{article
|author= K. D. Joshi,Lei Chi,Avimanyu Datta,Shu Han,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = We theoretically and empirically investigate the relationship between information technology (IT) and firm innovation. Invoking absorptive capacity (ACAP) theory, we introduce and develop the concepts of three types of IT-enabled knowledge capabilities. Firm innovation is examined through two observable innovation outcomes: patents, and new product and service introductions. These innovation outcomes are often labeled as competitive actions aggressively undertaken by firms to gain market share or to achieve profitability. We use secondary data about IT-enabled knowledge capabilities and innovation outcomes of 110 firms. Our data results provide strong support for our main assertion that knowledge capabilities that are enhanced through the use of IT contribute to firm innovation. The study's findings suggest that the three types of IT-enabled knowledge capabilities have differential effects on firm innovation. This study substantially contributes to the information systems (IS) research, methodology, and practice in multiple ways.
|keyword = absorptive capacity,business value of IT,competitive impacts of IS,firm innovation,IT-enabled knowledge capability,knowledge management,strategic management of IT,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Managerial Interpretations of the Role of Information Systems in Competitive Actions and Firm Performance: A Grounded Theory Investigation'''
{{header}}
{{article
|author= Sandra A. Vannoy,A. F. Salam,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Using an interpretive grounded theory research approach, we investigate the utilization of organization-wide information systems in the competitive actions and responses undertaken by top managers to sustain their firms' leading competitive position. Our central contribution is a model that explicates the role of information systems in the process by which competitive actions or responses are conceived, enacted, and executed, and resulting impacts on firm performance-issues that have been largely missing from contemporary research in both the information systems and competitive dynamics domains. This study has important implications for both research and practice. Specifically, researchers should consider organizational context; the intentions and actions of key players; and the process of conceiving, enacting, and executing competitive actions or responses carried out by the organization to account for the impact of information systems on firm performance. Findings suggest that when managers envision information systems as a resource that provides opportunities for competitive actions rather than viewing information systems in a service role, competitive advantages will evolve. Furthermore, practitioners will be better able to leverage information systems investments if they recognize the embedded role of information systems within the competitive actions or responses a firm undertakes to maintain or improve relative performance.
|keyword = competitive dynamics,competitive actions,information systems,firm performance,strategy,grounded theory,interpretative research,managerial interpretation,process,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Leveraging IT Capabilities and Competitive Process Capabilities for the Management of Interorganizational Relationship Portfolios'''
{{header}}
{{article
|author= Arun Rai,Xinlin Tang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Firms are increasingly dependent on external resources and are establishing portfolios of interorganizational relationships (IRs) to leverage external resources for competitive advantage. However, the systems of information technology (IT) and process capabilities that firms should develop to manage IR portfolios dynamically are not well-understood. In order to theorize how key structural IT capabilities (IT integration and IT reconfiguration) and competitive process capabilities (process alignment, partnering flexibility, and offering flexibility) operate as systems of complements, we draw on the competitive dynamics perspective and resource dependency theory and on the literature for IT business value, interorganizational systems, and interorganizational relationship management. We also theorize how a firm's IR portfolio moderates the effects of structural IT capabilities on competitive process capabilities and why a firm's environmental turbulence moderates the effects of complementary process capabilities on competitive performance. We test our model using survey data from 318 firms in 4 industries. Our results provide broad support for the following: (1) structural IT capabilities and process capabilities operating as a system of complements, (2) the effects of structural IT capabilities on competitive process capabilities being contingent on IR portfolio concentration, and (3) the effects of complementary process capabilities on competitive performance being contingent on environmental turbulence. We discuss the theoretical and practical implications of how firms should develop complementary systems of structural IT capabilities and competitive process capabilities to manage IR portfolios dynamically and leverage external resources.
|keyword = competitive dynamics perspective,IT business value,interorganizational relationships,relationship portfolios,competitive performance,structural IT capabilities,competitive process capabilities,complementarities,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Technology, Network Structure, and Competitive Action'''
{{header}}
{{article
|author= Lei Chi,T. Ravichandran,Goce Andrevski,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Researchers in competitive dynamics have demonstrated that firms that carry out intense, complex, and heterogeneous competitive actions exhibit better performance. However, there is a need to understand factors that enable firms to undertake competitive actions. In this study, we focus on two antecedents of competitive behavior of firms: (1) access to network resources and (2) use of information technology (IT). We argue that while network structure provides firms with the opportunity to tap into external resources, the extent to which they are actually exploited depends on firms' IT-enabled capability. We develop a theoretical model that examines the relationships between IT-enabled capability, network structure, and competitive action. We test the model using secondary data, about 12 major automakers over 16 years from 1988 to 2003. We find that network structure rich in structural holes has a positive direct effect on firms' ability to introduce a greater number and a wider range of competitive actions. However, the effect of dense network structure is contingent on firms' IT-enabled capability. Firms benefit from dense network structure only when they develop a strong IT-enabled capability. Our results suggest that IT-enabled capability plays both a substitutive role, when firms do not have advantageous access to brokerage opportunities, and a complementary role, when firms are embedded in dense network structure, in the relationship between network structure and competitive actions.
|keyword = competitive action,IT-enabled capability,interfirm network structure,social network theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Network Perspective of Digital Competition in Online Advertising Industries: A Simulation-Based Approach'''
{{header}}
{{article
|author= Ray M. Chang,Wonseok Oh,Alain Pinsonneault,Dowan Kwon,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Using agent-based simulation experiments, we investigate the outcome of SAs between two smaller online search engine companies in competition with a dominant market leader in settings where an advertiser's decision making is the consequence of a combination of NI (e. g., an individual's willingness to follow others' decisions) and IP. In particular, we focus on a context in which the combined search engine company competes with a market leader holding a larger share of the market than the two runner-up "underdogs" combined. Our results indicate that, with the presence of NI and cascading effects, an alliance with "only" 35%-40% combined market share could compete with a leader whose market share, at the time of an alliance, is 60%-65%. Although important, size alone might be insufficient to build the market as suggested by the "vanilla" network effect theory. Another noteworthy finding is that a nonlinear association exists between NI and an alliance outcome; the combined runner-up companies have the best chance of success when the extent of NI is midrange, rather than on the high or low end of continuum. Contrary to the conventional view, this finding might also stimulate discussions among network science researchers. Furthermore, our results suggest that NI substantially moderates the relationship between the combined market share at the time of an alliance and the likelihood of resulting alliance success.
|keyword = digital competition,NI,IP,switching force,SAs,online sponsored advertising,agent-based simulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Competitive Actions and Dynamics in the Digital Age: An Empirical Investigation of Social Networking Firms'''
{{header}}
{{article
|author= Devi R. Gnyawali,Weiguo Fan,James Penner,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = This paper examines two important questions in the context of the social networking services (SNS) firms: what kind of competitive moves do SNS firms undertake and to what extent do the competitive moves impact firm performance? We blend the literature streams on information systems (IS) and strategic management and argue that given the unique characteristics of this nascent industry, SNS firms' competitive moves are likely to focus on value cocreation, as well as enhancement of the repertoire of their moves. We propose a conceptual model by blending value cocreation perspectives from the IS literature and repertoire of competitive actions from the competitive dynamics literature, and test our hypotheses using archival data. Results show that firms that emphasize value cocreation actions through the engagement of codevelopers in their technology platform and formation of strategic alliances enhance their performance. Furthermore, firms that undertake complex action repertoires achieve better performance. This study provides unique insights about the ways in which firms compete in the industry and has several implications for future research.
|keyword = competition strategy,competition dynamics,competitive actions,firm performance,social networking services,page view,business value of information technology,value cocreation,repertoire of actions,network centrality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Competing in Crowded Markets: Multimarket Contact and the Nature of Competition in the Enterprise Systems Software Industry'''
{{header}}
{{article
|author= Ramnath K. Chellappa,V. Sambamurthy,Nilesh Saraf,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = As more and more firms seek to digitize their business processes and develop new digital capabilities, the enterprise systems software (ESS) has emerged as a significant industry. ESS firms offer software components (e. g., ERP, CRM, Marketing analytics) to shape their clients' digitization strategies. With rapid rates of technological and market innovation, the ESS industry consists of several horizontal markets that form around these components. As numerous vendors compete with each other within and across these markets, many of these horizontal markets appear to be crowded with rivals. In fact, multimarket contact and presence in crowded markets appear to be the pathways through which a majority of the ESS firms compete. Though the strategy literature has demonstrated the virtues of multimarket contact, paradoxically, the same literature argues that operating in crowded markets is not wise. In particular, crowded markets increase a firm's exposure to the whirlwinds of intense competition and have deleterious consequences for financial performance. Thus, the behavior of ESS firms raises an interesting anomaly and research question: Why do ESS firms continue to compete in crowded markets if they are deemed to be bad for financial performance? We argue that the effects of rivalry in crowded markets are counteracted by a different force, in the form of the economics of demand externalities. Demand externalities occur because the customers of ESS firms expect that software components from one market will be easily integrated with those that they buy from other markets. However, with rapid rates of technological innovation and market formation and dissolution, customers experience significant ambiguity in deciding which markets and components suit their needs. Therefore, they look at crowded markets as an important signal about the legitimacy and viability of specific components for their needs. Through their presence in crowded markets, ESS firms can signal their commitment to many of the components that customers might need for their digital platforms. Customers might find that such firms are attractive because their commitments to crowded markets can mitigate concerns about compatibilities between the components purchased across several markets. This unique potential for demand externality across markets suggests that ESS vendors might, in fact, benefit from competing in many crowded markets. We test our explanations through data across three time periods from a set of ESS firms that account for more than 95% of the revenue in this market. We find that ESS firms do reap performance benefits by competing in crowded markets. More importantly, we find that they can enhance their benefits from crowded markets if they face the same competitors in multiple markets, thereby increasing their multimarket contact with rivals. These results have interesting implications not just for understanding competitive conduct in the ESS industry but also in many of the emerging digital goods industries where the markets have similar competitive characteristics to the ESS industry. Our ideas complement emerging ideas about platform models of competition in the digital goods industry and provide important directions for future research.
|keyword = enterprise software,standards,multimarket contact,crowded markets,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Why Do Software Firms Fail? Capabilities, Competitive Actions, and Firm Survival in the Software Industry from 1995 to 2007'''
{{header}}
{{article
|author= Shanling Li,Jennifer Shang,Sandra A. Slaughter,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = This study examines why firms fail or survive in the volatile software industry. We provide a novel perspective by considering how software firms' capabilities and their competitive actions affect their ultimate survival. Drawing on the resource-based view (RBV), we conceptualize capabilities as a firm's ability to efficiently transform input resources into outputs, relative to its peers. We define three critical capabilities of software-producing firms-research and development (RD), marketing (MK), and operations (OP)-and hypothesize that in the dynamic, high-technology software industry, RD and MK capabilities are most important for firm survival. We then draw on the competitive dynamics literature to theorize that competitive actions distinguished by a greater emphasis on innovation-related moves will increase firm survival more than actions emphasizing resource-related moves. Finally, we postulate that firms' capabilities will complement their competitive actions in affecting firm survival. Our empirical evaluation examines a cross-sectional, time series panel of 5,827 observations on 870 software companies from 1995 to 2007. We use a stochastic frontier production function to measure the capability for each software firm in each time period. We then use the Cox proportional hazard regression technique to relate capabilities and competitive actions to software firms' failure rates. Unexpectedly, our results reveal that higher OP capability increases software firm survival more than higher MK and RD capabilities. Further, firms with a greater emphasis on innovation-related than resource-related competitive actions have a greater likelihood of survival, and this likelihood increases even further when these firms have higher MK and OP capabilities. Additional analyses of subsectors within the software industry reveal that firms producing visual applications (e. g., graphical and video game software) have the highest MK capability but the lowest OP and RD capabilities and make twice as many innovation-related as resource-related moves. These firms have the highest market values but the worst Altman Z scores, suggesting that they are valued highly but also are at high risk for failure, and indeed the firms in this sector fail at a greater rate than expected. In contrast, firms producing traditional decision-support applications and infrastructure software have different capabilities and make different competitive moves. Our findings suggest that the firms that persist and survive over the long term in the dynamic software industry are able to capitalize on their competitive actions because of their greater capabilities, and particularly OP capabilities.
|keyword = software industry,survival analysis,capability,resource-based view,marketing,operations,research and development,stochastic frontier production function,competitive actions,competitive dynamics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Predicting Collaboration Technology Use: Integrating Technology Adoption and Collaboration Research'''
{{header}}
{{article
|author= Susan A. Brown,Alan R. Dennis,Viswanath Venkatesh,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = The paper presents a model integrating theories from collaboration research (i.e., social presence theory, channel expansion theory, and the task closure model) with a recent theory from technology adoption research (i.e., unified theory of acceptance and use of technology, abbreviated to UTAUT) to explain the adoption and use of collaboration technology. We theorize that collaboration technology characteristics, individual and group characteristics, task characteristics, and situational characteristics are predictors of performance expectancy, effort expectancy, social influence, and facilitating conditions in UTAUT. We further theorize that the UTAUT constructs, in concert with gender, age, and experience, predict intention to use a collaboration technology, which in turn predicts use. We conducted two field studies in Finland among (1) 349 short message service (SMS) users and (2) 447 employees who were potential users of a new collaboration technology in an organization. Our model was supported in both studies. The current work contributes to research by developing and testing a technology-specific model of adoption in the collaboration context.
|keyword = channel expansion theory,collaboration technologies,social presence theory,task closure model,technology acceptance,technology adoption,unified theory of acceptance and use of technology,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Are Consumers More Likely to Contribute Online Reviews for Hit or Niche Products?'''
{{header}}
{{article
|author= Chrysanthos Dellarocas,Guodong (Gordon) Gao,Ritu Narayan,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = User-generated content has been hailed by some as a democratizing force that enables consumers to discuss niche products that were previously ignored by mainstream media. Nevertheless, the extent to which consumers truly prefer to use these new outlets to discuss lesser-known products as opposed to spending most of their energies on discussing widely marketed or already successful products has so far remained an open question. We explore this question by investigating how a population's propensity to contribute postconsumption online reviews for different products of the same category (motion pictures) relates to various indicators of those products' popularity. We discover that, ceteris paribus, consumers prefer to post reviews for products that are less available and less successful in the market. At the same time, however, they are also more likely to contribute reviews for products that many other people have already commented on online. The presence of these two opposite forces leads to a U-shaped relationship between a population's average propensity to review a movie postconsumption and that movie's box office revenues: moviegoers appear to be more likely to contribute reviews for very obscure movies but also for very high-grossing movies. Our findings suggest that online forum designers who wish to increase the contribution of user reviews for lesser-known products should make information about the volume of previously posted reviews a less-prominent feature of their sites.
|keyword = consumer behavior,econometrics,information intermediaries,online product reviews,online word of mouth,Web 2.0,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Empirical Analysis of the Impact of Recommender Systems on Sales'''
{{header}}
{{article
|author= Bhavik Pathak,Robert Garfinkel,Ram D. Gopal,Rajkumar Venkatesan,Fang Yin,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Online retailers are increasingly using information technologies to provide value-added services to customers. Prominent examples of these services are online recommender systems and consumer feedback mechanisms, both of which serve to reduce consumer search costs and uncertainty associated with the purchase of unfamiliar products. The central question we address is how recommender systems affect sales. We take into consideration the interaction among recommendations, sales, and price. We then develop a robust empirical model that incorporates the indirect effect of recommendations on sales through retailer pricing, potential simultaneity between sales and recommendations, and a comprehensive measure of the strength of recommendations. Applying the model to a panel data set collected from two online retailers, we found that the strength of recommendations has a positive effect on sales. Moreover, this effect is moderated by the recency effect, where more recently released recommended items positively affect the cross-selling efforts of sellers. We also show that recommender systems help to reinforce the long-tail phenomenon of electronic commerce, and obscure recommendations positively affect cross-selling. We also found a positive effect of recommendations on prices. These results suggest that recommendations not only improve sales but they also provide added flexibility to retailers to adjust their prices. A comparative analysis reveals that recommendations have a higher effect on sales than does consumer feedback. Our empirical results show that providing value-added services, such as digital word of mouth and recommendations, allows retailers to charge higher prices while at the same time increasing demand by providing more information regarding the quality and match of products.
|keyword = collaborative filtering,electronic commerce,e-tail,experience goods,recommender systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Net Neutrality and Vertical Integration of Content and Broadband Services'''
{{header}}
{{article
|author= Hong Guo,Subhajyoti Bandyopadhyay,Hsing Kenneth Cheng,Yu-Chen Yang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Whether broadband service providers (BSPs) should be allowed to vertically integrate with content providers is a contentious issue. This is even more so when viewed through the lens of the net neutrality debate, since the vertically integrated firm can prioritize the delivery of its own content at the expense of that of its competitors if net neutrality is not enforced. Using a game-theoretic model, we analyze the issues of vertical integration of content and broadband services surrounding this debate from an economic perspective. Our analysis establishes the various equilibria in the game and shows that the vertically integrated BSP does not have any incentive to abide by the principles of net neutrality. If net neutrality is not enforced, social welfare might, in certain cases, decrease with vertical integration, and in such cases, the BSP's objectives are at odds with that of the social planner. With other ranges of parameter values, social welfare increases with vertical integration at the expense of the competing pure-play content provider. Interestingly, we find that it is not always true that the BSP will always degrade the delivery of the competing content, and in fact will sometimes have the incentive to prioritize the latter over its own. The analysis thus provides crucial inputs to policymakers as they decide on whether to allow vertical integration between a BSP and a content provider in the absence of net neutrality.
|keyword = broadband service providers,consumer surplus,content providers,economics of net neutrality,net neutrality,social welfare,vertical integration,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Technology Diffusion with Influentials, Imitators, and Opponents'''
{{header}}
{{article
|author= Hasan Cavusoglu,Nan Hu,Yingjiu Li,Dan Ma,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Information technology (IT) innovations follow a diverse set of diffusion patterns. Early diffusion models explaining technology diffusion patterns assumed that there is a single homogeneous segment of potential adopters. It was later shown that a two-segment model considering two groups of adopters explains variations in diffusion patterns better than the existing one-segment models. While the two-segment model considers a group of adopters promoting adoption by exerting a positive influence on prospective adopters, it does not consider the members of society who aim to inhibit the adoption process by exerting a negative influence on prospective adopters. In fact, most IT innovations face opposition. Yet it is not clear how opposition affects the diffusion process. In this paper, we model the diffusion of an IT innovation through its target population with three types of actors: influentials, who are autonomous in adopting new technology and promote its adoption; opponents, who are opposed to the technology and inhibit its adoption; and imitators, who are information seekers, thus affected by both influentials and opponents. We show that opponents play a crucial role in determining the diffusion path of an innovation. The empirical tests using real as well as simulated data sets demonstrate the ability of our model to fit the data better and to identify the segments of adopters correctly.
|keyword = diffusion of innovation,information technology diffusion,technology opposition,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DETECTING FAKE WEBSITES: THE CONTRIBUTION OF STATISTICAL LEARNING THEORY'''
{{header}}
{{article
|author= Ahmed Abbasi,Zhu Zhang,David Zimbra,Hsinchun Chen,Jr. Jay F. Nunamaker,
|source= MIS QUARTERLY
|year= 2010
|abstract = Fake websites have become increasingly pervasive, generating billions of dollars in fraudulent revenue at the expense of unsuspecting Internet users. The design and appearance of these websites makes it difficult for users to manually identify them as fake. Automated detection systems have emerged as a mechanism for combating fake websites, however most are fairly simplistic in terms of their fraud cues and detection methods employed Consequently, existing systems are susceptible to the myriad of obfuscation tactics used by fraudsters, resulting in highly ineffective fake website detection performance. In light of these deficiencies, we propose the development of a new class of fake website detection systems that are based on statistical learning theory (SLT). Using a design science approach, a prototype system was developed to demonstrate the potential utility of this class of systems. We conducted a series of experiments, comparing the proposed system against several existing fake website detection systems on a test bed encompassing 900 websites. The results indicate that systems grounded in SLT can more accurately detect various categories of fake websites by utilizing richer sets of fraud cues in combination with problem-specific knowledge. Given the hefty cost exacted by fake websites, the results have important implications for e-commerce and online security.
|keyword = Fake website detection,Internet fraud,design science,statistical learning theory,information systems development,website classification,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CIRCUITS OF POWER: A STUDY OF MANDATED COMPLIANCE TO AN INFORMATION SYSTEMS SECURITY DE JURE STANDARD IN A GOVERNMENT ORGANIZATION'''
{{header}}
{{article
|author= Stephen Smith,Donald Winchester,Deborah Bunker,Rodger Jamieson,
|source= MIS QUARTERLY
|year= 2010
|abstract = Organizations need to protect information assets against cyber crime, denial-of-service attacks, web hackers, data breaches, identity and credit card theft, and fraud. Criminals often try to achieve financial, political, or personal gain through these attacks, so the threats that their actions prompt are insidious motivators for organizations to adopt information systems security (ISS) approaches. Extant ISS research has traditionally examined ISS in e-commerce business organizations. The present study investigates ISS within government, analyzing power relationships during an ISS standards adoption and accreditation process, where a head of state mandates that all government agencies are to comply with a national de jure ISS standard. Using a canonical action research method, designated managers of ISS services across small, medium, and large agencies were monitored and assessed for progress to accreditation through surveys, interviews, participant observation at round table forums, and focus groups. By 2008, accreditation status across the 89 agencies participating in this study was approximately 33 percent fully accredited, with 67 percent partially compliant. The research uses Clegg's (1989) circuits of power framework to interpret power, resistance, norms, and cultural relationships in the process of compliance. The paper highlights that a strategy based on organization subunit size is helpful in motivating and assisting organizations to move toward accreditation. Mandated standard accreditation was inhibited by insufficient resource allocation, lack of senior management input, and commitment. Factors contributing to this resistance were group norms and cultural biases.
|keyword = Information systems security (ISS),ISS de jure standards,politics and power,circuits of power,resistance,norms,culture,institutionalization,canonical action research,e-commerce,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''NEUTRALIZATION: NEW INSIGHTS INTO THE PROBLEM OF EMPLOYEE INFORMATION SYSTEMS SECURITY POLICY VIOLATIONS'''
{{header}}
{{article
|author= Mikko Siponen,Anthony Vance,
|source= MIS QUARTERLY
|year= 2010
|abstract = Employees' failure to comply with information systems security policies is a major concern for information technology security managers. In efforts to understand this problem, IS security researchers have traditionally viewed violations of IS security policies through the lens of deterrence theory. In this article, we show that neutralization theory. a theory prominent in Criminology but not yet applied in the context of IS, provides a compelling explanation for IS security policy violations and offers new insight into how employees rationalize this behavior. In doing so, we propose a theoretical model in which the effects of neutralization techniques are tested alongside those of sanctions described by deterrence theory. Our empirical results highlight neutralization as an important factor to take into account with regard to developing and implementing organizational security policies and practices.
|keyword = Neutralization theory,deterrence theory,IS security policies,IS security,compliance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''USER PARTICIPATION IN INFORMATION SYSTEMS SECURITY RISK MANAGEMENT'''
{{header}}
{{article
|author= Janine L. Spears,Henri Barki,
|source= MIS QUARTERLY
|year= 2010
|abstract = This paper examines user participation in information systems security risk management and its influence in the context of regulatory compliance via a multi-method study at the organizational level. First, eleven informants across five organizations were interviewed to gain an understanding of the types of activities and security controls in which users participated as part of Sarbanes-Oxley compliance, along with associated outcomes. A research model was developed based on the findings of the qualitative study and extant user participation theories in the systems development literature. Analysis of the data collected in a questionnaire survey of 228 members of ISACA, a professional association specialized in information technology governance, audit, and security, supported the research model. The findings of the two studies converged and indicated that user participation contributed to improved security control performance through greater awareness, greater alignment between IS security risk management and the business environment, and improved control development. While the IS security literature often portrays users as the weak link in security, the current study suggests that users may be an important resource to IS security by providing needed business knowledge that contributes to more effective security measures. User participation is also a means to engage users in protecting sensitive information in their business processes.
|keyword = Information security,user participation,security risk management,Sarbanes-Oxley Act,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION SECURITY POLICY COMPLIANCE: AN EMPIRICAL STUDY OF RATIONALITY-BASED BELIEFS AND INFORMATION SECURITY AWARENESS'''
{{header}}
{{article
|author= Burcu Bulgurcu,Hasan Cavusoglu,Izak Benbasat,
|source= MIS QUARTERLY
|year= 2010
|abstract = Many organizations recognize that their employees, who are often considered the weakest link in information security, can also be great assets in the effort to reduce risk related to information security. Since employees who comply with the information security rules and regulations of the organization are the key to strengthening information security, understanding compliance behavior is crucial for organizations that want to leverage their human capital. This research identifies the antecedents of employee compliance with the information security policy (ISP) of an organization. Specifically, we investigate the rationality-based factors that drive an employee to comply with requirements of the ISP with regard to protecting the organization's information and technology resources. Drawing on the theory of planned behavior, we posit that, along with normative belief and self-efficacy, an employee's attitude toward compliance determines intention to comply with the ISP. As a key contribution, we posit that an employee's attitude is influenced by benefit of compliance, cost of compliance, and cost of noncompliance, which are beliefs about the overall assessment of consequences of compliance or noncompliance. We then postulate that these beliefs are shaped by the employee's outcome beliefs concerning the events that follow compliance or noncompliance: benefit of compliance is shaped by intrinsic benefit, safety of resources, and rewards, while cost of compliance is shaped by work impediment; and cost of noncompliance is shaped by intrinsic cost, vulnerability of resources, and sanctions. We also investigate the impact of information security awareness (ISA) on outcome beliefs and an employee's attitude toward compliance with the ISP. Our results show that an employee's intention to comply with the ISP is significantly influenced by attitude, normative beliefs, and self-efficacy to comply. Outcome beliefs significantly affect beliefs about overall assessment of consequences, and they, in turn, significantly affect an employee's attitude. Furthermore, ISA positively affects both attitude and outcome beliefs. As the importance of employees' following their organizations' information security rules and regulations increases, our study sheds light on the role of ISA and compliance-related beliefs in an organization's efforts to encourage compliance.
|keyword = Information security awareness,information security management,compliance,information security policy,behavioral issues of information security,theory of planned behavior,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''FEAR APPEALS AND INFORMATION SECURITY BEHAVIORS: AN EMPIRICAL STUDY'''
{{header}}
{{article
|author= Allen C. Johnston,Merrill Warkentin,
|source= MIS QUARTERLY
|year= 2010
|abstract = Information technology executives strive to align the actions of end users with the desired security posture of management and of the firm through persuasive communication. In many cases, some element of fear is incorporated within these communications. However, within the context of computer security and information assurance, it is not yet clear how these fear-inducing arguments, known as fear appeals, will ultimately impact the actions of end users. The purpose of this study is to investigate the influence of fear appeals on the compliance of end users with recommendations to enact specific individual computer security actions toward the mitigation of threats. An examination was performed that culminated in the development and testing of a conceptual model representing an infusion of technology adoption and fear appeal theories. Results of the study suggest that fear appeals do impact end user behavioral intentions to comply with recommended individual acts of security, but the impact is not uniform across all end users. It is determined in part by perceptions of self-efficacy, response efficacy, threat severity, and social influence. The findings of this research contribute to information systems security research, human computer interaction, and organizational communication by revealing a new paradigm in which IT users form perceptions of the technology, not on the basis of performance gains, but on the basis of utility for threat mitigation.
|keyword = Information security,countermeasures,protection motivation theory,fear appeals,persuasive communication,information assurance,threat appraisal,coping appraisal,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''MARKET VALUE OF VOLUNTARY DISCLOSURES CONCERNING INFORMATION SECURITY'''
{{header}}
{{article
|author= Lawrence A. Gordon,Martin P. Loeb,Tashfeen Sohail,
|source= MIS QUARTERLY
|year= 2010
|abstract = Information security is a fundamental concern for corporations operating in today's digital economy. The number of firms disclosing items concerning their information security on reports filed with the U. S. Securities and Exchange Commission (SEC) has increased in recent years. A question then arises as to whether or not there is value to the voluntary disclosures concerning information security. Thus, the primary objective of this paper is to assess empirically the market value of voluntary disclosures of items pertaining to information security. Based on a sample of 1,641 disclosing and 19,266 non-disclosing firm-years in a cross-sectional pooled model, our primary findings provide strong evidence that voluntarily disclosing items concerning information security is associated positively with the market value of a firm. These findings are based on the use of a market-value relevance model, as well as a bid-ask spread analysis. The study's findings are robust to alternative statistical analyses. The findings also provide support for the signaling argument, which states that managers disclose information in a manner consistent with increased firm value. Finally, the study findings provide some insight into the strategic choice that firms make regarding voluntary disclosures about information security.
|keyword = Information security,market value,voluntary disclosures,selection-bias,bid ask spread,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE IMPACT OF MALICIOUS AGENTS ON THE ENTERPRISE SOFTWARE INDUSTRY'''
{{header}}
{{article
|author= Michael R. Galbreth,Mikhael Shor,
|source= MIS QUARTERLY
|year= 2010
|abstract = In this paper, a competitive software market that includes horizontal and quality differentiation, as well as a negative network effect driven by the presence of malicious agents, is modeled. Software products with larger installed bases, and therefore more potential computers to attack, present more appealing targets for malicious agents. One finding is that software firms may profit from increased malicious activity. Software products in a more competitive market are less likely to invest in security, while monopolistic or niche products are likely to be more secure from malicious attack. The results provide insights for IS managers considering enterprise software adoption.
|keyword = Information system security,network externalities,software selection,game theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PRACTICING SAFE COMPUTING: A MULTIMETHOD EMPIRICAL EXAMINATION OF HOME COMPUTER USER SECURITY BEHAVIORAL INTENTIONS'''
{{header}}
{{article
|author= Catherine L. Anderson,Ritu Agarwal,
|source= MIS QUARTERLY
|year= 2010
|abstract = Although firms are expending substantial resources to develop technology and processes that can help safeguard the security of their computing assets, increased attention is being focused on the role people play in maintaining a safe computing environment. Unlike employees in a work setting, home users are not subject to training, nor are they protected by a technical staff dedicated to keeping security software and hardware current. Thus, with over one billion people with access to the Internet, individual home computer users represent a significant point of weakness in achieving the security of the cyber infrastructure. We study the phenomenon of conscientious cybercitizens, defined as individuals who are motivated to take the necessary precautions under their direct control to secure their own computer and the Internet in a home setting. Using a multidisciplinary, phased approach, we develop a conceptual model of the conscientious cybercitizen. We present results from two studies a survey and an experiment conducted to understand the drivers of intentions to perform security-related behavior, and the interventions that can positively influence these drivers. In the first study, we use protection motivation theory as the underlying conceptual foundation and extend the theory by drawing upon the public goods literature and the concept of psychological ownership. Results from a survey of 594 home computer users from a wide range of demographic and socioeconomic backgrounds suggest that a home computer user's intention to perform security-related behavior is influenced by a combination of cognitive, social, and psychological components. In the second study, we draw upon the concepts of goal framing and self-view to examine how the proximal drivers of intentions to perform security-related behavior identified in the first study can be influenced by appropriate messaging. An experiment with 101 subjects is used to test the research hypotheses. Overall, the two studies shed important new light on creating more conscientious cybercitizens. Theoretical and practical implications of the findings are discussed.(2)
|keyword = Behavioral security,protection motivation,home computer user,goal framing,self-view,survey,experiment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Transparency in Business-to-Consumer Markets: Concepts, Framework, and Research Agenda'''
{{header}}
{{article
|author= Nelson Granados,Alok Gupta,Robert J. Kauffman,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = The Internet has brought about significant changes in the availability of market information in many industries. E-commerce technologies provide sellers with opportunities to design electronic mercantile mechanisms that reveal, conceal, bias, and distort market information, depending on their goals and market position (e.g., suppliers versus intermediaries). In particular, in information-intensive industries where electronic markets play an important role, many firms are using advanced technologies to put innovative strategies into play that are based on the provision of differential information to their customers. We examine the role of information transparency in electronic markets. We contend that there is an opportunity to develop research on sellers' strategies regarding information disclosure to customers and competitors. For that purpose, we develop a set of concepts and a framework to guide future research. We then propose an interdisciplinary agenda for research on the emerging and increasingly important topic of transparency strategy, which we define as the set of policies and decisions that a firm makes to disclose, conceal, bias, or distort market information.
|keyword = business-to-business e-commerce,business-to-consumer e-commerce,electronic markets,information transparency,market mechanism design,transparency strategy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Resource Allocation Policies for Personalization in Content Delivery Sites'''
{{header}}
{{article
|author= Dengpan Liu,Sumit Sarkar,Chelliah Sriskandarajah,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = One of the distinctive features of sites on the Internet is their ability to gather enormous amounts of information about their visitors and to use this information to enhance a visitor's experience by providing personalized information or recommendations. In providing personalized services, a website is typically faced with the following trade-off: When serving a visitor's request, it can deliver an optimally personalized version of the content to the visitor, possibly with a long delay because of the computational effort needed, or it can deliver a suboptimal version of the content more quickly. This problem becomes more complex when several requests are waiting for information from a server. The website then needs to trade off the benefit from providing more personalized content to each user with the negative externalities associated with higher waiting costs for all other visitors that have requests pending. We examine several deterministic resource allocation policies in such personalization contexts. We identify an optimal policy for the above problem when requests to be scheduled are batched, and show that the policy can be very efficiently implemented in practice. We provide an experimental approach to determine optimal batch lengths, and demonstrate that it performs favorably when compared with viable queueing approaches.
|keyword = recommendation systems,user profiling,delay externality,scheduling,batching,queueing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Technological Frames, Organizational Capabilities, and IT Use: An Empirical Investigation of Electronic Procurement'''
{{header}}
{{article
|author= Abhay Nath Mishra,Ritu Agarwal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = The process by which organizations incorporate technological innovations into existing routines and use them on a regular basis persists as a central concern in the literature. Although we now have a fairly robust understanding of the drivers of innovation adoption, the use of innovations is less understood. In this paper, we draw on two streams of literature, managerial and organizational sensemaking, and organizational capabilities that have hitherto been used independently, to investigate organizational use of information technology (IT)-based innovations. Building on and extending prior work, we posit that organizational capabilities serve as complements to managers' technological frames related to an innovation. We focus on the use of an important technological innovation-business-to-business (B2B) electronic markets for procurement. We examine interactions between three technological frames-benefits frame, threat frame, and adjustment frame, and two organizational capabilities-technological opportunism and technological sophistication, and their relationship with the use of B2B electronic markets in firms. We test our research model using survey data collected from 292 firms. Results largely support the proposed conceptualization and shed new light on the key factors associated with firms' use of B2B electronic markets. Theoretical and practical implications of the findings are discussed.
|keyword = electronic procurement,B2B electronic markets,technological frames,benefits frame,threat frame,adjustment frame,organizational capabilities,technological opportunism,technological sophistication,sensemaking,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Diffusion Models for Peer-to-Peer (P2P) Media Distribution: On the Impact of Decentralized, Constrained Supply'''
{{header}}
{{article
|author= Kartik Hosanagar,Peng Han,Yong Tan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = In peer-to-peer (P2P) media distribution, users obtain content from other users who already have it. This form of decentralized product distribution demonstrates several unique features. Only a small fraction of users in the network are queried when a potential adopter seeks a file, and many of these users might even free-ride, i.e., not distribute the content to others. As a result, generated demand might not always be fulfilled immediately. We present mixing models for product diffusion in P2P networks that capture decentralized product distribution by current adopters, incomplete demand fulfillment and other unique aspects of P2P product diffusion. The models serve to demonstrate the important role that P2P search process and distribution referrals-payments made to users that distribute files-play in efficient P2P media distribution. We demonstrate the ability of our diffusion models to derive normative insights for P2P media distributors by studying the effectiveness of distribution referrals in speeding product diffusion and determining optimal referral policies for fully decentralized and hierarchical P2P networks.
|keyword = peer-to-peer file diffusion,P2P,supply-constrained diffusion,free-riding,mixing model of diffusion,distributed systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Complementarities Between Organizational IT Architecture and Governance Structure'''
{{header}}
{{article
|author= Amrit Tiwana,Benn Konsynski,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = This study addresses the theoretically neglected interplay between organizational information technology ( IT) architecture and IT governance structure in shaping IT alignment. We theoretically develop the idea that IT architecture modularity helps sustain IT alignment by increasing IT agility, and that decentralization of IT governance strengthens this relationship. IT architecture therefore complements IT governance structure. Tests of the proposed mediated-moderation model using data from 223 organizations support these ideas. Implications for theory and practice are also discussed.
|keyword = modularity,information technology architecture,governance,mediated moderation,alignment,IT strategy,IT agility,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Assessing Screening and Evaluation Decision Support Systems: A Resource-Matching Approach'''
{{header}}
{{article
|author= Chuan-Hoo Tan,Hock-Hai Teo,Izak Benbasat,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = This research explores how consumers use online decision aids with screening and evaluation support functionalities under varying product attribute-load conditions. Drawing on resource-matching theory, we conducted a 3 x 2 factorial experiment to test the interaction between decision aid features (i.e., low versus high-screening support, and aids with weight assignment and computation decision tools) and attribute load (i.e., large versus small number of product attributes) on decision performance. The findings reveal that: (1) where the decision aids render cognitive resources that match those demanded for the task environment, consumers will process more information and decision performance will be enhanced; (2) where the decision aids render cognitive resources that exceed those demanded for the task environment, consumers will engage in less task-related elaboration of decision-making issues to the detriment of decision performance; and (3) where the decision aids render cognitive resources that fall short of those demanded for the task environment, consumers will use simplistic heuristic decision strategies to the detriment of decision performance or invest additional effort in information processing to attain a better decision performance if they perceive the additional investments in effort to be manageable.
|keyword = decision support systems,electronic commerce,resource matching,consumer behavior,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Visualization of Network Concepts: The Impact of Working Memory Capacity Differences'''
{{header}}
{{article
|author= Bin Zhu,Stephanie A. Watts,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = As networks of all forms become ubiquitous, the network-based information they generate is increasingly being used in a wide variety of analysis tasks. In organizations, social network analysis techniques are being applied to a number of domains, particularly the understanding of knowledge stocks and flows. Because this information is generated from large data sets, computerized visualizations of it are very helpful for accomplishing these complex tasks. This paper presents a model for evaluating the effectiveness of network visualizations based on theories of cognitive fit, working memory capacity, and information load. The model was empirically tested in two experiments using two types of data visualizations from two different social networks. Results support the theoretical model, illustrating that variations in cognitive fit and working memory interact. Findings suggest that visualizations can enable superior outcomes when they are designed to support this interaction.
|keyword = information visualization,network visualization,social network analysis,working memory capacity,evaluation of information visualization systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Predicting Web Page Status'''
{{header}}
{{article
|author= Gautam Pant,Padmini Srinivasan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = The World Wide Web has become a key intermediary between producers and consumers of information. Web's linkage structure has been exploited by contemporary search engines to decrease the search cost for consumers while usually also rewarding the producers of higher status Web pages. In addition to influencing visibility and accessibility, in-links, as marks of recognition, accord status to a Web page. In this paper we show how Web page status may be predicted at least in part by page location and topic specificity. Moreover, we observe that the "philanthropic" contributions of a Web page-specifically, contributions of information brokerage function-are also good predictors of in-links. The observations are made in the presence of domain-and topic-specific effects. Interestingly, all of these features that may predict status are "local" to a given Web page and within the control of the owner/author of the page. This is in contrast to the "global" nature of Web linkage-based metrics such as in-link count that are derived as a result of downloading and indexing billions of pages. Because the linkage structure of the Web affects browsing, crawling, and retrieval, our results have implications for vertical and general search, business intelligence, and content management.
|keyword = Web search,search engine marketing,Web visibility,status,influence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Toward a Causal Interpretation from Observational Data: A New Bayesian Networks Method for Structural Models with Latent Variables'''
{{header}}
{{article
|author= Zhiqiang (Eric) Zheng,Paul A. Pavlou,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Because a fundamental attribute of a good theory is causality, the information systems (IS) literature has strived to infer causality from empirical data, typically seeking causal interpretations from longitudinal, experimental, and panel data that include time precedence. However, such data are not always obtainable and observational (cross-sectional, nonexperimental) data are often the only data available. To infer causality from observational data that are common in empirical IS research, this study develops a new data analysis method that integrates the Bayesian networks (BN) and structural equation modeling (SEM) literatures. Similar to SEM techniques (e. g., LISREL and PLS), the proposed Bayesian networks for latent variables (BN-LV) method tests both the measurement model and the structural model. The method operates in two stages: First, it inductively identifies the most likely LVs from measurement items without prespecifying a measurement model. Second, it compares all the possible structural models among the identified LVs in an exploratory (automated) fashion and it discovers the most likely causal structure. By exploring the causal structural model that is not restricted to linear relationships, BN-LV contributes to the empirical IS literature by overcoming three SEM limitations (Lee, B., A. Barua, A. B. Whinston. 1997. Discovery and representation of causal relationships in MIS research: A methodological framework. MIS Quart. 21(1) 109-136)-lack of causality inference, restrictive model structure, and lack of nonlinearities. Moreover, BN-LV extends the BN literature by (1) overcoming the problem of latent variable identification using observed (raw) measurement items as the only inputs, and (2) enabling the use of ordinal and discrete (Likert-type) data, which are commonly used in empirical IS studies. The BN-LV method is first illustrated and tested with actual empirical data to demonstrate how it can help reconcile competing hypotheses in terms of the direction of causality in a structural model. Second, we conduct a comprehensive simulation study to demonstrate the effectiveness of BN-LV compared to existing techniques in the SEM and BN literatures. The advantages of BN-LV in terms of measurement model construction and structural model discovery are discussed.
|keyword = causality,Bayesian networks,structural equation modeling,observational data,Bayesian graphs,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Does Technological Progress Alter the Nature of Information Technology as a Production Input? New Evidence and New Results'''
{{header}}
{{article
|author= Paul Chwelos,Ronald Ramirez,Kenneth L. Kraemer,Nigel P. Melville,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Prior research at the firm level finds information technology (IT) to be a net substitute for both labor and non-IT capital inputs. However, it is unclear whether these results hold, given recent IT innovations and continued price declines. In this study we extend prior research to examine whether these input relationships have evolved over time. First, we introduce new price indexes to account for varying technological progress across different types of IT hardware. Second, we use the rental price methodology to measure capital in terms of the flow of services provided. Finally, we use hedonic methods to extend our IT measures to 1998, enabling analysis spanning the emergence of the Internet. Analyzing approximately 9,800 observations from over 800 Fortune 1,000 firms for the years 1987-1998, we find firm demand for IT to be elastic for decentralized IT and inelastic for centralized IT. Moreover, Allen Elasticity of Substitution estimates confirm that through labor substitution, the increasing factor share of IT comes at the expense of labor. Last, we identify a complementary relationship between IT and ordinary capital, suggesting an evolution in this relationship as firms have shifted to more decentralized organizational forms. We discuss these results in terms of prior research, suggest areas of future research, and discuss managerial implications.
|keyword = IT business value,productivity,substitute,complement,hedonic,capital services,technological change,rental price,price index,organizational decentralization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Follow the Sun Workflow in Global Software Development'''
{{header}}
{{article
|author= Erran Carmel,J. Alberto Espinosa,Yael Dubinsky,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Follow the sun (FTS) has interesting appeal-hand off work at the end of every day from one site to the next, many time zones away, in order to speed up product development. Although the potential effect on "time to market" can be profound, at least conceptually, FTS has enjoyed few documented industry successes because it is acknowledged to be extremely difficult to implement. In order to address this "FTS challenge," we provide here a conceptual foundation and formal definition of FTS. We then analyze the conditions under which FT'S can be successful in reducing duration in software development. We show that handoff efficiency is paramount to successful FTS practices and that duration can be reduced only when lower within-site coordination and improved personal productivity outweigh the corresponding increase in cross-site coordination. We also develop 12 research propositions based on fundamental issues surrounding FTS, such as calendar efficiency, development method, product architecture and handoff efficiency, within-site coordination, cross-site coordination, and personal productivity. We combine the conceptual analysis with a description of our FTS exploratory comparative field studies and draw out their key findings and learning. The main implication of this paper is that understanding calendar efficiency, handoff efficiency, within-site coordination, and cross-site coordination is necessary to evaluation-if FTS is to be successful in reducing software development duration.
|keyword = calendar-efficient software development,global coordination,round-the-clock development,software development,software handoff efficiency,time to market,24-hour development,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Perpetual Versus Subscription Licensing Under Quality Uncertainty and Network Externality Effects'''
{{header}}
{{article
|author= Jie (Jennifer) Zhang,Abraham Seidmann,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = We discuss the optimal way for a software vendor to license software: a perpetual license at a posted price, a subscription contract that subscribers receive automatic updates for periodic payment, or a hybrid approach that involves both. By addressing specific issues in the software market such as network effects, quality uncertainty, upgrade compatibility, and the vendor's ability to commit to future prices in a dynamic environment, we demonstrate how a software vendor can manage the trade-offs of perpetual licensing and subscription to optimize profit, as well as the corresponding welfare effect on consumers. Although the subscription model helps the vendor lock in consumers so as to increase profit when there is great uncertainty associated with the next version software, it destroys the path dependence in creating network externalities. Therefore, when the network effect is sufficiently large, it is more profitable for a software vendor to provide both perpetual licensing and subscription.
|keyword = compatibility,network externality,price discrimination,quality uncertainty,software licensing,upgrades,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Power of Patterns and Pattern Recognition When Developing Information-Based Strategy'''
{{header}}
{{article
|author= Eric K. Clemons,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Just as scientists in other disciplines use experience and a small set of frequently occurring problems to structure unfamiliar situations, information strategy and economics provides its own patterns to guide and structure the use of experience in managerial settings. These patterns emerged through case studies, theoretical derivations, and empirical analyses of company, industry, and national data sets. The six most frequently observed patterns identified here are (1) newly vulnerable markets experience opportunistic pickoff; (2) transparency of product attributes increases informedness, enabling resonance marketing and increasing the benefits from offering truly differentiated products and services; (3) changes in transaction costs have changed the boundary of the firm; (4) unique resources endowments can confer or sustain competitive advantage; (5) the geometry of distribution determines power and affects profitability; and (6) network-based advantages can form the basis of platform-envelopment strategies. Finally, prospects for the future of information, strategy, and economics over the coming two decades are reviewed.
|keyword = hyperdifferentiation,newly vulnerable markets,outsourcing risks,platform envelopment strategies,resonance marketing,resource-based competitive advantage,strategic information systems,transaction costs of outsourcing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Models of Collaboration as the Foundation for Collaboration Technologies'''
{{header}}
{{article
|author= Steven Poltrock,Mark Handel,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Can models of collaboration serve as foundations for development of collaborative technologies in much the same way that engineers use models when developing complex systems? We explore this issue by investigating how eight approaches to understanding or modeling collaboration could be used to improve technologies that support processes used in a large aerospace program. Some modeling approaches are ostensive, defining how collaboration should be achieved or how the technology should be used. These approaches provide ways of documenting, analyzing, simulating, and automating the process. Other approaches are performative, describing actual collaboration behavior and actual technology use. Performative approaches reveal the variability in collaboration and deviations from the intended process. Technologies can benefit from and facilitate both types of modeling approaches by recording collaborative events for later analysis. We conclude by considering ways that modeling collaboration could contribute to requirements analysis, new collaboration capabilities, adoption, and maximizing benefit from technologies.
|keyword = collaboration,coordination theory,modeling,social network models,temporal models,workflow,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Bounded Ideation Theory'''
{{header}}
{{article
|author= Robert O. Briggs,Bruce A. Reinig,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Organizations often look to their information systems (IS) professionals to work with system stakeholders to generate new ideas to solve complex problems and to provide information technology (IT) artifacts to support ideation processes. Much research therefore seeks to increase the number of ideas people generate based on Alex F. Osborn's conjecture that more ideas give rise to more good ideas. Recent research, however, calls the quantity-quality conjecture into question. This paper advances bounded ideation theory (BIT), an explanation for the ideation function-the relationship between the number of good ideas and the number of ideas contributed. BIT posits that boundaries of understanding, attention resources, goal congruence, mental and physical stamina, and the solution space moderate a primary relationship between individual ability and idea quality, yielding an ideation function with an inflected curve. We discuss six strategies for improving ideation and call into question the value of the quantity focus of ideation research in the IS/IT literature, arguing that a quality focus would be more useful.
|keyword = bounded ideation theory,brainstorming,group support systems,ideation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Network Externalities and Technology Use: A Quantitative Analysis of Intraorganizational Blogs'''
{{header}}
{{article
|author= Sunil Wattal,Pradeep Racherla,Munir Mandviwalla,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = We examine the role of network externalities on the use of blogs in an organization. Prior research has considered social influences such as peer pressure, but there is little prior work on how the extent of others' actual usage can influence an individual's use of technology. We also examine how technology usage is influenced by positive feedback from others. Finally, we look at how the relation between technology usage and network effects is moderated by demographic variables such as age and gender. The results of the study show that usage of blogs within an individual's network is associated with an increase in one's own usage. We also show that network effects are stronger for younger generations and that this relation is nonmonotonic with age. This is interesting considering that prior research suggests that social influences are stronger for older employees. Our results also show that network effects are stronger for women than for men. Further, we show that the impact of age on blog usage in not linear. We also find that feedback or appreciation from others is associated with higher blog usage by an individual. Finally, we subdivide the network effects into various subtypes and find that network effects are strongest for relational networks, and that use of blogs by an employee's managers is associated with higher usage by the employee.
|keyword = corporate blogs,network externalities,social computing,social networks,technology usage,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Technology Dominance in Complex Decision Making: The Case of Aided Credibility Assessment'''
{{header}}
{{article
|author= Matthew L. Jensen,Paul Benjamin Lowry,Judee K. Burgoon,Jr. Jay F. Nunamaker,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Decision aids have long been an important source of help in making structured decisions. However, decision support for more complex problems has been much more difficult to create. Decision aids are now being developed for very complex problems, and their effects among low- and high-task-knowledge individuals are still being explored. One such task is credibility assessment, in which message recipients or observers must determine a message's veracity and trustworthiness. Credibility assessment is made difficult by lack of constraints, hidden or incomplete information, and mistaken beliefs of the assessor. The theory of technology dominance (TTD) proposes that technology is most effectively applied in intelligent decision aids when an experienced user is paired with a sophisticated decision aid. This work examines TTD in the complex task of credibility assessment. To assist in credibility assessment, we created a decision aid that augments the capabilities of the user-whether novice or professional. Using hypotheses based on TTD, we tested the decision aid using high-stakes deception in recorded interviews and involved both student (novice) and law enforcement (professional) users. Both professionals and novices improved their assessment accuracy by using the decision aid. Consistent with TTD, novices were more reliant on the decision aid than were professionals. However, contrary to TTD, there was no significant difference in the way novices and professionals interacted with the system, and the decision aid was not more beneficial to professionals. Novices and professionals frequently discounted the aid's recommendations, and in many cases professionals did not view explanations when the decision aid contradicted their assessments. Potential reasons for these findings, as well as limitations and future research opportunities, are discussed.
|keyword = credibility,credibility assessment,deception,deception detection,decision aids,decision making,theory of technology dominance (TTD),
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Team Size, Dispersion, and Social Loafing in Technology-Supported Teams: A Perspective on the Theory of Moral Disengagement'''
{{header}}
{{article
|author= Omar A. Alnuaimi,Jr. Lionel P. Robert,Likoebe M. Maruping,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Social loafing is the tendency of individuals to withhold contributions to a task in a team setting. Team size and dispersion are two primary drivers of social loafing in technology-supported team settings. However, the mechanisms through which these drivers affect social loafing are not well understood. Consequently, the objective of this study is to identify the cognitive mechanisms that mediate the effect of team size and dispersion on social loafing in technology-supported teams. Drawing on the theory of moral disengagement, we posit that three primary cognitive mechanisms-diffusion of responsibility, attribution of blame, and dehumanization-will mediate the effect of team size and dispersion on social loafing. We conducted a laboratory study involving 140 students randomly assigned to 32 teams performing a brainstorming task using group systems software. The results show that diffusion of responsibility, attribution of blame, and dehumanization all mediate (partially) the effects of team size on social loafing. Meanwhile, only dehumanization mediates (fully) the effect of dispersion on social loafing.
|keyword = computer-mediated communication,creativity,electronic brainstorming,idea generation,individuals in teams,social loafing,team performance,team productivity,technology-mediated collaborative environments,technology-supported team efficacy,theory of moral disengagement,virtual collaboration,virtual teams,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Antecedents and Effects of CIO Supply-Side and Demand-Side Leadership: A Staged Maturity Model'''
{{header}}
{{article
|author= Daniel Q. Chen,David S. Preston,Weidong Xia,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = As organizations' information technology (IT) investment goals evolve from improving operational efficiency to enhancing strategic growth, the chief information officer (CIO) is increasingly expected to play not only the traditional supply-side leadership role that focuses on exploiting existing IT competencies to support known business needs but also the demand-side leadership role that focuses on exploring new IT-enabled business opportunities that result in competitive advantage. Using matched CIO business executive responses from 174 firms, we test a staged maturity relationship between CIO supply-side and demand-side leadership and examine three antecedents (CIO human capital, CIO structural power, and organizational support for IT) and two effects (IT contribution to firm efficiency and strategic growth) of CIO leadership. The staged maturity model is supported by our findings and provides insight into how these two stages of CIO leadership influence IT impact within the organization and how they are influenced by these key antecedents.
|keyword = chief information officer,exploitation,exploration,IT functional impact,IT leadership,staged maturity model,strategic value of IT,structural equation modeling,survey research,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Influence of Experiential and Dispositional Factors in Phishing: An Empirical Investigation of the Deceived'''
{{header}}
{{article
|author= Ryan T. Wright,Kent Marett,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Phishing has been a major problem for information systems managers and users for several years now. In 2008, it was estimated that phishing resulted in close to $50 billion in damages to U.S. consumers and businesses. Even so, research has yet to explore many of the reasons why Internet users continue to be exploited. The goal of this paper is to better understand the behavioral factors that may increase one's susceptibility for complying with a phisher's request for personal information. Using past research on deception detection, a research model was developed to help explain compliant phishing responses. The model was tested using a field study in which each participant received a phishing e-mail asking for sensitive information. It was found that four behavioral factors were influential as to whether the phishing e-mails were answered with sensitive information. The paper concludes by suggesting that the behavioral aspect of susceptible users be integrated into the current tools and materials used in antiphishing efforts.
|keyword = computer-mediated deception,electronic mail fraud,Internet security,interpersonal deception theory,phishing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COMPUTING IN EVERYDAY LIFE: A CALL FOR RESEARCH ON EXPERIENTIAL COMPUTING'''
{{header}}
{{article
|author= Youngjin Yoo,
|source= MIS QUARTERLY
|year= 2010
|abstract = The information systems field emerged as a new discipline of artificial science as a result of intellectual efforts to understand the nature and consequences of computer and communication technology in modern organizations. As the rapid development of digital technology continues to make computers and computing apart of everyday experiences, we are once again in need of a new discipline of the artificial. In this essay, I argue that the IS community must expand its intellectual boundaries by embracing experiential computing as an emerging field of inquiry in order to fill this growing intellectual void. Experiential computing involves digitally mediated embodied experiences in everyday activities through everyday artifacts that have embedded computing capabilities. Experiential computing is enabled by the mediation of four dimensions of human experiences ('time, space, actors, and artifacts) through digital technology. Drawing on a research framework that encompasses both behavioral and design sciences, six research opportunities that the IS research community can explore are suggested. Ultimately, I propose that the IS field return to its roots, the science of the artificial, by decisively expanding the scope of its inquiry and establishing a new domain of research on computing in everyday life experiences.
|keyword = Experiential computing,science of artificial,design,digitalization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION SYSTEMS STRATEGY: RECONCEPTUALIZATION, MEASUREMENT, AND IMPLICATIONS'''
{{header}}
{{article
|author= Daniel Q. Chen,Martin Mocker,David S. Preston,Alexander Teubner,
|source= MIS QUARTERLY
|year= 2010
|abstract = Information systems strategy is of central importance to IS practice and research. Our extensive review of the literature suggests that the concept of IS strategy is a term that is used readily; however, it is also a term that is not fully understood. In this study, we fallow a perspective paradigm based on the strategic management literature to define IS strategy as an organizational perspective on the investment in, deployment, use, and management of IS. Through a systematic literature search, we identify the following three conceptions of IS strategy employed implicitly in 48 articles published in leading IS journals that focus on the construct of IS strategy: (1) IS strategy as the use of IS to support business strategy; (2) IS strategy as the master plan of the IS function; and (3) IS strategy as the shared view of the IS role within the organization. We find the third conception best fits our definition of IS strategy. As such, we consequently propose to operationalize IS strategy as the degree to which the organization has a shared perspective to seek innovation through IS. Specifically, our proposed IS strategic typology suggests an organization's IS strategy falls into one of the two defined categories (i.e., IS innovator or IS conservative) or is simply undefined. We also develop measures for this new typology. We argue that the proposed instrument, which was cross-validated across both chief information officers and senior business executives, has the potential to serve as a diagnostic tool through which the organization can directly assess its IS strategy. We contend that our reconceptualization and operationalization of IS strategy provides theoretical and practical implications that advance the current level of understanding of IS strategy from extant studies within three predominant literature streams: strategic IS planning, IS/business strategic alignment, and competitive use of IS.
|keyword = IS strategy,IS strategic alignment,strategic IS planning,competitive advantage,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''BRAND POSITIONING STRATEGY USING SEARCH ENGINE MARKETING'''
{{header}}
{{article
|author= Wenyu Dou,Kai H. Lim,Chenting Su,Nan Zhou,Nan Cui,
|source= MIS QUARTERLY
|year= 2010
|abstract = Whether and how firms can employ relative rankings in search engine results pages (SERPs) to differentiate their brands from competitors in cyberspace remains a critical, puzzling issue in e-commerce research. By synthesizing relevant literature from cognitive psychology, marketing, and e-commerce, this study identifies key contextual factors that are conducive for creating brand positioning online via SERPs. In two experiments, the authors establish that when Internet users' implicit beliefs (i.e., schema) about the meaning of the display order of search engine results are activated or heightened through feature priming, they will have better recall of an unknown brand that is displayed before the well-known brands in SERPs. Further, those with low Internet search skills tend to evaluate the unknown brand more favorably along the particular brand attribute that activates the search engine ranking schema. This research has both theoretical and practical implications for understanding the effectiveness of search engine optimization techniques.
|keyword = e-commerce,search engine optimization,web design,brand positioning,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EXPECTATION DISCONFIRMATION AND TECHNOLOGY ADOPTION: POLYNOMIAL MODELING AND RESPONSE SURFACE ANALYSIS'''
{{header}}
{{article
|author= Viswanath Venkatesh,Sandeep Goyal,
|source= MIS QUARTERLY
|year= 2010
|abstract = Individual-level information systems adoption research has recently seen the introduction of expectation disconfirmation theory (EDT) to explain how and why user reactions change over time. This prior research has produced valuable in-sights into the phenomenon of technology adoption beyond traditional models, such as the technology acceptance model. First, we identify gaps in EDT research that present potential opportunities advances specifically, we discuss methodological and analytical limitations in EDT research in information systems and present polynomial modeling and response surface methodology as solutions. Second, we draw from research on cognitive dissonance, realistic job preview, and prospect theory to present a polynomial model of expectation-disconfirmation in information systems. Finally, we test our model using data gathered over a period of 6 months among 1,143 employees being introduced to a new technology. The results confirmed our hypotheses that disconfirmation in general was bad, as evidenced by low behavioral intention to continue using a system for both positive and negative disconfirmation, thus supporting the need for a polynomial model to understand expectation disconfirmation in information systems.
|keyword = Polynomial modeling,response surface methodology,nonlinear modeling,difference scores,direct measures,technology acceptance model,expectation disconfirmation theory,IS continuance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A MULTI-PROJECT MODEL OF KEY FACTORS AFFECTING ORGANIZATIONAL BENEFITS FROM ENTERPRISE SYSTEMS'''
{{header}}
{{article
|author= Peter B. Seddon,Cheryl Calvert,Song Yang,
|source= MIS QUARTERLY
|year= 2010
|abstract = This paper develops a long-term, multi-project model of factors affecting organizational benefits from enterprise systems (ES), then reports a preliminary test of the model. In the shorter-term half of the model, it is hypothesized that once a system has gone live, two factors, namely functional fit and overcoming organizational inertia, drive organizational benefits flowing from each major ES improvement project. The importance of these Actors may vary from project to project. In the long-term half of the model, it is hypothesized that four additional factors, namely integration, process optimization, improved access to information, and on-going major ES business improvement projects, drive organizational benefits from ES over the long term. Preliminary tests of the model were conducted using data from 126 customer presentations from SAP's 2003 and 2005 Sapphire U.S. conferences. All six factors were found to be important in explaining variance in organizational benefits from enterprise systems from the perspective of senior management.
|keyword = Enterprise system success,packaged software,functional fit,overcoming organizational inertia,change management,IS implementation,IS project management,integration,process optimization,improved access to information,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION ABOUT INFORMATION: A TAXONOMY OF VIEWS'''
{{header}}
{{article
|author= Jr. Earl H. McKinney,II Charles J. Yoos,
|source= MIS QUARTERLY
|year= 2010
|abstract = Information is poorly defined in the Information Systems research literature, and is almost always unspecified, a reflexive, all-purpose but indiscriminant solution to an unbounded variety of problems. We present a taxonomy of four views token, syntax, representation, and adaptation to enable scholars and practitioners to specify their concept of information. This taxonomy is normative, but we also provide a background review of the etymology and chronology of information, and we sample uses of the term in current IS research. IS research will improve as the term information, via the taxonomy we contribute, is employed more explicitly and consistently.
|keyword = Information,theory,taxonomy,token,syntax,representation,adaptation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INVESTIGATING Two CONTRADICTORY VIEWS OF FORMATIVE MEASUREMENT IN INFORMATION SYSTEMS RESEARCH'''
{{header}}
{{article
|author= Gimun Kim,Bongsik Shin,Varun Grover,
|source= MIS QUARTERLY
|year= 2010
|abstract = The use of formative measurement in the field of Information Systems has increased, arguably due to statistical tools (e.g., PLS) that can test such models. However, in the literature, there exist two contradictory views on the potential deficiency of formative measurement. While opponents who are critical of formative measurement argue that there are native weaknesses of the formative approach in model estimation, proponents who are in favor of using formative measurement counter that opponents research methods in measurement model specification are flawed. The goal of this work is to empirically test these opposing views on whether the alleged estimation instability of formative measurement is due to measurement model misspecification or simply the shortcoming of formative measurement. To assess the integrity of arguments of both parties, we adopt a research design in which four different cases are tested in terms of interpretational confounding and external consistency. We find that regardless of whether there is a specification issue, formative measures can lead to misleading outcomes. Based on the results, we offer guidelines that researchers may adopt in planning and executing data analysis with structural equation modeling. Given that the use of formative measurement is at a critical juncture in the IS field, we believe that the guidelines in this research note are important to promote appropriate use of the approach rather than relegate it to a bandwagon effect.
|keyword = Formative measurement,formative indicators,measurement models,measurement instability,external consistency,interpretational confounding,information systems measures,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INTRODUCTION TO THE SPECIAL ISSUE ON NOVEL PERSPECTIVES ON TRUST IN INFORMATION SYSTEMS'''
{{header}}
{{article
|author= Izak Benbasat,David Gefen,Paul A. Pavlou,
|source= MIS QUARTERLY
|year= 2010
|abstract = Research on trust has taken center stage in the MIS field in the past few decades, covering a wide range of trust-related topics based on a multitude of theories from sociology and psychology to economics. To extend this rapidly emerging trend and identify some ground-breaking perspectives on the study of trust, this special issue of the MIS Quarterly on "Novel Perspectives on Trust in Information Systems" aims to explore novel aspects of trust in new and under-researched IS contexts. In brief, the intent of the special issue was to publish innovative research articles about (1) novel ante- cedents of trust, (2) the construct of distrust and its relationship to trust, (3) the boundaries of trust, and (4) the study of trust in new and unexplored MIS contexts (Benbasat et al. 2008).
|keyword = 
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WHAT DOES THE BRAIN TELL US ABOUT TRUST AND DISTRUST? EVIDENCE FROM A FUNCTIONAL NEUROIMAGING STUDY'''
{{header}}
{{article
|author= Angelika Dimoka,
|source= MIS QUARTERLY
|year= 2010
|abstract = Determining whom to trust and whom to distrust is a major decision in impersonal IT-enabled exchanges. Despite the potential role of both trust and distrust in impersonal exchanges, the information systems literature has primarily focused on trust, alas paying relatively little attention to distrust. Given the importance of studying both trust and distrust, this study alms to shed light on the nature, dimensionality, distinction, and relationship, and relative effects of trust and distrust on economic outcomes in the context of impersonal IT-enabled exchanges between buyers and sellers in online marketplaces. This study uses functional neuroimaging (fMRI) tools to complement psychometric measures of trust and distrust by observing the location, timing, and level of brain activity that underlies trust and distrust and their underlying dimensions. The neural correlates of trust and distrust are identified when subjects interact with four experimentally manipulated seller profiles that differ on their level of trust and distrust. The results show that trust and distrust activate different brain areas and have different effects, helping explain why trust and distrust are distinct constructs associated with different neurological processes. Implications for the nature, distinction and relationship, dimensionality, and effects of trust and distrust are discussed.
|keyword = Trust,distrust,neuroIS,price premiums,functional neuroimaging,fMRI,cognitive neuroscience,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ARE THERE NEURAL GENDER DIFFERENCES IN ONLINE TRUST? AN FMRI STUDY ON THE PERCEIVED TRUSTWORTHINESS OF EBAY OFFERS'''
{{header}}
{{article
|author= Rene Riedl,Marco Hubert,Peter Kenning,
|source= MIS QUARTERLY
|year= 2010
|abstract = Research provides increasing evidence that women and men differ in their decisions to trust. However, information systems research does not satisfactorily explain why these gender differences exist. One possible reason is that, surprisingly, theoretical concepts often do not address the most obvious factor that influences human behavior: biology. Given the essential role of biological factors-and specifically those of the brain in decisions to trust, the biological influences should naturally include those related to gender. As trust considerations in economic decision making have become increasingly complex with the expansion of Internet use, understanding the related biological/brain functions and the involvement of gender provides a range of valuable insights. To show empirically that online trust is associated with activity changes in certain brain areas, we used functional magnetic resonance imaging (fMRI). In a laboratory experiment, we captured the brain activity of female and 10 male participants simultaneous to decisions on trustworthiness of eBay offers. We found that most of the brain areas that encode trustworthiness differ between women and men. Moreover, we found that women activated more brain areas than did men. These results confirm the empathizing systemizing theory, which predicts gender differences in neural information processing modes. In demonstrating that perceived trustworthiness of Internet offers is affected by neurobiology, our study has major implications for both IS research and management. We confirm the value of a category of research heretofore neglected in IS research and practice, and argue that future IS research investigating human behavior should consider the role of biological 'actors. In practice, biologicalfactors are a significant consideration.for management, marketing, and engineering attempts to influence behavior.
|keyword = Online trust,trustworthiness,functional magnetic resonance imaging (fMRI),gender,eBay,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IT Careers Camp: An Early Intervention Strategy to Increase IS Enrollments'''
{{header}}
{{article
|author= Vivek Choudhury,Alexandre B. Lopes,Doug Arthur,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = T his paper reports on a specific promotional initiative designed to spur enrollment in IT-related fieldsan IT Careers Camp aimed at high school students. The camp was different from most prior computer camps in that it was not aimed at building skills such as programming or Web development. Rather, it was specifically designed to convince participants that (1) job prospects in the field are strong, and (2) IT/IS work is interesting and creative. To this end, the camp was designed in partnership with a number of corporations, and included as a central element a series of experiential opportunities for participants. Each day of the camp featured a visit to a corporation where the students took part in a hands-on activity that involved solving a business problem with IT. Qualitative and quantitative evaluations indicate that the camp was very successful in changing students' perceptions about the nature of IT work and the IT job market. We believe the camp can be a useful tool to create a pipeline of well-informed students interested in IT careers. We present here details of the design and execution of the camp in the hope that others may wish to replicate our efforts.
|keyword = summer camps,IS enrollments,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''On Evaluating Information Revelation Policies in Procurement Auctions: A Markov Decision Process Approach'''
{{header}}
{{article
|author= Amy Greenwald,Karthik Kannan,Ramayya Krishnan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Each market session in a reverse electronic marketplace features a procurer and many suppliers. An important attribute of a market session chosen by the procurer is its information revelation policy. The revelation policy determines the information (such as the number of competitors, the winning bids, etc.) that will be revealed to participating suppliers at the conclusion of each market session. Suppliers participating in multiple market sessions use strategic bidding and fake their own cost structure to obtain information revealed at the end of each market session. The information helps to reduce two types of uncertainties encountered in future market sessions, namely, their opponents' cost structure and an estimate of the number of their competitors. Whereas the first type of uncertainty is present in physical and e-marketplaces, the second type of uncertainty naturally arises in IT-enabled marketplaces. Through their effect on the uncertainty faced by suppliers, information revelation policies influence the bidding behavior of suppliers which, in turn, determines the expected price paid by the procurer. Therefore, the choice of information revelation policy has important consequences for the procurer. This paper develops a partially observable Markov decision process model of supplier bidding behavior and uses a multiagent e-marketplace simulation to analyze the effect that two commonly used information revelation policies-complete information policy and incomplete information policy-have on the expected price paid by the procurer. We find that the expected price under the complete information policy is lower than that under the incomplete information policy. The integration of ideas from the multiagents literature, the machine-learning literature, and the economics literature to develop a method to evaluate information revelation policies in e-marketplaces is a novel feature of this paper.
|keyword = auctions,information revelation,MDP,game theory simulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Contractual Provisions to Mitigate Holdup: Evidence from Information Technology Outsourcing'''
{{header}}
{{article
|author= Anjana Susarla,Ramanath Subramanyam,Prasanna Karhade,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = T he complexity and scope of outsourced information technology (IT) demands relationship-specific investments from vendors, which, when combined with contract incompleteness, may result in underinvestment and inefficient bargaining, referred to as the holdup problem. Using a unique data set of over 100 IT outsourcing contracts, we examine whether contract extensiveness, i.e., the extent to which firms and vendors can foresee contingencies when designing contracts for outsourced IT services, can alleviate holdup. While extensively detailed contracts are likely to include a greater breadth of activities outsourced to a vendor, task complexity makes it difficult to draft extensive contracts. Furthermore, extensive contracts may still be incomplete with respect to enforcement. We then examine the role of nonprice contractual provisions, contract duration, and extendibility terms, which give firms an option to extend the contract to limit the likelihood of holdup. We also validate the ex post efficiency of contract design choices by examining renewals of contracting agreements.
|keyword = contract duration,extendibility clauses,holdup,underinvestment,information technology outsourcing,incomplete contracts,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Is Query Reuse Potentially Harmful? Anchoring and Adjustment in Adapting Existing Database Queries'''
{{header}}
{{article
|author= Gove Allen,Jeffrey Parsons,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Reusing database queries by adapting them to satisfy new information requests is an attractive strategy for extracting information from databases without involving database specialists. However, the reuse of information systems artifacts has been shown to be susceptible to the phenomenon of anchoring and adjustment. Anchoring often leads to a systematic adjustment bias in which people fail to make sufficient changes to an anchor in response to the needs of a new task. In a study involving 157 novice query writers from six universities, we examined the effect of this phenomenon on the reuse of Structured Query Language (SQL) queries under varying levels of domain familiarity and for different types of anchors. Participants developed SQL queries to respond to four information requests in a familiar domain and four information requests in an unfamiliar domain. For two information requests in each domain, participants were also provided with sample queries (anchors) that answered similar information requests. We found evidence that the opportunity to reuse sample queries resulted in an adjustment bias leading to poorer quality query results and greater overconfidence in the correctness of results. The results also indicate that the strength of the adjustment bias depends on a combination of domain familiarity and type of anchor. This study demonstrates that anchoring and adjustment during query reuse can lead to queries that are less accurate than those written from scratch. We also extend the concept of anchoring and adjustment by distinguishing between surface-structure and deep-structure anchors and by considering the impact of domain familiarity on the adjustment bias.
|keyword = reuse,anchoring and adjustment,SQL,query formulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Use of Pricing Schemes for Differentiating Information Goods'''
{{header}}
{{article
|author= Vidyanand Choudhary,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Information goods vendors offer different pricing schemes such as per user pricing and site licensing. Why do competing sellers adopt different pricing schemes for the same information good? Pricing schemes affect buyers' usage levels and thus the revenue generated from different segments of buyers. This can allow competing firms in a duopoly to differentiate themselves by offering different pricing schemes. Such strategic use of pricing schemes can allow undifferentiated sellers to earn substantial profits in a friction-free market for a commoditized information good. These conditions would otherwise lead to the Bertrand equilibrium and zero profits. We show that adopting asymmetric pricing schemes can be a Nash equilibrium for information goods with negligible marginal cost of production. We extend our model to the case of information goods that are horizontally differentiated and show that sellers will offer a single-pricing scheme that is different from competitors when the sellers are weakly differentiated. When the sellers are strongly differentiated, each seller will offer multiple pricing schemes. We show that it can be optimal for a seller to offer multiple pricing schemes-metered and flat fee pricing schemes, even in the absence of transactions costs.
|keyword = duopoly,price competition,pricing,pricing schemes,information goods,differentiation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Design and Analysis of Contracts for Software Outsourcing'''
{{header}}
{{article
|author= Debabrata Dey,Ming Fan,Conglei Zhang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Outsourcing of software development allows a business to focus on its core competency and take advantage of vendors' technical expertise, economies of scale and scope, and their ability to smooth labor demand fluctuations across several clients. However, contracting a software project to an outside developer is often quite challenging because of information asymmetry and incentive divergence. A typical software development contract must deal with a variety of interrelated issues such as the quality of the developed system, the timeliness of delivery, the effort and cost associated with the project, the contract payment, and the postdelivery software support. This paper presents a contract-theoretic model that incorporates these factors to analyze how software outsourcing contracts can be designed. We find that despite their relative inefficiency, fixed-price contracts are often appropriate for simple software projects that require short development time. Time-and-materials contracts work well for more complex projects when the auditing process is efficient and effective. We also examine a type of performance-based contract called quality-level agreement and find that the first-best solution can be reached with such a contract. Finally, we consider profit-sharing contracts that are useful in situations where the developer has more bargaining power.
|keyword = contract design,software engineering,software outsourcing,performance-based contracts,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Empirical Analysis of Software Vendors' Patch Release Behavior: Impact of Vulnerability Disclosure'''
{{header}}
{{article
|author= Ashish Arora,Ramayya Krishnan,Rahul Telang,Yubao Yang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = A key aspect of better and more secure software is timely patch release by software vendors for the vulnerabilities in their products. Software vulnerability disclosure, which refers to the publication of vulnerability information, has generated intense debate. An important consideration in this debate is the behavior of software vendors. How quickly do vendors patch vulnerabilities and how does disclosure affect patch release time? This paper compiles a unique data set from the Computer Emergency Response Team/Coordination Center (CERT) and SecurityFocus to answer this question. Our results suggest that disclosure accelerates patch release. The instantaneous probability of releasing the patch rises by nearly two and a half times because of disclosure. Open source vendors release patches more quickly than closed source vendors. Vendors are more responsive to more severe vulnerabilities. We also find that vendors respond more slowly to vulnerabilities not disclosed by CERT. We verify our results by using another publicly available data set and find that results are consistent. We also show how our estimates can aid policy makers in their decision making.
|keyword = security vulnerability,disclosure policy,patch release time,open source vendors,information security,software vendors,hazard model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Ex Ante Information and the Design of Keyword Auctions'''
{{header}}
{{article
|author= De Liu,Jianqing Chen,Andrew B. Whinston,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Keyword advertising, including sponsored links and contextual advertising, powers many of today's online information services such as search engines and Internet-based emails. This paper examines the design of keyword auctions, a novel mechanism that keyword advertising providers such as Google and Yahoo! use to allocate advertising slots. In our keyword auction model, advertisers bid their willingness-to-pay per click on their advertisements, and the advertising provider can weight advertisers' bids differently and require different minimum bids based on advertisers' click-generating potential. We study the impact and design of such weighting schemes and minimum-bid policies. We find that weighting scheme determines how advertisers with different click-generating potential match in equilibrium. Minimum bids exclude low-valuation advertisers and at the same time may distort the equilibrium matching. The efficient design of keyword auctions requires weighting advertisers' bids by their expected click-through-rates, and requires the same minimum weighted bids. The revenue-maximizing weighting scheme may or may not favor advertisers with low click-generating potential. The revenue-maximizing minimum-bid policy differs from those prescribed in the standard auction design literature. Keyword auctions that employ the revenue-maximizing weighting scheme and differentiated minimum bid policy can generate higher revenue than standard fixed-payment auctions. We draw managerial implications for pay-per-click and other pay-for-performance auctions and discuss potential applications to other areas.
|keyword = keyword auctions,keyword advertising,sponsored links,weighted unit-price auctions,weighting scheme,Google,Yahoo,minimum bid,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Electronic Markets, Search Costs, and Firm Boundaries'''
{{header}}
{{article
|author= Ramesh Sankaranarayanan,Arun Sundararajan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = We study how interorganizational systems (IOS) such as electronic markets and other enabling information technologies that facilitate broader interfirm transactions affect the extent of outsourcing in firms. We do so by modeling firms in a three-tier value chain consisting of buyers, intermediaries, and suppliers, who can interact using IOS that lower the procurement search costs associated with finding appropriate trading partners. In the context of complex business-to-business (B2B) search, we study how decreasing search costs affect a firm's decision to insource or outsource the procurement function, depending on whether the search process is information intensive or communication intensive. Variation in search costs changes the transaction costs of interaction between firms, as well as the contracting costs associated with outsourcing, owing to changes in the costs of moral hazard for delegated search. We study these effects in a new model that integrates search theory into the principal-agent framework, and establish that the optimal outsourcing contract has a simple "all or nothing" performance-based structure under fairly general assumptions. Our model predicts that when B2B search is information intensive, IOS will facilitate an increase in outsourcing, market-based transactions, and a reduction in the vertical scope of extended enterprises. In contrast, when B2B search is primarily communication intensive, IOS will lead to tighter integration and an increase in the vertical scope of the extended enterprise. Our research suggests that the nature of the information technologies and of the business activities supported by IOS are crucial determinants of the organizational and industry changes they induce, and our results have important implications for a variety of industries in which both technological and agency issues will influence the eventual success of global IT-facilitated extended enterprise initiatives.
|keyword = outsourcing,electronic commerce,interorganizational information systems,electronic markets,economics of IS,information systems and organizational change,IT impacts on industry and market structure,IT-enabled supply chains,IT and new organizational forms,search costs,moral hazard,agency theory,analytical modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Induction over Strategic Agents'''
{{header}}
{{article
|author= Fidan Boylu,Haldun Aytug,Gary J. Koehler,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = W e study the problem where a decision maker needs to discover a classification rule to classify intelligent, self-interested agents. Agents may engage in strategic behavior to alter their characteristics for a favorable classification. We show how the decision maker can induce a classification rule that anticipates such behavior while still satisfying an important risk minimization principle.
|keyword = discriminant analysis,principal-agent,strategic gaming,generalization,adversarial learning,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Quality Uncertainty and the Performance of Online Sponsored Search Markets: An Empirical Investigation'''
{{header}}
{{article
|author= Animesh Animesh,Vandana Ramachandran,Siva Viswanathan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2010
|abstract = Online sponsored search advertising has emerged as the dominant online advertising format largely because of their pay-for-performance nature, wherein advertising expenditures are closely tied to outcomes. While the pay-for-performance format substantially reduces the wastage incurred by advertisers compared to traditional pay-per-exposure advertising formats, the reduction of such wastage also carries the risk of reducing the signaling properties of advertising. Lacking a separating equilibrium, low-quality firms in these markets may be able to mimic the advertising strategies of high-quality firms. This study examines this issue in the context of online sponsored search markets. Using data gathered from sponsored search auctions for keywords in a market without intervention by the intermediary, we find evidence of adverse selection for products/services characterized by high uncertainty. On the other hand, there is no evidence of adverse selection for similar products in a regulated sponsored search market, suggesting that intervention by the search intermediary can have a significant impact on market outcomes and consumer welfare.
|keyword = electronic commerce,competitive impacts of IS,IT impacts on industry and market structure,econometrics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Interdisciplinary Perspective on IT Services Management and Service Science'''
{{header}}
{{article
|author= Indranil R. Bardhan,Haluk Demirkan,P. K. Kannan,Robert J. Kauffman,Ryan Sougstad,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = The increasing importance of information technology (IT) services in the global economy prompts researchers in the field of information systems (IS) to give special attention to the foundations of managerial and technical knowledge in this emerging arena of knowledge. Already we have seen the computer science discipline embrace the challenges of finding new directions in design science toward making services-oriented computing approaches more effective, setting the stage for the development of a new science service science, management, and engineering (SSME). This paper addresses the issues from the point of view of service science as a fundamental area for IS research. We propose a robust framework for evaluating the research on service science, and the likely outcomes and new directions that we expect to see in the coming decade. We emphasize the multiple roles of producers and consumers of services-oriented technology innovations, as well as value-adding seller intermediaries and systems integrators, and standards organizations, user groups, and regulators as monitors. The analysis is cast in multidisciplinary terms, including computer science and IS, economics and finance, marketing, and operations and supply chain management. Evaluating the accomplishments and opportunities for research related to the SSME perspective through a robust framework enables in-depth assessment in the present, as well as an ongoing evaluation of new knowledge in this area, and the advancement of the related management practice capabilities to improve IT services in organizations.
|keyword = cloud computing,economics,IS,IT services,literature survey,marketing,operations,research directions,service science,services management,services-oriented systems,system science,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Connecting IT Services Operations to Services Marketing Practices'''
{{header}}
{{article
|author= Mitzi M. Montoya,Anne P. Massey,Vijay Khatri,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = The importance of building relationships with customers and trust in the services provider is well documented in the marketing literature. Conceptually, we extend this logic to the context of internal information technology (IT) services operations through the notion of the service delivery chain. The purpose of the study is to examine how key service mechanisms in operational IT implementation are related to employee perceptions of actual system benefits and trust in the IT services provider. We report on a study with 380 employees of 14 bank affiliates that were recently acquired by a bank holding company. The focus of the study is on postimplementation trust rather than preimplementation or initial trust, and the service provider is viewed as the object of trust rather than the technology. Our findings suggest that training, trial, and social influence are key service mechanisms an IT services provider can use to stimulate trust in the IT services provider and the realization of system benefits.
|keyword = IT services,mandated systems,relational trust,service delivery chain,service mechanisms,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Multitask Agency, Modular Architecture, and Task Disaggregation in SaaS'''
{{header}}
{{article
|author= Anjana Susarla,Anitesh Barua,Andrew B. Whinston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = We examine contract choices in the provision of "software-as-a-service" (SaaS), which is a business innovation that transforms information technology (IT) resources into a continuously provided service. We draw upon agency theory and modularity theory to propose that one of the central challenges in service disaggregation is that of knowledge interdependencies across client and provider organizations. The resulting lack of verifiability of certain tasks results in a multitask agency problem. Our key research questions involve (1) the suitability of high- versus low-powered incentives in SaaS contracts when the outsourced tasks involve business analytics that are difficult to verify, and (2) how such contract choices are affected by the modularity of interfaces between the client and the provider. Analysis of data collected from 154 providers of SaaS offering a range of IT services supports our contention that when contracting for business analytics characterized by knowledge interdependencies across clients and providers, incentives should be "low powered." Modularity in the interfaces of the service provider increases the desirability of high-powered incentives in such situations. Our results are robust after accounting for endogeneity issues arising from unobserved matching between service providers and the nature of IT services outsourced by clients. With the increasing importance of information systems in services, this paper suggests that arm's-length relationships and high-powered incentives may be ineffective in incentivizing providers to perform on complex business analytic tasks, unless accompanied by the modularization of interfaces.
|keyword = endogenous matching,information technology,modularity,multitask agency,outsourcing,service science,services,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Coordination Strategies in an SaaS Supply Chain'''
{{header}}
{{article
|author= Haluk Demirkan,Hsing Kenneth Cheng,Subhajyoti Bandyopadhyay,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = The computing industry is gradually evolving to cater to the demand for software-as-a-service (SaaS). Two core competencies that have emerged over the past few years are that of the application service providers (ASPs) and the application infrastructure providers (AIPs). The arrangements between them result in system dynamics that is typical in supply chain networks. We examine the performance of an SaaS set up under different coordination strategies between these two players. Our analysis indicates that coordination between the monopoly ASP and the AIP can result in an outcome with the same overall surplus as can be achieved by a central planner. Even though the players have an incentive to deviate, it is possible to create the right incentives so that the economically efficient outcome is also the Nash equilibrium. The results of the analysis have significant implications for the coordination strategies for providers in the burgeoning business model of delivering software services over the Internet.
|keyword = cloud computing,economic analysis,information sharing,infrastructure-as-a-service,service science,services,services management,software-as-a-service,strategy,supply chain coordination,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding the Economic Potential of Service-Oriented Architecture'''
{{header}}
{{article
|author= Benjamin Mueller,Goetz Viering,Christine Legner,Gerold Riempp,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Service-oriented architecture (SOA) is one of the most discussed topics in the information systems (IS) discipline. While most computer scientists agree that the service-oriented paradigm has clear benefits in terms of technical quality attributes, it has been difficult to justify SOA economically. The few studies that have investigated the strategic and economic aspects of SOA are mostly exploratory and lack a more comprehensive framework for understanding the sources of its economic potential. Based on IS and SOA literature, our work goes further in suggesting the SOA economic potential model, which describes the causal relationships between the SOA's style characteristics and value it can provide on the business side. Using this model, we investigate 164 SOA cases published between 2003 and 2008 to explore the economic rationale for adopting SOA. Our findings suggest that SOA's business benefits are currently mainly driven by operational and information technology infrastructural improvements. However, enterprises also realize strategic benefits from SOA; for example, by electronically integrating with their business partners by means of SOA. We use the results of our study to derive propositions and suggest a research model for future studies on SOA's economic potential.
|keyword = business benefits,economic potential,IS value,service-oriented architecture,service science,services,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Managers' Judgments of Performance in IT Services Outsourcing'''
{{header}}
{{article
|author= Vandana Ramachandran,Anandasivam Gopal,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = An important task for managers in information technology (IT) service settings is the judgment of service performance. The complex and intangible nature of IT services, however, renders this task especially difficult. We use a sample of 85 outsourced software development projects to test for the presence of the "input bias," which is defined as the systematic misuse of nondiagnostic input information in forming managerial judgments of outcomes. The service outcome we examine is process performance. The diagnostic inputs are given by objective performance metrics based on the final cost and duration of completed projects, whereas the nondiagnostic inputs are risk anticipations formed by managers prior to the start of the project. We find strong evidence of the input bias, which leads managers' subjective assessments to diverge considerably from objective outcomes, and that it is moderated by contract type. Our study contributes to better service management by improving our understanding of managers' judgments of service performance and how these judgments are formed.
|keyword = decision-making biases,field studies,input bias,IT services outsourcing,judgment,regression analysis,service science,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Service Science Perspective on Strategic Choice, IT, and Performance in US Banking'''
{{header}}
{{article
|author= Paul P. Tallon,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = With the move to an information-based economy, financial services has become a key contributor to the U.S. gross domestic product. Even as consolidation reduces the number of banks, small banks with under $100 million in assets continue to report higher profit margins than large banks with over $100 million in assets. Lacking scale, small banks employ a service-oriented business strategy (customer intimacy), whereas large banks focus on productivity and throughput (operational excellence). Information technology (IT) plays a key role in applying each strategy, but as banks move toward customer intimacy in general, the challenge is to grow without undermining service quality. Using a balanced panel data set from 43 U.S. banks, this paper finds that banking strategies are becoming more customer focused. Yet for large banks in particular, IT remains resolutely operations focused. This misalignment could restrict future banking performance. In this way, this paper contributes to the service science literature by using size to dissect banking strategies and performance.
|keyword = banking,business value,customer intimacy,financial services,relationship banking,service science,services,strategic alignment,strategic choice,value disciplines,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Implementing Service-Oriented Architecture in Organizations'''
{{header}}
{{article
|author= Jae Choi,Derek L. Nazareth,Hemant K. Jain,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = Service-oriented architecture (SOA) has been promoted as a technology that can enhance information systems agility, interoperability between applications, deployment flexibility, and reusability. As with any new information technology (IT), the decision to adopt SOA cannot be taken lightly, given the nontrivial investment in economic and personnel resources. The complexity associated with industry-wide diffusion, coupled with organization, industry, and environment factors, contributes to a lack of a clear strategy for assessing the business value that SOA provides an organization. This research attempts to shed light on this process of value creation for an organization, using a system dynamics approach. A detailed model of the industry diffusion coupled with organization adoption is presented. After suitable calibration and validation, a series of simulations using the model evaluate the efficacy of SOA under a variety of diverse conditions. The results of the simulations indicate clear benefits of SOA over monolithic ITs when employed under appropriate conditions. Situations where SOA fails to live up to expectations are also identified. The model and accompanying simulations can serve as a practical decision support tool for an organization to help make the strategic decisions of adopting and implementing SOA.
|keyword = adoption,design science,service-oriented architecture,service science,services,system dynamics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Demand Information Sharing in Heterogeneous IT Services Environments'''
{{header}}
{{article
|author= Sagnika Sen,T. S. Raghu,Ajay Vinze,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = In an information technology services outsourcing arrangement, variance in demand volume and individual user preferences pose significant challenges to the provider organization in making resource allocation decisions. Such variations affect service levels, especially under fixed resource constraints. We explore the possible role of periodic demand information sharing and subsequent resource-level adjustments as a means of addressing issues arising from demand variation. As information exchange alters the dynamics of the relationship between the customer and provider organizations, incorporating information sharing in service-level agreements requires modifying current pricing schemes. A pricing heuristic is developed and tested under varying levels of information accuracy and granularity. The heuristic is shown to provide better economic welfare for both participants in comparison to the baseline pricing strategies considered. Also, it is shown that information, even at a coarse level of granularity, is very effective in providing stable service levels a finding that is encouraging for enhanced collaborations between customer and provider organizations in outsourcing arrangements.
|keyword = heterogeneous demand,information sharing,IT services,pricing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Should We Go Our Own Way? Backsourcing Flexibility in IT Services Contracts'''
{{header}}
{{article
|author= Michel Benaroch,Qizhi Dai,Robert J. Kauffman,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2010
|abstract = The emergence of new service science approaches to business problems in information technology (IT) services offers new, unusually relevant insights for the senior management of vendors in this business area. This research examines how service-level agreement contract flexibility should be designed when the technological and business market environments result in volatility of demand, based on an understanding of related changes in the cost drivers that underlie IT services contracts. Our approach draws on a blend of well-known methods from financial economics the real option pricing method and the contingent claims analysis method. In particular, our research examines a setting in which a vendor provides IT services to a client according to a prenegotiated IT services contract in the presence of demand volatility. We analyze the motivation of and value consequences for a vendor that offers the client the flexibility to opt out of the contract. For example, the client might switch to another vendor, or backsource and provide its own services internally. Our core results offer important foundational thinking for how to specify various forms of IT service-related flexibility in terms of put and call options from the point of view of an IT services vendor, so that their value and exercise timing can be estimated. We show that the client firm's demand trigger value for deciding when to backsource its IT services varies, and it depends on the degree of demand volatility as well as the usage-based fees charged by the vendor. Working from our modeling approach, we also are able to characterize the extent to which a vendor can benefit from bearing the costs of making a backsourcing flexibility option available to its client.
|keyword = contingent claims analysis,demand trigger value,demand uncertainty,financial economics,IT services,outsourcing,real options,service science,valuation,vendors,volatility,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION SYSTEMS INNOVATION FOR ENVIRONMENTAL SUSTAINABILITY'''
{{header}}
{{article
|author= Nigel P. Melville,
|source= MIS QUARTERLY
|year= 2010
|abstract = Human life, is dependent upon the natural environment, which, most would agree, is rapidly degrading. Business enterprises are a dominant form of social organization and contribute to the worsening, and enhancement, of the natural environment. Scholars in the administrative sciences examine questions spanning organizations and the natural environment but have largely omitted the information systems perspective. We develop a research agenda on information systems innovation for environmental sustainability that demonstrates the critical role that is can play in shaping beliefs about the environment, in enabling and transforming sustainable processes and practices in organizations, and in improving environmental and economic performance. The belief-action-outcome (BAO) framework and associated research agenda provide the basis for a new discourse on IS for environmental sustainability.
|keyword = Belief-action-outcome (BAO) framework,environment,environmental management system,green,information system,innovation,organization,sustainability,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION SYSTEMS AND ENVIRONMENTALLY SUSTAINABLE DEVELOPMENT: ENERGY INFORMATICS AND NEW DIRECTIONS FOR THE IS COMMUNITY'''
{{header}}
{{article
|author= Richard T. Watson,Marie-Claude Boudreau,Adela J. Chen,
|source= MIS QUARTERLY
|year= 2010
|abstract = While many corporations and Information Systems units recognize that environmental sustainability is an urgent problem to address, the IS academic community has been slow to acknowledge the problem and take action. We propose ways for the IS community to engage in the development of environmentally sustainable business practices. Specifially. as IS researchers, educators, journal editors, and association leaders, we need to demonstrate how the transformative power of IS can be leveraged to create an ecologically sustainable society. In this Issues and Opinions piece. we advocate a research agenda to establish a new subfield of energy informatics, which applies information systems thinking and skills to increase energy efficiency. We also articulate how IS scholars can incorporate environmental sustainability as an underlying foundation in their teaching, and how IS leaders can embrace environmental sustainability in their core principles and foster changes that reduce the environmental impact of our community.
|keyword = Environmental sustainability,energy informatics,IS community,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AN EMPIRICAL ANALYSIS OF THE IMPACT OF INFORMATION CAPABILITIES DESIGN ON BUSINESS PROCESS OUTSOURCING PERFORMANCE'''
{{header}}
{{article
|author= Deepa Mani,Anitesh Barua,Andrew Whinston,
|source= MIS QUARTERLY
|year= 2010
|abstract = Organizations today outsource diverse business processes to achieve a wide variety of business objectives ranging from reduction of costs to innovation and business tran formation. We build on the information processing view of the firm to theorize that performance heterogeneity across business process outsourcing (BPO) exchanges is a function of the design of information capabilities (IC) that fit the unique information requirement (IR) of the exchange. Further, we compare performance effects of the fit between IR and IC across dominant categories of BPO relationships to provide insights into the relative benefits of enacting such fit between the constructs. Empirical tests of our hypotheses using survey data on 127 active BPO relationships find a significant increase (decrease) in satisfaction as a result of the fit (misfit) between IR and IC of the relationship. The results have implications for how BPO relationships must be designed and managed to realize significant performance gains. The study also extends the IPV to identify IC that provide the incentives and means to process information in an interfirm relationship.
|keyword = Business process outsourcing,governance,performance,information requirements,information capabilities,information processing view,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CHASING THE HOTTEST IT: EFFECTS OF INFORMATION TECHNOLOGY FASHION ON ORGANIZATIONS'''
{{header}}
{{article
|author= Ping Wang,
|source= MIS QUARTERLY
|year= 2010
|abstract = What happens to organizations that chase the hottest information technologies? This study examines some of the important organizational impacts of the fashion phenomenon in IT. An IT fashion is a transitory collective belief that an information technology is new, efficient, and at the forefront of practice. Using data collected from published discourse and annual IT budgets of 109 large companies for a decade, I have found that firms whose names were associated with IT fashions in the press did not have higher performance, but they had better reputation and higher executive compensation in the near term. Companies investing in IT in fashion also had higher reputation and executive pay but they had lower performance in the short term and then improved performance in the long term. These results support a fashion explanation for the middle phase diffusion of IT innovations, illustrating that following fashion can legitimize organizations and their leaders regardless of performance improvement. the findings also extend institutional theory from its usual focus on taken-for-granted practices to fashion as a novel source of social approval. This study suggests that practitioners balance between performance pressure and social approval when they confront whatever is hottest in IT.
|keyword = Information technology fashion,management fashion,innovation,diffusion,discourse,corporate reputation,executive compensation,legitimacy,performance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TOWARD AGILE: AN INTEGRATED ANALYSIS OF QUANTITATIVE AND QUALITATIVE FIELD DATA ON SOFTWARE DEVELOPMENT AGILITY'''
{{header}}
{{article
|author= Gwanhoo Lee,Weidong Xia,
|source= MIS QUARTERLY
|year= 2010
|abstract = As business and technology environments change at an unprecedented rate, software development agility to respond to changing user requirements has become increasingly critical for software development performance. Agile software development approaches, which emphasize sense-and-respond, self-organization, cross-functional teams, and continuous adaptation, have been adopted by an increasing number of organizations to improve their software development agility. However, the agile development literature is largely anecdotal and prescriptive, lacking empirical evidence and theoretical foundation to support the principles and practices of agile development. Little research has empirically examined the software development agility construct in terms of its dimensions, determinants, and effects on software development performance. As a result, there is a lack of understanding about how organizations can effectively implement an agile development approach. Using an integrated research approach that combines quantitative and qualitative data analyses, this research opens the black box of agile development by empirically examining the relationships among two dimensions of software development agility (software team response extensiveness and software team response efficiency), two antecedents that can be con trolled (team autonomy and team diversity), and three aspects of software development performance (on-time completion, on-budget completion, and software functionality). Our PLS results of survey, responses of 399 software project managers suggest that the relationships among these variables are more complex than what has been perceived by the literature. The results suggest a tradeoff relationship between response extensiveness and response efficiency. These two agility dimensions impact software development performance differently: response efficiency positively affects all of on-time completion, on-budget completion, and software functionality, whereas response extensiveness positively affects only software functionality. The results also suggest that team autonomy has a positive effect on response efficiency and a negative effect on response extensiveness, and that team diversity has a positive effect on response extensiveness, We conducted 10 post hoc case studies to qualitatively cross-validate our PLS results and provide rich, additional insights regarding the complex, dynamic interplays between autonomy, diversity, agility, and performance. The qualitative analysis also provides explanations for both supported and unsupported hypotheses. We discuss these qualitative analysis results and conclude with the theoretical and practical implications of our research findings for agile development approaches.
|keyword = Software development agility,agile software development,team autonomy,team diversity,software development performance,requirement change,partial least square,case study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''VITAL SIGNS FOR VIRTUAL TEAMS: AN EMPIRICALLY DEVELOPED TRIGGER MODEL FOR TECHNOLOGY ADAPTATION INTERVENTIONS'''
{{header}}
{{article
|author= Dominic M. Thomas,Robert P. Bostrom,
|source= MIS QUARTERLY
|year= 2010
|abstract = This study explores how team leaders sense the need for technology adaptation intervention in distributed, computer mediated ("virtual') teams. Analysis and coding of critical incident data collected in interviews of practicing leaders produce a five-trigger model including (1) external constraint, (2) internal constraint, (3) information and communication technology (ICT) inadequacy, (4) ICT knowledge, skills, and abilities inadequacy, and (5) trust and relationship inadequacies. The resulting five-trigger model provides several key contributions including (1) a diagnostic tool for examining real, multi-trigger team technology, adaptation contexts, enabling better leader training and evaluation as well as improved research on team technology adaptation and interventions and (2) a better understanding of the relationship between the technology structure strength indicators in adaptive structuration theory and the need for team technology adaptation intervention.
|keyword = Virtual teams,leadership,project management,IS development teams,empirical research,critical incident technique,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''JOB CHARACTERISTICS AND JOB SATISFACTION: UNDERSTANDING THE ROLE OF ENTERPRISE RESOURCE PLANNING SYSTEM IMPLEMENTATION'''
{{header}}
{{article
|author= Michael G. Morris,Viswanath Venkatesh,
|source= MIS QUARTERLY
|year= 2010
|abstract = Little research has examined the impacts of enterprise resource planning (ERP) systems implementation on job satisfaction. Based on a 12-month study of 2,794 employees in a telecommunications firm, we found that ERP system implementation moderated the relationships between three job characteristics (skill variety, autonomy, and feedback) and job satisfaction. Our findings highlight the key role that ERP system implementation can have in altering well established relationships in the context of technology-enabled organizational change situations. This work also extends research on technology diffusion by moving beyond a focus on technology-centric outcomes, such as system use, to understanding broader job outcomes.
|keyword = ERP systems,job characteristics,job satisfaction,technology adoption,system implementation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE FORMATION AND VALUE OF IT-ENABLED RESOURCES: ANTECEDENTS AND CONSEQUENCES OF SYNERGISTIC RELATIONSHIPS'''
{{header}}
{{article
|author= Saggi Nevo,Michael R. Wade,
|source= MIS QUARTERLY
|year= 2010
|abstract = This paper informs the literature on the business value of information technology by conceptualizing a path from IT assets-that is, commodity-like or off-the-shelf information technologies-to, sustainable competitive advantage. This path suggests that IT assets can play a strategic role when they are combined with organizational resources to create IT-enabled resources. To the extent that relationships between IT assets and organizational resources are synergistic, the ensuing IT-enabled resources are capable of positively affecting firms' sustainable competitive advantage via their improved strategic potential. This is an important contribution since IT-related organizational benefits have been hard to demonstrate despite attempts to study them through a variety of methods and theoretical lenses. This paper synthesizes systems theory and the resource-based view of the firm to build a unified conceptual model linking IT assets with firm-level benefits. Several propositions are derived from the model and their implications for IS research and practice are discussed.
|keyword = Business value of IT,systems theory,resource-based view of the firm,IT-enabled resources,emergent capabilities,synergy,strategic potential,compatibility,integration effort,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WHAT MAKES A HELPFUL ONLINE REVIEW? A STUDY OF CUSTOMER REVIEWS ON AMAZON.COM'''
{{header}}
{{article
|author= Susan M. Mudambi,David Schuff,
|source= MIS QUARTERLY
|year= 2010
|abstract = Customer reviews are increasingly available online for a wide range of products and services. They supplement other information provided by electronic storefronts such as product descriptions, reviews from experts, and personalized advice generated by automated recommendation systems. While researchers have demonstrated the benefits of the presence of customer reviews to an online retailer, a largely uninvestigated issue is what makes customer reviews helpful to a consumer in the process of making a purchase decision. Drawing on the paradigm of search and experience goods from information economics, we develop and test a model of customer review helpfulness. An analysis of 1,587 reviews from Amazon.com across six products indicated that review extremity, review depth, and product type affect the perceived helpfulness of the review. Product type moderates the effect of revieiv extremity on the helpfulness of the review. For experience goods, reviews with extreme ratings are less helpful than reviews with moderate ratings. For both product types, review depth has a positive effect on the helpfulness of the review, but the product type moderates the effect of review depth on the helpfulness of the revieiv. Review depth has a greater positive effect on the helpfulness of the review for search goods than for experience goods. We discuss the implications of our findings for both theory and practice.
|keyword = Electronic commerce,product reviews,search and experience goods,consumer behavior,information economics,diagnosticity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AMBIENT AWARENESS AND KNOWLEDGE ACQUISITION: USING SOCIAL MEDIA TO LEARN "WHO KNOWS WHAT" AND "WHO KNOWS WHOM"'''
{{header}}
{{article
|author= Paul M. Leonardi,
|source= MIS QUARTERLY
|year= 2015
|abstract = The argument proffered in this paper is that use of enterprise social networking technologies can increase the accuracy of people's metaknowledge (knowledge of "who knows what" and "who knows whom") at work. The results of a quasi-natural field experiment in which only one of two matched-sample groups within a large financial services firm was given access to the enterprise social networking technology for six months revealed that by making people's communications with specific partners visible to others in the organization, the technology enabled observers to become aware of the communications occurring amongst their coworkers and to make inferences about what and whom those coworkers knew based on the contents of the messages they sent and to whom they were sent. Consequently only individuals in the group that used the social networking technology for six months improved the accuracy of their metaknowledge (a 31% improvement in knowledge of who knows what and an 88% improvement in knowledge of who knows whom). There were no improvements in the other group over the same time period. Based on these findings, how technologically enabled "ambient awareness"-awareness of ambient communications occurring amongst others in the organization-can be an important antecedent for knowledge acquisition is discussed.
|keyword = Social networking sites,knowledge sharing,organizational learning,accuracy,technology use,communication,collaboration,transparency,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WORK HARDER OR WORK SMARTER? INFORMATION TECHNOLOGY AND RESOURCE ALLOCATION IN HEALTHCARE PROCESSES'''
{{header}}
{{article
|author= Adrian Yeow,Kim Huat Goh,
|source= MIS QUARTERLY
|year= 2015
|abstract = While the impacts of health information technology (HIT) are widely studied, prior research presents mixed findings. In this study, a granular examination of the impact of HIT systems on how resources are allocated to healthcare tasks and processes was undertaken. A longitudinal field study that combined interview, archival, observation, and survey data was conducted. The effects of telemedicine on the input allocative efficiency of the healthcare process through the reallocation of organizational resources was evaluated and an assessment of whether gains in allocative efficiency resulted in improvements in organizational outcomes, such as lower hospitalization rates and lower uncertainty in patient wait time, was conducted. Applying the theory of swift and even flow, our findings suggest that the gains in allocative efficiency for some processes are associated with improved organizational outcomes.
|keyword = Healthcare,IT,telemedicine,stochastic frontier analysis,resource allocations,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''SOFTWARE PROCESS DIVERSITY: CONCEPTUALIZATION, MEASUREMENT, AND ANALYSIS OF IMPACT ON PROJECT PERFORMANCE'''
{{header}}
{{article
|author= Narayan Ramasubbu,Anandhi Bharadwaj,Giri Kumar Tayi,
|source= MIS QUARTERLY
|year= 2015
|abstract = This article investigates software process diversity, defined as the project condition arising out of the simultaneous use of multiple software development process frameworks within a single project. Software process diversity is conceptualized as the response of a project team to such contingencies as requirements volatility, design and technological novelty, customer involvement, and the level of organizational process compliance enforced on the project. Moreover, we conceptualize that the degree of fit (or match) between a project's software process diversity and the level of process compliance enforced on the project impacts overall project performance. This conceptualization was empirically tested by utilizing data collected from 410 large commercial software projects of a multinational firm. The results show that higher levels of requirements volatility, design and technological novelty, and customer involvement increased software process diversity within a project. However, software process diversity decreased relative to increases in the level of process compliance enforced on the project. A higher degree of fit between the process diversity and process compliance of a project, rather than the effects of those variables independently, was found to be significantly associated with a higher level of project performance, as measured in terms of project productivity and software quality. These results indicate that increasing software process diversity in response to project-level contingencies improves project performance only when there is a concomitant increase in organizational process compliance efforts. The implications of these results for research are discussed and prescriptive guidelines derived to manage the fit between process diversity and process compliance for improving software project performance.
|keyword = Software process diversity,process compliance,plan-based processes,agile processes,software engineering,productivity,quality,fit as matching,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION TECHNOLOGY IMPACTS ON FIRM PERFORMANCE: AN EXTENSION OF KOHLI AND DEVARAJ (2003)'''
{{header}}
{{article
|author= Rajiv Sabherwal,Anand Jeyaraj,
|source= MIS QUARTERLY
|year= 2015
|abstract = Despite the importance of investing in information technology, research on business value of information technology (BVIT) shows contradictory results, raising questions about the reasons for divergence. Kohli and Devaraj (2003) provided valuable insights into this issue based on a meta-analysis of 66 BVIT studies. This paper extends Kohli and Devaraj by examining the influences on BVIT through a meta-analysis of 303 studies published between 1990 and 2013. We found that BVIT increases when the study does not consider IT investment, does not use profitability measure of value, and employs primary data sources, fewer IT-related antecedents, and larger sample size. Considerations of IT alignment, IT adoption and use, and interorganizational IT strengthen the relationship between IT investment on BVIT, whereas the focus on environmental theories dampens the same relationship. However, the use of productivity measures of value, the number of dependent variables, the economic region, the consideration of IT assets and IT infrastructure or capability, and the consideration of IT sophistication do not affect BVIT. Finally, BVIT increases over time with IT progress. Implications for future research and practice are discussed.
|keyword = Information technology,business value of information technology,firm performance,meta-analysis,investment,payoff,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WHAT DO SYSTEMS USERS HAVE TO FEAR? USING FEAR APPEALS TO ENGENDER THREATS AND FEAR THAT MOTIVATE PROTECTIVE SECURITY BEHAVIORS'''
{{header}}
{{article
|author= Scott R. Boss,Dennis F. Galletta,Paul Benjamin Lowry,Gregory D. Moody,Peter Polak,
|source= MIS QUARTERLY
|year= 2015
|abstract = Because violations of information security (ISec) and privacy have become ubiquitous in both personal and work environments, academic attention to ISec and privacy has taken on paramount importance. Consequently, a key focus of ISec research has been discovering ways to motivate individuals to engage in more secure behaviors. Over time, the protection motivation theory (PMT) has become a leading theoretical foundation used in ISec research to help motivate individuals to change their security-related behaviors to protect themselves and their organizations. Our careful review of the foundation for PMT identified four opportunities for improving ISec PMT research. First, extant ISec studies do not use the full nomology of PMT constructs. Second, only one study uses fear-appeal manipulations, even though these are a core element of PMT. Third, virtually no ISec study models or measures fear. Fourth, whereas these studies have made excellent progress in predicting security intentions, none of them have addressed actual security behaviors. This artticle describes the theoretical foundation of these four opportunities for improvement. We tested the nomology of PMT, including manipulated fear appeals, in two different ISec contexts that model the modern theoretical treatment of PMT more closely than do extant ISec studies. The first data collection was a longitudinal study in the context of data backups. The second study was a short-term cross-sectional study in the context of anti-malware software. Our new model demonstrated better results and stronger fit than the existing models and confirms the efficacy of the four potential improvements we identified.
|keyword = Information security,protection motivation theory,system backups,model comparison,fear appeals,threat,coping,intentions,behavior,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''FIT AND MISFIT OF PLURAL SOURCING STRATEGIES AND IT-ENABLED PROCESS INTEGRATION CAPABILITIES: CONSEQUENCES OF FIRM PERFORMANCE IN THE US ELECTRIC UTILITY INDUSTRY'''
{{header}}
{{article
|author= Arun Rai,Ilgaz Arikan,Jessica Pye,Amrit Tiwana,
|source= MIS QUARTERLY
|year= 2015
|abstract = Recent work has shown that a firm's plural sourcing strategy, which determines how much it chooses to make versus how much it chooses to buy, requires consideration of the complementarities and constraints that affect the differential advantages of making and buying. Elaborating on this perspective, we theorize how (mis)fit between a firm's plural sourcing strategy of simultaneously making and buying and its development of information technology (IT) enabled interfirm and intrafirm process integration capabilities influences firm performance in deregulated markets. We position our theory development and empirical tests in the context of the power-generation segment of the U.S. electric utility industry (EUI), an asset-intensive industry that has been deregulated to promote the separation of key value chain activities (i.e., generation, transmission, and distribution) and the development of wholesale energy markets. We draw on the transaction cost economics, coordination costs, and IT capabilities perspectives to theorize that a firm achieves fit (realizing performance benefits) by increasing market sourcing intensity (MSI)-or, how much it buys relative to how much it makes- and developing IT-enabled interfirm process integration capability for external coordination with the market, or misfit (realizing performance penalties) by increasing MSI and developing IT-enabled intrafirm process integration capability for coordinating internal production. We collated data from archival sources for 342 utility firms in the power-generation segment to construct a panel dataset for the period 1994-2004 on (1) firms' MSI from wholesale electricity markets, (2) firms' IT investment decisions to develop interfirm and intrafirm process integration capabilities, (3) measures of firm performance, and (4) several control variables related to exogenous shocks (i.e., regulatory change, oil crisis), region of operation, and firm-level factors. Our results suggest that fit between MSI and the development of IT-enabled interfirm process integration capability improves firm profitability, assessed by return on assets, and misfit between MSI and the development of IT-enabled intrafirm process integration capability extracts penalties in firm profitability. We also find evidence that fit between MSI and the development of IT-enabled interfirm process integration capability improves market valuation, assessed by Tobin's Q, and asset turnover, assessed by operating revenue/total assets. We discuss the implications of our findings for the development of IT capabilities to accompany a firm's plural sourcing strategy and the literature on IT business value.
|keyword = Plural sourcing,market sourcing intensity,IT-enabled process integration,IT capabilities,firm performance,IT business value,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''STRIKE A HAPPY MEDIUM: THE EFFECT OF IT KNOWLEDGE ON VENTURE CAPITALISTS' OVERCONFIDENCE IN IT INVESTMENTS'''
{{header}}
{{article
|author= Harpreet Singh,Rohit Aggarwal,Irina Cojuharenco,
|source= MIS QUARTERLY
|year= 2015
|abstract = In this article, the effect of IT knowledge on the overconfidence of venture capitalists (VCs) in their IT investments is examined. Our findings show that the effect of IT knowledge on overconfidence is nonlinear. VCs with moderate levels of IT knowledge are least overconfident. At the same time, VCs with moderate levels of IT knowledge are most resistant to the biasing effects of past successes. Past failures show a negative association with overconfidence independent of the level of the VC's IT knowledge. Finally, the negative association between stakes and VC overconfidence is stronger with greater levels of IT knowledge. These results shed light on the highly disputed role of IT knowledge in the domain of IT investments.
|keyword = IT knowledge,overconfidence,IT startups,IT investments,venture capital,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CAMPUS EMERGENCY NOTIFICATION SYSTEMS: AN EXAMINATION OF FACTORS AFFECTING COMPLIANCE WITH ALERTS'''
{{header}}
{{article
|author= Wencui Han,Serkan Ada,Raj Sharman,H. Raghav Rao,
|source= MIS QUARTERLY
|year= 2015
|abstract = The increasing number of campus-related emergency incidents, in combination with the requirements imposed by the Clery Act, have prompted college campuses to develop emergency notification systems to inform community members of extreme events that may affect them. Merely deploying emergency notification systems on college campuses, however, does not guarantee that these systems will be effective; student compliance plays a very important role in establishing such effectiveness. Immediate compliance with alerts, as opposed to delayed compliance or noncompliance, is a key factor in improving student safety on campuses. This paper investigates the critical antecedents that motivate students to comply immediately with messages from campus emergency notification systems. Drawing on Etzioni's compliance theory, a model is developed. Using a scenario-based survey method, the model is tested in five types of events-snowstorm, active shooter, building fire, health-related, and robbery-and with more than 800 college students from the Northern region of the United States. The results from this study suggest that subjective norm and information quality trust are, in general, the most important factors that promote immediate compliance. This research contributes to the literature on compliance, emergency notification systems, and emergency response policies.
|keyword = Compliance,campus alerts,emergency notification systems,information quality trust,scenario-based survey,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ME, MY SELF, AND I(T): CONCEPTUALIZING INFORMATION TECHNOLOGY IDENTITY AND ITS IMPLICATIONS'''
{{header}}
{{article
|author= Michelle Carter,Varun Grover,
|source= MIS QUARTERLY
|year= 2015
|abstract = As social roles and relationships become increasingly inseparable from people's interactions with information technologies (ITs), new constructs representing this intertwinement are needed to expand understandings of human behavior. As part of that endeavor, this paper draws on structural symbolic interactionist identity theories to systematically develop a conceptual definition of one such construct, IT identity-defined as the extent to which an individual views use of an IT as integral to his or her sense of self-as a new form of identity. The construct is framed within a theoretical model. Our goal is to facilitate the establishment of IT identity as an important and relevant construct that can improve our understanding of a variety of phenomena. In doing so, this paper makes three contributions to the information systems (IS) literature. First, it delineates current understanding of IT as a medium, determinant, or consequent of identity. Second, it defines the conceptual domain and theme of IT identity, which is necessary for investigating the construct's theoretical influence. Third, it demonstrates the utility of IT identity to a wide range of IS topics relating to how people express, maintain, and expand their self-concepts. In doing so, it offers potential directions and opportunities for IS researchers to incorporate this novel concept into IS research.
|keyword = IT identity,human behavior,individual IT use,IT embeddedness,theory development,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CULTURAL SENSEMAKING IN OFFSHORE INFORMATION TECHNOLOGY SERVICE SUPPLIERS: A CULTURAL FRAME PERSPECTIVE'''
{{header}}
{{article
|author= Ning Su,
|source= MIS QUARTERLY
|year= 2015
|abstract = In today's global IT outsourcing relationships, individual employees need to operate effectively in culturally diverse environments. Such intercultural interactions can be especially challenging for members of IT service suppliers based in offshore locations. Through an in-depth qualitative case study of one of the largest China-based IT service firms with diverse clients from Japan, the United States, and China, this research elaborates the cultural sensemaking activities of the supplier's individual employees. Specifically, drawing on the dynamic constructivist view of culture, this study develops the construct of "cultural frames" in the context of global IT outsourcing to characterize the knowledge structures guiding an individual's collaboration with diverse clients. A portfolio of cultural frames emerges and evolves through the individual's cultural sensemaking activities, which consist of the iterative enactment, alignment, and retention of cultural frames. In the cultural sensemaking process, the activity of frame bridging, in particular, creates significant value for the outsourcing relationship, and is especially salient among bicultural employees.
|keyword = IT outsourcing,IT supplier,cultural sensemaking,cultural frame,China,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Informing Privacy Research Through Information Systems, Psychology, and Behavioral Economics: Thinking Outside the "APCO" Box'''
{{header}}
{{article
|author= Tamara Dinev,Allen R. McConnell,H. Jeff Smith,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Recently, several researchers provided overarching macromodels to explain individuals' privacy-related decision making. These macromodels-and almost all of the published privacy-related information systems (IS) studies to date-rely on a covert assumption: responses to external stimuli result in deliberate analyses, which lead to fully informed privacy-related attitudes and behaviors. The most expansive of these macromodels, labeled "Antecedents- Privacy Concerns-Outcomes" (APCO), reflects this assumption. However, an emerging stream of IS research demonstrates the importance of considering principles from behavioral economics (such as biases and bounded rationality) and psychology (such as the elaboration likelihood model) that also affect privacy decisions. We propose an enhanced APCO model and a set of related propositions that consider both deliberative (high-effort) cognitive responses (the only responses considered in the original APCO model) and low-effort cognitive responses inspired by frameworks and theories in behavioral economics and psychology. These propositions offer explanations of many behaviors that complement those offered by extant IS privacy macromodels and the information privacy literature stream. We discuss the implications for research that follow from this expansion of the existing macromodels.
|keyword = privacy,macromodels,elaboration likelihood model,behavioral economics,psychology,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Discriminating IT Governance'''
{{header}}
{{article
|author= Amrit Tiwana,Stephen K. Kim,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = The information technology (IT) governance literature predominantly explains firms' IT governance choices, but not their strategic consequences. We develop the idea that a firm's IT governance choices induce adeptness at strategically exploiting IT only when they are discriminatingly aligned with its departments' knowledge outside their specialty. Discriminating means that governing the two undertheorized classes of IT assets-apps and infrastructure-requires "peripheral" knowledge in different departments. Analyses of data from 105 firms support our middle-range theory.
|keyword = IT governance,IT infrastructure,IT applications,discriminating alignment,IT agility,Garen method,IT strategy,endogeneity,IT asset classes,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Embarrassing Exposures in Online Social Networks: An Integrated Perspective of Privacy Invasion and Relationship Bonding'''
{{header}}
{{article
|author= Ben C. F. Choi,Zhenhui (Jack) Jiang,Bo Xiao,Sung S. Kim,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Online social networks greatly facilitate social exchange among friends. At times, for amusement, individuals may be targeted by friends' playful teases, which often involve exposing individuals' private embarrassing information, such as information that reveals their past indecent behavior, mischief, or clumsiness. Although individuals sometimes do enjoy the humor, they might also be offended by the involuntary exposure. Drawing on social exchange theory, this paper elucidates the consequences of an embarrassing exposure in online social networks. Specifically, this study examines the effects of information dissemination and network commonality on individuals' exchange assessment as well as how this assessment shapes their behavioral responses. The results of our experiment provide strong evidence that information dissemination and network commonality jointly influence individuals' perceived privacy invasion and perceived relationship bonding. In addition, whereas perceived privacy invasion increases transactional avoidance, it reduces approach behavior. Furthermore, whereas perceived relationship bonding impedes both transactional avoidance and interpersonal avoidance, it leads to approach behavior. The theoretical and practical implications of the findings are discussed.
|keyword = online social networks,embarrassing exposure,privacy invasion,relationship bonding,inaction,avoidance behavior,approach behavior,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Do Organic Results Help or Hurt Sponsored Search Performance?'''
{{header}}
{{article
|author= Ashish Agarwal,Kartik Hosanagar,Michael D. Smith,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = We study the impact of changes in the competitors' listings in organic search results on the performance of sponsored search advertisements. Using data from an online retailer's keyword advertising campaign, we measure the impact of organic competition on both click-through rate and conversion rate of sponsored search advertisements. We find that an increase in organic competition leads to a decrease in the click performance of sponsored advertisements. However, organic competition helps the conversion performance of sponsored ads and leads to higher revenue. We also find that organic competition has a higher negative effect on click performance than does sponsored competition. Our results inform advertisers on how the presence of organic results influences the performance of their sponsored advertisements. Specifically, we show that organic competition acts as a substitute for clicks, but has a complementary effect on the conversion performance.
|keyword = sponsored search,organic search,ad placement,hierarchical Bayesian estimation,online advertising,online auctions,search engine marketing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Design of Consumer Review Systems and Product Pricing'''
{{header}}
{{article
|author= Yabing Jiang,Hong Guo,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Consumer review systems have become an important marketing communication tool through which consumers share and learn product information. Although there is abundant evidence that consumer reviews have a significant impact on product sales, the design of consumer review systems and its impact on review outcomes and product sales have not yet been well examined. This paper analyzes firms' review system design and product pricing strategies. We formally model two review system design decisions-what rating scale cardinality to use and whether to offer granular review reports. We show that firms' optimal design and pricing strategies critically depend on contextual characteristics such as product valuation, product mainstream level, and consumer misfit cost. Our results suggest that it is beneficial to host a review system only when the product valuation is higher than a threshold. Furthermore, firms should choose low rating scale cardinality for niche products and high rating scale cardinality for mainstream products. When consumers' misfit cost is relatively high, including granular reports in the review system enables firms to attract the favorable consumer segment. Different pricing strategies should be deployed during the initial sale period for different product types. For niche products, firms are advised to adopt lower-bound pricing for high-quality products to take advantage of the positive word of mouth. For mainstream products, firms are advised to adopt upper-bound pricing for high-quality products to enjoy the direct profit from the initial sale period, even after taking into account the negative impact of high price on consumer reviews.
|keyword = economics of IS,electronic commerce,consumer reviews,online word-of-mouth systems,product uncertainty,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Versioning in the Software Industry: Heterogeneous Disutility from Underprovisioning of Functionality'''
{{header}}
{{article
|author= Shivendu Shivendu,Zhe (James) Zhang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Literature has identified factors such as piracy, network externality, or concave cost of producing quality as key drivers of software versioning. However, software firms adopt versioning strategies that are often invariant across different market settings. To explain universal business practice of software versioning, we focus on "inconvenience" or disutility that users experience when software has lower functionality than what they require to accomplish tasks. In our model, users are heterogeneous on marginal valuation for functionality and the required level of functionality such that those with higher valuation have a higher required level of functionality. Users do not derive any additional utility if the software has more functionality than what they require. We show that heterogeneous disutility from underprovisioning of functionality is a sufficient condition for optimality of versioning under fairly general conditions. We also show that, as high-type users' required level of functionality increases, the firm increases the functionality level of the high version. Yet surprisingly, the firm may decrease the functionality level of the low version if the proportion of high-type users is moderate. On the other hand, as the required level of functionality of low-type users increases, the firm may reduce the functionality level of the low version when the proportion of high-type users is high, though the functionality level of the high version remains the same. Counterintuitively, an increase in the high-type (low-type) users' required level of functionality negatively (positively) impacts high-type users' consumer surplus.
|keyword = vertical differentiation,versioning,pricing,disutility from underprovisioning,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Can Payment-per-Click Induce Improvements in Click Fraud Identification Technologies?'''
{{header}}
{{article
|author= Min Chen,Varghese S. Jacob,Suresh Radhakrishnan,Young U. Ryu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Pay-per-click (PPC) is a common pricing model used to pay for ads on the Web and is open to the possibility for click fraud, where clicks are not from a legitimate user. Identifying click fraud is generally done in a three-stage process: the service provider (SP) first classifies clicks as fraudulent or not, then the advertiser does the same with a different technology, and if there is a disagreement, the SP examines further and his conclusions are considered binding. The advertiser pays for clicks that are identified as valid in the first two stages or confirmed as valid in the last stage. We model the choice of the identification technologies as a double moral hazard problem. We analyze the case where the PPC is incentive compatible to overcome the moral hazard problem, and examine the question of whether the incentive compatible PPC is sufficient to incentivize the two parties to unilaterally make further improvements to their identification technologies and simultaneously increase their profits. We show that when the cost of the third-stage identification technology is large, which is likely to be the case because of its complexity and use of expensive human experts, the incentive compatible PPC does not support unilateral technological improvements. We then examine a setting where the third-stage identification is delegated to a third party and find that this arrangement can induce unilateral improvements to the identification technologies in the first two stages. Collectively our results show that although the PPC model itself may not induce improvements in the first two stages of click fraud identification, a common arrangement espoused of having a third party resolve disagreements helps make PPC support unilateral technological improvements. Accordingly, we show an indirect benefit to the third-party arrangement.
|keyword = click fraud,online advertising,game theory,double moral hazard,incentives,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''What Motivates Contributors vs. Lurkers? An Investigation of Online Feedback Forums'''
{{header}}
{{article
|author= Chee Wei Phang,Atreyi Kankanhalli,Bernard C. Y. Tan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Organizations are setting up online forums to obtain inputs and feedback from key stakeholders, such as employees, customers, and citizens. Examples of such virtual spaces are online policy deliberation forums (OPDFs) initiated by government organizations to garner citizens' views on policy issues. Incorporating the inputs from these forums can result in more inclusive policies for societal benefit. Yet, as with other such forums, a common issue facing OPDFs is the sustainability of participation. When examining this issue, previous research has mostly explored the participation antecedents of existing contributors. However, engaging lurkers is also important, because these forums need to compensate for contributor attrition and become more effective with greater reach. Thus motivated, this study develops a model to explain the antecedents of both contributors' and lurkers' participation deriving from public participation and information technology-enabled public goods theories. It hypothesizes differences in the antecedents for contributors versus lurkers based primarily on construal level theory. The model was empirically validated through a survey of contributors and lurkers in a nationwide OPDF. The results reveal significant differences in the participation antecedents of the two groups as hypothesized. Specifically, contributors are influenced by political career benefit and political efficacy motives, whereas lurkers' future participation intention is driven by collective benefits, possession of civic skills, and mobilization. Furthermore, perceived connectivity of the OPDF directly influences participation intention for contributors and indirectly impacts participation intention for both groups via perceived communality. Perceived communality, on the other hand, influences collective and persuasion benefits for both contributors and lurkers. These findings are useful for understanding and promoting participation through differential strategies for contributors and lurkers in OPDFs in particular, and by extension, other feedback or online forums.
|keyword = online policy deliberation forums,online feedback forums,contributors,lurkers,public participation theories,IT-enabled public goods theory,construal level theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Designing Warning Messages for Detecting Biased Online Product Recommendations: An Empirical Investigation'''
{{header}}
{{article
|author= Bo Xiao,Izak Benbasat,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = The increasing adoption of product recommendation agents (PRAs) by e-commerce merchants makes it an important area of study for information systems researchers. PRAs are a type of Web personalization technology that provides individual consumers with product recommendations based on their product-related needs and preferences expressed explicitly or implicitly. Whereas extant research mainly assumes that such recommendation technologies are designed to benefit consumers and focuses on the positive impact of PRAs on consumers' decision quality and decision effort, this study represents an early effort to examine PRAs that are designed to produce their recommendations on the basis of benefiting e-commerce merchants (rather than benefiting consumers) and to investigate how the availability and the design of warning messages (a potential detection support mechanism) can enhance consumers' performance in detecting such biased PRAs. Drawing on signal detection theory, the literature on warning messages, and the literature on message framing, we identified two content design characteristics of warning messages-the inclusion of risk-handling advice and the framing of risk-handling advice-and investigated how they influence consumers' detection performance. The results of an online experiment reveal that a simple warning message without accompanying advice on how to detect bias is a double-edged sword, because it increases correct detection of biased PRAs (hits) at the cost of increased incorrect detection (false alarms). By contrast, including in warning messages risk-handling advice about how to check for bias (particularly when the advice is framed to emphasize the loss from not following the advice) increases correct detection and, more importantly, also decreases incorrect detection. The patterns of findings are in line with the predictions of signal detection theory. With an enriched understanding of how the availability and the content design of warning messages can assist consumers in the context of PRA-assisted online shopping, the results of this study serve as a basis for future theoretical development and yield valuable insights that can guide practice and the design of effective warning messages.
|keyword = electronic commerce,product recommendation agent,personalization,bias,signal detection theory,manipulative practices,warning,message framing,online experiment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Tigerblood: Newspapers, Blogs, and the Founding of Information Technology Firms'''
{{header}}
{{article
|author= Brad N. Greenwood,Anand Gopal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = In this paper, we study the impact of increases in media coverage from two sources, newspapers and blogs, on firm founding rates in the context of technology-based entrepreneurship. Although increasing work in information systems (IS) has begun to investigate the effect of user-generated content on entrepreneurial behavior, limited attention has been devoted to how media affects firm founding or the boundary conditions of such an effect. Arguing for the direct effect of increased discourse in traditional and user-generated media in the information technology (IT) industry, results suggest that discourse in traditional media and blogs strongly influences IT firm founding rates. We further consider the differential impacts of media discourse on firm founding in different IT subsectors, over time, and in different locations. We test our hypotheses using entrepreneurial firm founding data from VentureXpert from 1998 to 2007, social media data from the three largest blogging platforms, and traditional media coverage from 11 major U.S. newspapers. Our work contributes to a better understanding of the concurrent effects of multiple forms of media on decision making and adds to the small but emerging literature addressing entrepreneurship-related research questions in IS.
|keyword = entrepreneurship,information technology firms,firm founding,media,newspapers,blogs,user-generated media,econometric analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Parenting New Acquisitions: Acquirers' Digital Resource Redeployment and Targets' Performance Improvement in the US Hospital Industry'''
{{header}}
{{article
|author= Kui Du,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = This paper examines how information technology ( IT) can contribute to value creation in horizontal acquisitions. We propose that acquisition value can be created when an acquirer redeploys its digital resources to its newly acquired businesses and consequently improves their operations. However, not all acquirers are equally capable of redeploying their digital resources. In this study, we propose two enabling factors pertaining to an acquirer's IT resource base: IT extensiveness and IT standardization. We argue that the magnitude of digital resource redeployment increases when the acquirer has had extensive use of IT systems within its existing business units and has standardized IT systems across its business units. Moreover, the relative strength of the IT resources of the acquirer, as compared to those of the acquired business, also affects the reuse of the acquirer's IT resources in its digital resource redeployment activities. We empirically test these hypotheses by tracking the IT and performance changes in 108 U.S. hospitals before and after they were acquired across a seven-year study timeframe.
|keyword = acquisitions,resource redeployment,IT extensiveness,IT standardization,IT gap,hospitals,efficiency and quality of healthcare,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Patching the Cloud: The Impact of SaaS on Patching Strategy and the Timing of Software Release'''
{{header}}
{{article
|author= Vidyanand Choudhary,Zhe (James) Zhang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = This paper extends prior research on the software vendors' optimal release time and patching strategy in the context of cloud computing and software as a service (SaaS). Traditionally, users are responsible for running on-premises software; by contrast, a vendor is responsible for running SaaS software, and the SaaS vendor incurs a larger proportion of defect-related costs than a vendor of on-premises software. We examine the effect of this difference on a vendor's choice of when to release software and the proportion of software defects to fix. Surprisingly, we find that, despite incurring a larger proportion of defect-related costs, it is optimal for the SaaS vendor to release software earlier and with more defects, and to patch a smaller proportion of defects, than the on-premises software vendor. Even though the SaaS vendor incurs higher defect-related costs, he obtains a larger profit than the traditional vendor. In addition, we find that for a vendor who uses the SaaS model, the optimal number of defects after patching may be lower than the socially efficient outcome. This occurs despite the fact that the number of defects after patching in the SaaS model is higher than in the traditional on-premises model.
|keyword = software security,cloud,software as a service,patch management,software release time,software maintenance,defect-related costs,economics of information systems,monopoly,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Can't Buy Me Love ... Or Can I? Social Capital Attainment Through Conspicuous Consumption in Virtual Environments'''
{{header}}
{{article
|author= Oliver Hinz,Martin Spann,Il-Horn Hann,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Conspicuous consumption affects anyone who cares about social status; it has intrigued sociologists and economists for more than 100 years. The idea that conspicuous consumption can increase social status, as a form of social capital, has been broadly accepted, yet researchers have not been able to test this effect empirically. In this work, we provide empirical evidence by analyzing the digital footprints of purchases and social interactions in different virtual worlds. We use a multimethod approach, such that we both analyze transactional data and conduct a randomized field experiment. Virtual worlds, as artificial laboratories, offer the opportunity to analyze the social capital of their inhabitants, subsequent to their purchase of virtual prestige goods, which provides a means to empirically test hypotheses that would be nearly impossible to test in real-world settings. Our results are consistent with the notion that conspicuous consumption represents an investment in social capital.
|keyword = social status,social capital,conspicuous consumption,prestige goods,virtual worlds,randomized field experiment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''FAIRNESS IN THE INSTITUTIONAL VALUATION OF BUSINESS JOURNALS'''
{{header}}
{{article
|author= Gary F. Templeton,Bruce R. Lewis,
|source= MIS QUARTERLY
|year= 2015
|abstract = The fairness of performance evaluation is a concern for all professions, and the appraisal of research output is of particular interest to business scholars and academic administrators. We describe research assessment as a process of social construction that is heavily influenced by journal valuation in business schools. Using journal quality data from multiple sources, we empirically investigate whether the journals in each of eight business disciplines (Accounting, Economics, Finance, Information Systems, Management, Marketing, Operations Management, and Quantitative Methods) are treated evenly across the board. Specifically, we explore whether each business discipline exhibits recognition fairness (i.e., actual institutional journal evaluations are the same as market expectations) and inclusion fairness (i.e., actual availability of publication space in top journals being the same as market expectations). Our findings indicate that faculty in some disciplines enjoy an advantage, while faculty in other fields are disadvantaged. Consequently, we offer recommendations to ameliorate this inequity.
|keyword = Journal valuation fairness,institutional and public business journal lists,citation metrics,research evaluation,social constructionism,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''GENRES OF INQUIRY IN DESIGN-SCIENCE RESEARCH: JUSTIFICATION AND EVALUATION OF KNOWLEDGE PRODUCTION'''
{{header}}
{{article
|author= Richard L. Baskerville,Mala Kaul,Veda C. Storey,
|source= MIS QUARTERLY
|year= 2015
|abstract = Recognizing that design is at the core of information systems development has led to a design-science research paradigm where differing kinds of knowledge goals give form to differing kinds of knowledge processes within a single study. This paper analyzes knowledge production in design-science research to explain how an endogenous form of pluralism characterizes such studies, making it problematic to associate any design-science study with a single view of knowledge production. Instead, a design-science research study exhibits up to four different modes of reasoning, called genres of inquiry. These genres are derived from two dualities that contrast differing knowledge goals and differing knowledge scope in the knowledge production process. The first duality arises from the sometimes seemingly contradictory knowledge goals of science versus design. The second duality reflects the contradiction between the scope of the knowledge produced, which may be idiographic or nomothetic. The evolutionary and iterative nature of a design-science study compels different knowledge goals and scope at different moments throughout a project. Because of this momentary nature, a single design-science study can be associated with multiple genres of inquiry. This understanding of the variety in the genres of inquiry advances the discourse on the nature of design-science research and the justification and evaluation of its outcomes. Consequently, a corresponding set of criteria for knowledge justification and evaluation is provided for each genre of inquiry.
|keyword = Design science research,genres of inquiry,evaluation,duality,knowledge scope,knowledge goal,knowledge moment,centrality of knowledge,idiographic science,nomothetic science,endogenous pluralism,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''VOCAL MINORITY AND SILENT MAJORITY: HOW DO ONLINE RATINGS REFLECT POPULATION PERCEPTIONS OF QUALITY'''
{{header}}
{{article
|author= Guodong (Gordon) Gao,Brad N. Greenwood,Ritu Agarwal,Jeffrey S. McCullough,
|source= MIS QUARTERLY
|year= 2015
|abstract = Consumer-generated ratings typically share an objective of illuminating the quality of a product or service for other buyers. While ratings have become ubiquitous and influential on the Internet, surprisingly little empirical research has investigated how these online assessments reflect the opinion of the population at large, especially in the domain of professional services where quality is often opaque to consumers. Building on the word-of-mouth literature, we examine the relationship between online ratings and population perceptions of physician quality. We leverage a unique dataset which includes direct measures of both the offline population's perception of physician quality and consumer-generated online reviews. As a result, we are able to examine how online ratings reflect patients' opinions about physician quality. In sharp contrast to the widely voiced concerns by medical practitioners, we find that physicians who are rated lower in quality by the patient population are less likely to be rated online. Although ratings provided online are positively correlated with patient population opinions, the online ratings tend to be exaggerated at the upper end of the quality spectrum. This study is the first to provide empirical evidence of the relationship between online ratings and the underlying consumer-perceived quality, and extends prior research on online word-of-mouth to the domain of professional services.
|keyword = Online ratings,physician quality,online word-of-mouth,professional services,informativeness,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''JAMMING WITH SOCIAL MEDIA: HOW COGNITIVE STRUCTURING OF ORGANIZING VISION FACETS AFFECTS IT INNOVATION DIFFUSION'''
{{header}}
{{article
|author= Shaila M. Miranda,Inchan Kim,Jama D. Summers,
|source= MIS QUARTERLY
|year= 2015
|abstract = Organizing vision theory is an institutional alternative to the economic-rationality view of IT innovation diffusion. Institutional theorists have called for more attention to cognitive processes and structures in order to understand institutional mechanisms. Our objective was to unpack the cognitive structure of an organizing vision to understand its role in the diffusion of IT innovations. We focus on the know-why component of organizing visions and on social media as an IT innovation. In a two-stage study, Stage I leveraged schema theory, the "orders of worth" framework's six justificatory principles, and relational class analysis to discover the hierarchical structure of the social media organizing vision. This resulted in a view of the organizing vision as comprised of four schemas, which we conceptualized as visions-in-use, and ten nested business use cases, each comprised of different combinations of the six principles. Based on this understanding, Stage II explored how community appropriations of visions-in-use and business use cases from the repertoire provided by an organizing vision shape four facets of an organizing vision-coherence, continuity, clarity, and diversity-and how these facets influence diffusion of the IT innovation. We found that the two vision facets we surfaced-clarity and diversity-are essential to understanding diffusion and how and why coherence and continuity matter to diffusion. Much as the "vision" of a musical jam session emerges from players' multivocal performances, an organizing vision emerges from community members' multivocal discourse about an IT innovation. Just as a jam session depends on a structure of rules and individual player creativity, diffusion of an IT innovation depends on an organizing vision that offers prospective adopters a well-defined repertoire of moves to choose from, yet affords them the freedom to improvise.
|keyword = IT innovation,organizing vision,social media,schema,relational class analysis,quantitative grounded theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION TECHNOLOGY USE AS A LEARNING MECHANISM: THE IMPACT OF IT USE ON KNOWLEDGE TRANSFER EFFECTIVENESS, ABSORPTIVE CAPACITY, AND FRANCHISEE PERFORMANCE'''
{{header}}
{{article
|author= Kishen Iyengar,Jeffrey R. Sweeney,Ramiro Montealegre,
|source= MIS QUARTERLY
|year= 2015
|abstract = This study aims to contribute to the literature through the theoretical development and empirical investigation of the role of information technology use in organizational learning. We develop a theoretical framework that unpacks organizational learning into mechanisms and outcomes. The outcomes of organizational learning are distinguished at two levels: first-order and second-order. Based on the framework, we propose a research model set in the franchising context. We conceptualize franchisee use of IT provided by the franchisor as an important learning mechanism that impacts knowledge transfer effectiveness (first-order outcome) and absorptive capacity (second-order outcome). Further, the influence of IT use on financial performance is mediated through absorptive capacity. The model was tested on a sample of 783 independently owned real-estate franchisees using a comprehensive dataset comprised of primary and secondary data. The results indicate that IT use is an important learning mechanism for franchisees by impacting knowledge transfer effectiveness and absorptive capacity. In turn, absorptive capacity mediates the relationship between IT use and financial performance. The empirical support for the research model serves to affirm the underlying learning mechanisms-outcomes framework. The results are stable across the choice of statistical method and the operationalization of financial performance. Theoretical contributions, implications for practice, and limitations of the study are discussed.
|keyword = IT use,organizational learning,knowledge transfer effectiveness,absorptive capacity,IT value,franchising,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ORGANIZATIONAL PATH CONSTITUTION IN TECHNOLOGICAL INNOVATION: EVIDENCE FROM RURAL TELEHEALTH'''
{{header}}
{{article
|author= Rajendra Singh,Lars Mathiassen,Abhay Mishra,
|source= MIS QUARTERLY
|year= 2015
|abstract = Path constitution theory has emerged as a promising combination of two contrasting perspectives on technological innovation: path dependence, which focuses on historically embedded, contingent processes that are more or less beyond the control of actors, and path creation, which emphasizes mindful contributions from powerful actors. However, the current path constitution literature focuses on macro- and multi-level inquiry without addressing the specific processes, opportunities, and challenges related to organizational (micro-level) technological innovation. Against this backdrop, we draw on the innovation and path literature as well as a case study of telehealth innovation in a public health organization to theorize how technological innovation paths constitute in organizational contexts. The proposed theory distinguishes between innovation path status and innovation path trajectory to help researchers understand and explain how organizations transform and reinforce path constitution patterns, how innovation paths may merge with or separate from other paths, and how organizations may arrive at a lock-in that challenges them to break out from dominant and seemingly irreversible action patterns.
|keyword = Technological innovation,innovation path constitution,path creation,path dependence,rural telehealth,social construction of technology,public health,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COMPARING POTENTIAL AND ACTUAL INNOVATORS: AN EMPIRICAL STUDY OF MOBILE DATA SERVICES INNOVATION'''
{{header}}
{{article
|author= Atreyi Kankanhalli,Hua (Jonathan) Ye,Hock Hai Teo,
|source= MIS QUARTERLY
|year= 2015
|abstract = Firms are increasingly opening up their innovation efforts to allow users to tap into the benefits they can offer, such as mobile data service (MDS) innovation on iOS and Google Android platforms. For this purpose, platforms typically provide toolkits to facilitate user participation, aiming to create an ecosystem for sustainable innovation. However, with the barriers to user innovation and attrition of existing innovators, it could be challenging for firms to attract and sustain users' MDS innovation. With the possible benefits from user innovation, and considering the challenges faced, firms need to understand how to influence potential user innovators to take part and to encourage extant user innovators to innovate again. However, there is a lack of comprehensive research and understanding of what drives users' intentions to innovate services and the differences in the antecedents of such intention between potential and actual user innovators. Further, although prior studies have suggested that toolkits can support user innovation, little research has theorized and empirically tested their influence. Motivated thus, this study proposes a model based on (1) user innovation theory to explain the antecedents (including toolkit support) of user MDS innovation intention and (2) construal level theory to explain the differential effects of the antecedents for actual and potential user innovators. We tested the model through survey data from potential and actual MDS user innovators on Google Android and iOS platforms. We find that trend leadership and anticipated extrinsic reward influence both potential and actual user innovators' intentions to innovate. However, anticipated recognition and toolkit support affect only actual user innovators, while anticipated enjoyment affects only potential user innovators. Interestingly, toolkit support strengthens the influence of anticipated enjoyment for actual user innovators but weakens its influence for potential user innovators. Further, potential user innovators value anticipated extrinsic rewards less than actual innovators do. The implications for research and practice are discussed.
|keyword = User service innovation,mobile data services,user innovation theory,construal level theory,potential and actual user innovators,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COMPETING FOR ATTENTION: AN EMPIRICAL STUDY OF ONLINE REVIEWERS' STRATEGIC BEHAVIOR'''
{{header}}
{{article
|author= Wenqi Shen,Yu Jeffrey Hu,Jackie Rees Ulmer,
|source= MIS QUARTERLY
|year= 2015
|abstract = Top online reviewers who reliably gain consumers' attention stand to make significant financial gains and monetize the amount of attention and reputation they have earned. This study explores how online reviewers strategically choose the right product to review and the right rating to post so that they can gain attention and enhance reputation. Using book reviews from Amazon and Barnes & Noble (BN), we find that reviewers on Amazon, where a reviewer ranking system quantifies reviewers' online reputations, are sensitive to the competition among existing reviews and thus tend to avoid crowded review segments. However, on BN, which does not include such a ranking mechanism, reviewers do not respond to the competition effect. In addition, reviewers on Amazon post more differentiated ratings compared with reviewers on BN since the competition for attention on Amazon is more intense than on BN. Overall, reviewers on Amazon behave more strategically than reviewers on BN. This study yields important managerial implications for companies to improve their design of online review systems and enhance their understanding of reviewers' strategic behaviors.
|keyword = Online attention,scarcity of attention,competing for attention,online product reviews,user-generated content,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EXTENDING ICT4D STUDIES: THE VALUE OF CRITICAL RESEARCH'''
{{header}}
{{article
|author= Cecilia I. C. Lin,Feng-Yang Kuo,Michael D. Myers,
|source= MIS QUARTERLY
|year= 2015
|abstract = The purpose of this paper is to demonstrate the value of critical research for information and communications technology for development (ICT4D) studies. Most previous IS research on ICT4D projects is interpretive and has focused on the immediate organizational context, but there are very few critical studies that have engaged in macro sociopolitical analyses regarding institutional change. Hence we extend previous IS research on ICT4D by adopting a critical research perspective on the macro sociopolitical context within which most ICT4D projects take place. We illustrate this with an ethnographic study of a project that was intended to improve the education and social welfare of the aboriginal people in Taiwan. On the surface the project was tremendously successful; it became a showcase on national radio and TV showing how ICT could be used to support underprivileged children. However, our research uncovered a different story altogether-a story of the aboriginal people themselves feeling marginalized and without much of a voice. We use concepts from postcolonial theory to make sense of these two contradictory stories. We found that the interrelationship between the macro sociopolitical context and the local organizational context of the ICT4D project is the key to understanding what went wrong, something which we would not have discovered if we had taken the traditional approach. The postcolonial context is powerful and pervasive, hampering any real progress.
|keyword = ICT4D,development,critical research,postcolonial theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EXHAUSTION FROM INFORMATION SYSTEM CAREER EXPERIENCE: IMPLICATIONS FOR TURN-AWAY INTENTION'''
{{header}}
{{article
|author= Deborah J. Armstrong,Nita G. Brooks,Cynthia K. Riemenschneider,
|source= MIS QUARTERLY
|year= 2015
|abstract = While the U.S. economy is recovering slowly, reports tell us that the supply of information systems (IS) professionals is declining and demand is once again on the rise. With organizations challenged in their efforts to hire additional staff, IS professionals are being asked to do even more, often leading to burnout, turnover, and turnaway intentions. Building on Ahuja et al.'s (2007) work on turnover intentions and using the job demands-resources model of burnout as an organizing framework for the antecedents to exhaustion from IS career experience (EISCE), this illustrative research note draws attention to exhaustion in IS professionals that spans an individual's professional career. Findings indicate that IS professionals' perceived workload (demand) was associated with higher levels of EISCE, whereas fairness and perceived control of career (resources) were associated with lower levels of EISCE. The influence of EISCE on affective commitment to the IS profession (ACISP) was found to be negative and, ultimately, ACISP fully mediated the effect of EISCE on the intention to turn away from an IS career. The results suggest the importance of studying IS professionals' perceptions regarding the demands and resources associated with working in the IS field when testing exhaustion across IS career experience.
|keyword = Information systems,IS personnel,workforce,burnout,exhaustion,affective commitment,turnaway intention,occupational turnover,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''FRIENDSHIPS IN ONLINE PEER-TO-PEER LENDING: PIPES, PRISMS, AND RELATIONAL HERDING'''
{{header}}
{{article
|author= De Liu,Daniel J. Brass,Yong Lu,Dongyu Chen,
|source= MIS QUARTERLY
|year= 2015
|abstract = This paper investigates how friendship relationships act as pipes, prisms, and herding signals in a large online, peer-to-peer (P2P) lending site. By analyzing decisions of lenders, we find that friends of the borrower, especially close offline friends, act as financial pipes by lending money to the borrower. On the other hand, the prism effect of friends' endorsements via bidding on a loan negatively affects subsequent bids by third parties. However, when offline friends of a potential lender, especially close friends, place a bid, a relational herding effect occurs as potential lenders are likely to follow their offline friends with a bid.
|keyword = Peer-to-peer lending,friendship relationships,social networks,prism effect,herding,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Network Dynamics: How Can We Find Patients Like Us?'''
{{header}}
{{article
|author= Lu (Lucy) Yan,Jianping Peng,Yong Tan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Social networks have been shown to affect health. Because online social networking makes it easier for individuals to interact with experientially similar others in regard to health issues and to exchange social support, there has been an increasing effort to understand how networks function. Nevertheless, little attention has been paid to how these networks are formed. In this paper, we examine the driving forces behind patients' social network formation and evolution. We argue that patients' health-related traits influence their social connections and that the patients' network layout is shaped by their cognitive capabilities and their network embeddedness. By studying longitudinal data from 1,322 individuals and their communication ties in an online healthcare social network, we find that firsthand disease experience, which provides knowledge of the disease, increases the probability that patients will find experientially similar others and establish communication ties. Patients' cognitive abilities, including the information load that they can process and the range of social ties that they can manage, however, limit their network growth. In addition, we find that patients' efforts to reach out for additional social resources are associated with their embeddedness in the network and the cost of maintaining connections. Practical implications of our findings are discussed.
|keyword = social networks,healthcare,network dynamics,homophily,cognitive capabilities,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IT-Enabled Broadcasting in Social Media: An Empirical Study of Artists' Activities and Music Sales'''
{{header}}
{{article
|author= Hailiang Chen,Prabuddha De,Yu Jeffrey Hu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = With the emergence of social media and Web 2.0, broadcasting in the online environment has evolved into a new form of marketing due to the much broader reach enabled by information technology. This paper quantifies the effect of artists' broadcasting activities on a well-known social media site for music, MySpace, on music sales. We employ a panel vector autoregression model to investigate the interrelationship between broadcasting promotions in social media and music sales, while controlling for influential factors such as advertising in traditional media channels, album prices, new music releases, user-generated content, and artist popularity. We characterize two types of broadcast messages in the MySpace context, personal and automated. We find that broadcasting in social media has a significant effect on sales even after controlling for the aforementioned factors, and more important, the effect mainly comes from personal messages rather than automated messages. We also show that the timing and content of personal messages play a role in affecting sales. Our findings point to the importance of conducting captivating conversations with customers in social media marketing.
|keyword = broadcasting,social media marketing,music sales,panel vector autoregression,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Recommendations Using Information from Multiple Association Rules: A Probabilistic Approach'''
{{header}}
{{article
|author= Abhijeet Ghoshal,Syam Menon,Sumit Sarkar,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Business analytics has evolved from being a novelty used by a select few to an accepted facet of conducting business. Recommender systems form a critical component of the business analytics toolkit and, by enabling firms to effectively target customers with products and services, are helping alter the e-commerce landscape. A variety of methods exist for providing recommendations, with collaborative filtering, matrix factorization, and association-rule-based methods being the most common. In this paper, we propose a method to improve the quality of recommendations made using association rules. This is accomplished by combining rules when possible and stands apart from existing rule-combination methods in that it is strongly grounded in probability theory. Combining rules requires the identification of the best combination of rules from the many combinations that might exist, and we use a maximum-likelihood framework to compare alternative combinations. Because it is impractical to apply the maximum likelihood framework directly in real time, we show that this problem can equivalently be represented as a set partitioning problem by translating it into an information theoretic context-the best solution corresponds to the set of rules that leads to the highest sum of mutual information associated with the rules. Through a variety of experiments that evaluate the quality of recommendations made using the proposed approach, we show that (i) a greedy heuristic used to solve the maximum likelihood estimation problem is very effective, providing results comparable to those from using the optimal set partitioning solution; (ii) the recommendations made by our approach are more accurate than those made by a variety of state-of-the-art benchmarks, including collaborative filtering and matrix factorization; and (iii) the recommendations can be made in a fraction of a second on a desktop computer, making it practical to use in real-world applications.
|keyword = personalization,Bayesian estimation,maximum likelihood,information theory,data analytics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Contemporaneous and Delayed Sales Impact of Location-Based Mobile Promotions'''
{{header}}
{{article
|author= Zheng Fang,Bin Gu,Xueming Luo,Yunjie Xu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Can location-based mobile promotion (LMP) trigger contemporaneous and delayed sales purchases? As mobile technologies can reach users anywhere and anytime, LMP becomes a promising new channel. We unravel the dynamic sales impact of LMP on the basis of a randomized field experiment with 22,000 mobile users sponsored by one of the largest mobile service providers in the world. Our identification strategy is to gauge the marginal increases in consumer purchases of the geo-fenced treatment group of users who received LMP, above and beyond the baseline control groups. There are two controls: one group who received the same LMP but not in the virtual geo-fencing locational range (nongeo-fenced control), and the other who did not receive the LMP but in the geo-fencing range (geo-fenced control). The latter control serves as an organic holdout baseline from the similar population, i.e., counterfactual test of what if without the mobile LMP intervention, to identify the actual "lift" of incremental purchases caused by the treatment with the mobile LMP intervention. Findings suggest that LMP treatment has a significantly stronger impact on contemporaneous (same-day) purchases and delayed (subsequent-days) purchases than the controls. The randomized experiment design renders these findings robust to alternative explanations such as mobile usage behavior heterogeneity, product effects heterogeneity, nonrandomized sample-selection bias, and endogeneity concerns. Follow-up surveys with the field experiment users explore the nuanced mechanisms via which LMP may induce the impulsive, same-day purchases, and create product awareness for the planned subsequent-days purchases. LMP can generate six times more purchases than nongeo-fenced control with the LMP intervention, and 12 times more than geo-fenced control without the LMP intervention. LMP has a delayed sales effect for 12 days after the mobile promotions. The total sales impact of LMP could be underestimated by 54% if excluding the delayed sales impact and only including the contemporaneous impact. These findings are new to the literature and often neglected in mobile promotion practices, proffering novel implications on the sales value of LMP in the mobile era.
|keyword = mobile computing,mobile promotion,location-based mobile promotion,advertising,dynamic impact,randomized field experiment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Disclosure and the Diffusion of Information Security Attacks'''
{{header}}
{{article
|author= Sabyasachi Mitra,Sam Ransbotham,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = With the nearly instantaneous dissemination of information in the modern era, policies regarding the disclosure of sensitive information have become the focus of significant discussion in several contexts. The fundamental debate centers on trade-offs inherent in disclosing information that society needs, but that can also be used for nefarious purposes. Using information security as a research context, our empirical study examines the adoption of software vulnerabilities by a population of attackers. We compare attacks based on software vulnerabilities disclosed through full-disclosure and limited-disclosure mechanisms. We find that full disclosure accelerates the diffusion of attacks, increases the penetration of attacks within the target population, and increases the risk of first attack after the vulnerability is reported. Interestingly, the effect of full disclosure is greater during periods when there are more overall vulnerabilities reported, indicating that attackers may strategically focus on busy periods when the effort of security professionals is spread across many vulnerabilities. Although the aggregate volume of attacks remains unaffected by full disclosure, attacks occur earlier in the life cycle of the vulnerability. Building off our theoretical insights, we discuss the implications of our findings in more general contexts.
|keyword = information security,information disclosure,software vulnerability,diffusion of innovation,negative innovation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Why Following Friends Can Hurt You: An Exploratory Investigation of the Effects of Envy on Social Networking Sites among College-Age Users'''
{{header}}
{{article
|author= Hanna Krasnova,Thomas Widjaja,Peter Buxmann,Helena Wenninger,Izak Benbasat,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Research findings on how participation in social networking sites (SNSs) affects users' subjective well-being are equivocal. Some studies suggest a positive impact of SNSs on users' life satisfaction and mood, whereas others report undesirable consequences such as depressive symptoms and anxiety. However, whereas the factors behind the positive effects have received significant scholarly attention, little is known about the mechanisms that underlie the unfavorable consequences. To fill this gap, this study uses social comparison theory and the responses of 1,193 college-age Facebook users to investigate the role of envy in the SNS context as a potential contributor to those undesirable outcomes. Arising in response to social information consumption, envy is shown to be associated with reduced cognitive and affective well-being as well as increased reactive self-enhancement. These preliminary findings contribute to the growing body of information systems research investigating the dysfunctional consequences of information technology adoption in general and social media participation in particular.
|keyword = envy,self-enhancement,social comparison theory,social media,social networking sites,subjective well-being,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Migration of Service to the Internet: Evidence from a Federal Natural Experiment'''
{{header}}
{{article
|author= Kai-Lung Hui,I. P. L. Png,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Previous research into consumer choice of service channels studied the impact of online access as an addition to conventional service. Here, we study the impact of a compulsory migration to an online channel. We exploit a natural experiment in the implementation of a new federal government service to identify the causal effect of access channel on consumer choice. The government served western states through the Internet and telephone at all times. However, for the first 10 days, the government served the East through the Internet only. Comparing consumer responses in the East (only Internet service available) and West (both Internet and telephone service available), we find robust evidence that some consumers preferred telephone access. The unavailability of telephone service in the first 10 days resulted in a 4.3% loss of consumers who were otherwise interested in the service.
|keyword = service migration,channel choice,Do Not Call Registry,natural experiment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Exploration of Risk Characteristics of Information Security Threats and Related Public Information Search Behavior'''
{{header}}
{{article
|author= Jingguo Wang,Nan Xiao,H. Raghav Rao,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Information security (IS) threats are increasingly pervasive, and search engines are being used by the public as the primary tool for searching for relevant information. This research investigates the following two questions: (1) How can different IS threats be characterized and distinguished in terms of their risk characteristics? and (2) how are risk characteristics related to public searches for information on IS threats? Applying psychometric analysis, our analyses of survey data first show that unknown risk and dread risk are two underlying dimensions that can characterize different IS threats. Drawing broadly on the literature of information foraging theory, we examine the influence of risk characteristics on public searches for information on these threats. We utilize a search engine log to extract searches related to IS threats. We develop and estimate a system of equations with correlated individual-specific error terms using the Markov Chain Monte Carlo method. We find that the two risk characteristics exert differential impacts on information search behavior (including types of information sought, number of pages viewed, and length of query). The implications for IS research and practice are discussed.
|keyword = information-seeking behavior,information security threats,risk characteristics,psychometric analysis,Markov Chain Monte Carlo,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''NEW STATE OF PLAY IN INFORMATION SYSTEMS RESEARCH: THE PUSH TO THE EDGES'''
{{header}}
{{article
|author= Varun Grover,Kalle Lyytinen,
|source= MIS QUARTERLY
|year= 2015
|abstract = The dominant way of producing knowledge in information systems (IS) seeks to domesticate high-level reference theory in the form of mid-level abstractions involving generic and atheoretical information technology (IT) components. Enacting such epistemic scripts squeezes IS theory to the middle range, where abstract reference theory concepts are directly instantiated or slightly modified to the IS context, whereas IT remains exogenous to theory by being treated as an independent variable, mediator, or moderator. In this design, IT is often operationalized using proxies that detect the presence of IT or its variation in use or cost. Our analysis of 143 articles published in MIS Quarterly and Information Systems Research over the past 15 years demonstrates that over 70 percent of published theory conforms to this mode of producing IS knowledge. This state of play has resulted in two negative consequences: the field (1) agonizes over the dearth of original and bold theorizing over IT and (2) satisfices when integrating theory with empirics by creating incommensurate mid-range models that are difficult to consolidate. We propose that one way to overcome these challenges is to critically examine and debate the negative impacts of the field's dominant epistemic scripts and relax them by permitting IS scholarship that more fluidly accommodates alternative forms of knowledge production. This will push IS inquiry to the "edges" and emphasize, on the one hand, inductive, rich inquiries using innovative and extensive data sets and, on the other hand, novel, genuine, high-level theorizing around germane conceptual relationships between IT, information and its (semiotic) representations, and social behaviors. We offer several exemplars of such inquiries and their results. To promote this push, we invite alternative institutionalized forms of publishing and reviewing. We conclude by inviting individual scholars to be more open to practices that permit richer theorizing. These recommendations will broaden the field's knowledge ecology and permit the creation of good IS knowledge over just getting "hits." We surmise that, if such changes are carried out, the field can look confidently toward its future as one of the epicenters of organizational inquiry that deal with the central forces shaping human enterprise in the 21st century.
|keyword = Information systems discipline,research inquiry,epistemic scripts,IS theory,IT artifact,middle-range theory,theory borrowing,institutional analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CONSISTENT PARTIAL LEAST SQUARES PATH MODELING'''
{{header}}
{{article
|author= Theo K. Dijkstra,Jorg Henseler,
|source= MIS QUARTERLY
|year= 2015
|abstract = This paper resumes the discussion in information systems research on the use of partial least squares (PLS) path modeling and shows that the inconsistency of PLS path coefficient estimates in the case of reflective measurement can have adverse consequences for hypothesis testing. To remedy this, the study introduces a vital extension of PLS: consistent PLS (PLSc). PLSc provides a correction for estimates when PLS is applied to reflective constructs: The path coefficients, inter-construct correlations, and indicator loadings become consistent. The outcome of a Monte Carlo simulation reveals that the bias of PLSc parameter estimates is comparable to that of covariance-based structural equation modeling. Moreover, the outcome shows that PLSc has advantages when using non-normally distributed data. We discuss the implications for IS research and provide guidelines for choosing among structural equation modeling techniques.
|keyword = PLS,consistent partial least squares,SEM,variance-based structural equation modeling,Monte Carlo simulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DISASTER EXPERIENCE AND HOSPITAL INFORMATION SYSTEMS: AN EXAMINATION OF PERCEIVED INFORMATION ASSURANCE, RISK, RESILIENCE, AND HIS USEFULNESS'''
{{header}}
{{article
|author= Insu Park,Raj Sharman,H. Raghav Rao,
|source= MIS QUARTERLY
|year= 2015
|abstract = This paper examines how an individual's disaster experience affects his or her perceptions of sociotechnical safety factors (risk, information assurance, resilience) and perceived usefulness of hospital information systems (HIS). This paper consists of two studies focusing on different aspects: a quasi-field experiment conducted with employees in three hospitals affected by a severe snowstorm (labeled a federal disaster) (N = 103), where we compare the perceptual factors in the context of the disaster experience (with versus without recall), and a comparative study between a first sample group (with disaster experience) and a second, contrast sample group (with no disaster experience) of hospital employees (N = 179) from two similar hospitals. The results show that the disaster experience changes the relationships among the perceptual factors that affect perceived usefulness. Individuals tend to perceive negative factors (such as risk) as having greater effects when they actually have direct experience in a disaster situation than in a normal situation. Positive factors (such as information assurance and resilience) have a lesser impact among individuals who have disaster experience (with versus without recall).
|keyword = Disaster experience,information assurance,perceived system risk,perceived resilience,quasi-experiment,comparative study,hospital information systems usefulness,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INCREASING ACCOUNTABILITY THROUGH USER-INTERFACE DESIGN ARTIFACTS: A NEW APPROACH TO ADDRESSING THE PROBLEM OF ACCESS-POLICY VIOLATIONS'''
{{header}}
{{article
|author= Anthony Vance,Paul Benjamin Lowry,Dennis Eggett,
|source= MIS QUARTERLY
|year= 2015
|abstract = Access-policy violations are a growing problem with substantial costs for organizations. Although training programs and sanctions have been suggested as a means of reducing these violations, evidence shows the problem persists. It is thus imperative to identify additional ways to reduce access-policy violations, especially for systems providing broad access to data. We use accountability theory to develop four user-interface (UI) design artifacts that raise users' accountability perceptions within systems and in turn decrease access-policy violations. To test our model, we uniquely applied the scenario-based factorial survey method to various graphical manipulations of a records system containing sensitive information at a large organization with over 300 end users who use the system daily. We show that the UI design artifacts corresponding to four submanipulations of accountability can raise accountability and reduce access policy violation intentions. Our findings have several theoretical and practical implications for increasing accountability using UI design. Moreover, we are the first to extend the scenario-based factorial survey method to test design artifacts. This method provides the ability to use more design manipulations and to test with fewer users than is required in traditional experimentation and research on human-computer interaction. We also provide bootstrapping tests of mediation and moderation and demonstrate how to analyze fixed and random effects within the factorial survey method optimally.
|keyword = Accountability theory,identifiability,expectation of evaluation,awareness of monitoring,social presence,factorial survey method,user-interface design,information security policy violations,unauthorized access,mediation,moderation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COPING WITH INFORMATION TECHNOLOGY: MIXED EMOTIONS, VACILLATION, AND NONCONFORMING USE PATTERNS'''
{{header}}
{{article
|author= Mari-Klara Stein,Sue Newell,Erica L. Wagner,Robert D. Galliers,
|source= MIS QUARTERLY
|year= 2015
|abstract = Achieving the promised business benefits of an IT system is intimately tied to the continued incorporation of the system into the work practices it is intended to support. While much is known about different social, cognitive, and technical factors that influence initial adoption and use, less is known about the role of emotional factors in users' behaviors. Through an in-depth field study conducted in two North American universities, we examine the role of emotions in how specific IT use patterns emerge. We find that there are five different characteristics of an IT stimulus event (cues) that, when interacting in a reinforcing manner, elicit a single class of emotions (uniform affective responses) and, when interacting in an oppositional manner, elicit mixed emotions (ambivalent affective responses). While users respond to uniform emotions with clear adaptation strategies, they deal with ambivalent emotions by combining different adaptation behaviors, a vacillating strategy between emphasizing positive and negative aspects of the stimulus. Surprisingly, these ambivalent emotions and vacillating strategies can lead to active and positive user engagement, exhibited in task and tool adaptation behaviors and improvisational use patterns that, despite their nonconformity to terms of use, can have positive organizational implications.
|keyword = Emotions,IT use patterns,adaptation behaviors,ambivalence,qualitative research,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''LEADING COLLABORATION IN ONLINE COMMUNITIES'''
{{header}}
{{article
|author= Samer Faraj,Srinivas Kudaravalli,Molly Wasko,
|source= MIS QUARTERLY
|year= 2015
|abstract = Despite the growing importance of online communities in creating knowledge and facilitating collaboration, there has been limited research examining the role of leaders in such settings. In this paper, we propose a framework that integrates behavioral and structural approaches to explore the antecedents of leadership in online communities focused on knowledge work. Specifically, we propose that sociability and knowledge contribution behaviors as well as structural social capital lead to being identified as a leader by members of the online community. We test this framework using social network, survey, and message-level content analysis data collected from three different online communities focused on technical topics. The results from our zero inflated negative binomial models, with 6,709 messages from 976 individuals, provide strong support for the framework that is developed in this study. Our study contributes to both theory and practice by identifying the behavioral and structural antecedents of leadership in online communities.
|keyword = Online leadership,leader behaviors,online communities,structural social capital,knowledge collaboration,network analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PATTERNS IN INFORMATION SYSTEMS PORTFOLIO PRIORITIZATION: EVIDENCE FROM DECISION TREE INDUCTION'''
{{header}}
{{article
|author= Prasanna Karhade,Michael J. Shaw,Ramanath Subramanyam,
|source= MIS QUARTERLY
|year= 2015
|abstract = Questions pertaining to the locus of information systems (IS) governance have been extensively examined in existing research. However, questions pertaining to the decision rationale applied for IS portfolio prioritization (why are certain initiatives approved, and why are certain others rejected), noted to be a critical component of IS governance, need further investigation. We submit that the IS strategy of a firm is likely to explain the decision rationale it applies to IS portfolio prioritization and maintain that it is critical to ensure this decision rationale is in congruence with the firm's IS strategy. By extending prior theoretical work on IS strategy types, we develop theoretical profiles of the decision rationale applied to IS portfolio prioritization using three attributes: communicability of decision rationale, consistency in applying decision rationale, and risk appropriateness of decision rationale. Since the decision rationale applied for IS portfolio prioritization is often tacit, unknown even to the decision makers themselves, we employ the decision tree induction methodology to discover this tacit decision rationale. We analyze over 150 IS portfolio prioritization decisions on a multimillion dollar IS portfolio of a multibusiness, Fortune 50 firm and our findings, which support our propositions, indicate that firms that adopt different IS strategies rely on systematically different profiles of decision rationale for IS portfolio prioritization. Implications for IS governance practices are developed.
|keyword = IS strategy,IS portfolio prioritization,IT portfolio management,IS governance,IT governance,decision making,decision tree induction,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''MOBILE APPLICATION USABILITY: CONCEPTUALIZATION AND INSTRUMENT DEVELOPMENT'''
{{header}}
{{article
|author= Hartmut Hoehle,Viswanath Venkatesh,
|source= MIS QUARTERLY
|year= 2015
|abstract = This paper presents a mobile application usability conceptualization and survey instrument following the 10step procedure recommended by MacKenzie et al. (2011). Specifically, we adapted Apple's user experience guidelines to develop our conceptualization of mobile application usability that we then developed into 19 first-order constructs that formed 6 second-order constructs. To achieve our objective, we collected four datasets: content validity (n = 318), pretest (n = 440), validation (n = 408), and cross-validation (n = 412). The nomological validity of this instrument was established by examining its impact on two outcomes: continued intention to use and mobile application loyalty. We found that the constructs that represented our mobile application usability conceptualization were good predictors of both outcomes and compared favorably to an existing instrument based on Microsoft's usability guidelines. In addition to being an exemplar of the recent procedure of MacKenzie et al. to validate an instrument, this work provides a rich conceptualization of an instrument for mobile application usability that can serve as a springboard for future work to understand the impacts of mobile application usability and can be used as a guide to design effective mobile applications.
|keyword = Usability,mobile applications,survey instrument development,continued use,mobile application loyalty,mobility,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''SUPPORT STRUCTURES AND THEIR IMPACTS ON EMPLOYEE OUTCOMES: A LONGITUDINAL FIELD STUDY OF AN ENTERPRISE SYSTEM IMPLEMENTATION'''
{{header}}
{{article
|author= Tracy Ann Sykes,
|source= MIS QUARTERLY
|year= 2015
|abstract = Despite the impressive progress in understanding the benefits and challenges related to enterprise system (ES) implementations-such as enterprise resource planning (ERP) systems-little is known about how the support structures traditionally used by organizations to help employees cope with a new ES affect employee outcomes related to the system and their jobs. Likewise, little is known about how existing peer advice ties in the business unit influence these outcomes after an ES implementation. Understanding employee outcomes is critical because of their ramifications for long-term ES success. This paper examines the impacts of four traditional support structures (namely, training, online support, help desk support, and change management support), and peer advice ties on four key employee outcomes (namely, system satisfaction, job stress, job satisfaction, and job performance). This paper also seeks to show that it is peer advice ties that best fill the complex informational needs of employees after an ES implementation by providing the right information at the right time and in the right context. The proposed model was tested in a field study conducted in one business unit of a large telecommunications company and gathered data from 120 supplier liaisons over the course of a year. Both traditional support structures and peer advice ties were found to influence the various outcomes, even after controlling for pre-implementation levels of the dependent variables. In all cases, peer advice ties was the strongest predictor, thus underscoring the importance of this critical internal resource.
|keyword = Enterprise systems,ES implementation,peer advice ties,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''HOW INFORMATION TECHNOLOGY GOVERNANCE MECHANISMS AND STRATEGIC ALIGNMENT INFLUENCE ORGANIZATIONAL PERFORMANCE: INSIGHTS FROM A MATCHED SURVEY OF BUSINESS AND IT MANAGERS'''
{{header}}
{{article
|author= Shelly Ping-Ju Wu,Detmar W. Straub,Ting-Peng Liang,
|source= MIS QUARTERLY
|year= 2015
|abstract = Previous research has proposed different types for and contingency factors affecting information technology governance. Yet, in spite of this valuable work, it is still unclear through what mechanisms IT governance affects organizational performance. We make a detailed argument for the mediation of strategic alignment in this process. Strategic alignment remains a top priority for business and IT executives, but theory-based empirical research on the relative importance of the factors affecting strategic alignment is still lagging. By consolidating strategic alignment and IT governance models, this research proposes a nomological model showing how organizational value is created through IT governance mechanisms. Our research model draws upon the resource-based view of the firm and provides guidance on how strategic alignment can mediate the effectiveness of IT governance on organizational performance. As such, it contributes to the knowledge bases of both alignment and IT governance literatures. Using dyadic data collected from 131 Taiwanese companies (cross-validated with archival data from 72 firms), we uncover a positive, significant, and impactful linkage between IT governance mechanisms and strategic alignment and, further, between strategic alignment and organizational performance. We also show that the effect of IT governance mechanisms on organizational performance is fully mediated by strategic alignment. Besides making contributions to construct and measure items in this domain, this research contributes to the theory base by integrating and extending the literature on IT governance and strategic alignment, both of which have long been recognized as critical for achieving organizational goals.
|keyword = IT governance mechanisms,strategic alignment,organizational performance,degree-symmetric measures,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Finding Similar Mobile Consumers with a Privacy-Friendly Geosocial Design'''
{{header}}
{{article
|author= Foster Provost,David Martens,Alan Murray,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = This paper focuses on finding the same and similar users based on location-visitation data in a mobile environment. We propose a new design that uses consumer-location data from mobile devices (smartphones, smart pads, laptops, etc.) to build a "geosimilarity network" among users. The geosimilarity network (GSN) could be used for a variety of analytics-driven applications, such as targeting advertisements to the same user on different devices or to users with similar tastes, and to improve online interactions by selecting users with similar tastes. The basic idea is that two devices are similar, and thereby connected in the GSN, when they share at least one visited location. They are more similar as they visit more shared locations and as the locations they share are visited by fewer people. This paper first introduces the main ideas and ties them to theory and related work. It next introduces a specific design for selecting entities with similar location distributions, the results of which are shown using real mobile location data across seven ad exchanges. We focus on two high-level questions: (1) Does geosimilarity allow us to find different entities corresponding to the same individual, for example, as seen through different bidding systems? And (2) do entities linked by similarities in local mobile behavior show similar interests, as measured by visits to particular publishers? The results show positive results for both. Specifically, for (1), even with the data sample's limited observability, 70%-80% of the time the same individual is connected to herself in the GSN. For (2), the GSN neighbors of visitors to a wide variety of publishers are substantially more likely also to visit those same publishers. Highly similar GSN neighbors show very substantial lift.
|keyword = design science,mobile computing,analytical modeling,network analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Evolutionary Competition in Platform Ecosystems'''
{{header}}
{{article
|author= Amrit Tiwana,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Intraplatform competition has received scant attention in prior studies, which predominantly study interplatform competition. We develop a middle-range theory of how complementarity between input control and a platform extension's modularization-by inducing evolution-influences its performance in a platform market. Primary and archival data spanning five years from 342 Firefox extensions show that such complementarity fosters performance by accelerating an extension's perpetual evolution.
|keyword = platforms,ecosystems,evolution,modularity,input control,platform governance,Garen,endogeneity,apps,platform extensions,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Role of Extra-Role Behaviors and Social Controls in Information Security Policy Effectiveness'''
{{header}}
{{article
|author= Jack Shih-Chieh Hsu,Sheng-Pao Shih,Yu Wen Hung,Paul Benjamin Lowry,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Although most behavioral security studies focus on organizational in-role behaviors such as information security policy (ISP) compliance, the role of organizational extra-role behaviors-security behaviors that benefit organizations but are not specified in ISPs-has long been overlooked. This study examines (1) the consequences of organizational in-role and extra-role security behaviors on the effectiveness of ISPs and (2) the role of formal and social controls in enhancing in-role and extra-role security behaviors in organizations. We propose that both in-role security behaviors and extra-role security behaviors contribute to ISP effectiveness. Furthermore, based on social control theory, we hypothesize that social control can boost both in-and extra-role security behaviors. Data collected from practitioners-including information systems (IS) managers and employees at many organizations-confirmed most of our hypotheses. Survey data from IS managers substantiated the importance of extra-role behaviors in improving ISP effectiveness. Paired data, collected from managers and employees in the same organizations, indicated that formal control and social control individually and interactively enhance both in-and extra-role security behaviors. We conclude by discussing the implications of this research for academics and practitioners, along with compelling future research possibilities.
|keyword = IS security,behavioral security,in-role behaviors,extra-role behaviors,social control theory,SCT,security management,information security policy,ISP,formal control,social control,organizations,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Cable News Wars on the Internet: Competition and User-Generated Content'''
{{header}}
{{article
|author= Gaurav Sabnis,Rajdeep Grewal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Academics and practitioners alike recognize that user-generated content (UGC), such as blog posts, help not only predict but also boost performance (e.g., sales). However, the role of competition in the UGC domain is not well understood. Building on extant research pertaining to the UGC-performance relationship, the authors document empirical evidence for a relationship between competitor UGC and focal firm performance. Data from a 30-week period describe the viewership of competing cable news shows on Fox News, CNN, and MSNBC during the 7:00 P.M.-9:00 P.M. time slots. They find evidence of a statistically significant relationship between competitor UGC and viewership and of heterogeneity in the direction of these competitive relationships, positive in some time slots and negative in others. The predictive power of UGC for viewership is enhanced by 3% to 5% simply by incorporating competitors' UGC, in addition to a show's own UGC. Thus, the study, as well as formulation of UGC-related marketing strategies, should incorporate competitive relationships.
|keyword = user-generated content,social media,competition,cable news,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Net Neutrality, Exclusivity Contracts, and Internet Fragmentation'''
{{header}}
{{article
|author= Frago Kourandi,Jan Kraemer,Tommaso Valletti,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Net neutrality (NN) is believed to prevent the emergence of exclusive online content, which yields Internet fragmentation. We examine the relationship between NN regulation and Internet fragmentation in a game-theoretic model that considers the interplay between termination fees, exclusivity, and competition between two Internet service providers (ISPs) and between two content providers (CPs). An exclusivity arrangement between an ISP and a CP reduces the CP's exposure to some end users, but it also reduces competition over ads among the CPs. Fragmentation arises in equilibrium when competition over ads among the CPs is very strong, the CPs' revenues from advertisements are very low, the content of the CPs is highly complementary, or the termination fees are high. We find that the absence of fragmentation is always beneficial for consumers, because they can enjoy all available content. Policy interventions that prevent fragmentation are thus good for consumers. However, results for total welfare are more mixed. A zero-price rule on traffic termination is neither a sufficient nor a necessary policy instrument to prevent fragmentation. In fact, regulatory interventions may be ineffective or even detrimental to welfare and are only warranted under special circumstances.
|keyword = net neutrality,Internet fragmentation,exclusivity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Learning User Real-Time Intent for Optimal Dynamic Web Page Transformation'''
{{header}}
{{article
|author= Amy Wenxuan Ding,Shibo Li,Patrali Chatterjee,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Many e-commerce websites struggle to turn visitors into real buyers. Understanding online users' real-time intent and dynamic shopping cart choices may have important implications in this realm. This study presents an individual-level, dynamic model with concurrent optimal page adaptation that learns users' real-time, unobserved intent from their online cart choices, then immediately performs optimal Web page adaptation to enhance the conversion of users into buyers. To suggest optimal strategies for concurrent page adaptation, the model analyzes each individual user's browsing behavior, tests the effectiveness of different marketing and Web stimuli, as well as comparison shopping activities at other sites, and performs optimal Web page transformation. Data from an online retailer and a laboratory experiment reveal that concurrent learning of the user's unobserved purchase intent and real-time, intent-based optimal interventions greatly reduce shopping cart abandonment and increase purchase conversions. If the concurrent, intent-based optimal page transformation for the focal site starts after the first page view, shopping cart abandonment declines by 32.4% and purchase conversion improves by 6.9%. The optimal timing for the site to intervene is after three page views, to achieve efficient learning of users' intent and early intervention simultaneously.
|keyword = real-time learning,shopping intent,optimization,concurrent page adaptation,website productivity,hierarchical Bayes models,hidden Markov models,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Analyzing Software as a Service with Per-Transaction Charges'''
{{header}}
{{article
|author= Dan Ma,Abraham Seidmann,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Software as a Service (SaaS) delivers a bundle of applications and services through the Web. Its on-demand feature allows users to enjoy full scalability and to handle possible demand fluctuations at no risk. In recent years, SaaS has become an appealing alternative to purchasing, installing, and maintaining modifiable off-the-shelf (MOTS) software packages. We present a game-theoretical model to study the competitive dynamics between the SaaS provider, who charges a variable per-transaction fee, and the traditional MOTS provider. We characterize the equilibrium conditions under which the two coexist in a competitive market and those under which each provider will fail and exit the market. Decreasing the lack-of-fit (or the cross-application data integration) costs of SaaS results in four structural regimes in the market. These are MOTS Dominance! Segmented Market! Competitive Market! SaaS Dominance. Based on our findings, we recommend distinct competitive strategies for each provider. We suggest that the SaaS provider should invest in reducing both its lack-of-fit costs and its per-transaction price so that it can offer increasing economies of scale. The MOTS provider, by contrast, should not resort to a price-cutting strategy; rather, it should enhance software functionality and features to deliver superior value. We further examine this problem from the software life-cycle perspective, with multiple stages over which users can depreciate the fixed costs of installing and customizing their MOTS solutions on site. We then present an analysis that characterizes the competitive outcomes when future technological developments could change the relative levels of the lack-of-fit costs. Specifically, we explain why the SaaS provider will always use a forward-looking pricing strategy: When lack-of-fit costs are expected to decrease (increase) in the future, the SaaS provider should reduce (increase) its current price. This is in contrast with the MOTS provider, who will use the forward-looking pricing strategy only when lack-of-fit costs are expected to increase. Surprisingly, when such costs are expected to decrease, the MOTS provider should ignore this expectation and use the same pricing strategy as in the benchmark with invariant lack-of-fit costs.
|keyword = software as a service,game theory model,pricing based on transactions,competitive strategies,lack-of-fit costs,economies of scale,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Social Capital and Contract Duration in Buyer-Supplier Networks for Information Technology Outsourcing'''
{{header}}
{{article
|author= Kiron Ravindran,Anjana Susarla,Deepa Mani,Vijay Gurbaxani,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = This paper presents new evidence on the role of embeddedness in predicting contract duration in the context of information technology outsourcing. Contract duration is a strategic decision that aligns interests of clients and vendors, providing the benefits of business continuity to clients and incentives to undertake relationship specific investments for vendors. Considering the salience of this phenomenon, there has been limited empirical scrutiny of how contract duration is awarded. We posit that clients and vendors obtain two benefits from being embedded in an interorganizational network. First, the learning and experience accumulated from being embedded in a client-vendor network could mitigate the challenges in managing longer term contracts. Second, the network serves as a reputation system that can stratify vendors according to their trustworthiness and reliability, which is important in longer term arrangements. In particular, we attempt to make a substantive contribution to the literature by theorizing about embeddedness at four distinct levels: structural embeddedness at the node level, relational embeddedness at the dyad level, contractual embeddedness at the level of a neighborhood of contracts, and finally, positional embeddedness at the level of the entire network. We analyze a data set of 22,039 outsourcing contracts implemented between 1989 and 2008. We find that contract duration is indeed associated with structural and positional embeddedness of participant firms, with the relational embeddedness of the buyer-seller dyad, and with the duration of other contracts to which it is connected through common firms. Given the nature of our data, identification using traditional ordinary least squares based approaches is difficult given the unobserved errors clustered along two nonnested dimensions and the autocorrelation in a firm's decision (here the contract) with those of contracts in its reference group. We use a multiway cluster robust estimation and a network auto-regressive estimation to address these issues. Implications for literature and practice are discussed.
|keyword = social capital,reputation,IT outsourcing,contract design,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''How Does IT Ambidexterity Impact Organizational Agility?'''
{{header}}
{{article
|author= One-Ki (Daniel) Lee,Vallabh Sambamurthy,Kai H. Lim,Kwok Kee Wei,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Organizational agility is a significant business capability. Though there have been numerous studies about the effects of information technology (IT) capabilities on organizational agility, there has been limited attention on the enabling effects of IT ambidexterity, namely, the dual capacity to explore and exploit IT resources and practices. We propose that IT ambidexterity enhances organizational agility by facilitating operational ambidexterity, and that the magnitude of facilitation depends on the level of environmental dynamism. We test these relationships utilizing data from a large-scale, matched-pair field survey of business and IT executives. The results confirm that a firm's IT ambidexterity does enhance its organizational agility through the mediated effects of operational ambidexterity, and that the dynamism of a firm's environment affects these relationships.
|keyword = agility,IT ambidexterity,operational ambidexterity,environmental dynamism,moderated-mediation analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Road to Early Success: Impact of System Use in the Swift Response Phase'''
{{header}}
{{article
|author= Yu Tong,Sharon Swee-Lin Tan,Hock-Hai Teo,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = When an enterprise system is introduced, system users often experience a performance dip as they struggle with the unfamiliar system. Appropriately managing this phase, which we term as the swift response phase (SRP), is vital given its prominent impact on the eventual success of the system. Yet, there is a glaring lack of studies that examine the SRP. Drawing on sensemaking theory and early postadoptive literature, this study seeks to propose a theory-driven model to understand how different support structures facilitate different forms of use-related activities to induce a positive performance in the SRP. The model was tested through a two-stage survey involving 329 nurses. The results demonstrated the discriminating alignment between information system (IS) use-related activity and support structures in enhancing system users' work performance in the SRP. Specifically, suitability of impersonal support moderated the effects of standardized system use and individual adaption on performance, whereas availability of personal support only moderated the effect of nonstandardized system use on performance. For moderating role of personal support, IS specialists support had a lower influence than peer-champion support and peer-user support. This study contributes to the extant literature by (1) conceptualizing the turbulent SRP, (2) applying sensemaking theory to the initial postadoptive stage, (3) adding to the theoretical debate on the value of system use, and (4) unveiling the distinct roles of support structures under different types of use activities. Practical suggestions are provided for organizational management and policy makers to deal with the complexities in the SRP.
|keyword = early system success,sensemaking in organization,swift response phase,shakedown phase,system use,support structure,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Deliberation Without Attention: The Latent Benefits of Distracting Website Features for Online Purchase Decisions'''
{{header}}
{{article
|author= Barney Tan,Cheng Yi,Hock C. Chan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Early studies on Web design typically caution against the use of distracting website features in electronic commerce, such as animated banners, pop-ups, and floating advertisements, because they may cause annoyance for online consumers and disrupt information processing, leading to poorer purchase decisions. Yet, the recently uncovered deliberation-without-attention (D-W-A) effect suggests that distracting consumers from the decision-making process may improve their decision quality when there are a large number of decision parameters to consider. To ascertain whether the D-W-A effect can be triggered through the use of distracting website features in the context of online shopping, two experiments are conducted. The first experiment reveals that the presence of distracting website features, in the form of pop-ups, gives rise to annoyance in general, but also leads to better purchase decisions when the decision to be made is complex. The second experiment supports the findings of the first and sheds further light on the underlying mode of thought triggered by these features. In particular, by eliminating a number of potential alternative mechanisms, including online judgments, the mere disruption of decision-related thought, and cognitively constrained conscious deliberation, the second experiment demonstrates that unconscious deliberation is likely to be the underlying cause of superior decision making. With these findings, this research supports a more balanced view in the recent human-computer interaction literature, which suggests that the usual advice to minimize the use of distracting website features should be examined more carefully. The research also uncovers evidence that contributes to the ongoing debate surrounding the D-W-A effect and unconscious thought theory.
|keyword = Web design,human-computer interaction,unconscious thought theory,deliberation without attention,online shopping,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Investigating Firm Strategies on Offering Consumer-Customizable Products'''
{{header}}
{{article
|author= Zheyin (Jane) Gu,Giri K. Tayi,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Advances in the digital economy have driven the trend among manufacturers, particularly those in the information technology (IT) industry, to offer products that consumers can self-customize to satisfy their idiosyncratic needs. This study examines firm strategies on offering such consumer-customizable products. Our analysis shows that a monopolistic firm obtains a greater profit from offering a consumer-customizable product than from offering a preconfigured standardized product only if consumers are sufficiently capable to conduct the customization task; otherwise, it is more profitable for the firm to offer a standardized product. Moreover, consumers obtain a greater surplus when the firm offers the customizable product. We also consider the case where the firm is capable of offering both a customizable product and a standardized product and find that the firm benefits more from offering both products than offering either product if consumer customizing capability and the customization cost are not too high. Interestingly, when the firm offers both products, its effort in enhancing consumer customizability (e.g., offering free consumer training) always benefits both the firm and consumers, but its effort in increasing the value of the standardized product (e.g., offering more functions) can hurt both the firm profit and consumer surplus. Our theoretical results explain many interesting business practices and provide useful insights for marketing practitioners.
|keyword = consumer customization,consumer-customizable product,standardized product,IT products,game theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Role of Self-Control in Information Security Violations: Insights from a Cognitive Neuroscience Perspective'''
{{header}}
{{article
|author= Qing Hu,Robert West,Laura Smarandescu,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Self-control has been identified as a major factor influencing individual behavior in the social science, neuroscience, criminology, and information security literatures. In this study, we first developed and validated a novel paradigm suitable for use with event-related potentials (ERPs) in scenario-based laboratory experiments of decision making in the context of information security. We then used this paradigm to examine the association between individual differences in self-control and ERPs elicited while individuals deliberated over violations of information security policies. Our results show that the left and right hemispheres of the brain were involved in decision making, and that the participants with low self-control had lower levels of neural recruitment in both hemispheres relative to those with high self-control. This was especially the case for regions in or near the dorsal lateral prefrontal cortex (DLPFC) and inferior frontal cortex (IFC). These results extend the findings in neuroscience literature related to the role of self-control in decision making in general, and validate a new paradigm for use with the electroencephalography/event-related potentials (EEG/ERP) technique to examine theoretical questions in information security and criminology research.
|keyword = information security,neuroscience,self-control,policy compliance,neural correlates,electroencephalography (EEG),event-related potentials (ERPs),NeuroIS,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Behavioral Roots of Information Systems Security: Exploring Key Factors Related to Unethical IT Use'''
{{header}}
{{article
|author= Sutirtha Chatterjee,Suprateek Sarker,Joseph S. Valacich,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Unethical information technology (IT) use, related to activities such as hacking, software piracy, phishing, and spoofing, has become a major security concern for individuals, organizations, and society in terms of the threat to information systems (IS) security. While there is a growing body of work on this phenomenon, we notice several gaps, limitations, and inconsistencies in the literature. In order to further understand this complex phenomenon and reconcile past findings, we conduct an exploratory study to uncover the nomological network of key constructs salient to this phenomenon, and the nature of their interrelationships. Using a scenario-based study of young adult participants, and both linear and nonlinear analyses, we uncover key nuances of this phenomenon of unethical IT use. We find that unethical IT use is a complex phenomenon, often characterized by nonlinear and idiosyncratic relationships between the constructs that capture it. Overall, ethical beliefs held by the individuals, along with economic, social, and technological considerations are found to be relevant to this phenomenon. In terms of practical implications, these results suggest that multiple interventions at various levels may be required to combat this growing threat to IS security.
|keyword = unethical IT use,ethics,information ethics,information systems security,nonlinear analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Chasing Lemmings: Modeling IT-Induced Misperceptions About the Strategic Situation as a Reason for Flash Crashes'''
{{header}}
{{article
|author= Tobias Brandt,Dirk Neumann,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Flash crashes, perceived as sharp drops in market prices that rebound shortly after, have turned the public eye toward the vulnerability of information technology-based stock trading. In this paper, we explain flash crashes as the result of actions made by rational agents. We argue that the advancement of information technology (IT), which has long been associated with competitive advantages, may cause ambiguities with respect to the game form that give rise to a hypergame. We employ hypergame theory to demonstrate that a market crash constitutes an equilibrium state if players misperceive the true game. Once the ambiguity is resolved, prices readjust to the appropriate level, creating the characteristic flash-crash effect. By analyzing the interaction with herd behavior, we find that flash crashes may be an unavoidable systemic problem of modern financial markets.
|keyword = flash crash,game theory,impact of IT,hypergames,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Enhancing Predictive Analytics for Anti-Phishing by Exploiting Website Genre Information'''
{{header}}
{{article
|author= Ahmed Abbasi,Fatemeh Mariam Zahedi,Daniel Zeng,Yan Chen,Hsinchun Chen,Jr. Jay F. Nunamaker,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Phishing websites continue to successfully exploit user vulnerabilities in household and enterprise settings. Existing anti-phishing tools lack the accuracy and generalizability needed to protect Internet users and organizations from the myriad of attacks encountered daily. Consequently, users often disregard these tools' warnings. In this study, using a design science approach, we propose a novel method for detecting phishing websites. By adopting a genre theoretic perspective, the proposed genre tree kernel method utilizes fraud cues that are associated with differences in purpose between legitimate and phishing websites, manifested through genre composition and design structure, resulting in enhanced anti-phishing capabilities. To evaluate the genre tree kernel method, a series of experiments were conducted on a testbed encompassing thousands of legitimate and phishing websites. The results revealed that the proposed method provided significantly better detection capabilities than state-of-the-art anti-phishing methods. An additional experiment demonstrated the effectiveness of the genre tree kernel technique in user settings; users utilizing the method were able to better identify and avoid phishing websites, and were consequently less likely to transact with them. Given the extensive monetary and social ramifications associated with phishing, the results have important implications for future anti-phishing strategies. More broadly, the results underscore the importance of considering intention/purpose as a critical dimension for automated credibility assessment: focusing not only on the "what" but rather on operationalizing the "why" into salient detection cues.
|keyword = design science,data mining,phishing websites,genre theory,Internet fraud,website genres,credibility assessment,phishing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Exploring Knowledge Filtering Processes in Electronic Networks of Practice'''
{{header}}
{{article
|author= Kelly J. Fadel,Thomas O. Meservy,Matthew L. Jensen,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Electronic networks of practice (ENPs) have become an important mechanism for knowledge exchange among loosely connected individuals who share common knowledge interests. While prior research has explored factors that influence knowledge contribution in such networks, less is understood about the process by which individuals evaluate and ultimately adopt knowledge from ENPs. This study examines the process of knowledge filtering in online ENP forums. Drawing from dual process and information-evaluation theories, we hypothesize that performance on a knowledge-filtering task will be influenced by the constancy and directionality of search patterns employed by knowledge seekers. Hypotheses are tested in an experiment that utilized an eye tracker to record gaze data from professional software developers using an experimental ENP forum. By combining information-evaluation and dual process theory perspectives, our results deepen the insights offered in extant information-processing literature by showing that higher filtering accuracy is associated with (a) constant evaluation of some types of information attributes (solution content) but not others (peripheral cues), and (b) increasing attribute-based processing over time.
|keyword = electronic networks of practice,filtering,knowledge evaluation,constancy,directionality,field experiment,eye tracking,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Bundling Effects on Variety Seeking for Digital Information Goods'''
{{header}}
{{article
|author= Gediminas Adomavicius,Jesse Bockstedt,Shawn P. Curley,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Prior research with consumable goods has consistently found that consumers have a preference for greater variety when selecting items simultaneously as a bundle, rather than as a sequential series of individual decisions. However, digital information goods have a number of important differences from consumable goods that may impact variety-seeking behavior. In three experiments, we address two general research questions. First, as a precursor to studying digital goods, we disentangle the role of bundle cohesion (i.e., item relatedness) from the role of timing (simultaneous vs. sequential choice) as factors in variety seeking with consumable goods. Next, based on differences between digital and consumable goods, we theorize differences in the behavioral effects of bundle cohesion and timing on variety preferences for digital goods. The results show a reduction of influences upon variety-seeking behavior with digital goods, providing important implications for the sellers of such goods in contrast to what has been suggested for consumable goods. Therefore, a key takeaway is that, for digital goods such as music, the use of consumer-driven bundling variations does not suggest an advantage in terms of their ability to affect consumers' variety-seeking behavior.
|keyword = variety seeking,digital goods,information goods,bundled goods,simultaneous choice,sequential choice,bundle cohesion,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Enticing and Engaging Consumers via Online Product Presentations: The Effects of Restricted Interaction Design'''
{{header}}
{{article
|author= Cheng Yi,Zhenhui (Jack) Jiang,Izak Benbasat,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = This work investigates the effects of three different online product presentation formats, namely, a noninteractive video presentation and two virtual product experience (VPE) presentations (full interaction and restricted interaction), on engaging users in online product experience as well as enticing users to try products offline. The experimental results show that restricted interaction, which deprives users of part of the interactive product experience, is more enticing than both the noninteractive and fully interactive design for users with more product-class knowledge. In addition, restricted interaction is generally as good as full interaction in engaging users. Both engagement and enticement positively affect users' purchase intentions. This study contributes to the information systems literature by extending the theory in curiosity formation to the interaction design context and advocating designs for enticement. It contributes to design practice by revealing that less interactive and less costly presentations can be more effective in attracting consumers toward the products.
|keyword = virtual product experience (VPE),restricted interaction,full interaction,enticement,engagement,purchase intention,online product presentation,online video,online selling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Impact of Recommender System on Competition Between Personalizing and Non-Personalizing Firms'''
{{header}}
{{article
|author= Abhijeet Ghoshal,Subodha Kumar,Vijay Mookerjee,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = How do recommender systems affect prices and profits of firms under competition? To explore this question, we model the strategic behavior of customers who make repeated purchases at two competing firms: one that provides personalized recommendations and another that does not. When a customer intends to purchase a product, she obtains recommendations from the personalizing firm and uses this recommendation to eventually purchase from one of the firms. The personalizing firm profiles the customer (based on past purchases) to recommend products. Hence, if a customer purchases less frequently from the personalizing firm, the recommendations made to her become less relevant. While considering the impact on the quality of recommendations received, a customer must balance two opposing forces: (1) the lower price charged by the non-personalizing firm, and (2) an additional fit cost incurred when purchasing from the non-personalizing firm and the increased cost due to recommendations of reduced quality in the future. An outcome of the analysis is that the customers should distribute their purchases across both firms to maximize surplus over a planning horizon. Anticipating this response, the firms simultaneously choose prices. We study the sensitivity of the equilibrium prices and profits of the firms with respect to the effectiveness of the recommender system and the profile deterioration rate. We also analyze some interesting variants of the base model in order to study how its key results could be influenced. One of the key takeaways of this research is that the recommender system can influence the price and profit of not only the personalizing firm but also the non-personalizing firm.
|keyword = recommender systems,duopoly,pricing,dynamic optimization,online competition,Nash equilibrium,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Are You Feeling Lonely? The Impact of Relationship Characteristics and Online Social Network Features on Loneliness'''
{{header}}
{{article
|author= Sabine Matook,Jeff Cummings,Hillol Bala,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = In contemporary society, many people move away from their personal networks for extended periods to reach professional and/or educational goals. This separation can often lead to feelings of loneliness, which can be stressful and sometimes debilitating for the individual. We seek to understand how a person's use of online social networks (OSNs)-technology-enabled tools that assist users with creating and maintaining their relationships-might affect their perceptions of loneliness. Prior research has offered mixed results about how OSNs affect loneliness-reporting both positive and negative effects. We argue in this study that a clearer perspective can be gained by taking a closer look at how individuals approach their relationship management in OSNs. Building on theoretical works on loneliness, we develop a model to explain the effects of relationship characteristics (i.e., relationship orientation, self-disclosure, and networking ability) and OSN features (i.e., active or passive) on perceived loneliness. Our findings show that OSN can be linked to both more and less perceived loneliness, that is, individuals' relationship orientation significantly affects their feelings of loneliness, which are further moderated by their degree of self-disclosure within the OSN. Furthermore, how users engage in the OSN (either actively or passively) influences their perceptions of loneliness. Practical implications regarding perceived loneliness include recommendations for firms to encourage mobile workers to utilize OSNs when separated from others, for education providers to connect with their new students before they arrive, and for users to utilize OSNs as a social bridge to others they feel close with.
|keyword = social media,online social networks,loneliness,relationship management,communal orientation,social exchange theory,self-disclosure,networking ability,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding the Influence of Instant Messaging on Ending Concessions During Negotiations'''
{{header}}
{{article
|author= Norman A. Johnson,Randolph B. Cooper,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = In many online price negotiations, instant messaging (IM) and audio channels rival each other in use, but IM's use is on the rise. In these contexts, people who are strangers to each other are inclined to act more competitively. They are driven by self-interest and strive for greater gains from agreement in the form of what is termed "ending concessions." To date, however, researchers have focused on striving for agreement as the main goal of negotiators. This study uses a selfishness theory to explain how individuals using IM, as compared to those using audio, can encourage their negotiation partners to make ending concessions, and thereby increase individuals' gains when agreement is reached. We use data from a negotiation laboratory experiment to test a model of ending concessions that is predicted by unrestricted offers and comments that negotiators make over IM and audio. We base our analyses on the contents of the resulting communications. The objects of negotiation are simulated lottery tickets. Our results provide three key insights. First, when using IM, partners appear to interpret offers that include concessions from individuals as attempts to manipulate partners into accepting non-equitable agreements; as a result partners decrease their ending concessions. These interpretations do not appear to occur when using audio, and as a result individuals' concessions do not decrease partners' ending concessions. Second, using IM, when individuals disagree with anger directed at partners' bidding behaviors, partners respond by increasing their ending concessions. Ending concessions are further increased when using audio. Third, and in contrast, using IM, when individuals disagree with emotion that does not include anger, partners respond by decreasing their ending concessions. Ending concessions are further decreased when using audio. These insights provide guidance for practice, and are bases for future research on the use of IM and audio for negotiation.
|keyword = instant messaging,audio,selfishness,agreement,ending concession,self-interest,deindividuation,media,negotiation experiment,lottery,negative reciprocation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Health Information Exchange as a Multisided Platform: Adoption, Usage, and Practice Involvement in Service Co-Production'''
{{header}}
{{article
|author= Niam Yaraghi,Anna Ye Du,Raj Sharman,Ram D. Gopal,Ram Ramesh,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Health Information Exchanges (HIE) are becoming integral parts of the national healthcare reform efforts, chiefly because of their potential impact on cost reduction and quality enhancement in healthcare services. However, the potential of an HIE platform can only be realized when its multiple constituent users actively participate in using its variety of services. In this research, we model HIE systems as multisided platforms that incorporate self-service technologies whose value to the users depends on both user-specific and network-specific factors. We develop a model of adoption, use, and involvement of clinical practices in the coproduction of the HIE services. This model is grounded in social network theory, service operations theory, and institutional isomorphism theory. A longitudinal study of actual adoption and use behaviors of 2,054 physicians within 430 community medical practices in Western New York over a three-year period has been carried out to evaluate the proposed model. This study has been supported by HEALTHeLINK, the Regional Health Information Organization of Western New York, which has an extensive database comprising over half a million transactions on patient records by the HIE users. We extracted panel data on adoption, use, and service coproduction behaviors from this database and carried out a detailed analysis using metrics derived from the foundational theories. Positioning practices within two distinct but interrelated networks of patients and practitioners, we show that adoption, use, and service coproduction behaviors are influenced by the topographies of the two networks, isomorphic effects of large practices on the smaller ones, and practice labor inputs in HIE use. Our findings provide a comprehensive view of the drivers of HIE adoption and use at the level of medical practices. These results have implications for marketing and revenue management of HIE platforms, as well as public health and national/regional healthcare policy making.
|keyword = health information exchange,multisided platforms,network externalities,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Predictive Analytics for Readmission of Patients with Congestive Heart Failure'''
{{header}}
{{article
|author= Indranil Bardhan,Jeong-ha (Cath) Oh,Zhiqiang (Eric) Zheng,Kirk Kirksey,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Mitigating preventable readmissions, where patients are readmitted for the same primary diagnosis within 30 days, poses a significant challenge to the delivery of high-quality healthcare. Toward this end, we develop a novel, predictive analytics model, termed as the beta geometric Erlang-2 (BG/EG) hurdle model, which predicts the propensity, frequency, and timing of readmissions of patients diagnosed with congestive heart failure (CHF). This unified model enables us to answer three key questions related to the use of predictive analytics methods for patient readmissions: whether a readmission will occur, how often readmissions will occur, and when a readmission will occur. We test our model using a unique data set that tracks patient demographic, clinical, and administrative data across 67 hospitals in North Texas over a four-year period. We show that our model provides superior predictive performance compared to extant models such as the logit, BG/NBD hurdle, and EG hurdle models. Our model also allows us to study the association between hospital usage of health information technologies (IT) and readmission risk. We find that health IT usage, patient demographics, visit characteristics, payer type, and hospital characteristics, are significantly associated with patient readmission risk. We also observe that implementation of cardiology information systems is associated with a reduction in the propensity and frequency of future readmissions, whereas administrative IT systems are correlated with a lower frequency of future readmissions. Our results indicate that patient profiles derived from our model can serve as building blocks for a predictive analytics system to identify CHF patients with high readmission risk.
|keyword = patient readmissions,healthcare information technologies,congestive heart failure,predictive healthcare analytics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Infrastructure Development and Governance as Collective Action'''
{{header}}
{{article
|author= Panos Constantinides,Michael Barrett,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = In this paper, we examine the challenges around the development and scalability of information infrastructures. We identify two possible solutions proposed in the literature, one emphasizing more top-down control and the need for a clear IT governance framework, and a second arguing for a more flexible approach since absolute control is impossible and only leads to drift and unintended outcomes. We suggest that there is a clear gap in the literature in better understanding how to govern the development of information infrastructures using a bottom-up approach. We build on research that approaches IS development as a collective action problem and focus on how different actors frame the infrastructure as a public and private good, and how the framing process is underpinned by actors' different ideologies. We use our theoretical approach to examine the framing of the development of a regional health information infrastructure in Crete. Our analysis examines how different actors frame the infrastructure as a collective action good and explore their ideological positioning. We explore the struggle around meanings attributed to the good over time as being a public or private one in establishing or sustaining relations of power, and how legitimacy is challenged or reinforced. Finally, we develop contributions on the collective action challenges in infrastructure development and suggest how a polycentric approach to governance might be further developed to promote the ongoing cultivation of information infrastructures from the bottom up.
|keyword = information infrastructure,collective action,longitudinal research,healthcare,polycentric governance,framing,ideology,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Paradoxes and the Nature of Ambidexterity in IT Transformation Programs'''
{{header}}
{{article
|author= Robert Wayne Gregory,Mark Keil,Jan Muntermann,Magnus Mahring,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Though information technology (IT) transformation programs are gaining in importance, we know little about the nature of the challenges involved in such programs and how to manage them. Using grounded theory methodology, we conducted a multiyear case study of a large IT transformation program in a major commercial bank, during which we encountered the interrelated themes of paradoxes and ambidexterity. Grounded in our case, we construct a substantive theory of ambidexterity in IT transformation programs that identifies and explains the paradoxes that managers need to resolve in IT transformation programs. The ambidexterity areas we identified are (1) IT portfolio decisions (i.e., IT efficiency versus IT innovation), (2) IT platform design (i.e., IT standardization versus IT differentiation), (3) IT architecture change (i.e., IT integration versus IT replacement), (4) IT program planning (i.e., IT program agility versus IT project stability), (5) IT program governance (i.e., IT program control versus IT project autonomy), and (6) IT program delivery (i.e., IT program coordination versus IT project isolation). What weaves these six areas together is the combined need for IT managers to employ ambidextrous resolution strategies to ensure short-term IT contributions and continuous progress of IT projects while simultaneously working toward IT transformation program success as a foundation for IT-enabled business transformation. However, in addition to this commonality, we find that the nature of paradoxical tensions differs across the six areas and requires slightly different management strategies for paradox resolution. Ambidexterity areas (1), (2), and (3) are associated with IT transformation strategizing and, in addition to balancing short-and long-term goals, require the mutual accommodation and blending of business and IT interests in the spirit of IT-business partnering to achieve IT-enabled business change and IT-based competitiveness. Ambidexterity areas (4), (5), and (6) are associated with IT program and project execution and, in addition to balancing short-and long-term requirements, require a recurrent and dynamic act of balancing "local" needs at the IT project level and "global" needs at the IT program level.
|keyword = information technology,transformation programs,ambidexterity,paradoxical tensions,balancing,blending,grounded theory methodology,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Organizational Control, Incentive Contracts, and Knowledge Transfer in Offshore Business Process Outsourcing'''
{{header}}
{{article
|author= Ying Liu,Ravi Aron,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = We study the determinants of output quality in offshore business process outsourcing (BPO). Firms can exert control over output quality through incentives formally written into contracts and allow both clients and providers to manage the offshore agents creating a dual governance mechanism. We use a combination of two data sets, a cross sectional data set of 139 processes and a balanced panel data set comprising 21 processes with 36 observations per process, to investigate the impact of different factors on the quality of output of offshore BPO providers. Our findings point to the strong moderating effect of process codifiability on the dual governance mechanism. Process codifiability is not only associated with higher output quality, it also moderates the functioning of the dual governance mechanism and determines when the managerial efforts of the client and provider are substitutes and when they are complementary. We show that contractual incentives tied to quality are generally associated with a higher quality of output. Finally, we show that the use of process-level inter-organizational information systems also has a positive impact on the output quality of offshore BPO providers.
|keyword = business process outsourcing,offshoring,output quality,organizational control,empirical research,agency theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Market Positioning by IT Service Vendors Through Imitation'''
{{header}}
{{article
|author= Karen Ruckman,Nilesh Saraf,Vallabh Sambamurthy,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Information technology (IT) services vendors operate in a highly competitive but also institutional environment that render their service-line offerings mutually observable. This suggests that imitation of rivals' decisions can be an efficient means for IT vendors when reconfiguring their service-line offerings. To explore how such imitation unfolds in this sector, we estimate a series of logistic regression models of 116 IT vendors' service-line choices over three time periods. First, from the strategic imitation literature we identify the key imitation "referents," which is a group of firms or a single firm with specific traits, and we test the relative influence of each referent. All of our analysis includes these referents as predictors of service-line choice. Next, we tested more nuanced models using theoretically guided subsamples as follows. One, based on information systems (IS) literature, we consider the IT vendors as embedded in three distinct " institutional spheres," each corresponding to a knowledge domain, namely, technical, functional, and vertical industry domains. We separately examine imitation in each subsample corresponding to the three types of service lines. Two, based on strategy literature, we consider that the influence of the imitation referents differs when the choice under consideration is the addition of a new service line versus a withdrawal. Our results across all of these subsamples uncover a nuanced pattern of imitation that sometimes contrasts the full-sample results. The most prominent result is that although imitation is highly salient, the different imitation referents are not universally influential across all knowledge domains and between development versus withdrawal decisions. Specifically, the imitation of similar firms is widespread, whereas the imitation of largest firms or offering popular service-lines, which indicates bandwagon effects, are at play only selectively. This study contributes to the IS literature by laying a basis for a variety of research directions including resource spillovers and vicarious learning in IT sectors.
|keyword = IT outsourcing,institutional aspects of information systems,strategic management of IT,institutional theory,firm-level imitation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Early to Adopt and Early to Discontinue: The Impact of Self-Perceived and Actual IT Knowledge on Technology Use Behaviors of End Users'''
{{header}}
{{article
|author= Rohit Aggarwal,David Kryscynski,Vishal Midha,Harpreet Singh,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = For organizations to achieve the benefits of new information technology (IT) systems, their users must adopt and then actually use these new systems. Recent models help to articulate the potentially different explanations for why some users will adopt and then continue using new technologies, but these models have not explicitly incorporated IT knowledge. This is particularly important in contexts where the user base may be non-IT professionals-i.e., the users may vary substantially in their basic IT knowledge. We draw on psychology to argue that in situations where there is a wide variance in actual IT knowledge, there will often exist a U-shaped relationship between actual and self-perceived IT knowledge such that the least knowledgeable believe themselves to be highly knowledgeable. We then draw on individual-level adoption theories to argue that users with high self-perceived IT knowledge will be more likely to adopt new technologies and do so faster. We also draw on individual-level continuance theories to argue that users with low actual IT knowledge will be more likely to discontinue using new technologies and do so faster. We test our expectations using a proprietary data set of 225 sales professionals in a large Indian pharmaceutical company that is testing a new customer relationship management system. We find strong support for our hypotheses.
|keyword = IT knowledge,non-IT professionals,adoption,continuance,econometric analysis,healthcare,pharma,CRM,SaaS,cloud computing,self-assessment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Turnover or Turnaway? Competing Risks Analysis of Male and Female IT Professionals' Job Mobility and Relative Pay Gap'''
{{header}}
{{article
|author= Damien Joseph,Soon Ang,Sandra A. Slaughter,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = This study draws on distributive justice, human capital, and stigmatization theories to hypothesize relationships between relative pay gap and patterns of job mobility. Our study also expands the criterion space of job mobility by contrasting different job destinations when information technology (IT) professionals make job moves. We examine three job moves: (a) turnover to another IT job in a different firm, (b) turnaway-within to a non-IT job, and (c) turnaway-between to a different firm and a non-IT job. We analyze work histories spanning 28 years for 359 IT professionals drawn from the National Longitudinal Survey of Youth. We report three major findings. First, as hypothesized, larger relative pay gaps significantly increase the likelihood of job mobility. Second, IT males and IT females have different job mobility patterns. IT males are more likely to turn over than turn away-between when faced with a relative pay gap. Further, and contrary to predictions from human capital theory, IT males are more likely to turn away-within than turn over. This surprising finding suggests that the ubiquitous use of IT in other business functions may have increased the value of IT skills for non-IT jobs and reduced the friction of moving from IT to other non-IT positions. Third, and consistent with stigmatization arguments, IT females are more likely to turn away from IT than to turn over when faced with a relative pay gap. In fact, to reduce relative pay gaps, IT females tend to take on lower-status jobs that pay less than their IT jobs. We conclude this study with important theoretical, practical, and policy implications.
|keyword = information technology professionals,relative pay gap,turnover,turnaway,job mobility,stigmatization,human capital,survival analysis,competing risks,longitudinal,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Emergence of Online Community Leadership'''
{{header}}
{{article
|author= Steven L. Johnson,Hani Safadi,Samer Faraj,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Compared to traditional organizations, online community leadership processes and how leaders emerge are not well studied. Previous studies of online leadership have often identified leaders as those who administer forums or have high network centrality scores. Although communication in online communities occurs almost exclusively through written words, little research has addressed how the comparative use of language shapes community dynamics. Using participant surveys to identify leading online community members, this study analyzes a year of communication network history and message content to assess whether language use differentiates leaders from other core community participants. We contribute a novel use of textual analysis to develop a model of language use to evaluate the utterances of all participants in the community. We find that beyond communication network position-in terms of formal role, centrality, membership in the core, and boundary spanning-those viewed as leaders by other participants, post a large number of positive, concise posts with simple language familiar to other participants. This research provides a model to study online language use and points to the emergent and shared nature of online community leadership.
|keyword = online communities,leadership,natural language processing,knowledge management,network analysis,computer-mediated communication and collaboration,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Web Footprints of Firms: Using Online Isomorphism for Competitor Identification'''
{{header}}
{{article
|author= Gautam Pant,Olivia R. L. Sheng,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Competitive isomorphism refers to the phenomenon of competing firms becoming similar as they mimic each other under common market forces. With the growing presence of firms as well as their consumers and suppliers on the Web, we discover a parallel phenomenon of online isomorphism wherein the Web footprints of competing firms are found to overlap. We propose new online metrics based on the content, in-links, and outlinks of firms' websites to measure the presence of online isomorphism as well as uncover its utility in predicting competitor relationships. Through rigorous analysis involving more than 2,600 firms, we find that predictive models for competitor identification based on online metrics are largely superior to those using offline data such as Standard Industrial Classification codes and market values of firms. In addition, combining online and offline metrics can boost the predictive performance. We also find that such models are valuable for identifying nuances of competitor relationships such as asymmetry and the role of industrial divisions. Furthermore, the suggested predictive models can effectively rank firms in an industrial division by their likelihood of being competitors to a focal firm as well as identify new future competitors, thus adding to a portfolio of evidence indicating their utility for managers and analysts.
|keyword = isomorphism,competitor identification,Web metrics,predictive models,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Role of Social Media in Social Change: An Analysis of Collective Sense Making During the 2011 Egypt Revolution'''
{{header}}
{{article
|author= Onook Oh,Chanyoung Eom,H. R. Rao,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = This study explores the role of social media in social change by analyzing Twitter data collected during the 2011 Egypt Revolution. Particular attention is paid to the notion of collective sense making, which is considered a critical aspect for the emergence of collective action for social change. We suggest that collective sense making through social media can be conceptualized as human-machine collaborative information processing that involves an interplay of signs, Twitter grammar, humans, and social technologies. We focus on the occurrences of hashtags among a high volume of tweets to study the collective sense-making phenomena of milling and keynoting. A quantitative Markov switching analysis is performed to understand how the hashtag frequencies vary over time, suggesting structural changes that depict the two phenomena. We further explore different hashtags through a qualitative content analysis and find that, although many hashtags were used as symbolic anchors to funnel online users' attention to the Egypt Revolution, other hashtags were used as part of tweet sentences to share changing situational information. We suggest that hashtags functioned as a means to collect information and maintain situational awareness during the unstable political situation of the Egypt Revolution.
|keyword = social media,social change,2011 Egypt Revolution,Twitter,hashtag,sociomateriality,collective sense making,human-machine collaborative information process,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Perceived Firm Attributes and Intrinsic Motivation in Sponsored Open Source Software Projects'''
{{header}}
{{article
|author= Sebastian Spaeth,Georg von Krogh,Fang He,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2015
|abstract = Voluntary contributions are crucial to the success of open source software (OSS) projects. Firms sponsoring OSS projects may face substantial challenges in soliciting such contributions, since volunteer participants are neither regulated by an employment contract nor offered financial incentives. Although prior work has shown the positive impact of motivation on the effort expended by volunteer participants, there is limited understanding of how specific firm attributes shape volunteers' intrinsic motivation. We offer a theoretical model of how the perceived community-based credibility and openness of the sponsoring firm have a positive impact on the intrinsic motivation of volunteer participants. The model is explored using survey data on volunteer participants from two sponsored OSS projects. Results show that a sponsoring firm's community-based credibility (OSS developers' perception of its expertise and trustworthiness) and openness (its mutual knowledge exchange with the community) strengthen the volunteer participants' social identification with the firm-sponsored community, which in turn reinforces their intrinsic motivation to participate. Moreover, the perceived community-based credibility of a sponsoring firm directly enhances volunteer participants' intrinsic motivation, whereas perceived openness fails to affect motivation without the mediating mechanism of social identification. Implications for firms seeking voluntary contributions for their sponsored OSS projects are discussed.
|keyword = open source software,firm sponsorship,firm attributes,intrinsic motivation,voluntary contributions,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''MOTIVATING EMPLOYEES TO EXPLORE COLLABORATION TECHNOLOGY IN TEAM CONTEXTS'''
{{header}}
{{article
|author= Likoebe M. Maruping,Massimo Magni,
|source= MIS QUARTERLY
|year= 2015
|abstract = Firms are increasing their investments in collaboration technologies in order to leverage the intellectual resources embedded in their employees. Research on post-adoption use of technology suggests that the true gains from such investments are realized when users explore various system features and attempt to incorporate them into their work practices. However, the literature has been silent about how to promote such behavior when individuals are embedded in team settings, where members' actions are interdependent. This research develops a multilevel model that theorizes the cross-level influence of team empowerment on individual exploration of collaboration technology. Further, it identifies two cognitions-intention to continue exploring and expectation to continue exploring-that are oriented toward exploring ways to incorporate implemented technology into daily work routines over time. A 12-month field study of 212 employees in 48 organizational work teams was conducted to test the multilevel research model. The results provide support for the hypotheses, with team empowerment having a positive cross-level influence on intention to continue exploring and expectation to continue exploring and these, in turn, mediating the cross-level influence of team empowerment on individual exploration of collaboration technology.
|keyword = Collaboration technology,IT exploration,extended use,multilevel theory,cross-level mediation,teams,technology use,empowerment,post-implementation,post-adoption use,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''HOW DOES THE INTERNET AFFECT THE FINANCIAL MARKET? AN EQUILIBRIUM MODEL OF INTERNET-FACILITATED FEEDBACK TRADING'''
{{header}}
{{article
|author= Xiaoquan (Michael) Zhang,Lihong Zhang,
|source= MIS QUARTERLY
|year= 2015
|abstract = The ease of Internet stock trading has lured relatively inexperienced investors into the financial markets. This paper is a study of the consequences of the influx of these uninformed traders with a dynamic equilibrium framework. The results show that these strategic, uninformed online traders who adopt feedback strategies cannot outperform those who do not follow feedback strategies and that feedback trading cannot affect market equilibrium. The results also show that an informed trader's equilibrium strategy and expected profit remain unchanged with or without feedback trading. The presence of feedback trading in the market does not affect the speed at which information gets incorporated into prices. If uninformed traders aggregately adopt a more aggressive feedback trading strategy, they bear a higher risk. It is therefore important to manage and contain these uninformed traders' risks. The implications for regulating and designing such Internet trading systems are also discussed.
|keyword = Financial information,financial market,feedback strategy,market stability,online trading,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''HOW DO ENTERPRISE RESOURCE PLANNING SYSTEMS AFFECT FIRM RISK? POST-IMPLEMENTATION IMPACT'''
{{header}}
{{article
|author= Feng Tian,Sean Xin Xu,
|source= MIS QUARTERLY
|year= 2015
|abstract = Managing firm risk, or firm performance volatility, is a key task for contemporary firms. Although information technology ( IT) has been generally viewed as an effective information processing tool that enables firms to better cope with uncertainty, thus holding the potential to mitigate firm performance volatility, evidence to support this view is lacking in the literature. We theorize that enterprise resource planning (ERP) systems, a major type of enterprise IT applications, can help reduce firm risk and, in particular, we argue that, to uncover the risk reduction effect of ERP systems, a research focus on the post-implementation stage is needed. Based on a sample of 2,127 firm-year observations, we found that ERP systems in the post-implementation stage were associated with reduced firm risk, and that the risk reduction effect was stronger for ERP systems with a greater scope of functional and operational modules, especially functional modules. We further found that, on average, the risk reduction effect of ERP systems became greater when firms' operating environments feature higher uncertainty, while the risk reduction associated with fully deploying ERP system modules seem to level off as environmental uncertainty increases. These findings extend our understanding of the business value of ERP systems by shedding light on the risk reduction benefit of ERP systems.
|keyword = ERP systems,firm risk,performance volatility,post-implementation,environmental uncertainty,ERP system scope,business value,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INVESTING IN INFORMATION SYSTEMS: ON THE BEHAVIORAL AND INSTITUTIONAL SEARCH MECHANISMS UNDERPINNING HOSPITALS' IS INVESTMENT DECISIONS'''
{{header}}
{{article
|author= Torsten Oliver Salge,Rajiv Kohli,Michael Barrett,
|source= MIS QUARTERLY
|year= 2015
|abstract = This study integrates tenets of the behavioral theory of the firm and neo-institutional theory to identify four recurring search mechanisms that are expected to influence hospital managers' information systems investment decisions. To account for the critical role of regulation in healthcare, senior managers' reliance on each of these four search mechanisms is hypothesized to be contingent upon their hospital's regulative legitimacy. Analyses of panel data from all 153 public nonspecialist hospital organizations in England reveal that hospital managers invest in IS not only to find solutions to performance shortfalls (problemistic search), but also to achieve continuity and predictability in resource allocation (institutionalized search) and signal conformity with external norms and expectations (mimetic search). We find that the desire to make adequate use of uncommitted financial resources (slack search) is salient only among hospitals with low levels of regulative legitimacy. These new insights into the motives that trigger-and constrain-senior managers' IS investment decisions will help IS managers to strengthen their case for IS investment and guide policy makers in how best to allocate resources to IS in healthcare and possibly beyond.
|keyword = Decision making,IS investment,business value of IT,behavioral theory of the firm,institutional theory,regulative legitimacy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INSIDER THREATS IN A FINANCIAL INSTITUTION: ANALYSIS OF ATTACK-PRONENESS OF INFORMATION SYSTEMS APPLICATIONS'''
{{header}}
{{article
|author= Jingguo Wang,Manish Gupta,H. Raghav Rao,
|source= MIS QUARTERLY
|year= 2015
|abstract = This study investigates the risk of insider threats associated with different applications within a financial institution. Extending routine activity theory (RAT) from criminology literature to information systems security, hypotheses regarding how application characteristics, namely value, inertia, visibility, accessibility, and guardians, cause applications to be exposed to insider threats are developed. Routine activity theory is synthesized with survival modeling, specifically a Weibull hazard model, and users' system access behavior is investigated using seven months of field data from the institution. The inter-arrival times of two successive unauthorized access attempts on an application are employed as the measurement of risk. For a robustness check, the daily number of unauthorized attempts experienced by an application as an alternative measurement of risk are introduced and a zero-inflated Poisson-Gamma model is developed. The Markov chain Monte Carlo (MCMC) method is used for model estimations. The results of the study support the empirical application of routine activity theory in understanding insider threats, and provide a picture of how different applications have different levels of exposure to such threats. Theoretical and practical implications for risk management regarding insider threats are discussed. This study is among the first that uses behavioral logs to investigate victimization risk and attack proneness associated with information assets.
|keyword = Information security,insider threats,routine activity theory,information systems applications,MCMC,risk quantification,dark side of IS,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AN ENHANCED FEAR APPEAL RHETORICAL FRAMEWORK: LEVERAGING THREATS TO THE HUMAN ASSET THROUGH SANCTIONING RHETORIC'''
{{header}}
{{article
|author= Allen C. Johnston,Merrill Warkentin,Mikko Siponen,
|source= MIS QUARTERLY
|year= 2015
|abstract = Fear appeals, which are used widely in information security campaigns, have become common tools in motivating individual compliance with information security policies and procedures. However, empirical assessments of the effectiveness of fear appeals have yielded mixed results, leading IS security scholars and practitioners to question the validity of the conventional fear appeal framework and the manner in which fear appeal behavioral modeling theories, such as protection motivation theory (PMT), have been applied to the study of information security phenomena. We contend that the conventional fear appeal rhetorical framework is inadequate when used in the context of information security threat warnings and that its primary behavioral modeling theory, PMT, has been misspecified in the extant information security research. Based on these arguments, we propose an enhanced fear appeal rhetorical framework that leverages sanctioning rhetoric as a secondary vector of threats to the human asset, thereby adding the dimension of personal relevance, which is critically absent from previous fear appeal frameworks and PMT-grounded security studies. Following a hypothetical scenario research approach involving the employees of a Finnish city government, we validate the efficacy of the enhanced fear appeal framework and determine that informal sanction rhetoric effectively enhances conventional fear appeals, thus providing a significant positive influence on compliance intentions.
|keyword = Fear appeals,protection motivation theory,deterrence theory,information security,threats,responses,sanctions,rhetoric,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''SERVICE INNOVATION: A SERVICE-DOMINANT LOGIC PERSPECTIVE'''
{{header}}
{{article
|author= Robert F. Lusch,Satish Nambisan,
|source= MIS QUARTERLY
|year= 2015
|abstract = In this article, we offer a broadened view of service innovation-one grounded in service-dominant logic-that transcends the tangible-intangible and producer-consumer divides that have plagued extant research in this area. Such a broadened conceptualization of service innovation emphasizes (1) innovation as a collaborative process occurring in an actor-to-actor (A2A) network, (2) service as the application of specialized competences for the benefit of another actor or the self and as the basis of all exchange, (3) the generativity unleashed by increasing resource liquefaction and resource density, and (4) resource integration as the fundamental way to innovate. Building on these core themes, we offer a tripartite framework of service innovation: (1) service ecosystems, as emergent A2A structures actors create and recreate through their effectual actions and which offer an organizing logic for the actors to exchange service and cocreate value; (2) service platforms, which enhance the efficiency and effectiveness of service exchange by liquefying resources and increasing resource density (facilitating easy access to appropriate resource bundles) and thereby serve as the venue for innovation; and (3) value cocreation, which views value as cocreated by the service offer(er) and the service beneficiary (e. g., customer) through resource integration and indicate the need for mechanisms to support the underlying roles and processes. In discussing these components, we consider the role of information technology-both as an operand resource and as an operant resource-and then examine the implications for research and practice in digitally enabled service innovation.
|keyword = Service innovation,S-D logic,platforms,ecosystems,value cocreation,collaboration,resource integration,institutions,architecture,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE VALUE OF SELF-SERVICE: LONG-TERM EFFECTS OF TECHNOLOGY-BASED SELF-SERVICE USAGE ON CUSTOMER RETENTION'''
{{header}}
{{article
|author= Anne Scherer,Nancy V. Wuenderlich,Florian von Wangenheim,
|source= MIS QUARTERLY
|year= 2015
|abstract = Advancements in information technology have changed the way customers experience a service encounter and their relationship with service providers. Especially technology-based self-service channels have found their way into the 21st century service economy. While research embraces these channels for their cost-efficiency, it has not examined whether a shift from personal to self-service affects customer-firm relationships. Drawing from the service-dominant logic and its central concept of value-in-context, we discuss customers' value creation in self-service and personal service channels and examine the long-term impact of these channels on customer retention. Using longitudinal customer data, we investigate how the ratio of self-service versus personal service use influences customer defection over time. Our findings suggest that the ratio of self-service to personal service used affects customer defection in a U-shaped manner, with intermediate levels of both self-service and personal service use being associated with the lowest likelihood of defection. We also find that this effect mitigates over time. We conclude that firms should not shift customers toward self-service channels completely, especially not at the beginning of a relationship. Our study underlines the importance of understanding when and how self-service technologies create valuable customer experiences and stresses the notion of actively managing customers' cocreation of value.
|keyword = Self-service,e-service,value-in-context,customer retention,customer defection,longitudinal,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE ALGORITHM AND THE CROWD: CONSIDERING THE MATERIALITY OF SERVICE INNOVATION'''
{{header}}
{{article
|author= Wanda J. Orlikowski,Susan V. Scott,
|source= MIS QUARTERLY
|year= 2015
|abstract = This special issue acknowledges important innovations in the world of service and within this domain we are particularly interested in exploring the rise and influence of web-based crowd-sourcing and algorithmic rating and ranking mechanisms. We suggest that a useful way to make sense of these digital service innovations and their novel implications is to recognize that they are materialized in practice. We thus need effective conceptual and analytical tools that allow us to take materiality seriously in our studies of service innovation. To this end, we propose some theoretical ideas relating to a sociomaterial perspective, and then highlight empirically how this perspective helps us analyze the specific service materializations enacted through the algorithmic configuring of crowd-sourced data, and how these make a difference in practice to the outcomes produced.
|keyword = Algorithms,crowds,innovation,materiality,performativity,practice,sociomateriality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DISTRIBUTED TUNING OF BOUNDARY RESOURCES: THE CASE OF APPLE'S IOS SERVICE SYSTEM'''
{{header}}
{{article
|author= Ben Eaton,Silvia Elaluf-Calderwood,Carsten Sorensen,
|source= MIS QUARTERLY
|year= 2015
|abstract = The digital age has seen the rise of service systems involving highly distributed, heterogeneous, and resource-integrating actors whose relationships are governed by shared institutional logics, standards, and digital technology. The cocreation of service within these service systems takes place in the context of a paradoxical tension between the logic of generative and democratic innovations and the logic of infrastructural control. Boundary resources play a critical role in managing the tension as a firm that owns the infrastructure can secure its control over the service system while independent firms can participate in the service system. In this study, we explore the evolution of boundary resources. Drawing on Pickering's (1993) and Barrett et al.'s (2012) conceptualizations of tuning, the paper seeks to forward our understanding of how heterogeneous actors engage in the tuning of boundary resources within Apple's iOS service system. We conduct an embedded case study of Apple's iOS service system with an in-depth analysis of 4,664 blog articles concerned with 30 boundary resources covering 6 distinct themes. Our analysis reveals that boundary resources of service systems enabled by digital technology are shaped and reshaped through distributed tuning, which involves cascading actions of accommodations and rejections of a network of heterogeneous actors and artifacts. Our study also shows the dualistic role of power in the distributed tuning process.
|keyword = Service system innovation,mobile platform,ecosystem,digital infrastructure,boundary resource dynamics,tuning,sociomateriality,iOS,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''BRIDGING THE SERVICE DIVIDE THROUGH DIGITALLY ENABLED SERVICE INNOVATIONS: EVIDENCE FROM INDIAN HEALTHCARE SERVICE PROVIDERS'''
{{header}}
{{article
|author= Shirish C. Srivastava,G. Shainesh,
|source= MIS QUARTERLY
|year= 2015
|abstract = The digital divide is usually conceptualized through goods-dominant logic, where bridging the divide entails providing digital goods to disadvantaged segments of the population. This is expected to enhance their digital capabilities and thus to have a positive influence on the digital outcomes (or services) experienced. In contrast, this study is anchored in an alternative service-dominant logic and posits that viewing the divide from a service perspective might be better suited to the context of developing countries, where there is a huge divide across societal segments in accessing basic services such as healthcare and education. This research views the prevailing differences in the level of services consumed by different population segments (service divide) as the key issue to be addressed by innovative digital tools in developing countries. The study posits that information and communication technologies (ICTs) can be leveraged to bridge the service divide to enhance the capabilities of service-disadvantaged segments of society. But such service delivery requires an innovative assembly of ICT as well as non-ICT resources. Building on concepts from service-dominant logic and service science, this paper aims to understand how such service innovation efforts can be orchestrated. Specifically, adopting a process view, two Indian enterprises that have developed sustainable telemedicine healthcare service delivery models for the rural population in India are examined. The study traces the configurations of three interactional resources-knowledge, technology, and institutions-through which value-creating user-centric objectives of increasing geographical access and reducing cost are achieved. The theoretical contributions are largely associated with unearthing and understanding how the three interactional resources were orchestrated for service-centric value creation in different combinative patterns as resource exploitation, resource combination, and value reinforcement. The analysis also reveals the three distinct stages of service innovation evolution (idea and launch, infancy and early growth, and late growth and expansion), with a distinct shift in the dominant resource for each stage. Through an inductive process, the study also identifies four key enablers for successfully implementing these ICT-enabled service innovations: obsessive customer empathy, belief in the transformational power of ICT, continuous recursive learning, and efficient network orchestration.
|keyword = Service innovation,developing countries,service divide,healthcare,process view,service science,service systems,social entrepreneurship,society,digital divide,India,institutions,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Last Research Mile: Achieving Both Rigor and Relevance in Information Systems Research'''
{{header}}
{{article
|author= Jr. Jay F. Nunamaker,Robert O. Briggs,Douglas C. Derrick,Gerhard Schwabe,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = From our desk chairs it may be tempting to work up an idea, build a quick prototype, test it in a lab, and say, "Our work here is done; the rest is merely details." More scholarly knowledge awaits discovery, however, by researchers who shepherd an information systems (IS) solution through the last research mile, that is, through successful transition to the workplace. Going the last research mile means using scientific knowledge and methods to address important unsolved classes of problems for real people with real stakes in the outcomes. The last research mile proceeds in three stages: proof-of-concept research to demonstrate the functional feasibility of a solution; proof-of-value research to investigate whether a solution can create value across a variety of conditions; and proof-of-use research to address complex issues of operational feasibility. The last research mile ends only when practitioners routinely use a solution in the field. We argue that going the last research mile negates the assumption that one must trade off rigor and relevance, showing it to be it a false dilemma. Systems researchers who take their solutions through the last research mile may ultimately have the greatest impact on science and society. We demonstrate the last research mile with cases from our own work and the work of others spanning more than forty years.
|keyword = design science,prototypes,research methodology,research rigor,systems research,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Barriers to Interorganizational Knowledge Transfer in Post-Hospital Care Transitions: Review and Directions for Information Systems Research'''
{{header}}
{{article
|author= Shi Ying Lim,Sirkka L. Jarvenpaa,Holly J. Lanham,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Post-hospital care transitions involve coordination and continuity of care from hospital providers to patients and community providers. These care transitions represent a domain of high-risk interorganizational collaborations. However, a conversation about how health information technology (HIT) can enhance interorganizational knowledge transfer during care transitions is largely absent in the information systems literature. We conducted a review of qualitative studies of post-hospital care transitions to better understand barriers to knowledge transfer in high-risk interorganizational collaborations. Our analysis highlights how time pressures inhibit multilateral knowledge transfers, accommodation of fluctuating absorptive capacity, and reconciliation of knowledge and goal conflicts. We advance research questions that focus on HIT capabilities to ease these barriers.
|keyword = absorptive capacity,health information technology,health-care transitions,interorganizational knowledge transfer,IS design,knowledge management,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Anatomy of Successful Business Models for Complex Services: Insights from the Telemedicine Field'''
{{header}}
{{article
|author= Christoph Peters,Ivo Blohm,Jan Marco Leimeister,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Telemedicine services may improve the quality of life of individuals while also reducing the costs of service provisioning. They represent an important but as yet understudied type of complex services that integrates many stakeholders acting in service value networks. These complex services typically comprise a combination of information technology (IT) services and highly person-oriented, non-IT services, and are characterized by long service delivery periods. In such an environment, it is particularly difficult to generate successful and sustainable business models, which are necessary for the widespread provision of telemedicine services. Following a design research approach, we develop and evaluate the CompBizMod framework, a morphological box allowing for: (1) the analysis, description, and classification of telemedicine business models, (2) the identification of white spots for future business opportunities, (3) and the identification of patterns for successful business models. We contribute to the literature by presenting a specific business model framework and identifying three business model patterns in the telemedicine industry. We exhibit how business models for complex services can be decomposed into their constituent elements and present an easy and replicable approach for identifying business model patterns in a given industry.
|keyword = analysis frameworks,business model,business model pattern,complex service,telemedicine,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''It Is Not Just About Competition with "Free": Differences Between Content Formats in Consumer Preferences and Willingness to Pay'''
{{header}}
{{article
|author= Benedikt Berger,Christian Matt,Dennis M. Steininger,Thomas Hess,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = While consumption of content in offline formats continues to decline, many providers are still struggling to monetize their content online, because consumers' willingness to pay (WTP) for content in online formats is low. The availability of free content on the Internet is often considered the primary reason for this issue. However, we hold that the lower WTP is also related to a lower appraisal of online formats per se. Using a conjoint analysis and the example of newspaper subscriptions, we explore differences in consumer preferences and WTP between offline and online formats. Our results show that after price, format is the second-most important attribute of a newspaper subscription. While consumers still prefer the printed newspaper to any online format, WTP differs across online formats and is strongly associated with device ownership. Our study provides a novel understanding of the previously neglected factor content format and its importance for content providers.
|keyword = conjoint analysis,consumer preferences,content formats,digital device ownership,digital media,media industries,willingness to pay,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Evaluating Team Collaboration Quality: The Development and Field Application of a Collaboration Maturity Model'''
{{header}}
{{article
|author= Imed Boughzala,Gert-Jan De Vreede,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = The quality of collaboration directly affects the quality of an organization's outcomes and performance. Trends like globalization and increased product and service complexity have pushed organizations to become more and more reliant on collaboration in distributed, cross-disciplinary, cross-cultural, virtual teams. The present research is based on an applied science/engineering (AS/E) research paradigm to address an important class of unsolved problems-measuring the quality of collaboration within and across organizational boundaries. This paper presents a collaboration maturity model (Col-MM) to assess an organization's team collaboration maturity as a first step toward a generalizable solution to that class of problems. The Col-MM is intended to be sufficiently generic to be applied to different organizational and team settings and usable by practitioners for conducting self-assessments. The Col-MM was developed during a series of focus group meetings with professionals (business unit managers). The model was then piloted and subsequently applied in a field study in an automotive company. This paper reports on the development and field application of the Col-MM. It contributes to the collaboration science literature, theory, and practice through a detailed AS/E study that develops a maturity model and a system for administering it that provides proof of value and effective use in the field.
|keyword = collaboration maturity,collaboration maturity model,collaboration quality,collaboration technology,online collaboration,organizational performance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Strategic Relevance of Organizational Virtues Enabled by Information Technology in Organizational Innovation'''
{{header}}
{{article
|author= Sutirtha Chatterjee,Gregory Moody,Paul Benjamin Lowry,Suranjan Chakraborty,Andrew Hardin,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = The central theme of this paper is that information technology (IT) can serve to create ethical organizations endowed with virtuous characteristics, and that such ethical organizations can innovate better in today's dynamic market environment. Drawing on the notion of virtue ethics propounded by the Greek philosopher Aristotle, we theorize that core organizational IT affordances influence the development of organizational virtues, which in turn influence organizational improvisational capabilities and innovation. We propose the "IT-virtues-innovation" (IVI) model and test it using a cross-organizational survey of 250 employees from various organizations in the United States. Our findings largely support our proposal that IT affordances positively influence organizational virtues, which then influence organizational improvisational capabilities, thus improving organizational innovation. This paper contributes to the understanding of organizational innovation by articulating the strategic usefulness of IT-enabled organizational ethics, and it explains how IT-enabled ethical competence (virtues) influences strategic competence (improvisational capabilities and innovation).
|keyword = ethical organizations,information technology affordances,information technology strategy,organizational capabilities,organizational courage,organizational innovation,organizational justice,organizational memory affordance,organizational temperance,organizational virtues,organizational wisdom,process management affordance,virtue ethics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Machiavellianism or Morality: Which Behavior Pays Off In Online Innovation Contests?'''
{{header}}
{{article
|author= Katja Hutter,Johann Fueller,Julia Hautz,Volker Bilgram,Kurt Matzler,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Prior research on user behavior in online innovation contests has mainly focused on factors that positively impact prosocial, collaborative behavior, which should ultimately lead to innovative outcomes. However, little is known about the effects of more negative personal characteristics that might result in more competitive, antisocial, and even unethical behavior. This paper considers Machiavellianism as one of the traits that constitute the "dark triad of personality" and explores the relationship between Machiavellianism and participants' contribution behavior in online innovation contests. Specifically we investigate how Machiavellian characteristics influence individuals' contribution intensity, communication, and interaction behavior within the contest community as well as the quality and kind of their contributions. This study relies on multisource individual-level data from a large innovation contest in the field of public transportation. We find that the three dimensions of Machiavellianism-distrust of others, amorality, and desire for status-have very distinct behavioral consequences in the context of online innovation contests. Specifically, the oppositional consequences of amoral manipulation and striving for status on the one hand and showing distrust of others on the other hand concerning contribution quantity and contribution quality are found. This study contributes to a deeper understanding of negative personality traits such as Machiavellianism as powerful predictors of behavior and of success within competitive innovation environments and leads to important managerial implications regarding the design and management of innovation contests.
|keyword = business ethics,co-creation,competitive behavior,crowd-sourcing,innovation,innovation contests,Machiavellianism,online contests,personality traits,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Taxonomy of Evaluation Methods for Information Systems Artifacts'''
{{header}}
{{article
|author= Nicolas Prat,Isabelle Comyn-Wattiau,Jacky Akoka,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Artifacts, such as software systems, pervade organizations and society. In the field of information systems (IS) they form the core of research. The evaluation of IS artifacts thus represents a major issue. Although IS research paradigms are increasingly intertwined, building and evaluating artifacts has traditionally been the purview of design science research (DSR). DSR in IS has not reached maturity yet. This is particularly true of artifact evaluation. This paper investigates the "what" and the "how" of IS artifact evaluation: what are the objects and criteria of evaluation, the methods for evaluating the criteria, and the relationships between the "what" and the "how" of evaluation? To answer these questions, we develop a taxonomy of evaluation methods for IS artifacts. With this taxonomy, we analyze IS artifact evaluation practice, as reflected by ten years of DSR publications in the basket of journals of the Association for Information Systems (AIS). This research brings to light important relationships between the dimensions of IS artifact evaluation, and identifies seven typical evaluation patterns: demonstration; simulation-and metric-based benchmarking of artifacts; practice-based evaluation of effectiveness; simulation- and metric-based absolute evaluation of artifacts; practice-based evaluation of usefulness or ease of use; laboratory, student-based evaluation of usefulness; and algorithmic complexity analysis. This study also reveals a focus of artifact evaluation practice on a few criteria. Beyond immediate usefulness, IS researchers are urged to investigate ways of evaluating the long-term organizational impact and the societal impact of artifacts.
|keyword = artifact evaluation,content analysis,design evaluation,design science,system design,taxonomy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Competition Between Open Source and Proprietary Software: Strategies for Survival'''
{{header}}
{{article
|author= Michael Sacks,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = There are two puzzles in the software competition literature: whether both proprietary and open source software will survive and how producers of proprietary software differentiate themselves from open source competition. I address both puzzles by analyzing competition between a firm producing proprietary software and a community producing open source software. If the firm faces no competition, then the software caters to less technologically savvy individuals. When facing competition, the open source software caters to the most technologically savvy individuals, leading the firm to target even less savvy individuals than it would when acting as a monopolist in order to differentiate its software from the open source option. The open source movement, then, may not be an unalloyed success as the growth in open source can be tied to deterioration in the proprietary software. Given that both types of software survive by catering to different segments of the market, an important avenue for research will be to analyze the stability of the underlying segments and the corresponding welfare implications.
|keyword = differentiation,endogenous fixed costs,heterogeneous consumers,Hotelling competition,mixed duopoly,open source software,proprietary software,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Task Division for Team Success in Crowdsourcing Contests: Resource Allocation and Alignment Effects'''
{{header}}
{{article
|author= Indika Dissanayake,Jie Zhang,Bin Gu,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Advances in information technology bring changes to the nature of work by facilitating companies to go beyond the wisdom of their workforce and tap into the "wisdom of the crowd" via online crowdsourcing contests. In these contests, active and motivated individuals collaborate in the form of self-organized teams that compete for rewards. Using a rich data set of 732 teams in 52 contests collected from the crowdsourcing platform, Kaggle.com, from its launch in April 2010 to July 2012, we studied how the allocation of members' social and intellectual capital within a virtual team affects team performance in online crowdsourcing contests. Our econometric analysis uses a rank-ordered logistic regression model, and suggests that the effect of a member's social and intellectual capital on team performance varies depending on his or her roles. Though a team leader's social capital and a team expert's intellectual capital significantly influence team performance, a team leader's intellectual capital and a team expert's social capital do not. Further, we found that the alignment of a member's social and intellectual capital within a team has a significant influence on team performance. Moreover, the intensity of the competition moderates the impact. When a contest is highly competitive, the social and intellectual capital alignment negatively affects team performance, and when the competitive intensity is low, this alignment positively affects team performance. Our findings provide insights into improving performance in team-based competitions in crowdsourcing communities.
|keyword = crowdsourcing,crowdsourcing contests,econometrics,intellectual capital,social capital,social network analysis,team competition,virtual teams,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Family Preferences Concerning Online Privacy, Data Mining, and Targeted Ads: Regulatory Implications'''
{{header}}
{{article
|author= Eric K. Clemons,Joshua S. Wilson,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Young Internet users engage in risky or inappropriate behavior online that could either be embarrassing or harmful to their future. As importantly, young Internet users engage in online activities that reveal a great deal about the cost to serve them and their willingness to pay for goods and services, which could be used against them by well-informed sellers. Educational applications that collect users' information are becoming ubiquitous in the classroom, presenting the opportunity for students' data to be mined. We are not aware of prior studies that examine parental or students' attitudes and preferences toward data mining of educational application accounts, and how these attitudes differ across several countries. We used three survey instruments to measure parents' and students' attitudes toward data mining of educational applications. Parents in all countries studied prefer far less data mining of students' online activities than seems to be the current practice. Most importantly, aversion to data mining does not seem to be correlated with awareness of current practices of data mining of teens' activities. This study highlights regulatory alternatives and suggests future research and future data requirements for designing appropriate regulatory interventions. The nature of the intervention will be guided by the nature of the causes of inappropriate online behavior and inappropriate selection of educational software. Intervention could range from no regulation needed, through providing greater transparency, to new and detailed legal requirements that software providers must meet.
|keyword = data mining,educational software,online behavior,online teen behavior,privacy,privacy regulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Industry-Level Analysis of Information Technology Return and Risk: What Explains the Variation?'''
{{header}}
{{article
|author= Fei Ren,Sanjeev Dewan,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Motivated by the wide dispersion in the returns on the use of information technology (IT) across industries, we conduct an industry-level examination of IT return and risk, focusing on the moderating role of industry competition, regulation, and technological change. We address the following research questions: What is the impact of IT investment on the return and risk dimensions of industry financial performance? How do industry characteristics moderate the relationship between IT investment and industry performance? Our analysis of these questions finds that higher levels of industry competition are associated with higher IT productivity (contribution of IT to value-added output), lower IT profitability (contribution of IT to industry average return on assets [ROA]), and higher IT risk (contribution of IT to ex ante variability of ROA). This is consistent with the notion that competition induces riskier IT investments, despite the fact that returns tend to be competed away. Higher levels of industry regulation are associated with lower IT returns in both productivity and profitability, but also lower IT risk. Finally, a higher rate of technological change induces both higher IT returns and higher IT risk. A variety of tests indicate that our results are robust. Our results shed light on factors that drive variation in IT performance across industries, and provide useful industry-level performance benchmarks of the return and risk impacts of IT investments.
|keyword = competition,industry-level analysis,information technology investment,IT return and risk,IT value,productivity,profitability,regulation,technological change,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding the Dynamics of Service-Oriented Architecture Implementation'''
{{header}}
{{article
|author= Xitong Li,Stuart E. Madnick,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Despite the potential benefits, many organizations have failed in service-oriented architecture (SOA) implementation projects. Prior research often used a variance perspective and neglected to explore the complex interactions and timing dependencies between the critical success factors. This study adopts a process perspective to capture the dynamics while providing a new explanation for the mixed outcomes of SOA implementation. We develop a system dynamics model and use simulation analysis to demonstrate the phenomenon of "tipping point." That is, under certain conditions, even a small reduction in the duration of normative commitment can dramatically reverse, from success to failure, the outcome of an SOA implementation. The simulation results also suggest that (1) the duration of normative commitment can play a more critical role than the strength, and (2) the minimal duration of normative commitment for a successful SOA implementation is associated positively with the information delay of organizational learning of SOA knowledge. Finally, we discuss the theoretical causes and organizational traps associated with SOA implementation to help IT managers make better decisions about their implementation projects.
|keyword = normative commitment,organizational traps,service-oriented architecture (SOA),system dynamics,tipping point,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Contextualized Relationship Between Knowledge Sharing and Performance in Software Development'''
{{header}}
{{article
|author= Muammer Ozer,Doug Vogel,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = We study how the knowledge that software developers receive from other software developers in their company impacts their performance. We also study the boundary conditions of this relationship. The results of our empirical study indicate that receiving knowledge from other software developers in the company is positively related to the performance of the knowledge-receiving software developers. Moreover, this relationship was stronger when the software developers had high rather than low task autonomy, when they had high- rather than low-quality social exchanges with their supervisors, and when the software development firms used formal knowledge utilization processes. Theoretically, these results contribute to a better understanding of the processes through which software developers utilize the knowledge that they receive from their peers in the firm. Practically, they show software development firms how emphasizing the task, social, and institutional dimensions of the software development process can help them increase knowledge utilization and performance in software development.
|keyword = knowledge sharing,software developers,software development,software-development performance,systems design and implementation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding Members' Active Participation in Online Question-and-Answer Communities: A Theory and Empirical Analysis'''
{{header}}
{{article
|author= Lara Khansa,Xiao Ma,Divakaran Liginlal,Sung S. Kim,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Community-based question-and-answer (Q&A) websites have become increasingly popular in recent years as an alternative to general-purpose Web search engines for open-ended complex questions. Despite their unique contextual characteristics, only a handful of Q&A websites have been successful in sustaining members' active participation that, unlike lurking, consists of not only posting questions but also answering others' inquiries. Because the specific design of the information technology artifacts on Q&A websites can influence their level of success, studying leading Q&A communities such as Yahoo! Answers (YA) provides insights into more effective design mechanisms. We tested a goal-oriented action framework using data from 2,920 YA users, and found that active online participation is largely driven by artifacts (e.g., incentives), membership (e.g., levels of membership and tenure), and habit (e.g., past behavior). This study contributes to the information systems literature by showing that active participation can be understood as the setting, pursuit, and automatic activation of goals.
|keyword = active participation,dynamic panel data analysis,goal-oriented action,habit,incentives,online community,online question-and-answer community,system-generated data,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Social Media and Brand Purchase: Quantifying the Effects of Exposures to Earned and Owned Social Media Activities in a Two-Stage Decision Making Model'''
{{header}}
{{article
|author= Karen Xie,Young-Jin Lee,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = This study investigates the effects of exposures to earned and owned social media activities and their interaction on brand purchase in a two-stage decision model (i.e., likelihood to purchase and the amount purchased offline). Our study is instantiated on a unique single-source dataset of 12-month home-scanned brand purchase records of a group of fast-moving consumer good brands and Facebook brand Fan Page messages related to the brands. We first find that exposures to earned and owned social media activities for brands have significant and positive impacts on consumers' likelihood to purchase the brands. Their effects are, surprisingly, suppressive on each other. Second, exposures to earned and owned social media activities have almost no impact on the amount purchased offline with presence of in-store promotions. Our study contributes to our knowledge body of social media marketing by demonstrating that social media activities for a brand can foster the consumer base of the brand, but that effort is not necessarily sales-oriented. In addition, our study is conducive to guiding marketers onto the strategic allocation of advertising dollars to online social channels featuring a mixture of earned and owned social media.
|keyword = brand community,brand purchase,Facebook Fan Page,multilevel modeling,social media,social media marketing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Role of Affect in Self-Disclosure on Social Network Websites: A Test of Two Competing Models'''
{{header}}
{{article
|author= Jongtae Yu,Paul Jen-Hwa Hu,Tsang-Hsiang Cheng,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = This study examines how affect influences self-disclosure on social network (SN) websites. We test two competing models that build on direct causation theory and affect heuristic theory, respectively. In a direct effect model, affect steers self-disclosure, independent of cognitive cost-benefit appraisals. The indirect effect model instead suggests that affect influences self-disclosure by adjusting perceptions of benefits and costs. The empirical comparison of the models relies on survey data from more than 500 university students. Overall, affect influences self-disclosure indirectly by adjusting the benefits people perceive. In particular, affect toward self-disclosure and toward SN websites relate positively to self-disclosure motivators; their perceived values appear amplified in the presence of positive affect. We also offer a plausible, alternative explanation of the observed positive relationship between privacy risk and self-disclosure according to an indirect effect model, in which self-disclosure is driven mainly by motivators, whereas the effects of inhibitors depend a posteriori on self-disclosure. These findings call for a reconsideration of any exclusive focus on the direct impacts of affect on technology use, as is common in previous research, and suggest the importance of affective factors for understanding social technology uses and managing customer relationships.
|keyword = affect,dual processing approach,online privacy,online self-disclosure,social network sites,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Design Theory for Market Surveillance Systems'''
{{header}}
{{article
|author= Xin Li,Sherry X. Sun,Kun Chen,Terrance Fung,Huaiqing Wang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Market surveillance systems (MSSs) are information systems that monitor financial markets to combat market abuses. Existing MSSs focus mainly on analyzing trading activities and are often developed through a trial-and-error approach by screening data mining algorithms and features. The void of theoretical direction limits the effectiveness of MSSs and calls for the development of a design theory based on a thorough examination of the meta-requirements of MSSs. Based on the efficient market hypothesis and text understanding theory, this paper argues that market information analysis should be incorporated into MSSs and common-sense knowledge should be employed to connect related events to transactions and provide reference concepts for understanding market context and assessing transaction risk. We show the effectiveness of this proposed design theory through developing and evaluating a prototype system in the context of a real-world stock exchange market. By taking a theory-driven approach, this research shows the possibility and provides guidelines on the use of market information analysis to alleviate the market surveillance problem, which has significant implications for financial markets and the economy given the explosive growth of illegal trading activities worldwide.
|keyword = design theory,market surveillance systems,text mining,financial markets,efficient market hypothesis,text understanding theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Estimating the Contextual Risk of Data Breach: An Empirical Approach'''
{{header}}
{{article
|author= Ravi Sen,Sharad Borle,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Data breach incidents are on the rise, and have resulted in severe financial and legal implications for the affected organizations. We apply the opportunity theory of crime, the institutional anomie theory, and institutional theory to identify factors that could increase or decrease the contextual risk of data breach. We investigate the risk of data breach in the context of an organization's physical location, its primary industry, and the type of data breach that it may have suffered in the past. Given the location of an organization, the study finds support for application of the opportunity theory of crime and the institutional anomie theory in estimating the risk of data breach incidents within a state. In the context of the primary industry in which an organization operates, we find support for the institutional theory and the opportunity theory of crime in estimating risk of data breach incidents within an industry. Interestingly though, support for the opportunity theory of crime is partial. We find that investment in information technology (IT) security corresponds to a higher risk of data breach incidents within both a state and an industry, a result contrary to the one predicted by the opportunity theory of crime. A possible explanation for the contradiction is that investments in IT security are not being spent on the right kind of data security controls, a fact supported by evidence from the industry. The work has theoretical and practical implications. Theories from criminology are used to identify the risk factors of data breach incidents and the magnitude of their impact on the risk of data breach. Insights from the study can help IT security practitioners to assess the risk environment of their firm (in terms of data breaches) based on the firm's location, its industry sector, and the kind of breaches that the firm may typically be prone to.
|keyword = computer crime,computer security,data breach,data theft,information security,IT security risks,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of Firm Learning on Value Creation in Strategic Outsourcing Relationships'''
{{header}}
{{article
|author= Deepa Mani,Anitesh Barua,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Information technology (IT) is central to the process execution and management of an ongoing relationship in outsourcing, both of which are fraught with challenges, and often lead to poor business outcomes. Thus, it is important for IT groups in organizations to understand how to deal with such difficulties for improved outsourcing performance. We study whether firms learn over time to deal with these two related but distinct issues in IT and business process outsourcing. Does such learning affect financial value appropriation through outsourcing? We build on the literature in information systems and strategy to investigate whether value creation in outsourcing depends on relational learning that results from prior association with the vendor, and procedural learning that results from prior experience in managing interfirm relationships. We estimate value in terms of long-term abnormal stock returns to the client relative to an industry, size, and book-to-market matched sample of control firms following the implementation of the outsourcing contract. We also analyze announcement period returns and allied wealth effects. Using data from the hundred largest outsourcing deals between 1996 and 2005, we find that whereas relational learning influences value creation in both simple and complex outsourcing engagements, procedural learning impacts value only in complex initiatives. Financial markets are slow to price the value of learning. The results suggest that caution should be exercised when firms without the experience of managing interfirm relationships externalize complex tasks to vendors they have not worked with in the past. Furthermore, IT groups can help improve learning-based outcomes by developing processes and systems that enable a firm to improve outsourcing procedures in a cumulative manner and also to coordinate and collaborate with the vendor.
|keyword = abnormal returns,business process outsourcing,contracts,financial value,market efficiency,organizational learning,outsourcing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Role of Dynamic Capabilities in Responding to Digital Disruption: A Factor-Based Study of the Newspaper Industry'''
{{header}}
{{article
|author= Jahangir Karimi,Zhiping Walter,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Internet and digitization are fundamentally changing and disrupting newspaper companies' traditional operating models. Disruptive innovation theory offers explanations for why companies succeed or fail to respond to disruptive innovations. This study builds on disruptive innovation theory by ascertaining the role of dynamic capabilities in the performance of response to digital disruption. Empirical results suggest that first-order dynamic capabilities that are created by changing, extending, or adapting a firm's existing resources, processes, and values are positively associated with building digital platform capabilities, and that these capabilities impact the performance of response to digital disruption. For information systems (IS) researchers, this study clarifies the role of first-order dynamic capabilities in responding to digital disruption. For IS practice, it helps managers to focus on the most promising factors for creating first-order dynamic capabilities, for building digital platform capabilities, and for reinventing their core functions to accelerate digitization.
|keyword = autonomous growth group,common language,digital disruption,digital platforms,digital transformation,digitization,disruptive innovation,innovative culture,multimedia mindset,organizational capabilities,resources-processes-values (RPV) framework,response performance,staged resource allocation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Knowledge Integration in Outsourced Software Development: The Role of Sentry and Guard Processes'''
{{header}}
{{article
|author= Nikhil Mehta,Anandhi Bharadwaj,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = We examine the role of sentry and guard activities in outsourced software development. Sentry activities are designed to regulate the inflow of external information to the project teams and guard activities are designed to manage the outflow of teams' information and resources to external sources. The use of sentry and guard activities has been examined in teams in other contexts such as new product development, but their role and relationship to performance in software development teams is not well understood. We hypothesize and test curvilinear relationships between these activities and knowledge integration in vendor development teams. We also examine how these effects vary under conditions of greater project uncertainty. We tested the hypotheses using data from 139 vendor development teams drawn from sixteen Indian software companies. Results highlight complex curvilinear associations among sentry and guard activities, and knowledge integration, which are further impacted by the level of uncertainty that the project team faces. We recommend that carefully calibrating sentry and guard processes will help vendor development teams enhance project outcomes.
|keyword = guard processes,knowledge integration,project uncertainty,sentry processes,software development,software development teams,software projects,team boundary,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Exploitation and Exploration Networks in Open Source Software Development: An Artifact-Level Analysis'''
{{header}}
{{article
|author= Orcun Temizkan,Ram L. Kumar,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Open source software (OSS) development is an increasingly important paradigm of software development. However, key aspects of OSS such as the determinants of project success and motivations of developers in joining these projects are not well understood. Based on organizational theory, we propose that OSS activities of patch development and feature request can be classified as exploitation (implementation-oriented) and exploration (innovation-oriented) activities, respectively. We empirically examine how the structure of social network affects the success of patch-development and feature-request networks in OSS projects, using a data set collected from the SourceForge database. Our results provide empirical support for the view that patch development and feature request are exploitation and exploration activities, respectively. Network structures differ due to team formation differences and have a differential impact on development success based on the type of activity. The concepts of ambidextrous developers and ambidexterity are explored in the context of OSS projects. Collectively, our results indicate that studying OSS projects at the artifact level could improve our understanding of OSS project success and team formation. This, in turn, could lead to better management of OSS projects.
|keyword = exploitation and exploration,open source software development,project success,social networks,software development,team formation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Temporal Distance, Communication Patterns, and Task Performance in Teams'''
{{header}}
{{article
|author= J. Alberto Espinosa,Ning Nan,Erran Carmel,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Drawing on theories on dispersed teamwork, computer-mediated communications, and organizations, we examine the direct associations between temporal distance and team performance as well as the mediating role of team interaction. We tested our research model in a laboratory experiment with four temporal distance conditions. Results show that the direct associations between temporal distance and team performance are substantially diminished when we enter the intervening team communication variables (communication frequency and turn-taking) into the analysis model. We find that communication frequency and turn-taking have differentiated effects on conveyance of information and convergence on its meaning. Conveyance is positively associated with production speed, whereas convergence is positively associated with higher product quality (i.e., accuracy). These findings speak to the theoretical significance of communication patterns and information exchange behaviors in dispersed team research. They also transcend the common wisdom that temporal distance is good for speed and bad for quality.
|keyword = geographically dispersed teams,global teams,team performance,temporal distance,time-zone differences,virtual teams,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Lost in Cyberspace: The Impact of Information Scent and Time Constraints on Stress, Performance, and Attitudes Online'''
{{header}}
{{article
|author= Gregory D. Moody,Dennis F. Galletta,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = As competition online increases, website owners investigate ways in which they can attract and retain more users. One avenue is to reduce frustration and stress for the users. Furthermore, many website users are rushed when browsing for specific information on a website. To save time and prevent frustration, website owners should try to maximize information scent, that is, visual, audio, and semantic cues that are meant to lead or guide the user to his or her informational goal. This paper presents and tests a model to predict how information scent can reduce the amount of stress that consumers experience when seeking information under time constraints. The study also demonstrates the relationships between information scent, time constraints, stress, performance, and attitudes toward the website. Results demonstrate that high information scent is an important design goal for a website, and latent semantic analysis can be a useful tool for measuring scent. In addition, rather than an attribute of an overall site, the concept of scent is demonstrated to be dependent on both the website and the task(s) being performed by the user. This finding demonstrates that to maximize users' satisfaction and ability to accomplish their goals, website designers need to determine what tasks users need to accomplish, and to make sure that the links on each page point clearly to the appropriate destination to meet those goals. The latent semantic analysis tool can provide an indication of strength and clarity of the links. Clear links gain even more importance when considering the time constraints of users. Measurable stress explains some of the variance in performance and attitudes.
|keyword = human-computer interaction,information scent,Internet,latent semantic analysis,online anxiety,online stress,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Web Personalization Cues and Their Differential Effects on User Assessments of Website Value'''
{{header}}
{{article
|author= Alexander Benlian,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Although various kinds of personalization cues are pervasively used on websites, previous research studies have treated web personalization primarily as a coarse-grained, monolithic block (e.g., by comparing personalization vs. nonpersonalization or personalization vs. privacy) rather than as a combination of salient types of personalization cues that may create-either jointly or separately-different effects on user assessments of website value. Based on the stimulus-organism-response framework, we develop a research model that proposes users' preference fit and perceived enjoyment as two key intervening mechanisms that carry over the differential effects of content and design personalization cues on users' willingness to stick to a website and to pay for website offerings. In a field experiment with 206 subjects using a real-life news aggregator website, our findings provide evidence in support of different effect paths emanating from content and design personalization cues. Furthermore, we show that the effects of content personalization cues on website stickiness and users' willingness to pay (WTP) are mediated by both preference fit and perceived enjoyment, whereas design personalization cues exert their effects on website stickiness only through perceived enjoyment. Counter to intuition, we find that a combination of content and design personalization cues is ineffective-or even counterproductive-in increasing preference fit and users' WTP above and beyond the levels generated by content cues alone. With regard to perceived enjoyment and website stickiness, however, content and design personalization cues exhibit synergistic properties indicating that the combination of both cues are more than the sum of the individual cues alone. Recommendations are provided as to how online managers and web designers can use web personalization cues to positively influence website stickiness and to strengthen their digital business model.
|keyword = field experiment,online news aggregators,perceived enjoyment,personalization cues,preference fit,web personalization,website stickiness,website value,willingness to pay,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Online Price Dispersion Revisited: How Do Transaction Prices Differ from Listing Prices?'''
{{header}}
{{article
|author= Kexin Zhao,Xia Zhao,Jing Deng,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Price dispersion of a homogeneous product reflects market efficiency and has significant implications on sellers' pricing strategies. Two different perspectives, the supply and demand perspectives, can be adopted to examine this phenomenon. The former focuses on listing prices posted by sellers, and the latter uses transaction prices that consumers pay to obtain the product. However, no prior research has systematically compared both perspectives, and it is unclear whether different perspectives will generate different insights. Using a unique data set collected from an online market, we find that the dispersion of listing prices is three times higher than the dispersion of transaction prices. More interestingly, the drivers of price dispersion differ significantly between listing and transaction data. The dispersion of listing prices reflects sellers' perception of market environment and their pricing strategies, and it may not fully capture consumer behavior manifested through the variation of transaction prices. Our study indicates that the difference in perspectives taken on the online prices yields different results as to their dispersion.
|keyword = listing prices,online markets,online prices,price dispersion,transaction prices,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Push or Pull? A Website's Strategic Choice of Content Delivery Mechanism'''
{{header}}
{{article
|author= Dan Ma,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Really simple syndication (RSS) technology enables an alternative delivery mechanism for online content. Instead of waiting passively for users to pull online content out, websites can push it to potential users through RSS. This is expected to significantly affect user behavior, website profitability, and market equilibrium. This research uses an economic model to study the impact of RSS adoption and examine whether it increases a website's profit and competitive advantage. The findings are intriguing: they demonstrate that RSS can either increase or decrease website profit. In a competitive context, RSS adoption can actually be a disadvantage; in some cases, it hurts the adopter but benefits the competitor. Moreover, under certain conditions, the first mover will be worse off when the competitor mimics its adoption decision, which discourages the earlier adoption and thus creates an obstacle to using RSS. Derivation of the adoption equilibria in sequential and simultaneous games shows that multiple market outcomes may result. Finally, regardless of whether or not a website operator adopts RSS, it will still benefit by increasing user awareness of RSS technology, but only up to a certain level. Once this critical awareness level has been reached, websites will not gain by continuing to promote RSS to users. As a whole, these results show how technology adoption will have an impact on firm performance and market outcome, and illustrate the complexity of technology adoption strategy in a competitive setting.
|keyword = competition,e-commerce,game theory,information economics,online content delivery,RSS,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Employees' Exploration of Complex Systems: An Integrative View'''
{{header}}
{{article
|author= Huigang Liang,Zeyu Peng,Yajiong Xue,Xitong Guo,Nengmin Wang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2015
|abstract = Based on the theory of effective use and adaptive structuration theory, we propose that employees' system exploration behavior can be affected by factors related to three major components: task, system, and organizational environment. Specifically, we examine how task characteristics (job autonomy and task variety), system complexity, and innovation climate jointly affect employees' exploration, which, in turn, leads to extended use of enterprise systems. A field survey of enterprise resource planning (ERP) users yields several interesting findings. First, job autonomy and task variety directly enhance system exploration. Second, system complexity plays a moderating role by strengthening the relationship between job autonomy and exploration and weakening the relationship between task variety and exploration. Third, innovation climate, also acting as a moderator, strengthens both the impact of job autonomy on exploration and the impact of system exploration on extended use. This research contributes to information systems (IS) research by theoretically articulating that system exploration is subject to the simultaneous influences of task, system, and organizational environment factors and empirically testing these factors' main effects and interactions to shed new light on system exploration research. It also contributes to IS practice by suggesting that organizations could enhance employees' system exploration and facilitate the transition from exploration to extended use by increasing job autonomy and task variety, designing personalized training programs to reduce system complexity, and developing organizational climates that foster innovations.
|keyword = autonomy,ERP,innovation climate,IS jobs,system exploration,task complexity,task variety,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Healthcare IT Adoption: An Analysis of Knowledge Transfer in Socioeconomic Networks'''
{{header}}
{{article
|author= Gang Peng,Debabrata Dey,Atanu Lahiri,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Despite the potential of health information technology (HIT) systems to significantly reduce medical errors, streamline clinical processes, contain healthcare costs, and ultimately improve the quality of healthcare, their adoption by hospitals in the United States has been rather slow. To study this adoption process and get insights into the underlying mechanisms, in this work we synthesize the theories on social networks and knowledge transfer. We propose a research framework in which the absorptive capacity of a potential adopter and the collective disseminative capacity of connected adopters act as two key determinants of knowledge transfer in a socioeconomic network, and these two capacities substitute for each other in affecting HIT adoption. We also propose that, in a network setting, the mechanism of knowledge transfer manifests quite differently from that of social contagion in its impact on the diffusion process at different stages of adoption. Using a large longitudinal data set covering adoption decisions of more than five thousand hospitals across a thirteen-year horizon, we find strong support for our hypotheses. Our analysis shows that knowledge flow in provider networks plays a key role in fostering technology diffusion in initial years, allowing the contagion effect to set in sooner for quicker adoption in later years. Therefore, recent efforts at multiple levels to form integrated healthcare delivery networks should accelerate HIT adoption.
|keyword = absorptive capacity,disseminative capacity,healthcare,healthcare information system,healthcare information technology,healthcare information technology adoption,integrated healthcare delivery system,knowledge transfer,social network,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Intermediation in a Sharing Economy: Insurance, Moral Hazard, and Rent Extraction'''
{{header}}
{{article
|author= Thomas A. Weber,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = A key impediment to sharing is a lender's concern about damage to a lent item due to unobservable actions by a renter, usually resulting in moral hazard. This paper shows how an intermediary can eliminate the moral hazard problem by providing optimal insurance to the lender and first-best incentives to the renter to exert care, as long as market participants are risk neutral. The solution is illustrated for the collaborative housing market but applies in principle to any sharing market with vertically differentiated goods. A population of renters, heterogeneous both in their preferences for housing quality and with respect to the amount of care they exert in a rental situation, face a choice between collaborative housing and staying at a local hotel. The private hosts choose their prices strategically, and the intermediary sets commission rates on both sides of the market as well as insurance terms for the rental agreement. The latter are set to eliminate moral hazard. The intermediary is able to extract the gains the hosts would earn if transacting directly. Finally, even if hotels set their prices at the outset so as to maximize collusive profits, collaborative housing persists at substantial market shares, regardless of the difference between the efficiencies of hosts and hotels to reduce renters' cost of effort. The aggregate of hosts, intermediary, and hotels benefits from (a variety in) these effort costs, which indicates that the intermediated sharing of goods is an economically viable, robust phenomenon.
|keyword = collaborative consumption,digital economy,incentive contracting,intermediation,moral hazard,optimal insurance,sharing economy,trust,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Augmenting Conflict Resolution with Informational Response: A Holistic View of Governance Choice in Business Process Outsourcing'''
{{header}}
{{article
|author= Anitesh Barua,Deepa Mani,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = We develop a holistic model of governance choice in business process outsourcing (BPO) that represents a highly information-intensive form of outsourcing. We integrate perspectives from neoinstitutional economics and the information-processing view (IPV) of the firm. We argue that the governance structure in BPO is chosen not only to address opportunism concerns arising from relational uncertainty to and encourage cooperation, as suggested by institutional economics, but also as an informational response to task and relational uncertainty to encourage coordination between exchange partners. Using the lens of IPV, we posit that uncertainty in the outsourced task increases the information requirements (IR) of the BPO relationship, which, in turn, leads to more hierarchical governance structures. We also suggest that in addition to directly influencing governance choice, relational uncertainty, a key construct in transaction cost economics (TCE), increases IR, and hence has an indirect impact on governance choice. Furthermore, we hypothesize that technological capabilities enable more hierarchical governance in response to increasing IR needs. Data on 130 BPO initiatives provide empirical support for our hypotheses regarding the drivers of IR, its impact on governance choice, and the moderating role of technological capabilities. Our study contributes to theory by integrating the premises of TCE and IPV in the context of BPO, and to practice by underscoring the need to consider information requirements in designing appropriate coordination and collaboration processes.
|keyword = business process outsourcing,cooperation,coordination,governance,hierarchy,information requirements,uncertainty,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Autonomous Scientifically Controlled Screening Systems for Detecting Information Purposely Concealed by Individuals'''
{{header}}
{{article
|author= Nathan W. Twyman,Paul Benjamin Lowry,Judee K. Burgoon,Jr. Jay F. Nunamaker,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Screening individuals for concealed information has traditionally been the purview of professional interrogators investigating crimes. However, the ability to detect when a person is hiding important information would have high value in many other applications if results could be reliably obtained using an automated and rapid interviewing system. Unfortunately, this ideal has thus far been stymied by practical limitations and inadequate scientific control in current interviewing systems. This study proposes a new class of systems, termed autonomous scientifically controlled screening systems (ASCSS), designed to detect individuals' purposely hidden information about target topics of interest. These hidden topics of interest could cover a wide range, including knowledge of concealed weapons, privacy violations, fraudulent organizational behavior, organizational security policy violations, preemployment behavioral intentions, organizational insider threat, leakage of classified information, or even consumer product use information. ASCSS represent a systematic synthesis of structured interviewing, orienting theory, defensive response theory, noninvasive psychophysiological measurement, and behavioral measurement. To evaluate and enhance the design principles, we built a prototype automated screening kiosk system and configured it for a physical security screening scenario in which participants constructed and attempted to smuggle a fake improvised explosive device. The positive results provide support for the proposition that ASCSS may afford more widespread application of credibility assessment screening systems.
|keyword = automated screening kiosk,autonomous scientifically controlled screening system,concealed information test,credibility assessment,deception detection,defensive response,design science,eye-tracking measures,orienting response,physical security,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Digital Natives or Digital Immigrants? The Impact of User Characteristics on Online Trust'''
{{header}}
{{article
|author= Christian Pieter Hoffmann,Christoph Lutz,Miriam Meckel,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Previous research suggests that user characteristics such as web experience and demographics may affect online trust. Drawing on social cognitive theory, we explore the moderating effect of user characteristics on online trust. Based on a survey of German Internet users, we differentiate three groups by age, web experience, and education. We term these groups digital natives, digital immigrants, and naturalized digitals. A multiple-group analysis reveals significant differences in trust formation, particularly in the cues considered in the evaluation of online services. Whereas a large user base inspires confidence in digital natives, naturalized digitals are more geared toward familiar brands and recommendations. Digital immigrants most critically weigh the risks of a transaction against its benefits. We argue that specific user characteristics are associated with distinct cognitive schemata, implying distinct interests and evaluations in online transactions. Online services should differentiate their signaling efforts according to the targeted customer group.
|keyword = e-business,online trust,trust cues,web user characteristics,website signaling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Drivers of Quantity and Quality of Participation in Online Policy Deliberation Forums'''
{{header}}
{{article
|author= Chee Wei Phang,Atreyi Kankanhalli,Lihua Huang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Online policy deliberation forums (OPDFs) have been increasingly initiated by governments to allow citizens to provide their input and discuss policy issues. Yet, failure to garner participation, in terms of both quantity and quality, prevents the realization of their benefits. In this regard, prior research has suggested different antecedents for the quantity and quality of participation in online forums, but without systematically considering their differences. To address this research gap, in this study we develop a theoretical model to explain the antecedents of quantity and quality of OPDF participation and test the model using a survey and content analysis of forum logs. The results indicate that quantity of participation is enhanced by the information-technology-enabled resource factor of communality but negatively influenced by collective incentives. In contrast, the antecedents of the quality of participation include both motivational and resource factors. Furthermore, communality accentuates the perceived collective incentives and persuasion benefit of participation. This study contributes to the research by proposing and testing a theoretical model that explains the different antecedents of the quantity and quality of participation in OPDFs. More broadly, the findings inform research and practice on how outcomes of web-enabled cocreation, such as those generated through OPDF participation, can be evaluated and enhanced in these online communities.
|keyword = cocreation,online policy deliberation forum,participation theory,public policy deliberation,quality of participation,quantity of participation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Classifying, Measuring, and Predicting Users' Overall Active Behavior on Social Networking Sites'''
{{header}}
{{article
|author= Aihui Chen,Yaobin Lu,Patrick Y. K. Chau,Sumeet Gupta,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Although understanding the role of users' overall active behavior on a social networking site (SNS) is of significant importance for both theory and practice, the complexity and difficulty involved in measuring such behavior has inhibited research attention. To understand users' active behaviors on an SNS, it is important that we identify and classify various types of online behaviors before measuring them. In this paper we holistically examine users' active behaviors on an SNS. Toward this end, we conduct three studies. First, we classify active behaviors on an SNS into four categories using the Delphi method. Then, we develop a measurement model and validate it using the data collected from an online survey of 477 SNS users. The measures of the developed instrument exhibit satisfactory reliability and validity and are used as indicators of the latent constructs. This instrument is then used in a predictive model based on commitment theory and tested using data from 1,242 responses. The results of data analysis suggest that affective commitment and continuance commitment are good predictors of overall active behavior on an SNS. This study complements the existing research on social media, cocreation, and social commerce. Most important, this study provides a theoretically sound measurement instrument that addresses the complex characteristic of overall active behavior on an SNS and which should be useful for future research. The findings of this study have important implications for practice as they highlight managing and stimulating users' active behaviors on an SNS.
|keyword = Delphi study,measurement model,social media,social networking site,user commitment,users' active behavior,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Delivery Consolidation and Service Competition Among Internet Service Providers'''
{{header}}
{{article
|author= I. Robert Chiang,Jhih-Hua Jhang-Li,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = The infrastructure of the Internet, by and large, is maintained by Internet service providers (ISPs) that cater to regional customers and by Internet backbone providers (IBPs) that serve large organizations and ISPs. Some IBPs have recently branched into content delivery network (CDN) services; separately, other ISPs have started offering on-demand video streaming to compete with pure-play content providers. These developments have intensified the competition in both content delivery and media-streaming markets. For the content delivery market, we study the competition equilibriums by analyzing factors such as market share, cost structure, service pricing, and subscriber preference. Our approach helps identify conditions under which a content provider should choose an IBP over the incumbent CDN for content distribution. We also show how an IBP's CDN venture affects its interconnection relationship with ISPs. For the streaming service market, we examine conditions under which a content provider would partner with an ISP to lower operating and marketing costs while providing a more streamlined subscriber experience. Analytically, our game-theoretical models can optimize key contracting and pricing strategies for multiple classes of service providers; empirically, insights derived from the proposed models have anticipated events that coincide with several recent developments in content delivery and streaming service markets.
|keyword = content delivery network,Internet service provider,media streaming,peering and transit,service pricing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding the Drivers of Unethical Programming Behavior: The Inappropriate Reuse of Internet-Accessible Code'''
{{header}}
{{article
|author= Manuel Sojer,Oliver Alexy,Sven Kleinknecht,Joachim Henkel,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Programming is riddled with ethical issues. Although extant literature explains why individuals in IT would act unethically in many situations, we know surprisingly little about what causes them to do so during the creative act of programming. To address this issue, we look at the reuse of Internet-accessible code: software source code legally available for gratis download from the Internet. Specifically, we scrutinize the reasons why individuals would unethically reuse such code by not checking or purposefully violating its accompanying license obligations, thus risking harm for their employer. By integrating teleological and deontological ethical judgments into a theory of planned behavior model-using elements of expected utility, deterrence, and ethical work climate theory-we construct an original theoretical framework to capture individuals' decision-making process leading to the unethical reuse of Internet-accessible code. We test this framework with a unique survey of 869 professional software developers. Our findings advance the theoretical and practical understanding of ethical behavior in information systems. We show that programmers use consequentialist ethical judgments when carrying out creative tasks and that ethical work climates influence programmers indirectly through their peers' judgment of what is appropriate behavior. For practice, where code reuse promises substantial efficiency and quality gains, our results highlight that firms can prevent unethical code reuse by informing developers of its negative consequences, building a work climate that fosters compliance with laws and professional codes, and making sure that excessive time pressure is avoided.
|keyword = code reuse,ethical behavior,information systems ethics,Internet-accessible code,open source software,partial least squares,programming ethics,theory of planned behavior,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Effects of Freemium Strategy in the Mobile App Market: An Empirical Study of Google Play'''
{{header}}
{{article
|author= Charles Zhechao Liu,Yoris A. Au,Hoon Seok Choi,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = This paper examines the effect of the freemium strategy on Google Play, an online marketplace for Android mobile applications. By analyzing a large panel data set consisting of 711 ranked mobile apps, we found that the freemium strategy is positively associated with increased sales of the paid mobile apps. Positive trial experience as represented by high review rating of the free version of a mobile app leads to higher sales of its paid version, whereas high visibility of the free version of a mobile app as represented by its product rank does not have a significant impact on the sales of its paid version. This finding suggests that although offering a free trial version is a viable way to improve the visibility of a mobile app, offering a quality free app is more important in boosting sales of the paid app. Moreover, we found that the impact of review rating is reduced when the free version is offered, or when the mobile app is a hedonic app, because consumers have the ability to experience the app themselves before purchase. These findings extend understanding of the freemium business model to include a market characterized by simultaneous intra-market competition for both the freemium and paid products and demonstrate how such dynamics may influence sales of the paid products.
|keyword = Android,freemium,Google Play,mobile apps,online product rank,online reviews,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INTERNET'S DIRTY SECRET: ASSESSING THE IMPACT OF ONLINE INTERMEDIARIES ON HIV TRANSMISSION'''
{{header}}
{{article
|author= Jason Chan,Anindya Ghose,
|source= MIS QUARTERLY
|year= 2014
|abstract = Online platforms offer access to a larger social group than is generally available through offline contacts, making the Internet an emerging venue for seeking casual sex partners. The ease of seeking sex partners through classified ad sites may promote risky behaviors that increase the transmission of STDs. In this paper, using a natural experiment setup, we investigate whether the entry of a major online personals ad site, Craigslist, increases the prevalence of HIV over a 10 year period from 1999 to 2008 across 33 states in the United States. After controlling for extraneous factors, our results suggest that the entry of Craigslist is related to a 15.9 percent increase in HIV cases. Our analysis suggests that the site entry produces an average of 6,130 to 6,455 cases of HIV infection in the United States each year, mapping out to between $62 million and $65.3 million in annual treatment costs. In addition, the analyses reveal that nonmarket-related casual sex is the primary driver of the increase in HIV cases, in contrast to paid transactions solicited on the site (e.g., escort services and prostitution), which has a negative relationship with HIV trends. These findings are essential to understanding the social routes through which HIV transmission takes place and the extent to which site entry can influence HIV trends. Implications for healthcare practitioners and policy makers are discussed.
|keyword = Classified ad sites,HIV,Internet,online intermediaries,transmission route,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''MULTIHOMING USERS' PREFERENCES FOR TWO-SIDED EXCHANGE NETWORKS'''
{{header}}
{{article
|author= Tat Koon Koh,Mark Fichman,
|source= MIS QUARTERLY
|year= 2014
|abstract = Online business-to-business (B2B) exchanges are proliferating, giving firms numerous platforms from which to choose. Many firms are also multihoming, using competing platforms concurrently. In this study, we examine how selling and buying activities on B2B exchanges affect multihoming buyers' preferences for exchanges. We posit that these activities influence buyers' perceived returns and risks of using the exchanges, and impact buyers' preferences. Using a unique dataset of 118 buyers' participation in two B2B exchanges over seven months, we find that buyers prefer exchanges with more selling activities. However, buyers' preferences and buying levels on the exchanges are non-monotonically related. At low buying levels, an increase in buying by others positively affects buyers' preferences. This effect may result from observational learning, where individual buyers learn from other buyers' behaviors. On the other hand, as buying level increases further on the exchange, competition among buyers also increases. Consequently, buyers lower their preferences for the exchange. In addition, we find that the effects of selling and buying activities on buyers' preferences change over time. Our results highlight the need to correctly model buyers' homing behavior; failing to do so could bias the picture of competitive dynamics between platforms and lead to suboptimal strategies by exchanges.
|keyword = Online platforms,B2B exchanges,multihoming,network effects,observational learning,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ONTOLOGY-BASED EVALUATION OF NATURAL DISASTER MANAGEMENT WEBSITES: A MULTISTAKEHOLDER PERSPECTIVE'''
{{header}}
{{article
|author= Chen-Huei Chou,Fatemeh Mariam Zahedi,Huimin Zhao,
|source= MIS QUARTERLY
|year= 2014
|abstract = In recent years, the world has witnessed a number of severe natural disasters, causing heavy losses to families, communities, and even nations. Natural disaster management (NDM) websites play an important role in assisting people through various disaster stages. However, such websites are complex and there is little research on standards and guidelines for their development and evaluation. In this paper, we develop an ontology-based evaluation tool to assess the utility of NDM websites. Two main groups of stakeholders-experts who are in charge of NDM websites and potential users of such websites-contributed to the process. A total of 73 experts validated the ontology developed for NDM web elements through a Delphi study. These experts also provided importance ratings for web elements in the ontology. In a survey of the second major group of stakeholders-potential users-818 participants provided another set of importance ratings for web elements in the ontology. The design theory in this work is based on utility theory. The metrics for the evaluation of websites are relative utility and absolute utility. Using the evaluation tool, we evaluated the NDM websites of the 50 U.S. states from the perspectives of the two groups of stakeholders. The results indicate a lack of readiness in most of these websites.
|keyword = Ontology,utility theory,natural disaster management,Delphi method,website evaluation,web elements,analytic hierarchy process,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AN ANALYSIS OF PRICING MODELS IN THE ELECTRONIC BOOK MARKET'''
{{header}}
{{article
|author= Lin Hao,Ming Fan,
|source= MIS QUARTERLY
|year= 2014
|abstract = In this paper, we develop a game theoretic model to study the pricing of e-books and e-readers under two pricing models: wholesale and agency. We analyze pricing strategies for a publisher and a retailer. We identify the complementary relationship between e-books and e-readers as the main reason for the retailer to set a low e-book price in the wholesale model. Comparing the wholesale and the agency models, we find, in a wide range of market conditions, the price for e-book readers is lower in the agency model, leading to a higher e-book market share. However, a higher e-book price in the agency model lowers e-book consumption. Overall social welfare is lower in the agency model than in the wholesale model. While total consumer surplus is slightly higher in the agency model, largely because of a lower e-reader price, business profit is lower. The publisher, surprisingly, is worse off under the agency model.
|keyword = Electronic book,e-reader,pricing,agency model,wholesale model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''STRATEGIC BEHAVIOR IN ONLINE REPUTATION SYSTEMS: EVIDENCE FROM REVOKING ON EBAY'''
{{header}}
{{article
|author= Shun Ye,Guodong (Gordon) Gao,Siva Viswanathan,
|source= MIS QUARTERLY
|year= 2014
|abstract = This study examines how sellers respond to changes in the design of reputation systems on eBay. Specifically, we focus on one particular strategic behavior on eBay's reputation system: sellers' explicit retaliation against negative feedback provided by buyers to coerce buyers into revoking their negative feedback. We examine how these strategic sellers respond to removal of their ability to retaliate against buyers. We utilize one key policy change of eBay's reputation system, which provides a natural experimental setting that allows us to infer the causal impact of the reputation system on seller behavior. Our results show that coercing buyers to revoke their negative feedback through retaliation enables low-quality sellers to manipulate their reputations and masquerade as high-quality sellers. We find that these sellers reacted strongly to eBay's announcement of a proposed ban on revoking. Interestingly, after the power of these strategic sellers is curtailed, we find evidence that they exert more efforts to improve their reputation scores. This study provides valuable insights about the relationship between reputation system and seller behavior, which have important implications for the design of online reputation mechanisms.
|keyword = Reputation mechanisms,online ratings,quality transparency,online auctions,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION DISCOVERY AND THE LONG TAIL OF MOTION PICTURE CONTENT'''
{{header}}
{{article
|author= Anuj Kumar,Michael D. Smith,Rahul Telang,
|source= MIS QUARTERLY
|year= 2014
|abstract = Recent papers have shown that, in contrast to the long tail theory, movie sales remain concentrated in a small number of hits. These papers have argued that concentrated sales can be explained, in part, by heterogeneity in quality and increasing returns from social effects. Our research analyzes an additional explanation: how incomplete information may skew sales patterns. We use the movie broadcast on pay-cable channels as an exogenous shock to the availability of information, and analyze how this shock changes the resulting sales distribution. Our data show that the pay-cable broadcast shifts the distribution of DVD sales toward long tail movies, suggesting an information spillover from the broadcast. We develop a learning-based movie discovery model to precisely quantify the two mechanisms of movie discovery: word-of-mouth from previous sales and information spillover from broadcast. We use this model to estimate the lost DVD sales due to incomplete information. Our study contributes to the literature by analyzing how information provided in one channel can change the assortment of the same products demanded in another channel.
|keyword = Incomplete information,product discovery,multichannel distribution,movie industry,cannibalization,movie broadcast,DVD sales and rental,long tail,sales distribution,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION TECHNOLOGY AND ADMINISTRATIVE EFFICIENCY IN US STATE GOVERNMENTS: A STOCHASTIC FRONTIER APPROACH'''
{{header}}
{{article
|author= Min-Seok Pang,Ali Tafti,M. S. Krishnan,
|source= MIS QUARTERLY
|year= 2014
|abstract = This paper explores value creation from government use of information technologies (IT). While the majority of studies in the information systems (IS) discipline have focused on discovering IT business value in for-profit organizations, the performance effects of IT in the public sector have not been extensively studied in either the IS or the public administration literature. We examine whether IT improves administrative efficiency in U. S. state governments. Utilizing IT budget data in state governments, the census data on state government expenditures, and a variety of information on public services that states provide, we measure technical efficiency with a stochastic frontier analysis and a translog cost function and estimate the effect of IT spending on efficiency. Our analyses provide evidence for a positive relationship between IT spending and cost efficiency and indicate that, on average, a $1 increase in per capita IT budget is associated with $1.13 in efficiency gains. This study contributes to the IS literature by expanding the scope of IT value research to public sector organizations and provides meaningful implications for elected officials and public sector managers.
|keyword = IT value,public sector,US state governments,stochastic frontier analysis,translog cost function,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PEER INFLUENCE IN THE DIFFUSION OF IPHONE 3G OVER A LARGE SOCIAL NETWORK'''
{{header}}
{{article
|author= Miguel Godinho de Matos,Pedro Ferreira,David Krackhardt,
|source= MIS QUARTERLY
|year= 2014
|abstract = In this paper, we study the effect of peer influence in the diffusion of the iPhone 3G across a number of communities sampled from a large dataset provided by a major European Mobile carrier in one country. We identify tight communities of users in which peer influence may play a role and use instrumental variables to control for potential correlation between unobserved subscriber heterogeneity and friends' adoption. We provide evidence that the propensity of a subscriber to adopt increases with the percentage of friends who have already adopted. During a period of 11 months, we estimate that 14 percent of iPhone 3Gs sold by this carrier were due to peer influence. This result is obtained after controlling for social clustering, gender, previous adoption of mobile Internet data plans, ownership of technologically advanced handsets, and heterogeneity in the regions where subscribers move during the day and spend most of their evenings. This result remains qualitatively unchanged when we control for changes over time in the structure of the social network. We provide results from several policy experiments showing that, with this level of effect of peer influence, the carrier would have hardly benefitted from using traditional marketing strategies to seed the iPhone 3G to benefit from viral marketing.
|keyword = Peer influence,homophily,diffusion,community identification,viral marketing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''HARNESSING THE POWER OF SELF-ORGANIZATION IN AN ONLINE COMMUNITY DURING ORGANIZATIONAL CRISIS'''
{{header}}
{{article
|author= Ning Nan,Yong Lu,
|source= MIS QUARTERLY
|year= 2014
|abstract = Organizational crisis management has traditionally favored a centralized plan-and-control approach. This study explores the possibility for an orderly crisis management process to arise unintentionally from decentralized and spontaneous actions in an online community (i.e., self-organization). Based on complex adaptive systems theory, a multilevel model is developed to account for the logical relation between individual-level actions and interactions in an online community and an organizational-level orderly and rational crisis management process, as described by the organizational crisis management literature. We apply this multilevel model to an analysis of 89,596 posts from an online community that was deeply embedded in an earthquake-induced organizational crisis. Results indicate that fluctuation of message content themes in this online community served to energize continuous input from ordinary organization members. These input actualized new possibilities offered by the technology platform for crisis management actions (i.e., actualized IT affordances). Concatenation of immediate impacts of message content themes and actualized IT affordances formed feedback loops that moderated the crisis management activities toward an efficient trajectory. Our findings challenge the traditional assumption that macro-level order requires micro-level order-seeking behaviors. They suggest the viability of self-organization as a new source of organizational order that complements the traditional centralized plan-and-control approach. Theoretical and empirical implications for harnessing the power of ordinary organization members connected by today's technology platforms are discussed.
|keyword = Organizational crisis,self-organization,complex adaptive systems,online community,information technology,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''LOOKING TOWARD THE FUTURE OF IT-BUSINESS STRATEGIC ALIGNMENT THROUGH THE PAST: A META-ANALYSIS'''
{{header}}
{{article
|author= Jennifer E. Gerow,Varun Grover,Jason Thatcher,Philip L. Roth,
|source= MIS QUARTERLY
|year= 2014
|abstract = Research examining the relationship between IT-business strategic alignment (hereafter referred to as alignment) and firm performance (hereafter referred to as performance) has produced apparently conflicting findings (i.e., an alignment paradox). To examine the alignment paradox, we conducted a meta-analysis that probed the interrelationships between alignment, performance, and context constructs. We found the alignment dimensions (intellectual, operational, and cross-domain) demonstrate unique relationships with the different performance types (financial performance, productivity, and customer benefit) and with many of the other constructs in alignment's nomological network. All mean corrected correlations between dimensions of alignment and dependent variables were positive and most of the credibility interval values in these analyses were also positive. Overall, the evidence gathered from the extant literature suggests there is not much of an alignment paradox. This study contributes to the literature by clarifying the relationships between alignment and performance outcomes and offering insight into sources of inconsistencies in alignment research. By doing so, this paper lays a foundation for more consistent treatment of alignment in future IT research.
|keyword = Alignment,business-IT strategic alignment,alignment paradox,IT value,productivity paradox,meta-analysis,review,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''SYMBOLIC ACTION RESEARCH IN INFORMATION SYSTEMS: INTRODUCTION TO THE SPECIAL ISSUE'''
{{header}}
{{article
|author= Mark Aakhus,Par J. Agerfalk,Kalle Lyytinen,Dov Te'eni,
|source= MIS QUARTERLY
|year= 2014
|abstract = This special issue introduction explores the need to study information systems as symbolic action systems, defines broadly the research domain and related assumptions, notes the origins of this perspective, articulates its key lines of study, and discusses the state of the field in light of published research. The essay also positions the three papers of the special issue in the broader Information Systems (IS) discourse and notes their specific contribution in bridging so far unconnected streams of research and expanding research methods amenable to symbolic action research. This introductory essay furthermore observes some unique challenges in pulling together the special issue that invited the editors to combat against the tendency to approach communicative processes associated with information systems as primarily psychological processes. In closing we note several lines of inquiry that can strengthen future studies of symbolic action including better design theories, more flexible and open use of methods, and attentive use of rich traditions that inform symbolic action research in IS.
|keyword = Symbolic action,information system,semiotics,speech act,symbol action,communication,collaboration,design,research methods,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TAKE THEIR WORD FOR IT: THE SYMBOLIC ROLE OF LINGUISTIC STYLE MATCHES IN USER COMMUNITIES'''
{{header}}
{{article
|author= Stephan Ludwig,Ko de Ruyter,Dominik Mahr,Martin Wetzels,Elisabeth Bruggen,
|source= MIS QUARTERLY
|year= 2014
|abstract = User communities are increasingly becoming an essential element of companies' business processes. However, reaping the benefits of such social systems does not always prove effective, often because companies fail to stimulate members' collaboration continuously or neglect their social integration. Following communication accommodation theory, the authors posit that members' communication style alignment symbolically reflects their community identification and affects subsequent participation behavior. This research uses text mining to extract the linguistic style properties of 74,246 members' posts across 37 user communities. Two mixed multilevel Poisson regression models show that when members' linguistic style matches with the conventional community style, it signals their community identification and affects their participation quantity and quality. Drawing on an expanded view of organizational identification, the authors consider dynamics in members' social identification by examining trends and reversals in linguistic style match developments. Whereas a stronger trend of alignment leads to greater participation quantity and quality, frequent reversals suggest lower participation quantity. At a community level, greater synchronicity in the linguistic style across all community members fosters individual members' participation behavior.
|keyword = Linguistic style match (LSM),user communities,text mining,organizational identification,argument development quality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''BEYOND BEING THERE: THE SYMBOLIC ROLE OF COMMUNICATION AND IDENTIFICATION IN PERCEPTIONS OF PROXIMITY TO GEOGRAPHICALLY DISPERSED COLLEAGUES'''
{{header}}
{{article
|author= Michael Boyer O'Leary,Jeanne M. Wilson,Anca Metiu,
|source= MIS QUARTERLY
|year= 2014
|abstract = Using a mixed-methods approach, we develop the concept of perceived proximity, which is created through communication, shared identity, and the symbolic aspects thereof. Building on previous theoretical work, we create and validate measures of perceived proximity. Then, we compare how perceived proximity and objective distance relate to relationship quality for collocated and geographically dispersed work colleagues. Our results show that perceived proximity (i.e., a cognitive and affective sense of relational closeness) and not physical proximity (i.e., geographic closeness measured in miles or kilometers) affects relationship quality in an international survey of more than 600 people and 1,300 dyadic work relationships. We also find that people's perceptions of proximity mediate the effects of communication and identification on relationship quality. Using qualitative data (2,289 comments from 1,188 respondents coded into 9 themes), we explore the symbolic meaning of perceived proximity. We show how people can form strong bonds despite being separated by large distances and continue to shift the emphasis from information systems as "pipes" or channels to information systems as vehicles for conveying shared meaning and symbolic value. Our findings have important implications for scholars, managers, systems designers, and members of virtual teams, teleworkers, and other geographically dispersed contexts.
|keyword = Proximity,distance,relationships,symbolic action,geographically dispersed work,virtual work,telework,virtual teams,dyads,mixed methods,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''KNOWLEDGE EXCHANGE AND SYMBOLIC ACTION IN SOCIAL MEDIA-ENABLED ELECTRONIC NETWORKS OF PRACTICE: A MULTILEVEL PERSPECTIVE ON KNOWLEDGE SEEKERS AND CONTRIBUTORS'''
{{header}}
{{article
|author= Roman Beck,Immanuel Pahlke,Christoph Seebach,
|source= MIS QUARTERLY
|year= 2014
|abstract = Organizational knowledge is one of the most important assets of an enterprise. Therefore, many organizations invest in enterprise social media (ESM) to establish electronic networks of practice and to foster knowledge exchange among employees. ESM improves interaction transparency and can be regarded as a sociotechnical system that provides a language for communication and symbolic action as well as a better sense of others' social identity. Accordingly, the individual characteristics of knowledge seekers and contributors determine why and how interactions occur. However, existing studies tend to focus only on knowledge contributors' characteristics and to treat knowledge as an object that needs to be transferred. To address this gap, this study conceptualizes and empirically tests a multilevel model of knowledge exchange in electronic networks of practice (ENoP) that includes the characteristics of knowledge seekers and knowledge contributors as well as their dyadic relationship from an activity-centered language/action point of view. A dataset of 15,505 enterprise microblogging messages reveals that knowledge seekers' characteristics and relational factors drive knowledge exchanges in social media-enabled ENoP. Focusing on organizations with knowledge exchanges supported by information technology, our research extends prior findings by providing the first evidence that the communicative act expressed by question-answer pairs impacts the quality of knowledge exchanged.
|keyword = Knowledge exchange,enterprise social media,language action view,electronic networks of practice,hierarchical linear modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The IQ of the Crowd: Understanding and Improving Information Quality in Structured User-Generated Content'''
{{header}}
{{article
|author= Roman Lukyanenko,Jeffrey Parsons,Yolanda F. Wiersma,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = User-generated content (UGC) is becoming a valuable organizational resource, as it is seen in many cases as a way to make more information available for analysis. To make effective use of UGC, it is necessary to understand information quality (IQ) in this setting. Traditional IQ research focuses on corporate data and views users as data consumers. However, as users with varying levels of expertise contribute information in an open setting, current conceptualizations of IQ break down. In particular, the practice of modeling information requirements in terms of fixed classes, such as an Entity-Relationship diagram or relational database tables, unnecessarily restricts the IQ of user-generated data sets. This paper defines crowd information quality (crowd IQ), empirically examines implications of class-based modeling approaches for crowd IQ, and offers a path for improving crowd IQ using instance-and-attribute based modeling. To evaluate the impact of modeling decisions on IQ, we conducted three experiments. Results demonstrate that information accuracy depends on the classes used to model domains, with participants providing more accurate information when classifying phenomena at a more general level. In addition, we found greater overall accuracy when participants could provide free-form data compared to a condition in which they selected from constrained choices. We further demonstrate that, relative to attribute-based data collection, information loss occurs when class-based models are used. Our findings have significant implications for information quality, information modeling, and UGC research and practice.
|keyword = systems design and implementation,laboratory experiments,information quality,conceptual modeling,crowdsourcing,social media,citizen science,user-generated content,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Feeling Blue? Go Online: An Empirical Study of Social Support Among Patients'''
{{header}}
{{article
|author= Lu Yan,Yong Tan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = In this paper, we investigate whether social support exchanged in an online healthcare community benefits patients' mental health. We propose a nonhomogeneous Partially Observed Markov Decision Process (POMDP) model to examine the latent health outcomes for online health community members. The transition between different health states is modeled as a probability function that incorporates different forms of social support that patients exchange via discussion board posts. We find that patients benefit from learning from others and that their participation in the online community helps them to improve their health and to better engage in their disease self-management process. Our results also reveal differences in the influence of various forms of social support exchanged on the evolution of patients' health conditions. We find evidence that informational support is the most prevalent type in the online healthcare community. Nevertheless, emotional support plays the most significant role in helping patients move to a healthier state. Overall, the influence of social support is found to vary depending on patients' health conditions. Finally, we demonstrate that our proposed POMDP model can provide accurate predictions for patients' health states and can be used to recover missing or unavailable information on patients' health conditions.
|keyword = healthcare,social networks,social support,partially observed Markov decision process,user-generated content,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Effects of ICT Service Innovation and Complementary Strategies on Brand Equity and Customer Loyalty in a Consumer Technology Market'''
{{header}}
{{article
|author= Xin Xu,James Y. L. Thong,Viswanath Venkatesh,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = This paper examines the effects of information and communication technology (ICT) service innovation and its complementary strategies on brand equity and customer loyalty toward ICT service providers. We draw from research on brand equity and customer loyalty, ICT innovation management, and strategy complementarity to propose a model that includes new constructs representing ICT service innovation, i.e., service leadership, and its two complementary strategies, i.e., customization-personalization control and technology leadership, and how their interactions influence customer loyalty through customer-based brand equity. We test our model using data from an online survey of 1,210 customers of mobile data services. The results show that service leadership and customization-personalization control have significant direct impacts on ICT service providers' brand equity. Moreover, when either the level of technology leadership or the level of customization-personalization control is high, the impact of service leadership on brand equity is enhanced. In turn, brand equity has significant impacts on consumers' affective loyalty and conative loyalty, but not on cognitive loyalty. Our study contributes to the literature on service management and service science, and in particular to the management of ICT service innovation in a consumer technology market.
|keyword = ICT service innovation,ICT service management,service leadership,technology leadership,customization,personalization,brand equity,customer loyalty,strategy complementarity,mobile data services,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Optimal Management of Digital Content on Tiered Infrastructure Platforms'''
{{header}}
{{article
|author= Anna Ye Du,Sanjukta Das,Ram D. Gopal,Ram Ramesh,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Media firms are increasingly using tiered infrastructure to cost-effectively manage heterogeneous resources by strategically allocating digital content across multiple tiers to avoid overcapacitating high-performance, expensive infrastructure tiers. Complex migrations in tiered environments are currently possible in a seamless, nondisruptive manner. We model digital content as a network capturing the inter-item impacts and use this network structure to develop optimal migration policies that partition media content into tiers. Addressing the context of large content providers such as video-on-demand providers that employ infrastructure platforms for content storage and delivery, we develop a bilevel programming model to maximize the profits of a price-setting platform and a tiered allocation-setting content provider. We model two fundamental effects with digital content: a revenue effect emanating from the tiered architecture and a traffic generating effect among media objects. Using a detailed longitudinal simulation study, we demonstrate the effectiveness of the proposed provisioning policy and pricing strategy and illustrate the existence and impact of these effects in media markets. Finally, we show that repeated execution of the model can help providers respond effectively to a changing environment and thus better manage the risk from demand fluctuations.
|keyword = data migration,information lifecycle,digital content,networks,tiered infrastructure,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Lateral Coordination Mechanisms and the Moderating Role of Arrangement Characteristics in Information Systems Development Outsourcing'''
{{header}}
{{article
|author= S. Balaji,Carol V. Brown,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Although increased information systems (IS) development outsourcing is the trend, many of these arrangements fail to meet client expectations. We take a coordination perspective and adopt an information processing lens used by prior organization theorists to conceptualize sets of formal structural and informal nonstructural mechanisms, and predict their positive impacts on the strategic IT benefits achieved by the client. Utilizing a strategic alliance lens, we also predict that two characteristics of the client-vendor arrangement will moderate the impacts of both sets of coordination mechanisms. We test our hypotheses using hierarchical regression techniques on field survey data collected from 141 IS managers in client firms, responsible for IS development outsourcing arrangements. We found that the implementation of both structural and informal mechanisms positively impact the client's strategic IT benefits. In arrangements with greater resource provisioning by the vendor, the positive impacts of informal governance mechanisms are strengthened. In arrangements with higher values similarity, the positive impacts of structural governance mechanisms are strengthened, but the positive impacts of informal mechanisms are weakened. A post-hoc analysis of a mediation model reveals that values similarity also has a positive relationship to both structural and informal governance mechanisms. This study therefore provides empirical support for the validity of an information processing lens to theorize lateral mechanism solutions to the coordination challenges of IS development outsourcing. Implications for research and practice are discussed, including the need for future research to better understand how client managers evolve sets of formal and informal mechanisms over the life of an outsourcing arrangement to achieve strategic objectives for their IT organization.
|keyword = IS outsourcing,lateral coordination mechanisms,structural governance,informal governance,outsourcing arrangements,outsourcing performance benefits,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Partial Least Squares and Models with Formatively Specified Endogenous Constructs: A Cautionary Note'''
{{header}}
{{article
|author= Miguel I. Aguirre-Urreta,George M. Marakas,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Information systems researchers have recently begun to propose models that include formatively specified constructs, and largely rely on partial least squares (PLS) to estimate the parameters of interest in those models. In this research, we focus on those cases where the formatively specified constructs are endogenous to other constructs in the research model in addition to their own manifest indicators, which are quite common in published research in the discipline, and analyze whether PLS is a valid statistical technique for estimating those models. Although there is evidence that covariance-based approaches can accurately estimate them, this is the first research that examines whether PLS can indeed do so. Through a theoretical analysis based on the inner workings of the PLS algorithm, which is later validated and extended through a series of Monte Carlo simulations, we conclude that is not the case. Specifically, estimates obtained from PLS are capturing something other than the relationship of interest when the formatively specified constructs are endogenous to others in the model. We show how our results apply more generally to a class of models, and discuss implications for future research practice.
|keyword = formative specification,partial least squares,research methods,structural equation modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Conflating Antecedents and Formative Indicators: A Comment on Aguirre-Urreta and Marakas'''
{{header}}
{{article
|author= Edward E. Rigdon,Jan-Michael Becker,Arun Rai,Christian M. Ringle,Adamantios Diamantopoulos,Elena Karahanna,Detmar W. Straub,Theo K. Dijkstra,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Aguirre-Urreta and Marakas [Aguirre-Urreta MI, Marakas GM (2014) Research note-Partial least squares and models with formatively specified endogenous constructs: A cautionary note. Inform. Systems Res. 25(4): 761-778] aim to evaluate the performance of partial least squares (PLS) path modeling when estimating models with formative endogenous constructs, but their ability to reach valid conclusions is compromised by three major flaws in their research design. First, their population data generation model does not represent "formative measurement" as researchers generally understand that term. Second, their design involves a PLS path model that is misspecified with respect to their population model. Third, although their aim is to estimate a composite-based PLS path model, their design uses simulation data generated via a factor analytic procedure. In consequence of these flaws, Aguirre-Urreta and Marakas' (2014) study does not support valid inference about the behavior of PLS path modeling with respect to endogenous formatively measured constructs.
|keyword = formative indicators,partial least squares,endogenous constructs,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Rejoinder to Rigdon et al. (2014)'''
{{header}}
{{article
|author= Miguel I. Aguirre-Urreta,George M. Marakas,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = We appreciate the interest shown by Rigdon et al. [Rigdon EE, Becker J-M, Rai A, Ringle CM, Diamantopoulos A, Karahanna E, Straub DW, Dijkstra TK (2014) Conflating antecedents and formative indicators: A comment on Aguirre-Urreta and Marakas. Inform. Systems Res. 25(4):780-784.] in our recent work and for the time and effort spent in carefully considering it and offering their comments and concerns. In what follows, and within the limitations of a short rejoinder, we offer our response to their comments, highlighting points of agreement and noting where more research is necessary.
|keyword = formative specification,partial least squares,structural equation model,data generation,endogenous constructs,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information, Technology, and the Changing Nature of Work'''
{{header}}
{{article
|author= Chris Forman,John Leslie King,Kalle Lyytinen,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = The information systems field started with the expectation that information and technology will significantly shape the nature of work. The topic provides ample scope for significant scholarly inquiry. Work content, process, and organization are now different from what they were in the 1960s and 1970s, which provided a foundation for theories and understanding. Although investigations about the changing nature of work have been made for years, this special section recognizes that the time of reckoning has come again. There is a growing need for deeper understanding of information, technology, and work. The specific contributions of this special section are at the heart of new frontiers of research in information, technology, and work. We observe a continued need to study their relationships, and to separate short-term and long-term effects. We expect continued surprises and conclude that patience is required to achieve increased understanding in this important domain.
|keyword = information technology,work,information,effects,control,productivity,skills,work organization,sociotechnical systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Social Media, Knowledge Sharing, and Innovation: Toward a Theory of Communication Visibility'''
{{header}}
{{article
|author= Paul M. Leonardi,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = This paper offers a theory of communication visibility based on a field study of the implementation of a new enterprise social networking site in a large financial services organization. The emerging theory suggests that once invisible communication occurring between others in the organization becomes visible for third parties, those third parties could improve their metaknowledge (i.e., knowledge of who knows what and who knows whom). Communication visibility, in this case made possible by the enterprise social networking site, leads to enhanced awareness of who knows what and whom through two interrelated mechanisms: message transparency and network translucence. Seeing the contents of other's messages helps third-party observers make inferences about coworkers' knowledge. Tangentially, seeing the structure of coworkers' communication networks helps third-party observers make inferences about those with whom coworkers regularly communicate. The emerging theory further suggests that enhanced metaknowledge can lead to more innovative products and services and less knowledge duplication if employees learn to work in new ways. By learning vicariously rather than through experience, workers can more effectively recombine existing ideas into new ideas and avoid duplicating work. Moreover, they can begin to proactively aggregate information perceived daily rather than engaging in reactive search after confronting a problem. I discuss the important implications of this emerging theory of communication visibility for work in the knowledge economy.
|keyword = social networking,innovation,knowledge sharing,metaknowledge,computer-mediated communication and collaboration,knowledge management,ethnographic research,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Patient Data as Medical Facts: Social Media Practices as a Foundation for Medical Knowledge Creation'''
{{header}}
{{article
|author= Jannis Kallinikos,Niccolo Tempini,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = This paper investigates a web-based, medical research network that relies on patient self-reporting to collect and analyze data on the health status of patients, mostly suffering from severe conditions. The network organizes patient participation in ways that break with the strong expert culture of medical research. Patient data entry is largely unsupervised. It relies on a data architecture that encodes medical knowledge and medical categories, yet remains open to capturing details of patient life that have as a rule remained outside the purview of medical research. The network thus casts the pursuit of medical knowledge in a web-based context, marked by the pivotal importance of patient experience captured in the form of patient data. The originality of the network owes much to the innovative amalgamation of networking and computational functionalities built into a potent social media platform. The arrangements the network epitomizes could be seen as a harbinger of new models of organizing medical knowledge creation and medical work in the digital age, and a complement or alternative to established models of medical research.
|keyword = medical practice,medical knowledge,social data,social media,computation,patient participation,networking,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Infrastructuring Work: Building a State-Wide Hospital Information Infrastructure in India'''
{{header}}
{{article
|author= Margunn Aanestad,Bob Jolliffe,Arunima Mukherjee,Sundeep Sahay,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Information and communication technologies that strengthen knowledge-based governance in low and middle-income countries (LMIC) will affect work processes and organizations on a massive scale. This paper draws attention to demands on public sector organizations in resource-constrained contexts that face different challenges than in high-income societies. This paper from the Indian public healthcare sector reports on design, development, implementation, and scaling of a free and open-source software-based hospital information system for district hospitals. The paper focuses on the implications for work, competencies, and organization, building on and extending the concepts of "automate" and "informate." The paper focuses on the emerging and recursive interplay between information infrastructure and work within the context of organizational realities of a district hospital in an LMIC context, captured by the concepts of "infrastructuring of work" and "work of infrastructuring."
|keyword = information systems and organizational change,inter-organizational information systems,management of IS projects,action research,health,India,developing countries,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Efficacy of R&D Work in Offshore Captive Centers: An Empirical Study of Task Characteristics, Coordination Mechanisms, and Performance'''
{{header}}
{{article
|author= Deepa Mani,Kannan Srikanth,Anandhi Bharadwaj,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Seizing the latest technological advances in distributed work, an increasing number of firms have set up offshore captive centers (CCs) in emerging economies to carry out sophisticated R&D work. We analyze survey data from 132 R&D CCs established by foreign multinational companies in India to understand how firms execute distributed innovative work. Specifically, we examine the performance outcomes of projects using different technology-enabled coordination strategies to manage their interdependencies across multiple locations. We find that modularization of work across locations is largely ineffective when the underlying tasks are less routinized, less analyzable, and less familiar to the CC. Coordination based on information sharing across locations is effective when the CC performs tasks that are less familiar to it. A key contribution of our work is the explication of the task contingencies under which coordination based on modularization versus information sharing yield differential performance outcomes.
|keyword = offshoring,captive centers,R&D,coordination,distributed work,modularization,information sharing,performance,knowledge-intensive work,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Doing Business with Strangers: Reputation in Online Service Marketplaces'''
{{header}}
{{article
|author= Antonio Moreno,Christian Terwiesch,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Online service marketplaces allow service buyers to post their project requests and service providers to bid for them. To reduce the transactional risks, marketplaces typically track and publish previous seller performance. By analyzing a detailed transactional data set with more than 1,800,000 bids corresponding to 270,000 projects posted between 2001 and 2010 in a leading online intermediary for software development services, we empirically study the effects of the reputation system on market outcomes. We consider both a structured measure summarized in a numerical reputation score and an unstructured measure based on the verbal praise left by previous buyers, which we encode using text mining techniques. We find that buyers trade off reputation (both structured and unstructured) and price and are willing to accept higher bids posted by more reputable bidders. Sellers also respond to changes in their own reputation through three different channels. They increase their bids with their reputation score (price effect) but primarily use a superior reputation to increase their probability of being selected (volume effect) as opposed to increasing their bid prices. Negative shocks in seller reputation are associated to an increase in the probability of seller exit (exit effect), but this effect is moderated by the investment that the seller has made in the site. We conclude that participants in this market are very responsive to the numerical reputation score and also to the unstructured reputational information, which behaves in a similar way to the structured numerical reputation score but provides complementary information.
|keyword = auctions,online service marketplaces,procurement,reputation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Physical and Electronic Wholesale Markets: An Empirical Analysis of Product Sorting and Market Function'''
{{header}}
{{article
|author= Eric Overby,Sabyasachi Mitra,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Markets can yield significant economic benefits by improving transaction efficiency, but effective design is necessary to achieve these benefits. We compare a physical market to a discrete electronic market in the wholesale used vehicle industry to evaluate how their different designs work for different types of transactions. We find that buyers and sellers balance adverse selection costs and other transaction costs when using the two markets, with the physical market serving as the general exchange and the electronic market serving as a spot market for vehicles with low adverse selection risk. These findings increase our understanding of how sellers and buyers distribute supply and demand between physical and electronic markets in industries in which they coexist. They also increase our understanding of how information technology can improve market function in wholesale environments.
|keyword = adverse selection,automotive sector,electronic markets,market design,online markets,physical markets,quality sorting,transaction costs,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Launching Successful E-Markets: A Broker-Level Order-Routing Analysis of Two Options Exchanges'''
{{header}}
{{article
|author= Chris Parker,Bruce W. Weber,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = New e-markets try in a number of ways to attract a critical mass of participation and usage. Two innovative, all-electronic options exchanges, the International Securities Exchange (ISE) and the Boston Options Exchange (BOX), opened for trading in 2000 and 2004. In contrast to rival floor markets, they offer immediate order execution, direct user access, and reduced costs. As a result, ISE and BOX grew trading volumes and won market share from four incumbent exchanges in the United States. We observe significant differences between broker order-routing practices across ISE and BOX, leading to the markets' different growth patterns. We develop and test hypotheses about new market growth using a panel of six years of quarterly disclosures from 24 major brokerage firms. We find that membership affiliations are the dominant force in predicting brokers' order-routing patterns. In contrast to prior research, network externalities, as measured by an exchange's previous quarter market share, are not significant predictors after controlling for temporal heterogeneity. From our results, executives of new electronic exchanges should concentrate on developing broker exchange affiliation and incentive schemes in order to achieve sustainable order levels. Furthermore, keeping a keen eye on the competitive landscape and reacting to changes in current and prospective competitors' affiliation structures may prove the most beneficial way to ensure continued success. Top management must identify the relative advantages of new entrants' affiliation structures and respond accordingly. A new entrant that provides incentives through a novel affiliation structure can be routed significant orders if the incumbent exchange does not react swiftly and effectively. The results are not limited to analyzing electronic exchanges but, we expect, to many situations where competing information technology platforms also benefit from user affiliation and network effects.
|keyword = competitive effects of IS,electronic auctions,electronic financial markets,electronic market assessment,electronic market design,IT effects on industry structure,longitudinal research,market structure,network economics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of Buy-Now Features in Pay-per-Bid Auctions'''
{{header}}
{{article
|author= Jochen Reiner,Martin Natter,Bernd Skiera,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Pay-per-bid auctions require all bidders to pay for every bid. However, paying bidding fees without receiving the auction item in return often causes high dissatisfaction among losers, resulting in heated discussions and high churn rates. To reduce these negative reactions, pay-per-bid auctioneers created the Buy-Now feature, which allows losers to put all or part of the bidding fees that they paid during an auction toward buying the auction item. Using unique data, including individual customer bidding histories and cost data from more than 6,800 pay-per-bid auctions, we find that, overall, the Buy-Now feature leads to more aggressive bidding behavior, attracts more bidders, increases loyalty, and results in a higher profit per auction. However, for voucher auctions that represent common value auctions, the Buy-Now feature causes a decrease in the number of bidders and the profit per auction, although we find an increase in the average number of bids per bidder. We also show theoretically that a bidder can pursue a risk-free bidding strategy. However, we find empirically that bidders rarely use this strategy.
|keyword = Buy-Now feature,Buy-Now prices,electronic auctions,online marketing,online retailing,pay-per-bid auctions,penny auctions,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Customized Bundling and Consumption Variety of Digital Information Goods'''
{{header}}
{{article
|author= Jese C. Bockstedt,Kim Huat Goh,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Customized bundling retail strategies have become increasingly popular online. In customized bundling, consumers decide the bundle's components, and the effects of this change on consumption variety have important implications for information goods retailers. Although reduction in transaction and search costs increases supply-side product variety, customized bundling can introduce new types of friction in the consumption process. We show that customization of information good bundles reduces consumption variety through two effects: design cost effects and compromise effects. We present the results of three behavioral experiments and an empirical study using sales data from a national music retailer. This study contributes to the theoretical understanding of the effects of customized bundling on search costs and demand-side dynamics. The results provide insights for information goods retailers on the effects of design and search costs on consumer purchasing behavior. Implications for the design of retail platforms for customizable information goods are discussed.
|keyword = behavioral economics,bundling,content bundling,customization,e-commerce,information goods,mass customization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Determinants of Mobile Apps' Success: Evidence from the App Store Market'''
{{header}}
{{article
|author= Gunwoong Lee,T. S. Raghu,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Mobile applications markets with app stores have introduced a new approach to define and sell software applications with access to a large body of heterogeneous consumer population. This research examines key seller-and app-level characteristics that impact success in an app store market. We tracked individual apps and their presence in the top-grossing 300 chart in Apple's App Store and examined how factors at different levels affect the apps' survival in the top 300 chart. We used a generalized hierarchical modeling approach to measure sales performance, and confirmed the results with the use of a hazard model and a count regression model. We find that broadening app offerings across multiple categories is a key determinant that contributes to a higher probability of survival in the top charts. App-level attributes such as free app offers, high initial ranks, investment in less-popular (less-competitive) categories, continuous quality updates, and high-volume and high-user review scores have positive effects on apps' sustainability. In general, each diversification decision across a category results in an approximately 15 percent increase in the presence of an app in the top charts. Survival rates for free apps are up to two times more than that for paid apps. Quality (feature) updates to apps can contribute up to a threefold improvement in survival rate as well. A key implication of the results of this study is that sellers must utilize the natural segmentation in consumer tastes offered by the different categories to improve sales performance.
|keyword = app markets,apps,m-commerce,mobile software sustainability,product portfolio management,survival analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Gifting and Status in Virtual Worlds'''
{{header}}
{{article
|author= Sigi Goode,Greg Shailer,Mark Wilson,Jaroslaw Jankowski,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = While profitable business models elude many virtual worlds, sales of virtual products are a potentially lucrative source of revenue. One new addition to this strategy is virtual gifting, whereby users purchase virtual products to give to other users. The monetary value of such virtual good transactions is economically significant but no prior study has examined this phenomenon in a strictly virtual context. We apply theory from the economics literature to examine gifting behavior in a virtual world in which users' social status is reflected in observable social connections (friendships) and interactions (personal messages). We find strong evidence that gifting is associated with future enhancements of the gift giver's social status, consistent with a social status-seeking motivation, thus confirming a theorized behavior that is difficult to study in the real world. Our study has implications for system proprietors and managers because we show that gift giving increases system use continuance. We identify various antecedents of gift giving, which may assist a manager in identifying users who are most inclined to give gifts and enable the manager to signal the social exchange benefits to users as a way of improving their social connections.
|keyword = gift economy,MMOG,status in virtual worlds,virtual gifts,virtual worlds,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Digital Piracy, Teens, and the Source of Advice: An Experimental Study'''
{{header}}
{{article
|author= Matthew J. Hashim,Karthik N. Kannan,Sandra Maximiano,Jackie Rees Ulmer,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = The objective of our paper is to determine the effect of piracy advice from various sources on the behavior of the music consumer. Specifically, does it matter if the source of advice has a stake in the outcome of the piracy decision? Does it matter if the source of advice has a social tie with the advisee? Accordingly, we conduct a laboratory experiment using teenagers and their parents as subjects, increasing the realism of the context by sampling potential pirates and their parents. Treatments represent various sources of piracy advice (e.g., the teen's parent, a record label, or an external regulator). Subjects make decisions playing our new experimental game-The Piracy Game-extended from the volunteer's dilemma literature. Interestingly, subjects respond negatively to advice from record labels over time, purchasing fewer songs as compared to other sources such as the subject's parent. The existence of a social tie between the adviser and the subject assists in mitigating piracy, especially when a parent is facing potential penalties due to his or her child's behavior. An external regulator, having no social tie or stake in the decision, provides the least credible source of advice, leading to the greatest amount of piracy. Our analyses not only provide managerial insights but also develop theoretical understanding of the role of social ties in the context of advice.
|keyword = advice effectiveness,experimental economics,music consumers,music markets,music piracy,online piracy,volunteer's dilemma,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Collaborative Demand Forecasting: Toward the Design of an Exception-Based Forecasting Mechanism'''
{{header}}
{{article
|author= Yan Dong,Xiaowen Huang,Kingshuk K. Sinha,Kefeng Xu,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Sharing of truthful information involving business intelligence between supply chain partners is a challenge on account of the asymmetric nature of the information, where one party possesses information such as market intelligence that is neither available in the public domain nor verifiable through third parties. While busesinss-to-business (B2B) technology solutions, such as CPFR (collaborative planning, forecasting, and replenishment), facilitate the sharing of historical information (e.g., transaction records), business intelligence (e.g., potential customer demand) is considered private. Central to CPFR is collaborative demand forecasting (CDF) that allows supply chain partners to share private demand information and incorporate the jointly derived demand forecast into production planning and product replenishment decisions. Implementing CDF, however, is a challenge because of the high costs of the laborious collaboration effort (e.g., to resolve forecast differences). Hence, companies are unable to realize the benefits of CDF and, in turn, the full potential of CPFR. Typically, the issues of information truthfulness and collaboration cost are addressed through an exception management mechanism that defines a range of forecast updates within which collaboration is automated without any human intervention in B2B trading partners. In this paper, we develop incentive-based contracts that explicitly consider the truth-telling behavior and exception resolution in decisions related to the threshold values of demand information. Our first contribution to B2B information management is in establishing the strategic value of exception management and resolution mechanisms in B2B relationships, leading to truthful revelation of demand information. Our second contribution is in developing exception-based incentive contracts, especially in light of the advances in today's business practices and technology, to address issues associated with unobservable and asymmetric demand information. Specifically, we propose a resolution contract to coordinate the supply chain that directly incorporates both exceptions and resolution in an incentive mechanism. We show that these alternative contracts are all viable solutions in assuring truthful exchange of demand information but excel individually in specific situations and, thus, provide practitioners with alternative demand collaboration tools when price negotiation is not an option.
|keyword = B2B commerce,collaborative commerce,collaborative demand forecasting,collaborative planning,exception-based incentive mechanism,forecasting and replenishment,information sharing,supply chain management,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Understanding Employee Responses to Stressful Information Security Requirements: A Coping Perspective'''
{{header}}
{{article
|author= John D'Arcy,Tejaswini Herath,Mindy K. Shoss,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = We use coping theory to explore an underlying relationship between employee stress caused by burdensome, complex, and ambiguous information security requirements (termed "security-related stress" or SRS) and deliberate information security policy (ISP) violations. Results from a survey of 539 employee users suggest that SRS engenders an emotion-focused coping response in the form of moral disengagement from ISP violations, which in turn increases one's susceptibility to this behavior. Our multidimensional view of SRS-comprised of security-related overload, complexity, and uncertainty-offers a new perspective on the workplace environment factors that foster noncompliant user behavior and inspire cognitive rationalizations of such behavior. The study extends technostress research to the information systems security domain and provides a theoretical framework for the influence of SRS on user behavior. For practitioners, the results highlight the incidence of SRS in organizations and suggest potential mechanisms to counter the stressful effects of information security requirements.
|keyword = coping theory,ethical orientation,information security,moral disengagement theory,sanctions,security compliance,security policies,security policy violation,social cognitive theory,technostress,workplace stress,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Relational Contracts, Growth Options, and Heterogeneous Beliefs: A Game-Theoretic Perspective on Information Technology Outsourcing'''
{{header}}
{{article
|author= Xiaotong Li,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = More companies have realized that information technology (IT) outsourcing, once viewed as a cost reduction tool, could facilitate and even enable the transformation of their core business processes. The benefits from a potential outsourcing relationship expansion have strategic implications for relational incentive provision. Modeling "information poaching" in IT outsourcing as an incentive problem with contractibility constraints, our analysis shows that this problem could be mitigated in a repeated game where the outsourcing client and the service provider agree on a relational contract. When the two partners share the belief that they can potentially benefit from a future relationship expansion, they are more likely to behave cooperatively during the early stages of their relationship. However, when they disagree about the likelihood of the future relationship expansion, they will have different preferences on a set of otherwise equivalent relational bonus contracts. Specifically, they will adopt a relational contract with large but infrequent bonuses when the client is more optimistic than the service provider about the potential of their relationship. Because these results hold even when the sourcing partners' beliefs are very close to each other, our analysis sheds fresh light on the issue of equilibrium selection in relational contract theory. In the context of IT outsourcing, the results of this study suggest that, because salient forms of relational bonuses are often not adopted, relational incentive provision is likely more pervasive than what we can observe.
|keyword = contractibility,equilibrium selection,growth options,heterogeneous beliefs,IT outsourcing,outsourcing contracts,relational contracts,repeated games,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''KNOW YOURSELF AND KNOW YOUR ENEMY: AN ANALYSIS OF FIRM RECOMMENDATIONS AND CONSUMER REVIEWS IN A COMPETITIVE ENVIRONMENT'''
{{header}}
{{article
|author= Wael Jabr,Zhiqiang (Eric) Zheng,
|source= MIS QUARTERLY
|year= 2014
|abstract = Reviews and product recommendations at online stores enable customers to readily evaluate alternative products prior to purchase. In this context, firms generate recommendations referring customers to a wider variety of products. They also display customer-generated online reviews in order to facilitate evaluation of those recommended products. This study integrates these two IT artifacts to investigate consumer choice vis-a-vis competing products. We use a dataset we collected from Amazon.com consisting of books, sales ranks, recommendations, reviews, and reviewers. We derive the granular impact of reviews, product referrals, and reviewer opinions on product sale dynamics within a competitive market using comprehensive econometric analyses.
|keyword = Online review,eWOM,competition,recommendation system,instrument variable,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DIFFERENTIAL EFFECTS OF PRIOR EXPERIENCE ON THE MALWARE RESOLUTION PROCESS'''
{{header}}
{{article
|author= Seung Hyun Kim,Byung Cho Kim,
|source= MIS QUARTERLY
|year= 2014
|abstract = Despite growing interest in the economic and policy aspects of information security, little academic research has used field data to examine the development process of a security countermeasure provider. In this paper, we empirically examine the learning process a security software developer undergoes in resolving a malware problem. Using the data collected from a leading antivirus software company in Asia, we study the differential effects of experience on the malware resolution process. Our findings reveal that general knowledge from cross-family experience has greater impact than specific knowledge from within-family experience on performance in the malware resolution process. We also examine the factors that drive the differential effects of prior experience. Interestingly, our data show that cross-family experience is more effective than within-family experience in malware resolution when malware targets the general public than when a specific victim is targeted. Similar results-for example, the higher (lower) effect of cross-family (within-family) experience-were observed in the presence of information sharing among software vendors or during a disruption caused by a catastrophe. Our study contributes to a better understanding of the specific expertise required for security countermeasure providers to be able to respond under varying conditions to fast-evolving malware.
|keyword = Information security,economics of information systems,learning curve,antivirus software,malware,targeted attack,information sharing,catastrophe,knowledge retention,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DIGRESSION AND VALUE CONCATENATION TO ENABLE PRIVACY-PRESERVING REGRESSION'''
{{header}}
{{article
|author= Xiao-Bai Li,Sumit Sarkar,
|source= MIS QUARTERLY
|year= 2014
|abstract = Regression techniques can be used not only for legitimate data analysis, but also to infer private information about individuals. In this paper, we demonstrate that regression trees, a popular data-analysis and data-mining technique, can be used to effectively reveal individuals' sensitive data. This problem, which we call a regression attack, has not been addressed in the data privacy literature, and existing privacy-preserving techniques are not appropriate in coping with this problem. We propose a new approach to counter regression attacks. To protect against privacy disclosure, our approach introduces a novel measure, called digression, which assesses the sensitive value disclosure risk in the process of building a regression tree model. Specifically, we develop an algorithm that uses the measure for pruning the tree to limit disclosure of sensitive data. We also propose a dynamic value-concatenation method for anonymizing data, which better preserves data utility than a user-defined generalization scheme commonly used in existing approaches. Our approach can be used for anonymizing both numeric and categorical data. An experimental study is conducted using real-world financial, economic, and healthcare data. The results of the experiments demonstrate that the proposed approach is very effective in protecting data privacy while preserving data quality for research and analysis.
|keyword = Privacy,data analytics,data mining,regression,regression trees,anonymization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AN ATTRACTION-SELECTION-ATTRITION THEORY OF ONLINE COMMUNITY SIZE AND RESILIENCE'''
{{header}}
{{article
|author= Brian S. Butler,Patrick J. Bateman,Peter H. Gray,E. Ilana Diamant,
|source= MIS QUARTERLY
|year= 2014
|abstract = Online discussion communities play an important role in the development of relationships and the transfer of knowledge within and across organizations. Their underlying technologies enhance these processes by providing infrastructures through which group-based communication can occur. Community administrators often make decisions about technologies with the goal of enhancing the user experience, but the impact of such decisions on how a community develops must also be considered. To shed light on this complex and under-researched phenomenon, we offer a model of key latent constructs influenced by technology choices and possible causal paths by which they have dynamic effects on communities. Two important community characteristics that can be impacted are community size (number of members) and community resilience (membership that is willing to remain involved with the community in spite of variability and change in the topics discussed). To model community development, we build on attraction-selection-attrition (ASA) theory, introducing two new concepts: participation costs (how much time and effort are required to engage with content provided in a community) and topic consistency cues (how strongly a community signals that topics that may appear in the future will be consistent with what it has hosted in the past). We use the proposed ASA theory of online communities (OCASA) to develop a simulation model of community size and resilience that affirms some conventional wisdom and also has novel and counterintuitive implications. Analysis of the model leads to testable new propositions about the causal paths by which technology choices affect the emergence of community size and community resilience, and associated implications for community sustainability.
|keyword = Online communities,social media,benefits,costs,emergent systems,simulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EXPECTATION CONFIRMATION IN INFORMATION SYSTEMS RESEARCH: A TEST OF SIX COMPETING MODELS'''
{{header}}
{{article
|author= Susan A. Brown,Viswanath Venkatesh,Sandeep Goyal,
|source= MIS QUARTERLY
|year= 2014
|abstract = Expectation confirmation research in general, and in information systems (IS) in particular, has produced conflicting results. In this paper, we discuss six different models of expectation confirmation: assimilation, contrast, generalized negativity, assimilation-contrast, experiences only, and expectations only. Relying on key constructs from the technology acceptance model (TAM), we test each of these six models that suggests different roles for expectations and experiences of the key predictor-here, perceived usefulness-and their impacts on key outcomes-here, behavioral intention, use, and satisfaction. Data were collected in a field study from 1,113 participants at two points in time. Using polynomial modeling and response surface analysis, we provide the analytical representations for each of the six models and empirically test them to demonstrate that the assimilation-contrast is the best existing model in terms of its ability to explain the relationships between expectations and experiences of perceived usefulness and important dependent variables-namely, behavioral intention, use, and satisfaction-in individual-level research on IS implementations.
|keyword = Expectations,disconfirmation,software use,polynomial modeling,response surface analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ESTIMATING RETURNS TO TRAINING IN THE KNOWLEDGE ECONOMY: A FIRM-LEVEL ANALYSIS OF SMALL AND MEDIUM ENTERPRISES'''
{{header}}
{{article
|author= Amit Mehra,Nishtha Langer,Ravi Bapna,Ram Gopal,
|source= MIS QUARTERLY
|year= 2014
|abstract = The ongoing digitization of multiple industries has drastically reduced the half-life of skills and capabilities acquired by knowledge workers through formal education. Thus, firms are forced to make significant ongoing investments in training their employees to remain competitive. Existing research has not examined the role of training in improving firm-level productivity of knowledge firms. This paper provides an innovative econometric framework to estimate returns to such employee training investments made by firms. We use a panel dataset of small-to medium-sized Indian IT services firms and assess how training enhances human capital, a critical input for such firms, thereby improving firm revenues. We use econometric approaches based on optimization of the firm's profit function to eliminate the endogenous choice of inputs common in production function estimations. We find that an increase in training investments is significantly linked to an increase in revenue per employee. Further, marginal returns to training are increasing firm size. Therefore, relatively speaking, large firms benefit more from training. For the median company in our data, we find that a dollar invested in training yields a return of $4.67, and this effect approximately grows 2.5 times for the 75th percentile-sized firm. A variety of robustness checks, including the use of data envelopment analysis, are used to establish the veracity of our results.
|keyword = IT services,nonlinear growth,ROI of training,productivity,human capital,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CULTURAL DIFFERENCES AND GEOGRAPHY AS DETERMINANTS OF ONLINE PROSOCIAL LENDING'''
{{header}}
{{article
|author= Gordon Burtch,Anindya Ghose,Sunil Wattal,
|source= MIS QUARTERLY
|year= 2014
|abstract = In this paper, we analyze patterns of transaction between individuals using data drawn from Kiva.org, a global online crowdfunding platform that facilitates prosocial, peer-to-peer lending. Our analysis, which employs an aggregate dataset of country-to-country lending volumes based on more than three million individual lending transactions that took place between 2005 and 2010, considers the dual roles of geographic distance and cultural differences on lenders' decisions about which borrowers to support. While cultural differences have seen extensive study in the Information Systems literature as sources of friction in extended interactions, here, we argue and demonstrate their role in individuals' selection of a transaction partner. We present evid ence that lenders do prefer culturally similar and geographically proximate borrowers. An analysis of the marginal effects indicates that an increase of one standard deviation in the cultural differences between lender and borrower countries is associated with 30 fewer lending actions, while an increase of one standard deviation in physical distance is associated with 0.23 fewer lending actions. We also identify a substitution effect between cultural differences and physical distance, such that a 50 percent increase in physical distance is associated with an approximate 30 percent decline in the effect of cultural differences. Considering approaches to overcoming the observed cultural effect, we offer some empirical evidence of the potential of IT-based trust mechanisms, focusing on Kiva's reputation rating system for microfinance intermediaries. We discuss the implications of our findings for prosocial lending, online crowdfunding, and electronic markets more broadly.
|keyword = Prosocial lending,microfinance,cultural differences,geography,crowdfunding,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EMERGENCE OF POWER LAWS IN ONLINE COMMUNITIES: THE ROLE OF SOCIAL MECHANISMS AND PREFERENTIAL ATTACHMENT'''
{{header}}
{{article
|author= Steven L. Johnson,Samer Faraj,Srinivas Kudaravalli,
|source= MIS QUARTERLY
|year= 2014
|abstract = Online communities bring together individuals with shared interest in joint action or sustained interaction. Power law distributions of user popularity appear ubiquitous in online communities but their formation mechanisms are not well understood. This study tests for the emergence of power law distributions via the mechanisms of preferential attachment, least efforts, direct reciprocity, and indirect reciprocity. Preferential attachment, where new entrants favor connections with already popular participants, is the predominant explanation suggested by prior literature. Yet, the attribution of preferential attachment or any other mechanism as a single unitary reason for the emergence of power law distributions runs contrary to the social nature of online communities and does not account for diversity of participants' motivation. Agent-based modeling is used to test if a single social mechanism alone or multiple mechanisms together can generate power law distributions observed in online communities. Data from 28 online communities is used to calibrate, validate, and analyze the simulation. Simulated communication networks are randomly generated according to parameters for each hypothesis. The fit of the power law distribution in the model testing subset is then compared against the fit for these simulated networks. The major finding is that, in contrast to research in more general network settings, neither preferential attachment nor any other single mechanism alone generates a power law distribution. Instead, a blended model of preferential attachment with other social network formation mechanisms was most consistent with power law distributions seen in online communities. This suggests the need to move away from stylized explanations of network emergence that rely on single theories toward more highly socialized and multitheoretic explanations of community development.
|keyword = Online communities,scale-free,power law distribution,preferential attachment,social exchange,reciprocity,simulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DYNAMIC RECONFIGURATION IN PLANETARY EXPLORATION: A SOCIOMATERIAL ETHNOGRAPHY'''
{{header}}
{{article
|author= Melissa Mazmanian,Marisa Cohn,Paul Dourish,
|source= MIS QUARTERLY
|year= 2014
|abstract = In taking into account the ways in which material and social realms are constitutively entangled within organizations, it is rhetorically tempting to say that technologies and social structures reconfigure each other. But what does it mean to reconfigure? How does one "figure" the other and how do we fully embrace a mutually constitutive relationship when examining fluid relations? This paper delves into these questions by exploring how physical, social, material, technological, and organizational arrangements dynamically reconfigure each other in the duration of organizational practice. Using the venue of space exploration, we present three empirical examples from an ethnographic engagement with a NASA mission orbiting an outer planet in the solar system to examine various configurations and sociomaterial relations. In this endeavor, we suggest that theoretical and empirical traction can be gained by focusing attention on the dynamic reconfigurations between social and material realms. In so doing, we call attention to the ways in which current sociomaterial perspectives have difficulty articulating the shifting, figural, asymmetric and dynamic negotiations between people, social structures, information technologies, and representational objects. This paper contributes to current discussions of sociomaterial relations in information systems research by presenting an empirical treatment of entangled and shifting reconfigurations and providing language for engaging with this perspective.
|keyword = Sociomateriality,dynamic reconfiguration,organizational processes,software studies,representational practices,outer planetary exploration,qualitative empirical analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TOWARD GENERALIZABLE SOCIOMATERIAL INQUIRY: A COMPUTATIONAL APPROACH FOR ZOOMING IN AND OUT OF SOCIOMATERIAL ROUTINES'''
{{header}}
{{article
|author= James Gaskin,Nicholas Berente,Kalle Lyytinen,Youngjin Yoo,
|source= MIS QUARTERLY
|year= 2014
|abstract = In this paper, a computational, mixed methods approach that combines qualitative analysis with a novel approach to sequence analysis for studying the entanglement of human activities and digital capabilities in organizational routines is described. The approach is scalable across multiple contexts and complements the dominant idiographic modes of sociomaterial inquiry. The approach is rooted in the epistemology of a "rational reconstruction" consistent with the interpretive stance underlying the sociomaterial position. It arms researchers with the means to seek and uncover regularities in the ways human activities and digital capabilities become entangled across contexts by enabling the identification and articulation of generalizable patterns of sociomaterial activity. The computational approach is founded on sequence-analytic techniques that originated from the field of computational biology (genetics), but are now gaining popularity in the study of temporally ordered social phenomena such as organizational routines. These techniques are extended by drawing upon theoretical insights gained within sociomaterial scholarship on how the digital and the social become entangled. By detecting the variation in activities, actors, artifacts, and affordances that comprise what we denote a sociomaterial routine, the approach directly attends to ways in which human actors and the material features of technology become entangled in patterns of practice. Beyond motivating and describing the approach, the different insights that researchers can generate through its application in the study of the digitalization of organizational routines are illustrated. We conclude by suggesting several lines of inquiry that can enrich sociomaterial research.
|keyword = Sociomaterial,sociotechnical,rational reconstruction,computational social science,methodology,sequence analysis,routines,mixed methods,organizational routines,generative grammar,lexicon,lexical notation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ENTANGLEMENTS IN PRACTICE: PERFORMING ANONYMITY THROUGH SOCIAL MEDIA'''
{{header}}
{{article
|author= Susan V. Scott,Wanda J. Orlikowski,
|source= MIS QUARTERLY
|year= 2014
|abstract = Information systems researchers have shown an increasing interest in the notion of sociomateriality. In this paper, we continue this exploration by focusing specifically on entanglement: the inseparability of meaning and matter. Our particular approach is differentiated by its grounding in a relational and performative ontology, and its use of agential realism. We explore some of the key ideas of entanglement through a comparison of two phenomena in the travel sector: an institutionalized accreditation scheme offered by the AA and an online social media website hosted by TripAdvisor. Our analysis centers on the production of anonymity in these two practices of hotel evaluation. By examining how anonymity is constituted through an entanglement of matter and meaning, we challenge the predominantly social treatments of anonymity to date and draw attention to the uncertainties and outcomes generated by specific performances of anonymity in practice. In closing, we consider what the particular agential realist concept of entanglement entails for understanding anonymity, and discuss its implications for research practice.
|keyword = Anonymity,entanglement,agential realism,social media,materiality,sociomateriality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A MATTER OF LIFE AND DEATH: EXPLORING CONCEPTUALIZATIONS OF SOCIOMATERIALITY IN THE CONTEXT OF CRITICAL CARE'''
{{header}}
{{article
|author= Matthew Jones,
|source= MIS QUARTERLY
|year= 2014
|abstract = Sociomateriality has been attracting growing attention in the Organization Studies and Information Systems literatures since 2007, with more than 140 journal articles now referring to the concept. Over 80 percent of these articles have been published since January 2011 and almost all cite the work of Orlikowski (2007, 2010; Orlikowski and Scott 2008) as the source of the concept. Only a few, however, address all of the notions that Orlikowski suggests are entailed in sociomateriality, namely materiality, inseparability, relationality, performativity, and practices, with many employing the concept quite selectively. The contribution of sociomateriality to these literatures is, therefore, still unclear. Drawing on evidence from an ongoing study of the adoption of a computer-based clinical information system in a hospital critical care unit, this paper explores whether the notions, individually and collectively, offer a distinctive and coherent account of the relationship between the social and the material that may be useful in Information Systems research. It is argued that if sociomateriality is to be more than simply a label for research employing a number of loosely related existing theoretical approaches, then studies employing the concept need to pay greater attention to the notions entailed in it and to differences in their interpretation.
|keyword = Sociomateriality,practice,empirical,adoption,interpretive,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A TRICHORDAL TEMPORAL APPROACH TO DIGITAL COORDINATION: THE SOCIOMATERIAL MANGLING OF THE CERN GRID'''
{{header}}
{{article
|author= Will Venters,Eivor Oborn,Michael Barrett,
|source= MIS QUARTERLY
|year= 2014
|abstract = This paper develops a sociomaterial perspective on digital coordination. It extends Pickering's mangle of practice by using a trichordal approach to temporal emergence. We provide new understanding as to how the nonhuman and human agencies involved in coordination are embedded in the past, present, and future. We draw on an in-depth field study conducted between 2006 and 2010 of the development, introduction, and use of a computing grid infrastructure by the CERN particle physics community. Three coordination tensions are identified at different temporal dimensions, namelyobtaining adequate transparency in the present, modeling a future infrastructure, and the historical disciplining of social and material inertias. We propose and develop the concept of digital coordination, and contribute a trichordal temporal approach to understanding the development and use of digital infrastructure as being orientated to the past and future while emerging in the present.
|keyword = Grid computing,coordination,development,case study,mangle of practice,temporality,digital infrastructure,transparency,sustainable change,performativity,sociomaterial,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Using Income Accounting as the Theoretical Basis for Measuring IT Productivity'''
{{header}}
{{article
|author= Dennis O. Kundisch,Neeraj Mittal,Barrie R. Nault,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = We use the under-recognized income accounting identity to provide an important theoretical basis for using the Cobb-Douglas production function in IT productivity analyses. Within the income accounting identity we partition capital into non-IT and IT capital and analytically derive an accounting identity (AI)-based Cobb-Douglas form that both nests the three-input Cobb-Douglas and provides additional terms based on wage rates and rates of return to non-IT and IT capital. To empirically confirm the theoretical derivation, we use a specially constructed data set from a subset of the U. S. manufacturing industry that involve elaborate calculations of rates of return-a data set that is infeasible to obtain for most productivity studies-to estimate the standard Cobb-Douglas and our AI-based form. We find that estimates from our AI-based form correspond with those of the Cobb-Douglas, and our AI-based form has significantly greater explanatory power. In addition, empirical estimation of both forms is relatively robust to the assumption of intertemporally stable input shares required to derive the AI-based form, although there may be limits. Thus, in the context of future research the Cobb-Douglas form and its application in IT productivity work have a theoretically and empirically supported basis in the accounting identity. A poor fit to data or unexpected coefficient estimates suggests problems with data quality or intertemporally unstable input shares. Our work also shows how some returns to IT that do not show up in output elasticities can be found in total factor productivity (TFP)-the novel ways inputs are combined to produce output. The critical insight for future research is that many unobservables that have been considered part of TFP can be manifested in rates of return to IT capital, non-IT capital, and labor-rates of return that are separated from TFP in our AI-based form. Finally, finding that the additional rates of return terms partially explain TFP confirms the need for future IT productivity researchers to incorporate time-varying TFP in their models.
|keyword = information systems,IT policy and management,economics of IS,income accounting identity,IT productivity,production function,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Distinction and Status Production on User-Generated Content Platforms: Using Bourdieu's Theory of Cultural Production to Understand Social Dynamics in Online Fields'''
{{header}}
{{article
|author= Natalia Levina,Manuel Arriaga,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = In this paper, we propose an analytical lens for studying social status production processes across a wide variety of user-generated content (UGC) platforms. Various streams of research, including those focused on social network analysis in social media, online communities, reputation systems, blogs, and multiplayer games, have discussed social status production online in ways that are diverse and incompatible. Drawing on Bourdieu's theory of fields of cultural production, we introduce the notion of an online field and associated sociological concepts to help explain how diverse types of producers and consumers of content jointly generate unique power relations online. We elaborate on what role external resources and status markers may play in shaping social dynamics in online fields. Using this unifying theory we are able to integrate previous research findings and propose an explanation of social processes behind both the similarity across UGC platforms, which all offer multiple ways of pursuing distinction through content production, as well as the differences across such platforms in terms of which distinctions matter. We elaborate what role platform design choices play in shaping which forms of distinction count and how they are pursued as well as implications these have for status gaining strategies. We conclude the paper by suggesting how our theory can be used in future qualitative and quantitative research studies.
|keyword = electronic commerce,social media,user-generated content,status,power,Bourdieu practice theory,network analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Cloud Implications on Software Network Structure and Security Risks'''
{{header}}
{{article
|author= Terrence August,Marius Florin Niculescu,Hyoduk Shin,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = By software vendors offering, via the cloud, software-as-a-service (SaaS) versions of traditionally on-premises application software, security risks associated with usage become more diversified. This can greatly increase the value associated with the software. In an environment where negative security externalities are present and users make complex consumption and patching decisions, we construct a model that clarifies whether and how SaaS versions should be offered by vendors. We find that the existence of version-specific security externalities is sufficient to warrant a versioned outcome, which has been shown to be suboptimal in the absence of security risks. In high security-loss environments, we find that SaaS should be geared to the middle tier of the consumer market if patching costs and the quality of the SaaS offering are high, and geared to the lower tier otherwise. In the former case, when security risk associated with each version is endogenously determined by consumption choices, strategic interactions between the vendor and consumers may cause a higher tier consumer segment to prefer a lower inherent quality product. Relative to on-premises benchmarks, we find that software diversification leads to lower average security losses for users when patching costs are high. However, when patching costs are low, surprisingly, average security losses can increase as a result of SaaS offerings and lead to lower consumer surplus. We also investigate the vendor's security investment decision and establish that, as the market becomes riskier, the vendor tends to increase investments in an on-premises version and decrease investments in a SaaS version. On the other hand, in low security-loss environments, we find that SaaS is optimally targeted to a lower tier of the consumer market, average security losses decrease, and consumer surplus increases as a result. Security investments increase for both software versions as risk increases in these environments.
|keyword = cloud computing,software-as-a-service,network economics,security,versioning,on-premises software,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Online Gambling Behavior: The Impacts of Cumulative Outcomes, Recent Outcomes, and Prior Use'''
{{header}}
{{article
|author= Xiao Ma,Seung Hyun Kim,Sung S. Kim,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = The objective of this work is to examine various psychological forces underlying the behavior of people's online gambling, an increasingly popular form of entertainment in the gaming industry. Drawing on extant theories, we first developed a model of how cumulative outcomes, recent outcomes, and prior use affect online gambling behavior differently. We empirically tested the model using longitudinal panel data collected over eight months from 22,304 actual users of a gambling website. The results of a multilevel panel data analysis strongly supported our hypotheses. First, consistent with gambling theory, individuals' online gambling was found to increase with any increase in a cumulative net gain or cumulative net loss. Second, as the availability heuristic prescribes, a recent loss reduced online gambling, whereas a recent gain increased it. Third, consistent with the literature on repeated behavior, regular use and extended use moderated the relationship between current and subsequent gambling. Taken together, the present study clarifies how people react differently to immediate and cumulative outcomes and also how regular use and extended use facilitate routine behavior in the context of online gambling. In general, our findings suggest that the three perspectives, i.e., gambling theory, the availability heuristic, and repeated behavior, should be taken into account to understand online gambling, which is in essence a series of risk-taking attempts with the potential of eventually becoming routine behavior. This study is expected to offer valuable insights into other types of online games that could engage people in risking real or cyber money and, at the same time, could be easily enmeshed with everyday life (e. g., fantasy sports, online virtual worlds).
|keyword = online user behavior,online gambling,repeated behavior,decision making under uncertainty,panel data,multilevel analysis,hierarchical analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Central Role of Engagement in Online Communities'''
{{header}}
{{article
|author= Soumya Ray,Sung S. Kim,James G. Morris,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Online communities are new social structures dependent on modern information technology, and they face equally modern challenges. Although satisfied members regularly consume content, it is considerably harder to coax them to contribute new content and help recruit others because they face unprecedented social comparison and criticism. We propose that engagement-a concept only abstractly alluded to in information systems research-is the key to active participation in these unique sociotechnical environments. We constructed and tested a framework that demonstrates what engagement is, where it comes from, and how it powerfully explains both knowledge contribution and word of mouth. Our results show that members primarily contribute to and revisit an online community from a sense of engagement. Nonetheless, word of mouth is partly influenced by prior satisfaction. Therefore, engagement and satisfaction appear to be parallel mediating forces at work in online communities. Both mediators arise from a sense of communal identity and knowledge self-efficacy, but engagement also emerges from validation of self-identity. Nevertheless, we also found signs that the contributions of the most knowledgeable users are not purely from engagement, but also from a competing sense of self-efficacy. Our findings significantly contribute to the area of information systems by highlighting that engagement is a concrete phenomenon on its own, and it can be directly modeled and must be carefully managed.
|keyword = online communities,engagement,self-identity verification,knowledge self-efficacy,community identification,knowledge contribution,word of mouth,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Latent Growth Modeling for Information Systems: Theoretical Extensions and Practical Applications'''
{{header}}
{{article
|author= Zhiqiang (Eric) Zheng,Paul A. Pavlou,Bin Gu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = This paper presents and extends Latent Growth Modeling (LGM) as a complementary method for analyzing longitudinal data, modeling the process of change over time, testing time-centric hypotheses, and building longitudinal theories. We first describe the basic tenets of LGM and offer guidelines for applying LGM to Information Systems (IS) research, specifically how to pose research questions that focus on change over time and how to implement LGM models to test time-centric hypotheses. Second and more important, we theoretically extend LGM by proposing a model validation criterion, namely "d-separation," to evaluate why and when LGM works and test its fundamental properties and assumptions. Our d-separation criterion does not rely on any distributional assumptions of the data; it is grounded in the fundamental assumption of the theory of conditional independence. Third, we conduct extensive simulations to examine a multitude of factors that affect LGM performance. Finally, as a practical application, we apply LGM to model the relationship between word-of-mouth communication (online product reviews) and book sales over time with longitudinal 26-week data from Amazon. The paper concludes by discussing the implications of LGM for helping IS researchers develop and test longitudinal theories.
|keyword = latent growth modeling,LGM,longitudinal data,d-separation,word of mouth,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The "Most Popular News" Recommender: Count Amplification and Manipulation Resistance'''
{{header}}
{{article
|author= Shankar Prawesh,Balaji Padmanabhan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = A broad motivation for our research is to build manipulation resistant news recommender systems. There are several algorithms that can be used to generate news recommendations, and the strategies for manipulation resistance are likely specific to the algorithm (or class of algorithm) used. In this paper, we will focus on a common method used on the front page by many media sites of recommending the N most popular articles (e. g., New York Times, BBC, CNN, Wall Street Journal all prominently use this). We show that whereas recommendation of the N most read articles is easily susceptible to manipulation, a probabilistic variant is more robust to common manipulation strategies. Furthermore, for the "N most popular" recommender, probabilistic selection has other desirable properties. Specifically, the (N+1)th article, which may have just missed making the cut-off, is unduly penalized under common user models. Small differences are easily amplified initially, an observation that can be used by manipulators. Probabilistic selection, on the other hand, creates no such artificial penalty. We use classical results from urn models to derive theoretical results for special cases and study specific properties of the probabilistic recommender.
|keyword = recommender systems,news recommendation,polya urn,zipf,power law,sampling,manipulation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Empirical Analysis of the Impact of Pre-Release Movie Piracy on Box Office Revenue'''
{{header}}
{{article
|author= Liye Ma,Alan L. Montgomery,Param Vir Singh,Michael D. Smith,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Digital distribution channels raise many new challenges for managers in the media industry. This is particularly true for movie studios where high-value content can be stolen and released through illegitimate digital channels, even prior to the release of the movie in legal channels. In response to this potential threat, movie studios have spent millions of dollars to protect their content from unauthorized distribution throughout the lifecycle of films. They have focused their efforts on the pre-release period under the assumption that pre-release piracy could be particularly harmful for a movie's success. However, surprisingly, there has been little rigorous research to analyze whether, and how much, pre-release movie piracy diminishes legitimate sales. In this paper, we analyze this question using data collected from a unique Internet file-sharing site. We find that, on average, pre-release piracy causes a 19.1% decrease in revenue compared to piracy that occurs post-release. Our study contributes to the growing literature on piracy and digital media consumption by presenting evidence of the impact of Internet-based movie piracy on sales and by analyzing pre-release piracy, a setting that is distinct from much of the existing literature.
|keyword = movies,box office revenue,piracy,forecasting,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Allure of Homophily in Social Media: Evidence from Investor Responses on Virtual Communities'''
{{header}}
{{article
|author= Bin Gu,Prabhudev Konana,Rajagopal Raghunathan,Hsuanwei Michelle Chen,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Millions of people participate in online social media to exchange and share information. Presumably, such information exchange could improve decision making and provide instrumental benefits to the participants. However, to benefit from the information access provided by online social media, the participant will have to overcome the allure of homophily-which refers to the propensity to seek interactions with others of similar status (e. g., religion, education, income, occupation) or values (e. g., attitudes, beliefs, and aspirations). This research assesses the extent to which social media participants exhibit homophily (versus heterophily) in a unique context-virtual investment communities (VICs). We study the propensity of investors in seeking interactions with others with similar sentiments in VICs and identify theoretically important and meaningful conditions under which homophily is attenuated. To address this question, we used a discrete choice model to analyze 682,781 messages on Yahoo! Finance message boards for 29 Dow Jones stocks and assess how investors select a particular thread to respond. Our results revealed that, despite the benefits from heterophily, investors are not immune to the allure of homophily in interactions in VICs. The tendency to exhibit homophily is attenuated by an investor's experience in VICs, the amount of information in the thread, but amplified by stock volatility. The paper discusses important implications for practice.
|keyword = virtual communities,social media,homophily,heterophily,financial markets,psychological biases,psychological benefits,instrumental benefits,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Industry-Specific Human Capital and Wages: Evidence from the Business Process Outsourcing Industry'''
{{header}}
{{article
|author= Keongtae Kim,Sunil Mithas,Jonathan Whitaker,Prasanto K. Roy,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Human capital is becoming more critical as the global economy becomes more information intensive and service intensive. Although information systems (IS) researchers have studied some dimensions of human capital, the role of industry-specific human capital has remained understudied. The information technology enabled business process outsourcing (BPO) industry provides an ideal setting to study returns to human capital, because jobs in this industry are standardized and many professionals in this new industry have come from other industries. We build on IS and economics literature to theorize returns to human capital in the BPO industry, and we test the theory using data for over 2,500 BPO professionals engaged in call center work and other nonvoice services (e. g., accounting, finance, human resources, etc.) in India during the 2006-2008 time period. We find higher returns to industry-specific human capital than to firm-specific and general human capital. We also find that junior-level professionals, whose jobs are relatively more standardized, have higher returns to industry-specific human capital than senior-level professionals. We discuss implications for further research and practice in the global economy where inter-industry transfers and migration of skills are becoming increasingly common.
|keyword = global disaggregation,globalization,services,industry,human capital,BPO,outsourcing,professionals,wages,compensation,industry-specific human capital,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Heuristic Theorizing: Proactively Generating Design Theories'''
{{header}}
{{article
|author= Robert Wayne Gregory,Jan Muntermann,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Design theories provide explicit prescriptions, such as principles of form and function, for constructing an artifact that is designed to meet a set of defined requirements and solve a problem. Design theory generation is increasing in importance because of the increasing number and diversity of problems that require the participation and proactive involvement of academic researchers to build and test artifact-based solutions. However, we have little understanding of how design theories are generated. Drawing on key contributions by Herbert A. Simon, including the ideas of satisfice and bounded rationality and reviewing a large body of information systems and problem-solving literature, we develop a normative framework for proactive design theorizing based on the notion of heuristic theorizing. Heuristics are rules of thumb that provide a plausible aid in structuring the problem at hand or in searching for a satisficing artifact design. An example of a problem-structuring heuristic is problem decomposition and an example of an artifact design heuristic is analogical design. We define heuristic theorizing as the process of proactively generating design theory for prescriptive purposes from problem-solving experiences and prior theory by constantly iterating between the search for a satisficing problem solution, i.e., heuristic search, and the synthesis of new information that is generated during heuristic search, i.e., heuristic synthesis. Heuristic search involves alternating between structuring the problem at hand and generating new artifact design components, whereas heuristic synthesis involves different ways of thinking, including reflection and learning and forms of reasoning, that complement the use of heuristics for theorizing purposes. We illustrate the effectiveness of our heuristic theorizing framework through a detailed example of a multiyear design science research program in which we proactively generated a design theory for solving problems in the area of intelligent information management and so-called big data in the finance domain. We propose that heuristic theorizing is a useful alternative to established theorizing approaches, i.e., reasoning-based approaches. Heuristic theorizing is particularly relevant for proactive design theorizing, which emphasizes problem solving as being highly intertwined with theorizing, involves a greater variety of ways of thinking than other theorizing approaches, and assumes an engaged relationship between academics and practitioners.
|keyword = generating design theories,design science,proactive design theorizing,problem solving,heuristics,heuristic theorizing,heuristic search,heuristic synthesis,sciences of the artificial,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Discriminant Analysis with Strategically Manipulated Data'''
{{header}}
{{article
|author= Juheng Zhang,Haldun Aytug,Gary J. Koehler,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = We study the problem where a decision maker uses a linear classifier over attribute values (e. g., age, income, etc.) to classify agents into classes (e. g., creditworthy or not). Sometimes the attribute values are altered and/or hidden by agents to obtain a favorable but undeserved classification. Our main goal is to develop methods to thwart agents from hiding or distorting attribute values to obtain a favorable but incorrect classification. Intentionally altered attributes to obtain strategic goals have been studied. In this paper we develop methods that handle strategic hiding (i.e., nondisclosure) and then merge them with methods to thwart strategic distortion in the context of classification.
|keyword = classification,support vector machines,data imputation,missing values,adversarial learning,strategically hidden information,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Exploring How IT Professionals Experience Role Transitions at the End of Successful Projects'''
{{header}}
{{article
|author= Line Dube,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = In an increasingly fluid working environment, workers often find themselves in a state of transition and must be capable of adapting to rapid changes. This study focuses on intrafirm temporary role transitions, and more specifically on the case of information technology (IT) professionals transitioning out of a successful project and returning to their functional unit. In-depth interviews were conducted with 19 IT professionals. All of the respondents reported that they had experienced an adaptation period, albeit minor for some. Others, however, felt an important re-entry shock. A shock of high magnitude is mainly experienced when the successful project becomes a referent to which all other work assignments are compared. This idealized project work environment is the result of the decisions top management makes about the project structure, management, and governance. The results show that all people do not react the same way to a shock of high magnitude: some either adapt or change their new role, but others resist. This study highlights the need to better understand role transitions by further investigating the moderating variables at play in the relationships between actor, experience, magnitude of shock, and reaction. The study contributes to practice by questioning the widely shared assumption that IT professionals effortlessly navigate between project and functional work environments, and by highlighting the need to consider successful projects as a potential source of turmoil for team members. Finally, it raises the question of where the responsibility of managing transitions lies in the organization.
|keyword = IT professionals,IT projects,job satisfaction,project governance,project management,qualitative study,role theory,role transition,socialization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Talk Before It's Too Late: Reconsidering the Role of Conversation in Information Systems Project Management'''
{{header}}
{{article
|author= Stefano Mastrogiacomo,Stephanie Misonier,Riccardo Bonazzi,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Effective team coordination is essential for the information systems (IS) projects' success. We present a four-year study, based on design science research, to develop and instantiate a conceptual model-called Coopilot-to improve real-time coordination in IS projects. Coopilot is a simple conversational guide to help IS project managers minimize the number of coordination surprises that arise for teams during their project meetings. Drawing on coordination literature outside the IS research field, we have adapted and instantiated the theory of joint activity developed by psycholinguist Herbert Clark. The results illustrate the value Clark's theory can add to the IS field and both the importance of conversation intended as a new theoretical construct in IS team project coordination as well as the importance of reaching a sufficient level of understanding. Project managers involved in this study who used Coopilot reported both higher levels of confidence that their projects were on a successful path and overall higher levels of team motivation.
|keyword = conversation for coordination,IS project management,IS teams,project management,team coordination,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Achieving IT Program Goals with Integrative Conflict Management'''
{{header}}
{{article
|author= James J. Jiang,Jamie Y. T. Chang,Houn-Gee Chen,Eric T. G. Wang,Gary Klein,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Information technology (IT) programs are collections of projects structured to meet goals established by top management regarding the use of technology. Prior research has established the importance of commitment to the organizational goals set by top management and a shared understanding of the goals among the project teams. However, conflicts occur among project teams due to pursuit of their own goals, their unique approaches to completion of required tasks, and their individual need for limited resources. These conflicts need to be resolved in a fashion that leads to the pursuit of program goals, not the independent goals lodged in individual projects. We develop a model of an IT program environment to study the effects of goal interdependence among projects and shared understanding of organizational goals on promoting integrative conflict management (ICM). ICM techniques yield agreement on decisions in the face of conflicting ideas. In turn, ICM promotes arrival at an agreement about implementation means and commitment to the IT program goals, which are better achieved as a result. The model presents a new perspective for research on conflict that considers the specific resolution process to be a key component in the attainment of goals. Practitioners should instill integrative conflict resolution techniques into program and project processes as a fundamental means of achieving goals critical to the organization.
|keyword = conflict management,goal commitment,goal consensus,goal understanding,IT program,IT projects,means consensus project integration,project management,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Creating Shared Understanding in Heterogeneous Work Groups: Why It Matters and How to Achieve It'''
{{header}}
{{article
|author= Eva Alice Christiane Bittner,Jan Marco Leimeister,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Shared understanding has been claimed to be crucial for effective collaboration of researchers and practitioners. Heterogeneity in work groups further strengthens the challenge of integrating understanding among diverse group members. Nevertheless, shared understanding and especially its formation are largely unexplored. After conceptualizing shared understanding, we apply collaboration engineering to derive a validated collaboration process module (compound thinkLet " MindMerger") to systematically support heterogeneous work groups in building shared understanding. We conduct a large-scale action research study at a German car manufacturing company. The evaluation indicates that with the use of MindMerger, team learning behaviors occur, and shared understanding of the tasks in complex work processes increases among experienced diverse tool and dye makers. Thus, the validated compound thinkLet MindMerger provides designers of collaborative work practices with a reusable module of activities to solve clarification issues in group work early on. Furthermore, findings from the field study contribute to the conceptualization of the largely unexplored phenomenon of shared understanding and its formation.
|keyword = collaboration engineering,group collaboration,heterogeneous groups,knowledge integration,shared understanding,thinkLet,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of Social Network Structures on Prediction Market Accuracy in the Presence of Insider Information'''
{{header}}
{{article
|author= Liangfei Qiu,Huaxia Rui,Andrew B. Whinston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = This paper examines the effects of social network structures on prediction market accuracy in the presence of insider information through a randomized laboratory experiment. In the experiment, insider information is operationalized as signals on the state of nature with high precision. Motivated by the literature on insider information in the context of financial markets, we test and confirm two characterizations of insider information in the context of prediction markets: abnormal performance and less diffusion. Experimental results suggest that a more balanced social network structure is crucial to the success of prediction markets, whereas network structures akin to star networks are ill suited to prediction markets. As compared with other network structures, insider information has less positive effects on prediction market accuracy in star networks. We also find that the bias of the public information has a larger negative effect on prediction market accuracy in star networks.
|keyword = controlled experiment,insider information,prediction markets,social networks,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Rigidity Detection System for Automated Credibility Assessment'''
{{header}}
{{article
|author= Nathan W. Twyman,Aaron C. Elkins,Jude K. Burgoon,Jr. Jay F. Nunamaker,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Credibility assessment is an area in which information systems research can make a major impact. This paper reports on two studies investigating a system solution for automatic, noninvasive detection of rigidity for automated interviewing. Kinesic rigidity has long been a phenomenon of interest in the credibility assessment literature, but until now was infeasible as a veracity indicator in practical use cases. An initial study unexpectedly revealed the occurrence of rigidity in a highly controlled concealed information test setting, prompting the design and implementation of an automated rigidity detection system for interviewing. A unique experimental evaluation supported the system concept. The results of the second study confirmed the kinesic rigidity found in the first, and provided further theoretical insights explaining the rigidity phenomenon. Although additional research is needed, the evidence from this investigation suggests that credibility assessment can benefit from a rigidity detection system.
|keyword = automated interviewing systems,computer vision,concealed information test,credibility assessment,deception detection,freeze response,kinesic rigidity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''How Posture-Profile Misalignment in IT Innovation Diminishes Returns: Conceptual Development and Empirical Demonstration'''
{{header}}
{{article
|author= Robert G. Fichman,Nigel P. Melville,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = We conceive of information technology (IT) innovation posture-profile misalignment as a condition that exists when a firm's innovation posture (the extent to which a firm leads with IT innovation) does not match up with its innovation resource profile (the firm's stock of resources conducive to effective innovation). We theorize that firms with a posture-profile misalignment will see diminished returns from IT adoption because they will be less likely to possess (and be less effective at exploiting) crucial innovation resources when they need them most. We demonstrate how misalignment conditions the link between IT innovation adoption and organizational performance using a data set comprising electronic networking technologies in over 25,000 U.S. manufacturing plants. Productivity regression estimations reveal a consistent pattern that the association between IT innovation adoption and productivity is substantially diminished among misaligned firms. These empirical results provide initial confirmation of the theoretical value of innovation posture, innovation resource profile, and innovation posture-profile misalignment. We consider the implications for research on business value and innovation as well as for the practice of management.
|keyword = innovation,innovation outcomes,innovation with information technology,IT adoption,IT business value,IT innovation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''How Social Capital Among Information Technology and Business Units Drives Operational Alignment and IT Business Value'''
{{header}}
{{article
|author= Heinz-Theo Wagner,Daniel Beimborn,Tim Weitzel,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = It is widely acknowledged that information technology (IT) and business resources need to be well aligned to achieve organizational goals. Yet, year after year, chief information officers still name business-IT alignment a key challenge for IT executives. While alignment research has matured, we still lack a sound theoretical foundation for alignment. Transcending the predominantly strategic executive-level focus, we develop a model of "operational alignment" and IT business value that combines a social perspective of IT and business linkage with a view of interaction between business and IT at nonstrategic levels, such as in daily business operations involving regular staff. Drawing on social capital theory to explain how alignment affects organizational performance, we examine why common suggestions such as "communicate more" are insufficient to strengthen alignment and disclose how social capital between IT and business units drives alignment and ultimately IT business value. Empirical data from 136 firms confirms the profound impact of operational business-IT alignment, composed of social capital and business understanding of IT, on IT flexibility, IT utilization, and organizational performance. The results show that social capital theory is a useful theoretical foundation for understanding how business IT alignment works. The findings suggest that operational alignment is at least as important as strategic alignment for IT service quality; that managers need to focus on operational aspects of alignment beyond communication by fostering knowledge, trust, and respect; and that IT utilization and flexibility are appropriate intermediate goals for business-IT alignment governance.
|keyword = business-IT alignment,business value of IT,information systems alignment,operational alignment,social capital,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''User Roles and Contributions in Innovation-Contest Communities'''
{{header}}
{{article
|author= Johan Fueller,Katja Hutter,Julia Hautz,Kurt Matzler,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Organizations increasingly initiate Internet-based innovation-contest communities through which individuals can interact and contribute to the innovation process. To successfully manage these communities, organizations need to understand what roles members assume, how they communicate and vary in their contribution behavior. In this exploratory study, we investigate the heterogeneous roles of contest participants based on an international innovation-contest community. We identify six user types associated with various behavioral contribution patterns by using cluster and social network analysis. The six user types further differ in their communicative content and contribution quality. Our paper contributes to a better theoretical understanding of distinctive user types in innovation-contest communities, their role in the community, and their contribution to the success of innovation contests in the era of social software. From a managerial perspective, the study provides guidance for contest platform design and appropriate reward structures.
|keyword = co-creation,innovation contests,online communities,user contribution,user roles,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Supporting Creative Problem Solving with a Case-Based Reasoning System'''
{{header}}
{{article
|author= Niek Althuizen,Berend Wierenga,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Attention for the division of work between computers and humans is growing due to ever-increasing computer capabilities. Over the past decades, creativity support systems (CSSs) have gained ground as a means to enhance individual, group, and organizational creativity. Whereas prior research has focused primarily on the main effects of CSSs, we explore the interaction effects with the creative ability of the individual. In this paper, we investigate the use of the case-based reasoning (CBR) technology, which is based on the principle of analogical reasoning, to aid individuals in solving business problems creatively. The expectations as to why the CBR technology should enhance individual creativity, and under what conditions (i.e., the type and number of cases that are made available), are derived from creative cognition theory, and are tested empirically. In a series of studies, a CBR system loaded with a diverse set of cases was found to enhance the performance of individuals with lower creative ability, but it did not help the most creative individuals. Although the literature suggests that cases from remote problem domains should lead to more novel solutions, loading the CBR system only with cases closely related to the problem domain proved more effective than remote cases only. Finally, loading the CBR system with a larger set of diverse cases was found to positively influence the creativity of the solutions. These findings have the following implications for CSSs and creative cognition theory: (1) when considering the effectiveness of CSSs it is important to take into account the creative ability of the individual (i.e., "one size does not fit all"), (2) making a sufficiently large and diverse set of cases available is better for stimulating creativity, and (3) providing cases that are too remote may be counterproductive. On a practical note, organizations seeking to redesign their division of labor between individuals and machines can easily follow the CBR approach presented here using their own set of cases.
|keyword = case-based reasoning,creative problem solving,creativity support systems,creative cognition theory,domain knowledge,marketing campaigns,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DIGITAL INNOVATION AS A FUNDAMENTAL AND POWERFUL CONCEPT IN THE INFORMATION SYSTEMS CURRICULUM'''
{{header}}
{{article
|author= Robert G. Fichman,Brian L. Dos Santos,Zhiqiang (Eric) Zheng,
|source= MIS QUARTERLY
|year= 2014
|abstract = The 50-year march of Moore's Law has led to the creation of a relatively cheap and increasingly easy-to-use world-wide digital infrastructure of computers, mobile devices, broadband network connections, and advanced application platforms. This digital infrastructure has, in turn, accelerated the emergence of new technologies that enable transformations in how we live and work, how companies organize, and the structure of entire industries. As a result, it has become important for all business students to have a strong grounding in IT and digital innovation in order to manage, lead, and transform organizations that are increasingly dependent on digital innovation. Yet, at many schools, students do not get such grounding because the required information systems core class is stuck in the past. We present a vision for a redesigned IS core class that adopts digital innovation as a fundamental and powerful concept (FPC). A good FPC serves as both a foundational concept and an organizing principle for a course. We espouse a particularly broad conceptualization of digital innovation that allows for a variety of teaching styles and topical emphases for the IS core class. This conceptualization includes three types of innovation (i.e., process, product, and business model innovation), and four stages for the overall innovation process (i.e., discovery, development, diffusion, and impact). Based on this conceptualization, we examine the implications of adopting digital innovation as an FPC. We also briefly discuss broader implications relating to (1) the IS curriculum beyond the core class, (2) the research agenda for the IS field, and (3) the identity and legitimacy of IS in business schools.
|keyword = Fundamental and powerful concepts (FPC),digital innovation,IS core course,pedagogy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DATA COLLECTION IN THE DIGITAL AGE: INNOVATIVE ALTERNATIVES TO STUDENT SAMPLES'''
{{header}}
{{article
|author= Zachary R. Steelman,Bryan I. Hammer,Moez Limayem,
|source= MIS QUARTERLY
|year= 2014
|abstract = Online crowdsourcing markets (OCM) are becoming more popular as a source for data collection. In this paper, we examine the consistency of survey results across student samples, consumer panels, and online crowdsourcing markets (specifically Amazon's Mechanical Turk) both within the United States and outside. We conduct two studies examining the technology acceptance model (TAM) and the expectation-disconfirmation theory (EDT) to explore potential differences in demographics, psychometrics, structural model estimates, and measurement invariances. Our findings indicate that (1) U.S.-based OCM samples provide demographics much more similar to our student and consumer panel samples than the non-U.S.-based OCM samples; (2) both U.S. and non-U.S. OCM samples provide initial psychometric properties (reliability, convergent, and divergent validity) that are similar to those of both student and consumer panels; (3) non-U.S. OCM samples generally provide differences in scale means compared to those of our students, consumer panels, and U.S. OCM samples; and (4) one of the non-U.S. OCM samples refuted the highly replicated and validated TAM model in the relationship of perceived usefulness to behavioral intentions. Although our post hoc analyses isolated some cultural and demographic effects with regard to the non-U.S. samples in Study 1, they did not address the model differences found in Study 2. Specifically, the inclusion of non-U.S. OCM respondents led to statistically significant differences in parameter estimates, and hence to different statistical conclusions. Due to these unexplained differences that exist within the non-U.S. OCM samples, we caution that the inclusion of non-U.S. OCM participants may lead to different conclusions than studies with only U.S. OCM participants. We are unable to conclude whether this is due to of cultural differences, differences in the demographic profiles of non-U.S. OCM participants, or some unexplored factors within the models. Therefore, until further research is conducted to explore these differences in detail, we urge researchers utilizing OCMs with the intention to generalize to U.S. populations focus on U.S.-based participants and exercise caution in using non-U.S. participants. We further recommend that researchers should clearly describe their OCM usage and design (e. g., demographics, participant filters, etc.) procedures. Overall, we find that U.S. OCM samples produced models that lead to similar statistical conclusions as both U.S. students and U.S. consumer panels at a considerably reduced cost.
|keyword = Data collection,crowdsourcing,sampling,online research,crowdsourcing market,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE NATURE AND CONSEQUENCES OF TRADE-OFF TRANSPARENCY IN THE CONTEXT OF RECOMMENDATION AGENTS'''
{{header}}
{{article
|author= Jingjun (David) Xu,Izak Benbasat,Ronald T. Cenfetelli,
|source= MIS QUARTERLY
|year= 2014
|abstract = That recommendation agents (RAs) can substantially improve consumers' decision making is well understood. Far less understood is the influence of specific design attributes of the RA interface on decision making and other outcome measures. We investigate a novel design for an RA interface that enables it to interactively demonstrate trade-offs among product attribute values (i.e., trade-off transparency feature) to improve consumers' perceived product diagnosticity and perceived enjoyment. We also examine the extent to which the trade-offs among product attribute values should be revealed to the user. Further, based on the stimulus organism-response model, we develop a theoretical model that extends the effort-accuracy framework by proposing perceived enjoyment and perceived product diagnosticity as two antecedents for perceived decision quality and perceived decision effort, respectively. In an experimental study, we find that (1) the trade-off transparency feature significantly affects perceived enjoyment and perceived product diagnosticity, (2) perceived enjoyment and perceived product diagnosticity follow an inverted U-shaped curve as the level of trade-off transparency increases, (3) although users spend more time understanding attribute trade-offs with the trade-off transparency feature, they are more efficient in selecting a product, (4) perceived enjoyment simultaneously leads to better perceived decision quality and lower perceived decision effort, and (5) perceived product diagnosticity leads to better perceived decision quality without compromising perceptions of decision effort. Theoretically, this study increases our understanding of how the design of an RA interface can improve consumers' product diagnosticity and enjoyment, and proposes two antecedents to improve perceived decision quality and reduce perceived decision effort. For design practitioners, our results indicate the importance of providing the trade-off transparency design feature to potential consumers.
|keyword = Interface design,task complexity,recommendation agents (RAs),trade-off transparency,perceived enjoyment,perceived product diagnosticity,perceived decision effort,perceived decision quality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TRUST, SATISFACTION, AND ONLINE REPURCHASE INTENTION: THE MODERATING ROLE OF PERCEIVED EFFECTIVENESS OF E-COMMERCE INSTITUTIONAL MECHANISMS'''
{{header}}
{{article
|author= Yulin Fang,Israr Qureshi,Heshan Sun,Patrick McCole,Elaine Ramsey,Kai H. Lim,
|source= MIS QUARTERLY
|year= 2014
|abstract = The effects of e-commerce institutional mechanisms on trust and online purchase have traditionally been understood in the initial online purchase context. This study extends this literature by exploring the role of e-commerce institutional mechanisms in the online repurchase context. In doing so, it responds to the emerging call for understanding the institutional context under which customer trust operates in an e-commerce environment. Specifically, this study introduces a key moderator, perceived effectiveness of e-commerce institutional mechanisms (PEEIM), to the relationships between trust, satisfaction, and repurchase intention. Drawing on the theory of organizational trust, and based on a survey of 362 returning online customers, we find that PEEIM negatively moderates the relationship between trust in an online vendor and online customer repurchase intention, as it decreases the importance of trust to promoting repurchase behavior. We also find that PEEIM positively moderates the relationship between customer satisfaction and trust as it enhances the customer's reliance on past transaction experience with the vendor to reevaluate trust in the vendor. Consistent with the predictions made in the literature, PEEIM does not directly affect trust or repurchase intention. Academic and practical implications and future research directions are discussed.
|keyword = E-commerce,trust,online repurchase intention,e-commerce,institutional mechanisms,moderation analysis,partial least square modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AN ECONOMIC ANALYSIS OF ONLINE ADVERTISING USING BEHAVIORAL TARGETING'''
{{header}}
{{article
|author= Jianqing Chen,Jan Stallaert,
|source= MIS QUARTERLY
|year= 2014
|abstract = Online publishers and advertisers have recently shown increasing interest in using targeted advertising online. Such targeting allows them to present users with advertisements that are a better match, based on their past browsing and search behavior and other available information (e.g., hobbies registered on a web site). This technique, known as behavioral targeting, has been hailed as the new "Holy Grail" in online advertising because of its potential effectiveness. In this paper, we study the economic implications when an online publisher engages in behavioral targeting. The publisher auctions off an advertising slot and is paid on a cost-perclick basis. Using a horizontal differentiation model to capture the fit between a user and an advertisement being displayed, we identify the factors that affect the publisher's revenue, the advertisers' payoffs, and social welfare. We show that revenue for the online publisher in some circumstances can double when behavioral targeting is used. However, increased revenue for the publisher is not guaranteed: in some cases, the prices of advertising and hence the publisher's revenue can be lower, depending on the degree of competition and the advertisers' valuations. We identify two effects associated with behavioral targeting: a competitive effect and a propensity effect. The relative strength of the two effects determines whether the publisher's revenue is positively or negatively affected. We also demonstrate that, although social welfare is increased and small advertisers are better off under behavioral targeting, the dominant advertiser might be worse off and reluctant to switch from traditional advertising.
|keyword = Behavioral targeting,targeted advertising,online advertising,pricing,competition,auctions,analytical modeling,economic modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''PROACTIVE VERSUS REACTIVE SECURITY INVESTMENTS IN THE HEALTHCARE SECTOR'''
{{header}}
{{article
|author= Juhee Kwon,M. Eric Johnson,
|source= MIS QUARTERLY
|year= 2014
|abstract = This study identifies the effects of security investments that arise from previous failures or external regulatory pressure. Building on organizational learning theory, the study focuses on the healthcare sector where legislation mandates breach disclosure and detailed data on security investments are available. Using a Cox proportional hazard model, we demonstrate that proactive security investments are associated with lower security failure rates. Coupling that result with the economics of breach disclosure, we also show that proactive investments are more cost effective in healthcare security than reactive investments. Our results further indicate that this effect is amplified at the state level, supporting the argument that security investments create positive externalities. We also find that external pressure decreases the effect of proactive investments on security performance. This implies that proactive investments, voluntarily made, have more impact than those involuntarily made. Our findings suggest that security managers and policy makers should pay attention to the strategic and regulatory factors influencing security investment decisions.
|keyword = Security investment,organizational learning,proactive,reactive,healthcare,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE BUSINESS OF BEING A USER: THE ROLE OF THE REFERENCE ACTOR IN SHAPING PACKAGED ENTERPRISE SYSTEM ACQUISITION AND DEVELOPMENT'''
{{header}}
{{article
|author= Neil Pollock,Sampsa Hyysalo,
|source= MIS QUARTERLY
|year= 2014
|abstract = The paper extends the concept of "user" to account for a new, more formalized role that some client organizations play in the diffusion of packaged enterprise systems. Package vendors are attempting to draw parts of their user base into activities related to the promotion, selling, and commodification of systems. Users, in turn, appear willing to help construct these systems as objects of consumption for others. This can appear to be rather idiosyncratic behavior. Information Systems scholars have argued that relations between packaged enterprise system vendors and users are attenuated. Why might the user help the vendor market its systems in this way? What benefits accrue from it? And what role are users performing in carrying out this work? To show how this is becoming a general facet of the work of some packaged enterprise system users, we develop the notion of "reference actor," which is an extension of the earlier Information Systems concept of "social actor." In combining insights from the social shaping of technology and the biography of artifacts, and drawing on long-term qualitative fieldwork, we analyze this new actor role in relation to expectations and commitments coming from the wider packaged enterprise system community. In return for the help provided to prospective adopters, reference actors are also able to gather various kinds of benefits for themselves and others. In particular, they build closer relations with vendors such that they can influence product development strategies.
|keyword = User,reference site,demonstration,testimonial,commodification,marketing,enterprise system,procurement,innovation,social actor,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE EFFECTS OF WEB PERSONALIZATION ON USER ATTITUDE AND BEHAVIOR: AN INTEGRATION OF THE ELABORATION LIKELIHOOD MODEL AND CONSUMER SEARCH THEORY'''
{{header}}
{{article
|author= Shuk Ying Ho,David Bodoff,
|source= MIS QUARTERLY
|year= 2014
|abstract = Web personalization can achieve two business goals: increased advertising revenue and increased sales revenue. The realization of the two goals is related to two kinds of user behavior: item sampling and item selection. Prior research does not provide a model of attitude formation toward a personalization agent nor of how attitudes relate to these two behaviors. This limits our understanding of how web personalization can be managed to increase advertising revenues and/or sales revenues. To fill this gap, the current research develops and tests a theoretical model of user attitudes and behaviors toward a personalization agent. The model is based on an integration of two theories: the elaboration likelihood model (ELM) and consumer search theory (CST). In the integrated model, a user's attitude toward a personalization agent is influenced by both the number of items he/she has sampled so far (from CST) and the degree to which he/she cognitively processes each one (from ELM). In turn, attitude is modeled to influence both behaviors-that is, item selection and any further item sampling. We conducted a lab study and a field study to test six hypotheses. This research extends the theory on web personalization by providing a more complete picture of how sampling and processing of personalized recommendations influence a user's attitude and behavior toward the personalization agent. For online merchants, this research highlights the trade-off between item sampling and item selection and provides practical guidance on how to steer users toward the attitudes and behaviors that will realize their business goals.
|keyword = Elaboration likelihood model,consumer search theory,web personalization,attitude persistence,attitude confidence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''NATURE AND NURTURE: THE IMPACT OF AUTOMATICITY AND THE STRUCTURATION OF COMMUNICATION ON VIRTUAL TEAM BEHAVIOR AND PERFORMANCE'''
{{header}}
{{article
|author= Valerie L. Bartelt,Alan R. Dennis,
|source= MIS QUARTERLY
|year= 2014
|abstract = Much prior research on virtual teams has examined the impact of the features and capabilities of different communication tools (the nature of communication) on team performance. In this paper, we examine how the social structures (i.e., genre rules) that emerge around different communication tools (the nurture of communication) can be as important in influencing performance. During habitual use situations, team members enact genre rules associated with communication tools without conscious thought via automaticity. These genre rules influence how teams interact and ultimately how well they perform. We conducted an experimental study to examine the impact of different genre rules that have developed for two communication tools: instant messenger and discussion forum. Our results show that in habitual use situations, these tools triggered different genre rules with different behaviors, which in turn resulted in significantly different decision quality. We used heightened time pressure as a discrepant event to interrupt the automatic enactment of habitual genre rules and found that users adopted similar behaviors for both tools, which resulted in no significant differences in decision quality. These findings suggest that the automatic enactment of genre rules for a communication tool may have as powerful an effect on behavior and performance as the actual features of the tool itself. We believe that our results, taken together with past research showing the effects of social structures on communication, call for the expansion of task-technology fit theories to include the role of social structures in explaining the use of and performance from communication tools.
|keyword = Collaboration,virtual teams,genre rules,structuration theory,IM,discussion board,time pressure,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ANXIOUS OR ANGRY? EFFECTS OF DISCRETE EMOTIONS ON THE PERCEIVED HELPFULNESS OF ONLINE REVIEWS'''
{{header}}
{{article
|author= Dezhi Yin,Samuel D. Bond,Han Zhang,
|source= MIS QUARTERLY
|year= 2014
|abstract = This paper explores the effects of emotions embedded in a seller review on its perceived helpfulness to readers. Drawing on frameworks in literature on emotion and cognitive processing, we propose that over and above a well-known negativity bias, the impact of discrete emotions in a review will vary, and that one source of this variance is reader perceptions of reviewers' cognitive effort. We focus on the roles of two distinct, negative emotions common to seller reviews: anxiety and anger. In the first two studies, experimental methods were utilized to identify and explain the differential impact of anxiety and anger in terms of perceived reviewer effort. In the third study, seller reviews from Yahoo! Shopping web sites were collected to examine the relationship between emotional review content and helpfulness ratings. Our findings demonstrate the importance of examining discrete emotions in online word-of-mouth, and they carry important practical implications for consumers and online retailers.
|keyword = Discrete emotions,anxiety,anger,seller reviews,review helpfulness,online word-of-mouth,electronic commerce,consumer decision making,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''REFRAMING SUCCESS AND FAILURE OF INFORMATION SYSTEMS: A PERFORMATIVE PERSPECTIVE'''
{{header}}
{{article
|author= Dubravka Cecez-Kecmanovic,Karlheinz Kautz,Rebecca Abrahall,
|source= MIS QUARTERLY
|year= 2014
|abstract = The paper questions common assumptions in the dominant representational framings of information systems success and failure and proposes a performative perspective that conceives IS success and failure as relational effects performed by sociomaterial practices of IS project actor-networks of developers, managers, technologies, project documents, methodologies, and other actors. Drawing from a controversial case of a highly innovative information system in an insurance company-considered a success and failure at the same time-the paper reveals the inherent indeterminacy of IS success and failure and describes the mechanisms by which success and failure become performed and thus determined by sociomaterial practices. This is explained by exposing ontological politics in the reconfiguration and decomposition of the IS project actor-network and the emergence of different agencies of assessment that performed both different IS realities and competing IS assessments. The analysis shows that the IS project and the implemented system as objects of assessment are not given and fixed, but are performed by the agencies of assessment together with the assessment outcomes of success and failure. The paper demonstrates that by reframing IS success and failure, the performative perspective provides some novel and surprising insights that have a potential to change conversations on IS assessments in both the IS literature and IS practice.
|keyword = IS project success and failure,IS success and failure,IS project assessment,IS benefits assessment,sociomaterial worldview,performative perspective,actor-network theory (ANT),ontological politics,agency of assessment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''QUALITY COMPETITION AND MARKET SEGMENTATION IN THE SECURITY SOFTWARE MARKET'''
{{header}}
{{article
|author= Debabrata Dey,Atanu Lahiri,Guoying Zhang,
|source= MIS QUARTERLY
|year= 2014
|abstract = In recent years, we have witnessed an unprecedented growth in the security software market. This market is now fiercely competitive with hundreds of nearly identical products; yet, the price is high and coverage low. Although recent research has examined such idiosyncrasies and found the existence of a negative network effect as a possible explanation, several important questions still remain: (1) What possibly discourages product differentiation in such a competitive market? (2) Why is versioning absent here? (3) How does the presence of free alternatives in this market impact its structure? We develop a comprehensive oligopoly model, with endogenous quality and versioning decisions, to address these issues. Our analyses reveal that, although the presence of numerous competitors leads to a greater need to differentiate, the network effect in this market works as a counterweight, incentivizing vendors to sacrifice differentiation in favor of collocating in the top end of the quality spectrum. We explain the reasons and implications of this important finding. We further show that this result is robust and applicable even when versioning by competing vendors or the presence of free software is taken into consideration. Furthermore, given that the presence of free software actually intensifies competitive pressure and heightens the need to differentiate, the role of the network effect in abating differentiation becomes even more discernible.
|keyword = Security software,network effect,negative network effect,quality competition,market structure,vertical differentiation,fulfilled expectations equilibrium,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COORDINATING EXPERTISE ACROSS KNOWLEDGE BOUNDARIES IN OFFSHORE-OUTSOURCING PROJECTS: THE ROLE OF CODIFICATION'''
{{header}}
{{article
|author= Julia Kotlarsky,Harry Scarbrough,Ilan Oshri,
|source= MIS QUARTERLY
|year= 2014
|abstract = The coordination of effort within and among different expert groups is a central feature of contemporary organizations. Within the existing literature, however, a dichotomy has emerged in our understanding of the role played by codification in coordinating expert groups. One strand of literature emphasizes codification as a process that supports coordination by enabling the storage and ready transfer of knowledge. In contrast, another strand highlights the persistent differences between expert groups that create boundaries to the transfer of knowledge, seeing coordination as dependent on the quality of the reciprocal interactions between groups and individuals. Our research helps to resolve such contested understandings of the coordinative role played by codification. By focusing on the offshore-outsourcing of knowledge-intensive services, we examine the role played by codification when expertise was coordinated between client staff and onsite and offshore vendor personnel in a large-scale outsourcing contract between TATA Consultancy Services (TCS) and ABN AMRO bank. A number of theoretical contributions flow from our analysis of the case study, helping to move our understanding beyond the dichotomized views of codification outlined above. First, our study adds to previous work where codification has been seen as a static concept by demonstrating the multiple, coexisting, and complementary roles that codification may play. We examine the dynamic nature of codification and show changes in the relative importance of these different roles in coordinating distributed expertise over time. Second, we reconceptualize the commonly accepted view of codification as focusing on the replication and diffusion of knowledge by developing the notion of the codification of the "knower" as complementary to the codification of knowledge. Unlike previous studies of expertise directories, codification of the knower does not involve representing expertise in terms of occupational skills or competences but enables the reciprocal interrelating of expertise required by more unstructured tasks.
|keyword = Offshore-outsourcing,codification,expertise coordination,knowledge boundaries,qualitative case study,outsourcing transition,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Disciplines of Information: Lessons from the History of the Discipline of Medicine'''
{{header}}
{{article
|author= David G. Schwartz,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = In this research commentary we show that the discipline of information systems (IS) has much that can be learned from the history of the discipline of medicine. We argue that as interest in historical studies of information systems grows, there are important historical lessons to be drawn from disciplines other than IS, with the medical discipline providing fertile ground. Of particular interest are the circumstances that surrounded the practice of the medical craft in the 1800's-circumstances that drove a process of unification and specialization resulting in the modern conceptualization of medical education, research, and practice. In analyzing the history of the field of medicine, with its long-established methods for general practice, specialization, and sub-specialization we find that it serves as an example of a discipline that has dealt effectively with its initial establishment as a scientific discipline, exponential growth of knowledge and ensuing diversity of practice over centuries, and has much to say in regards to a number of discipline-wide debates of IS. Our objective is to isolate the key factors that can be observed from the writings of leading medical historians, and examine those factors from the perspective of the information systems discipline today. Through our analysis we identify the primary factors and structural changes which preceded a modern medical discipline characterized by unification and specialization. We identify these same historic factors within the present-day information systems milieu and discuss the implications of following a unification and specialization strategy for the future of the disciplines of information.
|keyword = critical perspectives on information technology,institutional aspects of information systems,medical discipline,specialization,history,academia,professions,DI,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Popularity Effect in User-Generated Content: Evidence from Online Product Reviews'''
{{header}}
{{article
|author= Paulo B. Goes,Mingfeng Lin,Ching-man Au Yeung,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Online product reviews are increasingly important for consumer decisions, yet we still know little about how reviews are generated in the first place. In an effort to gather more reviews, many websites encourage user interactions such as allowing one user to subscribe to another. Do these interactions actually facilitate the generation of product reviews? More importantly, what kind of reviews do such interactions induce? We study these questions using data from one of the largest product review websites where users can subscribe to one another. By applying both panel data and a flexible matching method, we find that as users become more popular, they produce more reviews and more objective reviews; however, their numeric ratings also systematically change and become more negative and more varied. Such trade-off has not been previously documented and has important implications for both product review and other user-generated content websites.
|keyword = product reviews,user-generated content,online community,opinion leader,social media,popularity,text mining,matching,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Machine Learning Approach to Improving Dynamic Decision Making'''
{{header}}
{{article
|author= Georg Meyer,Gediminas Adomavicius,Paul E. Johnson,Mohamed Elidrisi,William A. Rush,JoAnn M. Sperl-Hillen,Patrick J. O'Connor,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Decision strategies in dynamic environments do not always succeed in producing desired outcomes, particularly in complex, ill-structured domains. Information systems often capture large amounts of data about such environments. We propose a domain-independent, iterative approach that (a) applies data mining classification techniques to the collected data in order to discover the conditions under which dynamic decision-making strategies produce undesired or suboptimal outcomes and (b) uses this information to improve the decision strategy under these conditions. In this paper, we formally develop this approach and illustrate it by providing detailed examples of its application to a chronic disease care problem in a healthcare management organization, specifically the treatment of patients with type 2 diabetes mellitus. In particular, the proposed iterative approach is used to improve treatment strategies by predicting and eliminating treatment failures, i.e., insufficient or excessive treatment actions, based on information that is available in electronic medical record systems. We also apply the proposed approach to a manufacturing task, resulting in substantial decision strategy improvements, which further demonstrates the generality and flexibility of the proposed approach.
|keyword = dynamic decision making,process control,data mining,process mining,machine learning,simulation,healthcare,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Prediction in Economic Networks'''
{{header}}
{{article
|author= Vasant Dhar,Tomer Geva,Gal Oestreicher-Singer,Arun Sundararajan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = We define an economic network as a linked set of entities, where links are created by actual realizations of shared economic outcomes between entities. We analyze the predictive information contained in a specific type of economic network, namely, a product network, where the links between products reflect aggregated information on the preferences of large numbers of individuals to co-purchase pairs of products. The product network therefore reflects a simple "smoothed" model of demand for related products. Using a data set containing more than 70 million observations of a nonstatic co-purchase network over a period of two years, we predict network entities' future demand by augmenting data on their historical demand with data on the demand for their immediate neighbors, in addition to network properties, specifically, local clustering and PageRank. To our knowledge, this is the first study of a large-scale dynamic network that shows that a product network contains useful distributed information for demand prediction. The economic implications of algorithmically predicting demand for large numbers of products are significant.
|keyword = economic networks,prediction,co-purchase network,predictive modeling,neural networks,autoregressive models,network-based prediction,PageRank,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Selling vs. Profiling: Optimizing the Offer Set in Web-Based Personalization'''
{{header}}
{{article
|author= Monica Johar,Vijay Mookerjee,Sumit Sarkar,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = We study the problem of optimally choosing the composition of the offer set for firms engaging in web-based personalization. A firm can offer items or links that are targeted for immediate sales based on what is already known about a customer's profile. Alternatively, the firm can offer items directed at learning a customer's preferences. This, in turn, can help the firm make improved recommendations for the remainder of the engagement period with the customer. An important decision problem faced by a profit maximizing firm is what proportion of the offer set should be targeted toward immediate sales and what proportion toward learning the customer's profile. We study the problem as an optimal control model, and characterize the solution. Our findings can help firms decide how to vary the size and composition of the offer set during the course of a customer's engagement period with the firm. The benefits of the proposed approach are illustrated for different patterns of engagement, including the length of the engagement period, uncertainty in the length of the period, and the frequency of the customer's visits to the firm. We also study the scenario where the firm optimizes the size of the offer set during the planning horizon. One of the most important insights of this study is that frequent visits to the firm's website are extremely important for an e-tailing firm even though the customer may not always buy products during these visits.
|keyword = web-based personalization,electronic retailing,optimal control,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Using Personal Communication Technologies for Commercial Communications: A Cross-Country Investigation of Email and SMS'''
{{header}}
{{article
|author= Chuan-Hoo Tan,Juliana Sutanto,Chee Wei Phang,Anar Gasimov,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = The widespread use of personal communication technologies (PCTs) for commercial message dissemination necessitates understanding that PCTs might lead to better commercial performance in different situations. Building primarily on apparatgeist and social construction theories, this research proposes that consumer responses to PCT-disseminated commercial messages are jointly influenced by the PCT (i.e., technology) that carries general symbolic meanings about its nature and purpose (its "spirit"), and the context culture (i.e., the cultural milieu) in which it is used. We began with focus groups' assessments of two commonly utilized PCTs-email and short message service-which revealed their comparative symbolic meanings in terms of intimacy or formality of communication-to be in line with extant literature. Then, in a commercial setting where retailers leverage PCTs to disseminate product discount coupons, we examined the difference between two distinct environments that differed in their context-cultural dimensions (their cultural milieus of social interaction and communication)-i.e., China (an environment of high context-cultural dimension) and Switzerland (an environment of low context-cultural dimension). To do so, we first validated the context-cultural differences through a survey (study 1) and conducted two matching field experiments in the two countries involving more than one thousand consumers (study 2). Results support our propositions, demonstrating favorable commercial performance for SMS use in the high context-cultural environment and for email use in the low context-cultural environment. Follow-up surveys (study 3) corroborated the results and provided deeper insights into how both PCTs' general meanings and pertinent values in the cultural milieus we studied led to consumer responses. Besides presenting empirical evidence to inform the selection of appropriate PCTs for commercial communications, this research contributes to the theoretical development of apparatgeist and social construction theories via its joint examination of technologies and consumers' environments.
|keyword = personal communication technology,apparatgeist theory,social construction,context-cultural dimension,multimethod investigation,field experiment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Product Fit Uncertainty in Online Markets: Nature, Effects, and Antecedents'''
{{header}}
{{article
|author= Yili (Kevin) Hong,Paul A. Pavlou,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Product fit uncertainty (defined as the degree to which a consumer cannot assess whether a product's attributes match her preference) is proposed to be a major impediment to online markets with costly product returns and lack of consumer satisfaction. We conceptualize the nature of product fit uncertainty as an information problem and theorize its distinct effect on product returns and consumer satisfaction (versus product quality uncertainty), particularly for experience (versus search) goods without product familiarity. To reduce product fit uncertainty, we propose two Internet-enabled systems-website media (visualization systems) and online product forums (collaborative shopping systems)-that are hypothesized to attenuate the effect of product type (experience versus search goods) on product fit uncertainty. Hypotheses that link experience goods to product returns through the mediating role of product fit uncertainty are tested with analyses of a unique data set composed of secondary data matched with primary direct data from numerous consumers who had recently participated in buy-it-now auctions. The results show the distinction between product fit uncertainty and quality uncertainty as two distinct dimensions of product uncertainty and interestingly show that, relative to product quality uncertainty, product fit uncertainty has a significantly stronger effect on product returns. Notably, whereas product quality uncertainty is mainly driven by the experience attributes of a product, product fit uncertainty is mainly driven by both experience attributes and lack of product familiarity. The results also suggest that Internet-enabled systems are differentially used to reduce product (fit and quality) uncertainty. Notably, the use of online product forums is shown to moderate the effect of experience goods on product fit uncertainty, and website media are shown to attenuate the effect of experience goods on product quality uncertainty. The results are robust to econometric specifications and estimation methods. The paper concludes by stressing the importance of reducing the increasingly prevalent information problem of product fit uncertainty in online markets with the aid of Internet-enabled systems.
|keyword = product fit uncertainty,product quality uncertainty,product returns,Internet-enabled systems,expectation confirmation theory,online markets,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Consumer Informedness and Firm Information Strategy'''
{{header}}
{{article
|author= Ting Li,Robert J. Kauffman,Eric van Heck,Peter Vervest,Benedict G. C. Dellaert,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Consumer informedness plays a critical role in determining consumer choice in the presence of information technology deployed by competing firms in the marketplace. This paper develops a new theory of consumer informedness. Using data collected through a series of stated choice experiments in two different research contexts, we examine how consumer characteristics and observed behaviors moderate the influence of price and product informedness on consumer choice. The results indicate that different types of consumer informedness amplify different consumer behaviors in specific consumer segments. In particular, we found that price informedness is more influential among consumers in the commodity segment. They exhibit greater trading down behavior, which represents stronger preferences for choosing the products that provide the best price. In contrast, product informedness is more influential among consumers in the differentiated segment. This group exhibits greater trading out behavior, involving stronger preferences for choosing products that best suit their specific needs. These results suggest that firm information strategy should take into account consumers' characteristics, their past observed behaviors, and the impact of consumer informedness. We also discuss the theoretical contributions of this research and its broader implications for firm-level information strategy.
|keyword = consumer choice,information strategy,marketing and IS,price and product information,randomized experiment,stated choice experiment,theory of consumer informedness,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Project Managers' Practical Intelligence and Project Performance in Software Offshore Outsourcing: A Field Study'''
{{header}}
{{article
|author= Nishtha Langer,Sandra A. Slaughter,Tridas Mukhopadhyay,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = T his study examines the role of project managers' (PM) practical intelligence (PI) in the performance of software offshore outsourcing projects. Based on the extant literature, we conceptualize PI for PMs as their capability to resolve project related work problems, given their long-range and short-range goals; PI is targeted at resolving unexpected and difficult situations, which often cannot be resolved using established processes and frameworks. We then draw on the information processing literature to argue that software offshore outsourcing projects are prone to severe information constraints that lead to unforeseen critical incidents that must be resolved adequately for the projects to succeed. We posit that PMs can use PI to effectively address and resolve such incidents, and therefore the level of PMs' PI positively affects project performance. We further theorize that project complexity and familiarity contribute to its information constraints and the likelihood of critical incidents in a project, thereby moderating the relationship between PMs' PI and project performance. To evaluate our hypotheses, we analyze longitudinal data collected in an in-depth field study of a leading software vendor organization in India. Our data include project and personnel level archival data on 530 projects completed by 209 PMs. We employ the critical incidents methodology to assess the PI of the PMs who led these projects. Our findings indicate that PMs' PI has a significant and positive impact on project performance. Further, projects with higher complexity or lower familiarity benefit even more from PMs' PI. Our study extends the literatures on project management and outsourcing by conceptualizing and measuring PMs' PI, by theorizing its relationship with project performance, and by positing how that relationship is moderated by project complexity and familiarity. Our study provides unique empirical evidence of the importance of PMs' PI in software offshore outsourcing projects. Given that PMs with high PI are scarce resources, our findings also have practical implications for the optimal resource allocation and training of PMs in software offshore services companies.
|keyword = IT project management,practical intelligence,software offshore outsourcing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Influence Techniques in Phishing Attacks: An Examination of Vulnerability and Resistance'''
{{header}}
{{article
|author= Ryan T. Wright,Matthew L. Jensen,Jason Bennett Thatcher,Michael Dinger,Kent Marett,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Phishing is a major threat to individuals and organizations. Along with billions of dollars lost annually, phishing attacks have led to significant data breaches, loss of corporate secrets, and espionage. Despite the significant threat, potential phishing targets have little theoretical or practical guidance on which phishing tactics are most dangerous and require heightened caution. The current study extends persuasion and motivation theory to postulate why certain influence techniques are especially dangerous when used in phishing attacks. We evaluated our hypotheses using a large field experiment that involved sending phishing messages to more than 2,600 participants. Results indicated a disparity in levels of danger presented by different influence techniques used in phishing attacks. Specifically, participants were less vulnerable to phishing influence techniques that relied on fictitious prior shared experience and were more vulnerable to techniques offering a high level of self-determination. By extending persuasion and motivation theory to explain the relative efficacy of phishers' influence techniques, this work clarifies significant vulnerabilities and lays the foundation for individuals and organizations to combat phishing through awareness and training efforts.
|keyword = persuasion theory,influence techniques,motivation theory,self-determination,perceived locus of causality,social engineering,online deception,mediated deception,deception,field experiments,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''How Semantics and Pragmatics Interact in Understanding Conceptual Models'''
{{header}}
{{article
|author= Palash Bera,Andrew Burton-Jones,Yair Wand,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Underlying the design of any information system is an explicit or implicit conceptual model of the domain that the system supports. Because of the importance of such models, researchers and practitioners have long focused on how best to construct them. Past research on constructing conceptual models has generally focused on their semantics (their meaning), to discover how to convey meaning more clearly and completely, or their pragmatics (the importance of context in model creation and use), to discover how best to create or use a model in a given situation. We join these literatures by showing how semantics and pragmatics interact. Specifically, we carried out an experiment to examine how the importance of clear semantics in conceptual models-operationalized in terms of ontological clarity-varies depending on the pragmatics of readers' knowledge of the domain shown in the model. Our results show that the benefit of ontological clarity on understanding is concave downward (follows an inverted-U) as a function of readers' prior domain knowledge. The benefit is greatest when readers have moderate knowledge of the domain shown in the model. When readers have high or low domain knowledge, ontological clarity has no apparent benefit. Our study extends the theory of ontological clarity and emphasizes the need to construct conceptual models with readers' knowledge in mind.
|keyword = conceptual modeling,domain familiarity,ontological clarity,semantics,pragmatics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Influences of Online Service Technologies and Task Complexity on Efficiency and Personalization'''
{{header}}
{{article
|author= Jingjun (David) Xu,Izak Benbasat,Ronald T. Cenfetelli,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Online retailers are increasingly providing service technologies, such as technology-based and human-based services, to assist customers with their shopping. Despite the prevalence of these service technologies and the scholarly recognition of their importance, surprisingly little empirical research has examined the fundamental differences among them. Consequently, little is known about the factors that may favor the use of one type of service technology over another. In this paper, we propose the Model of Online Service Technologies (MOST) to theorize that the capacity of a service provider to accommodate the variability of customer inputs into the service process is the key difference among various types of service technologies. We posit two types of input variability: Service Provider-Elicited Variability (SPEV), where variability is determined in advance by the service provider; and User-Initiated Variability (UIV), where customers determine variability in the service process. We also theorize about the role of task complexity in changing the effectiveness of service technologies. We then empirically investigate the impact of service technologies that possess different capacities to accommodate input variability on efficiency and personalization, the two competing goals of service adoption. Our empirical approach attempts to capture both the perspective of the vendor who may deploy such technologies, as well as the perspective of customers who might choose among service technology alternatives. Our findings reveal that SPEV technologies (i.e., technologies that can accommodate SPEV) are more efficient, but less personalized, than SPEUIV technologies (i.e., technologies that can accommodate both SPEV and UIV). However, when task complexity is high (vs. low), the superior efficiency of SPEV technologies is less prominent, while both SPEV and SPEUIV technologies have higher personalization. We also find that when given a choice, a majority of customers tend to choose to use both types of technologies. The results of this study further our understanding of the differences in efficiency and personalization experienced by customers when using various types of online service technologies. The results also inform practitioners when and how to implement these technologies in the online shopping environment to improve efficiency and personalization for customers.
|keyword = input variability,online service technologies,SPEV technologies,SPEUIV technologies,task complexity,efficiency,personalization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''RELIABILITY GENERALIZATION OF PERCEIVED EASE OF USE, PERCEIVED USEFULNESS, AND BEHAVIORAL INTENTIONS'''
{{header}}
{{article
|author= Traci J. Hess,Anna L. McNab,K. Asli Basoglu,
|source= MIS QUARTERLY
|year= 2014
|abstract = A reliability generalization study (a meta-analysis of reliability coefficients) was conducted on three widely studied information systems constructs from the technology acceptance model (TAM): perceived ease of use, perceived usefulness, and behavioral intentions. This form of meta-analysis summarizes the reliability coefficients of the scores on a specified scale across studies and identifies the study characteristics that influence the reliability of these scores. Reliability is a critical issue in conducting empirical research as the reliability of the scores on well-established scales can vary with study characteristics, attenuating effect sizes. In conducting this study, an extensive literature search was conducted, with 380 articles reviewed and coded to perform reliability generalization. Study characteristics, including technology, sample, and measurement characteristics, for these articles were recorded along with effect size data for the relationships among these variables. After controlling for number of items, sample size, and sampling error, differences in reliability coefficients were found with several study characteristics for the three technology acceptance constructs. The reliability coefficients of PEOU and PU were lower in hedonic contexts than in utilitarian contexts, and were higher when the originally validated scales were used as compared to when other items were substituted. Only 27 percent of the studies that provided the measurement items used the original PEOU items, while 39 percent used the original PU items. Scales that were administered in English had higher reliability coefficients for PU and BI, with a marginal effect for PEOU. Reliability differences were also found for other study characteristics, including reliability type, subject experience, and gender composition. While average reliability coefficients were high, the results show that, on average, relationships among these constructs are attenuated by 12 percent with maximum attenuation in the range of 35 to 43 percent. Implications for technology acceptance research are discussed and suggestions for addressing variation in reliability coefficients across studies are provided.
|keyword = Reliability generalization,reliability,meta-analysis,technology acceptance model (TAM),ease of use,usefulness,behavioral intentions,effect size attenuation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COLLABORATION THROUGH OPEN SUPERPOSITION: A THEORY OF THE OPEN SOURCE WAY'''
{{header}}
{{article
|author= James Howison,Kevin Crowston,
|source= MIS QUARTERLY
|year= 2014
|abstract = This paper develops and illustrates the theory of collaboration through open superposition: the process of depositing motivationally independent layers of work on top of each other over time. The theory is developed in a study of community-based free and open source software (FLOSS) development, through a research arc of discovery (participant observation), replication (two archival case studies), and theorization. The theory explains two key findings: (1) the overwhelming majority of work is accomplished with only a single programmer working on any one task, and (2) tasks that appear too large for any one individual are more likely to be deferred until they are easier rather than being undertaken through structured team work. Moreover, the theory explains how working through open superposition can lead to the discovery of a work breakdown that results in complex, functionally interdependent, work being accomplished without crippling search costs. We identify a set of socio-technical contingencies under which collaboration through open superposition is likely to be effective, including characteristics of artifacts made from information as the objects being worked on. We demonstrate the usefulness of the theory by using it to analyze difficulties in learning from FLOSS in other domains of work and in the IS function of for-profit organizations.
|keyword = Open source,information systems development,materiality,socio-technical system,collaboration,coordination,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ENTERPRISE SYSTEM IMPLEMENTATION AND EMPLOYEE JOB PERFORMANCE: UNDERSTANDING THE ROLE OF ADVICE NETWORKS'''
{{header}}
{{article
|author= Tracy Ann Sykes,Viswanath Venkatesh,Jonathan L. Johnson,
|source= MIS QUARTERLY
|year= 2014
|abstract = The implementation of enterprise systems, such as enterprise resource planning (ERP) systems, alters business processes and associated workflows, and introduces new software applications that employees must use. Employees frequently find such technology-enabled organizational change to be a major challenge. Although many challenges related to such changes have been discussed in prior work, little research has focused on post-implementation job outcomes of employees affected by such change. We draw from social network theory-specifically, advice networks-to understand a key post-implementation job outcome (i.e., job performance). We conducted a study among 87 employees, with data gathered before and after the implementation of an ERP system module in a business unit of a large organization. We found support for our hypotheses that workflow advice and software advice are associated with job performance. Further, as predicted, we found that the interactions of workflow and software get-advice, workflow and software give-advice, and software get-and give-advice were associated with job performance. This nuanced treatment of advice networks advances our understanding of post-implementation success of enterprise systems.
|keyword = Social networks,get-advice,give-advice,enterprise system implementation,job performance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EXPLAINING DATA-DRIVEN DOCUMENT CLASSIFICATIONS'''
{{header}}
{{article
|author= David Martens,Foster Provost,
|source= MIS QUARTERLY
|year= 2014
|abstract = Many document classification applications require human understanding of the reasons for data-driven classification decisions by managers, client-facing employees, and the technical team. Predictive models treat documents as data to be classified, and document data are characterized by very high dimensionality, often with tens of thousands to millions of variables (words). Unfortunately, due to the high dimensionality, understanding the decisions made by document classifiers is very difficult. This paper begins by extending the most relevant prior theoretical model of explanations for intelligent systems to account for some missing elements. The main theoretical contribution is the definition of a new sort of explanation as a minimal set of words (terms, generally), such that removing all words within this set from the document changes the predicted class from the class of interest. We present an algorithm to find such explanations, as well as a framework to assess such an algorithm's performance. We demonstrate the value of the new approach with a case study from a real-world document classification task: classifying web pages as containing objectionable content, with the goal of allowing advertisers to choose not to have their ads appear on those pages. A second empirical demonstration on news-story topic classification shows the explanations to be concise and document-specific, and to be capable of providing understanding of the exact reasons for the classification decisions, of the workings of the classification models, and of the business application itself. We also illustrate how explaining the classifications of documents can help to improve data quality and model performance.
|keyword = Document classification,instance level explanation,text mining,comprehensibility,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''SOCIAL MEDIA, TRADITIONAL MEDIA, AND MUSIC SALES'''
{{header}}
{{article
|author= Sanjeev Dewan,Jui Ramaprasad,
|source= MIS QUARTERLY
|year= 2014
|abstract = Motivated by the growing importance of social media, this paper examines the relationship between new media, old media, and sales in the context of the music industry. In particular, we study the interplay between blog buzz, radio play, and music sales at both the album and song levels of analysis. We employ the panel vector autoregression (PVAR) methodology, an extension of vector autoregression to panel data. We find that radio play is consistently and positively related to future sales at both the song and album levels. Blog buzz, however, is not related to album sales and negatively related to song sales, suggesting that sales displacement due to free online sampling dominates any positive word-of-mouth effects of song buzz on sales. Further, the negative relationship between song buzz and sales is stronger for niche music relative to mainstream music, and for less popular songs within albums. We discuss the implications of these results for both research and practice regarding the role of new media in the music industry.
|keyword = Social media,traditional media,music industry,panel vector auto-regression,blog buzz,music sales,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CONTENT SHARING IN A SOCIAL BROADCASTING ENVIRONMENT: EVIDENCE FROM TWITTER'''
{{header}}
{{article
|author= Zhan Shi,Huaxia Rui,Andrew B. Whinston,
|source= MIS QUARTERLY
|year= 2014
|abstract = The rise of social broadcasting technologies has greatly facilitated open access to information worldwide, not only by powering decentralized information production and consumption, but also by expediting information diffusion through social interactions like content sharing. Voluntary information sharing by users in the context of Twitter, the predominant social broadcasting site, is studied by modeling both the technology and user behavior. A detailed data set about the official content-sharing function on Twitter, called retweet, is collected and the statistical relationships between users' social network characteristics and their retweeting acts are documented. A two-stage consumption-sharing model is then estimated using the conditional maximum likelihood estimatio (MLE) method. The empirical results convincingly support our hypothesis that weak ties (in the form of unidirectional links) are more likely to engage in the social exchange process of content sharing. Specifically, we find that after a median quality tweet (as defined in the sample) is consumed, the likelihood that a unidirectional follower will retweet is 3.1 percentage point higher than the likelihood that a bidirectional follower will do so.
|keyword = Content sharing,social broadcasting,information diffusion,Twitter,weak tie,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CONTRIBUTION BEHAVIOR IN VIRTUAL COMMUNITIES: COGNITIVE, EMOTIONAL, AND SOCIAL INFLUENCES'''
{{header}}
{{article
|author= Hsien-Tung Tsai,Richard P. Bagozzi,
|source= MIS QUARTERLY
|year= 2014
|abstract = The long-term viability of virtual communities depends critically on contribution behavior by their members. We deepen and extend prior research by conceptualizing contributions to virtual communities in terms of small friendship group-referent intentional actions. Specifically, we investigate cognitive, emotional, and social determinants of shared we-intentions and their consequences for member contribution behavior to the small friendship group to which they belong within a larger community. Using multiple measurement sources and a longitudinal quasi-experimental design, we show that group norms and social identity, as well as attitudes and anticipated emotions, contribute to the development of behavioral desires, which in turn influence we-intentions. In addition, subjective norms are less effective than either group norms or social identity in encouraging contribution behavior. Finally, members' experience levels positively moderate the relationship between we-intentions and contribution behaviors, and differences between collectivistic versus individualistic orientations moderate the effects of social identity and anticipated emotions on the desire to contribute to one's friendship group in the virtual community. Tests for methods biases were conducted, as well as rival hypotheses. These findings have significant research and managerial implications.
|keyword = Anticipated emotions,desire,individualism-collectivism,novice versus experienced members,social identity,social influence,virtual communities,we-intentions,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THEORIZATION AND TRANSLATION IN INFORMATION TECHNOLOGY INSTITUTIONALIZATION: EVIDENCE FROM DANISH HOME CARE'''
{{header}}
{{article
|author= Jeppe Agger Nielsen,Lars Mathiassen,Sue Newell,
|source= MIS QUARTERLY
|year= 2014
|abstract = Although institutional theory has become a more dominant perspective in information systems research, studies have only paid scant attention to how field dynamics and organizational processes coevolve during information technology institutionalization. Against this backdrop, we present a new conceptualization based on the "traveling of ideas" metaphor that distinguishes between theorization of ideas about IT usage across an organizational field and translation of such ideas into practical use of IT within particular organizations. Drawing on these distinct analytical views, we posit that IT institutionalization is constituted through recursive intertwining of theorization and translation involving both linguistic and material objects. To illustrate the detailed workings of this conceptualization, we apply it to a longitudinal study of mobile IT institutionalization within Danish home care. We demonstrate how heterogeneous actors within the Danish home care field theorized ideas about mobile IT usage and how these ideas translated into different local arrangements. Further, our account reveals a complex institutionalization process in which mobile IT was first seen as a fashionable recipe for improvement but subsequently became the subject of controversy. The paper adds to the emerging process and discourse literature on IT institutionalization by shedding new light on how IT ideas travel across a field and within individual organizations, how they transform and become legitimized over time, and how they take on different linguistic and material forms across organizational settings.
|keyword = IT institutionalization,institutional theory,theorization,translation,mobile IT,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''LEVERAGING PHILANTHROPIC BEHAVIOR FOR CUSTOMER SUPPORT: THE CASE OF USER SUPPORT FORUMS'''
{{header}}
{{article
|author= Wael Jabr,Radha Mookerjee,Yong Tan,Vijay S. Mookerjee,
|source= MIS QUARTERLY
|year= 2014
|abstract = Online user forums for technical support are being widely adopted by IT firms to supplement traditional customer support channels. Customers benefit from having an additional means of product support, while firms benefit by lowering the costs of supporting a large customer base. Typically these forums are populated with content generated by users, consisting of questioners (solution seekers) and solvers (solution providers). While questioners can be expected to keep returning as long as they can find answers, firms must employ different means in order to recognize and encourage the contributions of solvers. We identify and compare the impact of two widely adopted recognition mechanisms on the philanthropic behavior of solvers. In the first mechanism, feedback-based recognition, solver contribution is evaluated by questioners. In the second mechanism, quantity-based recognition, all contributions are weighted equally regardless of questioner feedback. We draw on the pro-social behavior literature to identify four drivers of solver contribution: (1) peer recognition, (2) image motivation, (3) social comparison, and (4) social exposure. We show that the choice of recognition mechanism strongly influences a solver's problem-solving behavior, highlighting the importance of the firm's decision in this regard. We address issues of solvers self-selecting a type of recognition mechanism by using propensity score analysis in order to show that solver behavior is a result of forum conditioning. We also study the impact of the recognition mechanism on forum quality and the effectiveness of support to draw comparative analytics.
|keyword = User support forum,text mining,pro-social behavior,recognition mechanism,feedback,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''SWIFT GUANXI IN ONLINE MARKETPLACES: THE ROLE OF COMPUTER-MEDIATED COMMUNICATION TECHNOLOGIES'''
{{header}}
{{article
|author= Carol Xiaojuan Ou,Paul A. Pavlou,Robert M. Davison,
|source= MIS QUARTERLY
|year= 2014
|abstract = The concept of guanxi (i.e., a close and pervasive interpersonal relationship) has received little attention in the literature on online marketplaces, perhaps due to their impersonal nature. However, we propose that computer-mediated communication (CMC) technologies can mimic traditional interactive face-to-face communications, thus enabling a form of guanxi in online marketplaces. Extending the literature on traditional guanxi, we herein introduce the concept of swift guanxi, conceptualized as the buyer's perception of a swiftly formed interpersonal relationship with a seller, which consists of mutual understanding, reciprocal favors, and relationship harmony. Integrating theories of CMC and guanxi, we develop a model that explains how a set of CMC tools (i.e., instant messaging, message box, feedback system) facilitate repeat transactions with sellers by building swift guanxi and trust through interactivity and presence (social presence and telepresence) with sellers. Longitudinal data from 338 buyers in TaoBao, China's leading online marketplace, support our structural model, showing that the buyers' effective use of CMC tools enable swift guanxi and trust by enhancing the buyers' perceptions of interactivity and presence. In turn, swift guanxi and trust predict buyers' repurchase intentions and their actual repurchases from sellers. We discuss the implications of swift guanxi in online marketplaces with the aid of CMC technologies.
|keyword = Guanxi,swift guanxi,computer-mediated communication (CMC) technologies,media synchronicity theory (MST),computer-mediated communication interactivity model (CMCIM),instant messenger (IM),online marketplaces,interactivity,presence,trust,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COMPLEMENTARY ONLINE SERVICES IN COMPETITIVE MARKETS: MAINTAINING PROFITABILITY IN THE PRESENCE OF NETWORK EFFECTS'''
{{header}}
{{article
|author= Hila Etzion,Min-Seok Pang,
|source= MIS QUARTERLY
|year= 2014
|abstract = A growing number of firms are strategically utilizing information technology and the Internet to provide online services to consumers who buy their products. Online services differ from traditional services because they often promote interactivity among users and exhibit positive network effects. While the service increases the value obtained by consumers, network effects are known to intensify price competition and thus may reduce firms' profits. In this paper, we model the competition between two firms that sell a differentiated product when each firm can offer a complementary online service to its customers. We derive the market equilibrium and determine how firms should adjust their strategies to account for network effects. We find that when the service exhibits network effects, a firm's decision whether or not to offer the service depends on both the competitor's decision and the competitor's service quality. When the service does not exhibit network effects, this is not the case. In addition, we show that a firm can benefit from the technological ability to offer the service, and from an increase in the strength of network effects or in the market size of the service, only when the value customers derive from the direct functionalities (those that do not rely on the network) of the service are sufficiently high. As a result, a firm's investment in the direct functionalities of its service increases with the strength of network effects of the service as long as the marginal development cost is not too high. Finally, we show that inefficiencies in terms of the number of firms offering the service as well as the total number of service users may prevail.
|keyword = Online services,network effects,e-commerce,analytical modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DISTRIBUTED COGNITION IN SOFTWARE DESIGN: AN EXPERIMENTAL INVESTIGATION OF THE ROLE OF DESIGN PATTERNS AND COLLABORATION'''
{{header}}
{{article
|author= George Mangalaraj,Sridhar Nerur,RadhaKanta Mahapatra,Kenneth H. Price,
|source= MIS QUARTERLY
|year= 2014
|abstract = Software design is a knowledge intensive task that constitutes a critical part of the software development process. Using a controlled experiment involving software practitioners, this research examines two potentially useful mechanisms for improving the software design process. Specifically, this study examines the impact of structural distribution of cognition through design patterns and social distribution of cognition through collaborating pairs on design outcomes. The results indicate that the use of design patterns as external cognitive artifacts improves design quality, reduces time taken to solve a design problem, and leads to higher participant satisfaction. Collaborating pairs of software designers were compared to participants working alone but whose efforts were conjointly considered as the best and second-best members of nominal pairs. It was found that paired designers produced higher quality designs compared with the second-best members of nominal pairs, did not differ from the best member of a nominal pair, but took more time to complete a design task than either member of a nominal pair. The results also indicate that the availability of design patterns raises the performance level of the second-best member of a nominal pair, in terms of quality, and reduces task completion time when compared with a pair not using design patterns. Finally, paired designers were found to experience higher levels of task satisfaction when compared with individuals. Implications for research and practice are discussed.
|keyword = Software design,agile methodology,paired design,design pattern,nominal group,distributed cognition,codified knowledge,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WHAT'S DIFFERENT ABOUT SOCIAL MEDIA NETWORKS? A FRAMEWORK AND RESEARCH AGENDA'''
{{header}}
{{article
|author= Gerald C. Kane,Maryam Alavi,Giuseppe (Joe) Labianca,Stephen P. Borgatti,
|source= MIS QUARTERLY
|year= 2014
|abstract = In recent years, we have witnessed the rapid proliferation and widespread adoption of a new class of information technologies, commonly known as social media. Researchers often rely on social network analysis (SNA) when attempting to understand these technologies, often without considering how the novel capabilities of social media platforms might affect the underlying theories of SNA, which were developed primarily through studies of offline social networks. This article outlines several key differences between traditional offline social networks and online social media networks by juxtaposing an established typology of social network research with a well-regarded definition of social media platforms that articulates four key features. The results show that at four major points of intersection, social media has considerable theoretical implications for SNA. In exploring these points of intersection, this study outlines a series of theoretically distinct research questions for SNA in social media contexts. These points of intersection offer considerable opportunities for researchers to investigate the theoretical implications introduced by social media and lay the groundwork for a robust social media agenda potentially spanning multiple disciplines.
|keyword = Social media,social network analysis,theory,blog,wiki,networks,framework,research agenda,knowledge management,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION TECHNOLOGY CAPABILITY AND FIRM PERFORMANCE: CONTRADICTORY FINDINGS AND THEIR POSSIBLE CAUSES'''
{{header}}
{{article
|author= Ho-Chang Chae,Chang E. Koh,Victor R. Prybutok,
|source= MIS QUARTERLY
|year= 2014
|abstract = Several studies support the positive link between information technology capability and firm performance, including Bharadwaj (2000) and Santhanam and Hartono (2003), which appeared in MIS Quarterly. We conducted a study to see if this link is still statistically significant. It is now over a decade since the first study was published, during which several significant developments in the IT industry have taken place. Unlike the 1990s, when proprietary information systems prevailed, the 2000s are characterized by more standardized and homogeneous information systems and with the rapid adoption of ERP and web technologies. Thus, we attempted to reexamine the link between IT capability and firm performance with data from the 2000s. Surprisingly, the results of our current analysis showed no significant link between IT capability and firm performance. Contrary to earlier studies, IT leader firms in our study didn't show better financial performance than control firms. We discuss several possible causes for the change in findings and present an in-depth comparison in business performance between the two groups-IT leader and control-over a period extending from 1991 to 2007.
|keyword = IT capability,firm performance,IW 500,IT business value,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Neuroscience and a Nomological Network for the Understanding and Assessment of Emotions in Information Systems Research'''
{{header}}
{{article
|author= Shirley Gregor,Aleck C. H. Lin,Tom Gedeon,Amir Riaz,Dingyun Zhu,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Human emotions' role in phenomena related to information systems ( IS) is increasingly of interest to research and practice, and is now informed by a burgeoning literature in neuroscience. This study develops a nomological network with an overarching view of relationships among emotions and other constructs of interest in IS research. The resulting 3-emotion systems' nomological network includes three interacting emotion systems: language, physiology, and behavior. Two laboratory experiments were conducted to test the nomological network, with six online travel service Web pages used as stimuli. The first study used paper-based self-report measures and qualitative comments, whereas the second included both self-reports and electroencephalography (EEG) measures. An outcome measure of e-loyalty was included in each study. The results of both studies showed positive and negative emotion-inducing stimuli were related to positive and negative emotions when viewing the Web sites as indicated by both self-reports and EEG data. In turn, positive and negative emotions as measured by both self-reports and EEG measures were linked to e-loyalty to some degree. This research is novel and significant because it is possibly the first in-depth study to link the study of emotions in IS with a sound theory base and multiple measurement approaches, including neuroscience measures. It shows that an EEG measure has some predictive power for an outcome such as e-loyalty. Implications of the research are that IS studies should distinguish between the different emotion systems of language and physiology, choose emotion measures carefully, and also recognize the intertwining of the emotion systems and cognitive processing.
|keyword = emotions in information systems,measurement,NeuroIS,neuroscience,nomological net,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Putting on the Thinking Cap: Using NeuroIS to Understand Information Processing Biases in Virtual Teams'''
{{header}}
{{article
|author= Randall K. Minas,Robert F. Potter,Alan R. Denis,Valerie Bartelt,Soyoung Bae,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Virtual teams are increasingly common in today's organizations, yet they often make poor decisions. Teams that interact using text-based collaboration technology typically exchange more information than when they perform the same task face-to-face, but past results suggest that team members are more likely to ignore information they receive from others. Collaboration technology makes unique demands on individual cognitive resources that may change how individual team members process information in virtual settings compared to face-to-face settings. This experiment uses electroencephalography, electrodermal activity, and facial electromyography to investigate how team members process information received from text-based collaboration during a team decision-making process. Our findings show that information that challenges an individual's prediscussion decision preference is processed similarly to irrelevant information, while information that supports an individual's prediscussion decision preference is processed more thoroughly. Our results present neurological evidence for the underlying processes of confirmation bias in information processing during online team discussions.
|keyword = collaboration technology,electroencephalography,information processing bias,NeuroIS,virtual teams,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Trusting Humans and Avatars: A Brain Imaging Study Based on Evolution Theory'''
{{header}}
{{article
|author= Rene Riedl,Peter N. C. Mohr,Peter H. Kening,Fred D. Davis,Hauke R. Hekeren,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Avatars, as virtual humans possessing realistic faces, are increasingly used for social and economic interaction on the Internet. Research has already determined that avatar-based communication may increase perceived interpersonal trust in anonymous online environments. Despite this trust-inducing potential of avatars, however, we hypothesize that in trust situations, people will perceive human faces differently than they will perceive avatar faces. This prediction is based on evolution theory, because throughout human history the majority of interaction among people has taken place in face-to-face settings. Therefore, unlike perception of an avatar face, perception of a human face and the related trustworthiness discrimination abilities must be part of the genetic makeup of humans. Against this background, we conducted a functional magnetic resonance imaging experiment based on a multiround trust game to gain insight into the differences and similarities of interactions between humans versus human interaction with avatars. Our results indicate that (1) people are better able to predict the trustworthiness of humans than the trustworthiness of avatars; (2) decision making about whether or not to trust another actor activates the medial frontal cortex significantly more during interaction with humans, if compared to interaction with avatars; this brain area is of paramount importance for the prediction of other individuals' thoughts and intentions (mentalizing), a notably important ability in trust situations; and (3) the trustworthiness learning rate is similar, whether interacting with humans or avatars. Thus, the major implication of this study is that although interaction on the Internet may have benefits, the lack of real human faces in communication may serve to reduce these benefits, in turn leading to reduced levels of collaboration effectiveness.
|keyword = agent,avatar,brain,cognitive neuroscience,evolutionary psychology,evolution theory,functional magnetic resonance imaging (fMRI),medial frontal cortex (MFC),mentalizing,NeuroIS,theory-of-mind (TOM),
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Enhancing User-Game Engagement Through Software Gaming Elements'''
{{header}}
{{article
|author= Mengxiang Li,Qiqi Jiang,Chuan-Ho Tan,Kwok-Kee Wei,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = User-game engagement is vital for building and retaining a customer base for software games. However, few studies have investigated such engagement during gameplay and the impact of gaming elements on engagement. Drawing on the theoretical foundation of engagement, we meticulously deduced two cognitive-related gaming elements of a software game, namely, game complexity and game familiarity, and argued that these elements have individual and joint effects on user-game engagement. This research adopted multimethod empirical investigations to validate our conceptions. The first investigation used electroencephalography and a self-report survey to study quantitatively the cognitive activities of user-game engagement. The second investigation adopted the qualitative interview method to triangulate the findings from the quantitative data. This research contributes to theory in two ways, namely, conceptualizing and empirically examining user-game engagement as well as theorizing and demonstrating how the two gaming elements affect user-game engagement. This work contributes to the gaming practice by providing a set of design principles for gaming elements.
|keyword = electroencephalography,NeuroIS,online games,software games,user-game engagement,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Informational and Normative Social Influence in Group-Buying: Evidence from Self-Reported and EEG Data'''
{{header}}
{{article
|author= Kevin K. Y. Kuan,Yingqin Zhong,Patrick Y. K. Chau,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = This study examines two types of information commonly used by group-buying sites to induce purchasing. The first study indicates the number of people who have bought a deal ("buy" information). The second one indicates Facebook friends who "like" a deal ("like" information). The effects of the group-buying information on opinions (attitude and intention) and emotions were examined using a controlled experiment. Our results show that positive and negative "buy" information has an asymmetric influence on attitude and intention, whereas "like" information has a positive influence on intention. The presence of "buy" information is associated with EEG activity that is generally linked to negative emotions. However, the addition of "like" information is associated with EEG activity that is generally linked to positive emotions. The different effects of the two types of group-buying information can be explained by the different social influences exerted by the information.
|keyword = electroencephalography,emotion online,group buying,informational social influence,NeuroIS,normative social influence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Explicit and Implicit Antecedents of Users' Behavioral Beliefs in Information Systems: A Neuropsychological Investigation'''
{{header}}
{{article
|author= Ana Ortiz de Guinea,Ryad Titah,Pierre-Majorique Leger,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Behavioral beliefs-perceived usefulness and perceived ease of use-have been identified as the most influential antecedents of individuals' information systems use intentions and behaviors within the technology acceptance model. However, little research has been aimed at investigating the implicit (automatic or unconscious) determinants of such cognitive beliefs, and more importantly, the potential nonlinear relationships of such antecedents with explicit (perceptual) ones. As such, this paper theorizes that implicit neurophysiological states-memory load and distraction- and explicit-engagement and frustration-antecedents interact in the formation of perceived usefulness and perceived ease of use. To test the study's hypotheses, we conducted an experiment that measured neurophysiological states while individuals worked on instrumental and hedonic tasks using technology. The results show that, as theorized, implicit and explicit constructs interact together, and thus have a nonlinear effect on behavioral beliefs. Specifically, when engagement is high, neurophysiological distraction does not statistically significantly affect perceived usefulness, whereas when engagement is low, neurophysiological distraction has a negative and significant effect on usefulness. The results also show that when frustration is high, neurophysiological memory load has a negative effect on perceived ease of use, whereas when it is low, neurophysiological memory load has a positive effect on perceived ease of use. This study makes several contributions to acceptance research and the emerging field of NeuroIS, including demonstration of the importance of emotional perceptions for moderating the effects of neurophysiological states on behavioral beliefs.
|keyword = behavioral belief formation,cognitive beliefs,electroencephalography (EEG),emotion,IS acceptance,IS use,NeuroIS,nonlinear effects,TAM,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Guidelines for Neuroscience Studies in Information Systems Research'''
{{header}}
{{article
|author= Jan vom Brocke,Ting-Peng Liang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Neuroscience provides a new lens through which to study information systems (IS). These NeuroIS studies investigate the neurophysiological effects related to the design, use, and impact of IS. A major advantage of this new methodology is its ability to examine human behavior at the underlying neurophysiological level, which was not possible before, and to reduce self-reporting bias in behavior research. Previous studies that have revisited important IS concepts such as trust and distrust have challenged and extended our knowledge. An increasing number of neuroscience studies in IS have given researchers, editors, reviewers, and readers new challenges in terms of determining what makes a good NeuroIS study. While earlier papers focused on how to apply specific methods (e. g., functional magnetic resonance imaging), this paper takes an IS perspective in deriving six phases for conducting NeuroIS research and offers five guidelines for planning and evaluating NeuroIS studies: to advance IS research, to apply the standards of neuroscience, to justify the choice of a neuroscience strategy of inquiry, to map IS concepts to bio-data, and to relate the experimental setting to IS-authentic situations. The guidelines provide guidance for authors, reviewers, and readers of NeuroIS studies, and thus help to capitalize on the potential of neuroscience in IS research.
|keyword = NeuroIS,neuroscience,research guidelines,research methods,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Effects of Social Networks on Prediction Markets: Examination in a Controlled Experiment'''
{{header}}
{{article
|author= Liangfei Qiu,Huaxia Rui,Andrew B. Whinston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = This paper examines the effect of a social network on prediction markets using a controlled laboratory experiment that allows us to identify causal relationships between a social network and the performance of an individual participant, as well as the performance of the prediction market as a whole. Through a randomized experiment, we first confirm the theoretical predictions that participants with more social connections are less likely to invest in information acquisition from outside information sources, but perform significantly better than other participants in prediction markets. We further show that when the cost of information acquisition is low, a social network-embedded prediction market outperforms a nonnetworked prediction market. We find strong support for peer effects in prediction accuracy among participants. These results have direct managerial implications for the business practice of prediction markets and are critical to understanding how to use social networks to improve the performance of prediction markets.
|keyword = information exchange,prediction markets,social networks,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Forming Interoperability Through Interorganizational Systems Standards'''
{{header}}
{{article
|author= Kexin Zhao,Mu Xia,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Interoperability is a crucial organizational capability that enables firms to manage information systems (IS) from heterogeneous trading partners in a value network. While interoperability has been discussed conceptually in the IS literature, few comprehensive empirical studies have been conducted to conceptualize this construct and examine it in depth. For instance, it is unclear how interoperability is formed and whether it can improve organizational performance. To fill the gap, we argue that interorganizational systems (IOS) standards are a key information technology infrastructure facilitating formation of interoperability. As an organizational ability to work with external trading partners, interoperability's development depends not only on capability building within firm boundaries but also on community readiness across firm boundaries. Using data collected from 194 organizations in the geospatial industry, we empirically confirm that interoperability is formed via these two different paths. Furthermore, our results show that interoperability acts as a mediator by enabling firms to achieve performance gains from IOS standards adoption. Our study sheds new light on formation mechanisms as well as the business value of interoperability.
|keyword = business value,geospatial industry,interoperability,interorganizational systems standards,IT standards,network effects,standardization,standardized data infrastructure,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Differential Effects of Keyword Selection in Search Engine Advertising on Direct and Indirect Sales'''
{{header}}
{{article
|author= Xianghua Lu,Xia Zhao,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2014
|abstract = Product sales via sponsored keyword advertising on search engines rely on an effective selection of keywords that describe the offerings. In this study, we consider both the direct sales of the advertised products and indirect sales (i.e., cross-selling) of other products, and examine how specific keywords and general keywords influence these two types of sales differently. We also examine how the cross-selling effects may vary across different types of products (main products and accessories). Our results suggest that the use of specific keywords leans toward improving the direct sales of advertised products, while the use of general keywords leans toward improving the indirect sales of other products. The contribution of keywords to indirect sales is influenced by product type. For main products, the use of specific keywords generates a higher marginal contribution to indirect sales than that of general keywords. For accessory products, the use of general keywords generates a higher marginal contribution to indirect sales than that of specific keywords. The key implication of this study is that sellers focusing on different types of sales (direct or indirect sales) or products (main or accessory products) should consider using different types of keywords in search engine advertising to drive sales.
|keyword = cross-selling,keyword advertising,keywords selection,online advertising,search engines,sponsored search,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Technology-Enabled Business Models: A Conceptual Framework and a Coevolution Perspective for Future Research'''
{{header}}
{{article
|author= Arun Rai,Xinlin Tang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = There is growing recognition that firms' information technology (IT)-enabled business models (i.e., how inter-firm transactions with suppliers, customers, and partners are structured and executed) are a distinctive source of value creation and appropriation. However, the concept of business models' (BMs) "IT enablement" remains coarse in the information systems and strategic management literatures. Our objectives are to introduce a framework to elaborate the concept of IT-enabled BMs and to identify areas for future research that will enhance our understanding of the subject. We introduce the idea that two business-to-business (B2B) IT capabilities-dyadic IT customization and network IT standardization-are the mediating execution mechanisms between the strategic intent of interfirm collaboration and the (re) configuration of BMs to both create and appropriate value. We develop the logic that B2B IT capabilities for BM (re) configuration operate at two levels-IT customization at the dyadic relationship level and IT standardization at the interfirm network level-that together provide the complementary IT capabilities for firms to exchange content, govern relationships, and structure interconnections between products and processes with a diverse set of customers, suppliers, and partners. We discuss how these two complementary B2B IT capabilities are pivotal for firms to pursue different sources of value creation and appropriation. We identify how a firm's governance choices to engage in interfirm collaboration and its interfirm networks coevolve with its B2B IT capabilities as fruitful areas for future research.
|keyword = IT-enabled business model,B2B IT capabilities,interfirm collaboration,governance choices,design elements,value creation,value appropriation,coevolution,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Evaluation of Competing Candidate Solutions in Electronic Networks of Practice'''
{{header}}
{{article
|author= Thomas O. Meservy,Matthew L. Jensen,Kelly J. Fadel,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Electronic networks of practice have become a prevalent means for acquiring new knowledge. Knowledge seekers commonly turn to online repositories constructed by these networks to find solutions to domain-specific problems and questions. Yet little is understood about the process by which such knowledge is evaluated and adopted by knowledge seekers. This study examines how individuals filter knowledge encountered in online forums, a common platform for knowledge exchange in an electronic network of practice. Drawing on dual process theory, we develop research hypotheses regarding both central and peripheral evaluation of knowledge. These hypotheses are examined in a field experiment in which participants evaluate online solutions for computer programming problems. Results show that peripheral cues (source expertise and validation) have a greater influence on knowledge filtering decisions than does the content quality of the solution. Moreover, elaboration increases the effect of content quality but does not seem to attenuate the effect of peripheral cues. Implications for research and practice are discussed.
|keyword = electronic networks of practice,dual process theory,elaboration likelihood,knowledge management,mediated knowledge exchange,knowledge forums,information influence,knowledge filtering,field experiment,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''How to Attract and Retain Readers in Enterprise Blogging?'''
{{header}}
{{article
|author= Param Vir Singh,Nachiketa Sahoo,Tridas Mukhopadhyay,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = We investigate the dynamics of blog reading behavior of employees in an enterprise blogosphere. A dynamic model is developed and calibrated using longitudinal data from a Fortune 1,000 IT services firm. Our modeling framework allows us to segregate the impact of textual characteristics (sentiment and quality) of a post on attracting readers from retaining them. We find that the textual characteristics that appeal to the sentiment of the reader affect both reader attraction and retention. However, textual characteristics that reflect only the quality of the posts affect only reader retention. We identify a variety-seeking behavior of blog readers where they dynamically switch from reading on one set of topics to another. The modeling framework and findings of this study highlight opportunities for the firm to influence blog-reading behavior of its employees to align it with its goals. Overall, this study contributes to improved understanding of reading behavior of individuals in communities formed around user generated content.
|keyword = blogs,employee blogs,enterprise 2.0,blog reading,dynamic models,user generated content,text mining,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Measuring Information Technology Spillovers'''
{{header}}
{{article
|author= Prasanna Tambe,Lorin M. Hitt,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = The measurement of the impact of IT spillovers on productivity is an important emerging area of research. Studies of IT spillovers often adopt a "production function" approach commonly used for measuring R&D spillovers, in which an external pool of IT investment is modeled using weighted measures of the IT investments of other firms, industries, or countries. We show that when using this approach, measurement error in a firm's own IT inputs can exert a significant upward bias on estimates of social returns to IT investment. This problem is particularly severe for IT spillovers because of the high levels of measurement error in most available IT data. The presence of the bias term can be demonstrated by using instrumental variable techniques to remove the effects of measurement error in a firm's own IT inputs. Using panel data on IT investment, we show that measurement error corrected estimates of IT spillovers are 40% to 90% lower than uncorrected estimates. This bias term is increasing in the correlation between the IT pool and firms' own IT investment. Therefore, estimates from models of spillover pools are less sensitive to the issues identified in this paper when the spillover paths minimize the correlation between a firm's own IT investment and the constructed external IT pool. Implications for researchers, policy makers, and managers are discussed.
|keyword = IT spillovers,IT productivity,measurement error,business value of IT,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IT-Enabled Coordination for Ambidextrous Interorganizational Relationships'''
{{header}}
{{article
|author= Ghiyoung Im,Arun Rai,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Contextual ambidexterity of an interorganizational relationship (IOR) is the ability of its management system to align partners' activities and resources for short-term goals and adapt partners' cognitions and actions for long-term viability. It is an alternative to structural ambidexterity in which separate units of the IOR pursue short-and long-term goals. We theorize that when utilized to coordinate the IOR, information technology (IT)-enabled operations and sensemaking, along with interdependent decision making, promote the IOR's contextual ambidexterity. We test our hypotheses on both sides of a customer-vendor relationship using data collected from (1) the account executives of one of the world's largest supply chain vendors (n = 76) and (2) its customers (n = 238). We find commonalities and differences in the influence coordination mechanisms have on contextual ambidexterity from the vendor's and the customer's perspectives. For both customers and vendors, contextual ambidexterity improves the quality and performance of the relationship, and decision interdependence promotes contextual ambidexterity. For customers, using operations support systems (OSSs) and interpretation support systems (ISSs) enhances contextual ambidexterity. For vendors, the impact of both OSS use and ISS use on contextual ambidexterity depends on the duration of the relationship. Our study shows that IT-enabled operations and sensemaking are key enablers of IOR ambidexterity and that vendors should combine these IT capabilities with relationship-specific knowledge that accumulates with relationship duration.
|keyword = interorganizational relationships,interorganizational systems,contextual ambidexterity,coordination,decision interdependence,sensemaking,operations support systems,interpretation support systems,relationship duration,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Online Product Reviews: Implications for Retailers and Competing Manufacturers'''
{{header}}
{{article
|author= Young Kwark,Jianqing Chen,Srinivasan Raghunathan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = This paper studies the effect of online product reviews on different players in a channel structure. We consider a retailer selling two substitutable products produced by different manufacturers, and the products differ in both their qualities and fits to consumers' needs. Online product reviews provide additional information for consumers to mitigate the uncertainty about the quality of a product and about its fit to consumers' needs. We show that the effect of reviews on the upstream competition between the manufacturers is critical in understanding which firms gain and which firms lose. The upstream competition is affected in fundamentally different ways by quality information and fit information, and each information type has different implications for the retailer and manufacturers. Quality information homogenizes consumers' perceived utility differences between the two products and increases the upstream competition, which benefits the retailer but hurts the manufacturers. Fit information heterogenizes consumers' estimated fits to the products and softens the upstream competition, which hurts the retailer but benefits the manufacturers. Furthermore, reviews may also alter the nature of upstream competition from one in which consumers' own assessment on the quality dimension plays a dominant role in consumers' comparative evaluation of products to one in which fit dimension plays a dominant role. If manufacturers do not respond strategically to reviews and keep the same wholesale prices regardless of reviews (i.e., the upstream competition is assumed to be unaffected by reviews), then, we show that reviews never hurt the retailer and the manufacturer with favorable reviews, and never benefit the manufacturer with unfavorable reviews, a finding that demonstrates why reviews' effect on upstream competition is critical for firms in online marketplaces.
|keyword = online product reviews,competition,electronic commerce,analytical modeling,economics of IS,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Framework and Guidelines for Context-Specific Theorizing in Information Systems Research'''
{{header}}
{{article
|author= Weiyin Hong,Frank K. Y. Chan,James Y. L. Thong,Lewis C. Chasalow,Gurpreet Dhillon,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = This paper discusses the value of context in theory development in information systems (IS) research. We examine how prior research has incorporated context in theorizing and develop a framework to classify existing approaches to contextualization. In addition, we expound on a decomposition approach to contextualization and put forth a set of guidelines for developing context-specific models. We illustrate the application of the guidelines by constructing and comparing various context-specific variations of the technology acceptance model (TAM)-i.e., the decomposed TAM that incorporates interaction effects between context-specific factors, the extended TAM with context-specific antecedents, and the integrated TAM that incorporates mediated moderation and moderated mediation effects of context-specific factors. We tested the models on 972 individuals in two technology usage contexts: a digital library and an agile Web portal. The results show that the decomposed TAM provides a better understanding of the contexts by revealing the direct and interaction effects of context-specific factors on behavioral intention that are not mediated by the TAM constructs of perceived usefulness and perceived ease of use. This work contributes to the ongoing discussion about the importance of context in theory development and provides guidance for context-specific theorizing in IS research.
|keyword = theory development,contextualization,context-specific model,general model,technology adoption,technology acceptance model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Joint Product Improvement by Client and Customer Support Center: The Role of Gain-Share Contracts in Coordination'''
{{header}}
{{article
|author= Shantanu Bhattacharya,Alok Gupta,Sameer Hasija,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = We study the role of different contract types in coordinating the joint product improvement effort of a client and a customer support center. The customer support center's costly efforts at joint product improvement include transcribing and analyzing customer feedback, analyzing market trends, and investing in product design. Yet this cooperative role must be adequately incentivized by the client, since it could lead to fewer service requests and hence lower revenues for the customer support center. We model this problem as a sequential game with double-sided moral hazard in a principal-agent framework (in which the client is the principal). We follow the contracting literature in modeling the effort of the customer support center, which is the first mover, as either unobservable or observable; in either case, the efforts are unverifiable and so cannot be contracted on directly. We show that it is optimal for the client to offer the customer support center a linear gain-share contract when efforts are unobservable, even though it can yield only the second-best solution for the client. We also show that the cost-plus contracts widely used in practice do not obtain the optimal solution. However, we demonstrate that if efforts are observable then a gain-share and cost-plus options-based contract is optimal and will also yield the first-best solution. Our research provides a systematic theoretical framework that accounts for the prevalence of gain-share contracts in the IT industry's joint improvement efforts, and it provides guiding principles for understanding the increased role for customer support centers in product improvement.
|keyword = IT outsourcing,gain-share contract,cost-plus contract,joint product improvement,double-sided moral hazard,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Platform Performance Investment in the Presence of Network Externalities'''
{{header}}
{{article
|author= Jr. Edward G. Anderson,Geoffrey G. Parker,Burcu Tan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = Managers of emerging platforms must decide what level of platform performance to invest in at each product development cycle in markets that exhibit two-sided network externalities. High performance is a selling point for consumers, but in many cases it requires developers to make large investments to participate. Abstracting from an example drawn from the video game industry, we build a strategic model to investigate the trade-off between investing in high platform performance versus reducing investment in order to facilitate third party content development. We carry out a full analysis of three distinct settings: monopoly, price-setting duopoly, and price-taking duopoly. We provide insights on the optimum investment in platform performance and demonstrate how conventional wisdom about product development may be misleading in the presence of strong cross-network externalities. In particular, we show that, contrary to the conventional wisdom about "winner-take-all" markets, heavily investing in the core performance of a platform does not always yield a competitive edge. We characterize the conditions under which offering a platform with lower performance but greater availability of content can be a winning strategy.
|keyword = two-sided markets,network externality,product development,video game industry,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Economics of Free Under Perpetual Licensing: Implications for the Software Industry'''
{{header}}
{{article
|author= Marius F. Niculescu,D. J. Wu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2014
|abstract = In this paper, we explore the economics of free under perpetual licensing. In particular, we focus on two emerging software business models that involve a free component: feature-limited freemium (FLF) and uniform seeding (S). Under FLF, the firm offers the basic software version for free, while charging for premium features. Under S, the firm gives away for free the full product to a percentage of the addressable market uniformly across consumer types. We benchmark their performance against a conventional business model under which software is sold as a bundle (labeled as "charge for everything" or CE) without free offers. In the context of consumer bounded rationality and information asymmetry, we develop a unified two-period consumer valuation learning framework that accounts for both word-of-mouth (WOM) effects and experience-based learning, and use it to compare and contrast the three business models. Under both constant and dynamic pricing, for moderate strength of WOM signals, we derive the equilibria for each model and identify optimality regions. In particular, S is optimal when consumers significantly underestimate the value of functionality and cross-module synergies are weak. When either cross-module synergies are stronger or initial priors are higher, the firm decides between CE and FLF. Furthermore, we identify nontrivial switching dynamics from one optimality region to another depending on the initial consumer beliefs about the value of the embedded functionality. For example, there are regions where, ceteris paribus, FLF is optimal when the prior on premium functionality is either relatively low or high, but not in between. We also demonstrate the robustness of our findings with respect to various parameterizations of cross-module synergies, strength of WOM effects, and number of periods. We find that stronger WOM effects or more periods lead to an expansion of the seeding optimality region in parallel with a decrease in the seeding ratio. Moreover, under CE and dynamic pricing, second period price may be decreasing in the initial consumer valuation beliefs when WOM effects are strong and the prior is relatively low. However, this is not the case under weak WOM effects. We also discuss regions where price skimming and penetration pricing are optimal. Our results provide key managerial insights that are useful to firms in their business model search and implementation.
|keyword = software,freemium business models,versioning,seeding strategies,product sampling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Horizontal Allocation of Decision Rights for On-Premise Applications and Software-as-a-Service'''
{{header}}
{{article
|author= Till J. Winkler,Carol V. Brown,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = This study addresses a major gap in our knowledge about the allocation of information technology (IT) decision rights between business and IT units at the application level, including the governance of applications delivered on-premise versus those delivered with a software-as-a-service (SaaS) model. Building on the findings from a multicase qualitative study of organizations that had adopted the same SaaS application, we draw on three theoretical lenses (agency theory, transaction cost economics, and knowledge-based view) to develop a theoretically grounded model with three organization-level factors, three application-level factors, and application-level IT governance. Hypotheses derived from the model, as well as a set of differential hypotheses about factor influences due to on-premise versus SaaS delivery, are tested with survey responses from 207 firms in which application-level governance is operationalized with two dimensions: decision control rights (decision authority) and decision management rights (task responsibility). Three antecedents (origin of the application initiative, scope of application use, business knowledge of the IT unit) were significantly associated with application governance postimplementation, and the on-premise/SaaS subgroup analyses provide preliminary evidence for the mode of application delivery as a moderator of these relationships. Overall, this study contributes to a growing body of research that takes a more modular approach to studying IT governance and provides theoretical explanations for differing application-level governance designs.
|keyword = agency theory,application governance,cloud computing,field survey,IT governance,knowledge-based view,multigroup analysis,software-as-a-service,transaction cost economics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Governance and Control of Open Source Software Projects'''
{{header}}
{{article
|author= Dany Di Tullio,D. Sandy Staples,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = A comprehensive set of governance mechanisms and dimensions were investigated to identify combinations of mechanisms that are effectively used together in on-going volunteer-based open source software (OSS) projects. Three configurations were identified: Defined Community, Open Community, and Authoritarian Community. Notably, Defined Community governance had the strongest coordination and project climate and had the most extensive use of outcome, behavior, and clan control mechanisms (controller driven). The controls in the Defined Community governance configuration appear to effectively enable open, coordinated contribution and participation from a wide variety of talented developers (one of the virtues of open source development) while managing the development process and outcomes. The results add to our theoretical understanding of control in different types of information systems projects, as the combination of control modes found in OSS projects is different from those found in previous research for internal or outsourced information systems development projects. This could be due to unique features of OSS projects, such as volunteer participation and the controller being part of the development team. The results provide guidance for practitioners about how to combine 19 identified governance mechanisms into effective project governance that stimulates productive participation.
|keyword = configuration theory,control modes and mechanisms,control theory,coordination,development activity,governance,IS development,open source software projects,OSS,project climate,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Process Model of Complementarity and Substitution of Contractual and Relational Governance in IS Outsourcing'''
{{header}}
{{article
|author= Thomas L. Huber,Thomas A. Fischer,Jens Dibbern,Rudy Hirschheim,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = This paper develops a process model of how and why complementarity and substitution form over time between contractual and relational governance in the context of information systems outsourcing. Our analysis identifies four distinct process patterns that explain this formation as the outcome of interaction processes between key elements of both contractual and relational governance. These patterns unveil the dynamic nature of complementarity and substitution. In particular, we show that the relationship between contractual and relational governance oscillates between complementarity and substitution. Those oscillations are triggered mainly by three types of contextual events (goal fuzziness, goal conflict, and goal misalignment). Surprisingly, substitution of informal control did not occur as an immediate reaction to external events but emerged as a consequence of preceding complementarity. Thus, our study challenges the prevailing view of an either/or dichotomy of complementarity and substitution by showing that they are causally connected over time.
|keyword = contract,contractual governance,formal control,informal control,information systems outsourcing,outsourcing,process view,relational governance,trust,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Evolution of Governance: Achieving Ambidexterity in IT Outsourcing'''
{{header}}
{{article
|author= Lan Cao,Kanan Mohan,Balasubramaniam Ramesh,Sumantra Sarkar,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Two types of information technology (IT) outsourcing governance-contractual and relational-are commonly employed to address different goals in IT service management in outsourcing arrangements. Contractual governance helps improve efficiency in an outsourcing relationship, whereas relational governance facilitates satisfying changing business needs. Past literature argues that both forms of governance are important and that an appropriate balance between them is necessary. This study finds that these two forms of governance often conflict with one another. We contribute to the research on IT outsourcing governance by opening the black box of the evolutionary process of achieving ambidexterity in this context. Organizations shift their focus between contractual and relational forms of governance in an attempt to develop practices that address conflicts between the two forms. We present the findings from a qualitative study of an organization that outsourced its IT services. Our findings reveal how a balance between contractual and relational governance can be achieved through a process we call the ambidexterity pendulum.
|keyword = IT outsourcing,IT outsourcing governance,organizational ambidexterity,outsourcing,outsourcing governance,pendulum process,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Information Artifact in IT Governance: Toward a Theory of Information Governance'''
{{header}}
{{article
|author= Paul P. Tallon,Ronald V. Ramirez,James E. Short,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = In recent years, chief information officers have begun to report exponential increases in the amounts of raw data captured and retained across the organization. Managing extreme amounts of data can be complex and challenging at a time when information is increasingly viewed as a strategic resource. Since the dominant focus of the information technology (IT) governance literature has been on how firms govern physical IT artifacts (hardware, software, networks), the goal of this study is to extend the theory of IT governance by uncovering the structures and practices used to govern information artifacts. Through detailed interviews with 37 executives in 30 organizations across 17 industries, we discover a range of structural, procedural, and relational practices used to govern information within a nomological net that includes the antecedents of these practices and their effects on firm performance. While some antecedents enable the speedy adoption of information governance, others can delay or limit the adoption of information governance practices. Once adopted, however, information governance can help to boost firm performance. By incorporating these results into an extended theory of IT governance, we note how information governance practices can unlock value from the ever-expanding mountains of data currently held within organizations.
|keyword = big data,data growth,information artifact,information governance,information life cycle management,information management,information risk,information value,IT governance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Centralizing Data Management with Considerations of Uncertainty and Information-Based Flexibility'''
{{header}}
{{article
|author= Chander K. Velu,Stuart E. Madnick,Marshall W. Van Alstyne,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = This paper applies the theory of real options to analyze how the value of information-based flexibility should affect the decision to centralize or decentralize data management under low and high uncertainty. This study makes two main contributions. First, we show that in the presence of low uncertainty, centralization of data management decisions creates more total surplus for the firm as the similarity of business units increases. In contrast, in the presence of high uncertainty, centralization creates more total surplus as the dissimilarity of business units increases. The pivoting distinction trades the benefit of reduction of uncertainty from dissimilar businesses for centralization (with cost saving) against the benefit of flexibility from decentralization. Second, the framework helps senior management evaluate the trade-offs in data centralization that drive different business models of the firm. We illustrate the application of these propositions formally using an analytical model and informally using case vignettes and simulation.
|keyword = economics of IS,flexibility and information systems decentralization,real options,uncertainty,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Effects of Different Types of Free Trials and Ratings in Sampling of Consumer Software: An Empirical Study'''
{{header}}
{{article
|author= Young-Jin Lee,Yong Tan,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Giving away trial software is a common practice for software developers to maximize the exposure of their products to potential consumers and to minimize the consumers' uncertainty about software quality. There are two types of free trials: (1) freeware, which consists of very basic features of focal software without a time lock, and (2) trialware, which has the full functionality of focal software with a time lock. In this paper, we study what factors make some free-trial software attract more potential adopters than others. Our empirical model under the traditional Bass-type diffusion examines the effects of the different types of free-trial software and ratings on consumer software sampling and reveals the dynamics of sampling over time. Using free-trial software downloading data on Download.com, we observe that the consumer software sampling process can be described by the theory of information diffusion. We find that user ratings affect sampling performance positively and that third-party ratings need to be positive to be effective. Finally, our results do not show any discernible differences between freeware and trialware with regard to their impact on sampling performance. This study contributes to the understanding of software free-trial practice from the perspective of consumer sampling growth of different types of free trials. Our findings can help design free-trial strategies to extrapolate the extent of consumer awareness of focal software and effectively convey its quality information to potential customers.
|keyword = freeware,Hausman-Taylor estimation,information diffusion,online user and third-party ratings,software commercialization,software free trials,software sampling,trialware,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Integrating Biosignals into Information Systems: A NeuroIS Tool for Improving Emotion Regulation'''
{{header}}
{{article
|author= Philip J. Astor,Marc T. P. Adam,Petar Jercic,Kristina Schaaff,Christof Weinhardt,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Traders and investors are aware that emotional processes can have material consequences on their financial decision performance. However, typical learning approaches for debiasing fail to overcome emotionally driven financial dispositions, mostly because of subjects' limited capacity for self-monitoring. Our research aims at improving decision makers' performance by (1) boosting their awareness to their emotional state and (2) improving their skills for effective emotion regulation. To that end, we designed and implemented a serious game-based NeuroIS tool that continuously displays the player's individual emotional state, via biofeedback, and adapts the difficulty of the decision environment to this emotional state. The design artifact was then evaluated in two laboratory experiments. Taken together, our study demonstrates how information systems design science research can contribute to improving financial decision making by integrating physiological data into information technology artifacts. Moreover, we provide specific design guidelines for how biofeedback can be integrated into information systems.
|keyword = biofeedback,design science,decision-making processes,emotion regulation,financial decision making,IT artifacts,NeuroIS,serious games,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Impact of Prior Reviews on the Subsequent Review Process in Reputation Systems'''
{{header}}
{{article
|author= Xiao (Sean) Ma,Lara Khansa,Yun Deng,Sung S. Kim,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Reputation systems have been recognized as successful online review communities and word-of-mouth channels. Our study draws upon the elaboration likelihood model to analyze the extent that the characteristics of reviewers and their early reviews reduce or worsen the bias of subsequent online reviews. Investigating the sources of this bias and ways to mitigate it is of considerable importance given the previously established significant impact of online reviews on consumers' purchasing decisions and on businesses' profitability. Based on a panel data set of 744 individual consumers collected from Yelp, we used the Markov chain Monte Carlo simulation method to develop and empirically test a system of simultaneous models of consumer review behavior. Our results reveal that male reviewers or those who lack experience, geographic mobility, or social connectedness are more prone to being influenced by prior reviews. We also found that longer and more frequent reviews can reduce online reviews' biases. This paper is among the first to examine the moderating effects of reviewer and review characteristics on the relationship between prior reviews and subsequent reviews. Practically, this study offers businesses effective customer relationship management strategies to improve their reputations and expand their clientele.
|keyword = consumer review,elaboration likelihood model,hierarchical modeling,MCMC simulation,reputation systems,simultaneous equations model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Comprehension and Assessment of Product Reviews: A Review-Product Congruity Proposition'''
{{header}}
{{article
|author= Liqiang Huang,Chuan-Hoo Tan,Weiling Ke,Kwok-Kee Wei,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = This work anchors on the theories of cognitive fit and schema congruity to advance a review-product congruity proposition. The proposition states that the effects of product review content (either attribute or experience based) on the product review comprehension (reflected by perceived cognitive effort and review comprehension time) and assessment (manifested by perceived review helpfulness) of a consumer are contingent on the assessed product type (either search or experience product). The results of our first experiment support the proposition by revealing that the two matching conditions, (1) attribute-based reviews describing a search product and (2) experience-based reviews describing an experience product, could lead consumers to perceive higher review helpfulness and lower cognitive effort (subjective measure) to comprehend the reviews. However, the subjective evaluation of cognitive effort is not reinforced by the resulting review comprehension time (an objective assessment of comprehension effort), which suggests that consumers spend significantly more time processing reviews in the presence of the two matching conditions. A second experiment was conducted using the think-aloud method to gain further insights into the effects. We found that under the review-product matching conditions, consumers engage in deeper-level comprehension and expend more time in comprehension without realizing it, compared to consumers under the mismatching conditions. This research extends our current understanding of how review content and product reviews jointly influence the comprehension and assessment behavior of the consumer, and provides guidelines on the identification and the presentation of reviews to facilitate the judgment and decision making of potential consumers.
|keyword = cognitive fit,product reviews,review assessment,review comprehension,schema congruity,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EVALUATING JOURNAL QUALITY AND THE ASSOCIATION FOR INFORMATION SYSTEMS SENIOR SCHOLARS' JOURNAL BASKET VIA BIBLIOMETRIC MEASURES: DO EXPERT JOURNAL ASSESSMENTS ADD VALUE?'''
{{header}}
{{article
|author= Paul Benjamin Lowry,Gregory D. Moody,James Gaskin,Dennis F. Galletta,Sean L. Humpherys,Jordan B. Barlow,David W. Wilson,
|source= MIS QUARTERLY
|year= 2013
|abstract = Information systems journal rankings and ratings help scholars focus their publishing efforts and are widely used surrogates for judging the quality of research. Over the years, numerous approaches have been used to rank IS journals, approaches such as citation metrics, school lists, acceptance rates, and expert assessments. However, the results of these approaches often conflict due to a host of validity concerns. In the current scientometric study, we make significant strides toward correcting for these limitations in the ranking of mainstream IS journals. We compare expert rankings to bibliometric measures such as the ISI Impact Factor T, the h-index, and social network analysis metrics. Among other findings, we conclude that bibliometric measures provide very similar results to expert-based methods in determining a tiered structure of IS journals, thereby suggesting that bibliometrics can be a complete, less expensive, and more efficient substitute for expert assessment. We also find strong support for seven of the eight journals in the Association for Information Systems Senior Scholars' "basket" of journals. A cluster analysis of our results indicates a two-tiered separation in the quality of the highest quality IS journals-with MIS Quarterly, Information Systems Research, and Journal of Management Information Systems belonging, in that order, to the highest A+ tier. Journal quality metrics fit nicely into the sociology of science literature and can be useful in models that attempt to explain how knowledge disseminates through scientific communities.
|keyword = Information systems journal rankings,scientometrics,bibliometrics,journal quality,SenS-6,SenS-8,self-citation,impact factor,h-index,social network analysis,expert opinion,composite ranking or rating,AIS Senior Scholars basket of journals,nomologies for dissemination of scientific knowledge,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A LONGITUDINAL STUDY OF HERD BEHAVIOR IN THE ADOPTION AND CONTINUED USE OF TECHNOLOGY'''
{{header}}
{{article
|author= Heshan Sun,
|source= MIS QUARTERLY
|year= 2013
|abstract = Herd literature suggests that people tend to discount their own beliefs and imitate others when making adoption decisions and that the resulting adoption decisions are fragile and can be easily reversed during the post-adoptive stage. This helps explain why the adoption of a number of new technologies. from Amazon's Kindle, to Apple's iPod, iPhone, and iPad, to various types of Web 2. 0 technologies. appears to have adoption patterns similar to those of new fashion trends (i. e., an initial en masse acquisition followed by subsequent abandonment). It is important to understand these phenomena because they are strongly related to the staying power of technology. From a herd behavior perspective, this study proposes two new concepts, namely discounting one's own information and imitating others, to describe herd behavior in technology adoption. A research model is developed to describe the conditions under which herd behavior in technology adoption occurs, how it impacts technology adoption decision making, and how it influences post-adoptive system use. A longitudinal study is conducted to examine the research model. Findings from this research suggest that the discounting of one's own beliefs and the imitating of others when adopting a new technology are provoked primarily by the observation of prior adoptions and perceptions of uncertainty regarding the adoption of new technology. Herd behavior has a significant influence on user technology adoption; however, it does not necessarily lead to the collapse of the user base, as predicted in the herd literature. Instead, imitation can help reduce post-adoption regret and thus serve as a legitimate strategy for choosing a good enough technology, which may or may not be the best option to enhance job performance. People tend to adjust their beliefs when herding and also to revive their discounted initial beliefs to modify their beliefs about the technology at the post-adoptive stage. Findings from this study have significant research and practical implications.
|keyword = Herd behavior,imitating,technology adoption and continued use,longitudinal study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IMPACT OF WIKIPEDIA ON MARKET INFORMATION ENVIRONMENT: EVIDENCE ON MANAGEMENT DISCLOSURE AND INVESTOR REACTION'''
{{header}}
{{article
|author= Sean Xin Xu,Xiaoquan (Michael) Zhang,
|source= MIS QUARTERLY
|year= 2013
|abstract = In this paper, we seek to determine whether a typical social media platform, Wikipedia, improves the information environment for investors in the financial market. Our theoretical lens leads us to expect that information aggregation about public companies on Wikipedia may influence how management's voluntary information disclosure reacts to market uncertainty with respect to investors' information about these companies. Our empirical analysis is based on a unique data set collected from financial records, management disclosure records, news article coverage, and a Wikipedia modification history of public companies. On the supply side of information, we find that information aggregation on Wikipedia can moderate the timing of managers' voluntary disclosure of companies' earnings disappointments, or bad news. On the demand side of information, we find that Wikipedia's information aggregation moderates investors' negative reaction to bad news. Taken together, these findings support the view that Wikipedia improves the information environment in the financial market and underscore the value of information aggregation through the use of information technology.
|keyword = Social media,Wikipedia,information environment,financial market,management disclosure,information aggregation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TALKING ABOUT TECHNOLOGY: THE EMERGENCE OF A NEW ACTOR CATEGORY THROUGH NEW MEDIA'''
{{header}}
{{article
|author= Emmanuelle Vaast,Elizabeth J. Davidson,Thomas Mattson,
|source= MIS QUARTERLY
|year= 2013
|abstract = This paper examines how a new actor category may emerge in a field of discourse through the new media of the Internet. Existing literatures on professional and organizational identity have shown the importance of identity claims and of the tensions surrounding "optimal distinctiveness" for new actors in a field, but have not examined the roles of new media in these processes. The literature on information technology (IT) and identity has highlighted the identity-challenging and identity-enhancing aspects of new IT use for existing actor categories but has not examined the dynamics associated with the emergence of new actor categories. Here, we investigate how a new actor category may emerge through the use of new media as a dynamic interaction of discursive practices, identity claims, and new media use. Drawing on findings from a case study of technology bloggers, we identified discursive practices through which a group of technology bloggers enacted claims of a distinctive identity in the joint construction of their discourse and in response to continuous developments in new media. Emergence of this new category was characterized by ongoing, opposing yet coexisting tendencies toward coalescence, fragmentation, and dispersion. Socio-technical dynamics underlying bloggers' use of new media and the actions of prominent ("A-list") bloggers contributed to these tendencies. We untangle theoretically the identity-enabling and identity-unsettling effects of new media and conceptualize the emergence of a new actor category through new media as an ongoing process in which the category identity may remain fluid, rather than progress to an endpoint.
|keyword = Web 2.0,discursive practices,identity,legitimacy,blogging,socio-technical dynamics,A-listers,coalescence,dispersion,fragmentation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DIFFERENTIAL INFLUENCE OF BLOGS ACROSS DIFFERENT STAGES OF DECISION MAKING: THE CASE OF VENTURE CAPITALISTS'''
{{header}}
{{article
|author= Rohit Aggarwal,Harpreet Singh,
|source= MIS QUARTERLY
|year= 2013
|abstract = In this paper, we study the differential influence of online user-generated content (UGC), specifically blogs, across the multiple stages of decision making of venture capitalists: screening stage, choice stage, and contract stage. We conjecture that, first, blogs are influential at the screening stage; second, after the screening stage, blogs are noninfluential since decision makers evaluate entities closely at later stages; third, blogs increase the interest from multiple decision makers which in turn increases the cost of the deal for a decision maker. This empirical investigation provides support for the hypotheses, which we tested for funding decisions by venture capitalists in information technology ventures. In particular, this study indicates that blogs can help managers in getting their products/services selected at the screening stage, but, beyond that, blogs do not help directly. However, since more decision makers screen products/services that receive blog coverage, the competition among decision makers helps managers in negotiating better contract terms. We advance the boundary of existing studies on the influence of UGC from single stage process to multiple stages.
|keyword = UGC,WOM,Blogs,IT ventures,VC funding,venture capital,econometric analysis,multistage decision making,screening stage,choice stage,contract stage,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CHANGES IN EMPLOYEES' JOB CHARACTERISTICS DURING AN ENTERPRISE SYSTEM IMPLEMENTATION: A LATENT GROWTH MODELING PERSPECTIVE'''
{{header}}
{{article
|author= Hillol Bala,Viswanath Venkatesh,
|source= MIS QUARTERLY
|year= 2013
|abstract = Enterprise system implementations often create tension in organizations. On the one hand, these systems can provide significant operational and strategic benefits. On the other hand, implementation of these systems is risky and a source of major disruptions. In particular, employees experience significant changes in their work environment during an implementation. Although the relationship between ES implementations and employees' jobs has been noted in prior research, there is limited research on the nature, extent, determinants, and outcomes of changes in employees' job characteristics following an ES implementation. This paper develops and tests a model, termed the job characteristics change model (JCCM), that posits that employees will experience substantial changes in two job characteristics (i.e., job demands and job control) during the shakedown phase (i.e., immediately after the rollout) of an ES implementation. These changes are theorized to be predicted by work process characteristics, namely perceived process complexity, perceived process rigidity, and perceived process radicalness, that in turn will be influenced by technology characteristics (i.e., perceived technology complexity, perceived technology reconfigurability, and perceived technology customization). JCCM further posits that changes in job characteristics will influence employees' job satisfaction. Longitudinal field studies conducted in two organizations (N = 281 and 141 respectively) provided support for the model. The scientific and practical implications of the findings are discussed.
|keyword = Enterprise systems,business process,work process,job characteristics,job demands,job control,job satisfaction,latent growth modeling,process characteristics,technology characteristics,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ADDRESSING THE PERSONALIZATION-PRIVACY PARADOX: AN EMPIRICAL ASSESSMENT FROM A FIELD EXPERIMENT ON SMARTPHONE USERS'''
{{header}}
{{article
|author= Juliana Sutanto,Elia Palme,Chuan-Hoo Tan,Chee Wei Phang,
|source= MIS QUARTERLY
|year= 2013
|abstract = Privacy has been an enduring concern associated with commercial information technology ( IT) applications, in particular regarding the issue of personalization. IT-enabled personalization, while potentially making the user computing experience more gratifying, often relies heavily on the user's personal information to deliver individualized services, which raises the user's privacy concerns. We term the tension between personalization and privacy, which follows from marketers exploiting consumers' data to offer personalized product information, the personalization-privacy paradox. To better understand this paradox, we build on the theoretical lenses of uses and gratification theory and information boundary theory to conceptualize the extent to which privacy impacts the process and content gratifications derived from personalization, and how an IT solution can be designed to alleviate privacy concerns. Set in the context of personalized advertising applications for smartphones, we propose and prototype an IT solution, referred to as a personalized, privacy-safe application, that retains users' information locally on their smartphones while still providing them with personalized product messages. We validated this solution through a field experiment by benchmarking it against two more conventional applications: a base non-personalized application that broadcasts non-personalized product information to users, and a personalized, non-privacy safe application that transmits user information to a central marketer's server. The results show that (compared to the non-personalized application), while personalized, privacy-safe or not increased application usage (reflecting process gratification), it was only when it was privacy-safe that users saved product messages (reflecting content gratification) more frequently. Follow-up surveys corroborated these nuanced findings and further revealed the users' psychological states, which explained our field experiment results. We found that saving advertisements for content gratification led to a perceived intrusion of information boundary that made users reluctant to do so. Overall our proposed IT solution, which delivers a personalized service but avoids transmitting users' personal information to third parties, reduces users' perceptions that their information boundaries are being intruded upon, thus mitigating the personalization-privacy paradox and increasing both process and content gratification.
|keyword = Personalization-privacy paradox,mobile advertising applications,uses and gratification,information boundary theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''AN INVESTIGATION OF INFORMATION SYSTEMS USE PATTERNS: TECHNOLOGICAL EVENTS AS TRIGGERS, THE EFFECT OF TIME, AND CONSEQUENCES FOR PERFORMANCE'''
{{header}}
{{article
|author= Ana Ortiz de Guinea,Jane Webster,
|source= MIS QUARTERLY
|year= 2013
|abstract = Information systems use represents one of the core concepts defining the discipline. In this article, we develop a rich conceptualization of IS use patterns as individuals' emotions, cognition, and behaviors while employing an information technology to accomplish a work-related task. By combining two novel perspectives-the affect-object paradigm and automaticity-with coping theory, we theorize how different patterns appear and disappear as a result of different IT events-expected and discrepant-as well as over time, and how these patterns influence short-term performance. In order to test our hypotheses, we conducted two studies, one qualitative and the other quantitative, that combined different methods (e. g., open-ended questions, physiological data, videos, protocol analysis) to study the influence of expected and discrepant events. The synergistic properties of the two studies demonstrate the existence of two IS use patterns, automatic and adjusting. Most interactions are automatic, and adjusting patterns, triggered by discrepant IT events, fade over time and transition into automatic ones. Further, automatic patterns result in enhanced short-term performance, while adjusting ones do not. Our conceptualization of IS use patterns is useful because it addresses important questions (such as why negative IT perceptions persist) and clarifies that it is how (rather than how much) people use IT that is pertinent for performance.
|keyword = Emotion,affect,behavior,cognition,performance,pattern,IS use,usage,heart rate,EKG,physiology,physiological arousal,automaticity,continuance,technological effects,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INSIDERS' PROTECTION OF ORGANIZATIONAL INFORMATION ASSETS: DEVELOPMENT OF A SYSTEMATICS-BASED TAXONOMY AND THEORY OF DIVERSITY FOR PROTECTION-MOTIVATED BEHAVIORS'''
{{header}}
{{article
|author= Clay Posey,Tom L. Roberts,Paul Benjamin Lowry,Rebecca J. Bennett,James F. Courtney,
|source= MIS QUARTERLY
|year= 2013
|abstract = Protecting information from a variety of security threats is a daunting organizational activity. Organization managers must recognize the roles that organization insiders have in protecting information resources rather than solely relying upon technology to provide this protection. Unfortunately, compared to negative insider behaviors, the extant literature provides sparse coverage of beneficial insider activities. The few beneficial activities in the literature represent only a small portion of the diverse collection of insiders' protective actions. This research focuses on protection-motivated behaviors (PMBs), which are volitional behaviors enacted by organization insiders to protect (1) organizationally relevant information and (2) the computer-based information systems in which the information is stored, collected, disseminated, and/or manipulated from information security threats. Based on systematics, we propose a six-step methodology of qualitative and quantitative approaches to develop a taxonomy and theory of diversity for PMBs. These approaches integrate the classification techniques of multidimensional scaling (MDS), property fitting (ProFit), and cluster analyses. We leverage these techniques to identify and display how insiders collectively classify 67 unique PMBs and their homogeneous classes. Our taxonomy provides researchers and practitioners a comprehensive guide and common nomenclature for PMBs. Our methodology can be similarly used to create other theories of diversity.
|keyword = Protection-motivated behaviors,behavioral information security,systematics,theory of diversity,multidimensional scaling,cluster analysis,taxonomy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CONTROL BALANCING IN INFORMATION SYSTEMS DEVELOPMENT OFFSHORING PROJECTS'''
{{header}}
{{article
|author= Robert Wayne Gregory,Roman Beck,Mark Keil,
|source= MIS QUARTERLY
|year= 2013
|abstract = While much is known about selecting different types of control that can be exercised in information systems development projects, the control dynamics associated with ISD offshoring projects represent an important gap in our understanding. In this paper, we develop a substantive grounded theory of control balancing that addresses this theoretical gap. Based on a longitudinal case study of an ISD offshoring project in the financial services industry, we introduce a three-dimensional control configuration category that emerged from our data, suggesting that control type is only one dimension on which control configuration decisions need to be made. The other two dimensions that we identified are control degree (tight versus relaxed) and control style (unilateral versus bilateral). Furthermore, we illustrate that control execution during the life cycle of an ISD offshoring project is highly intertwined with the development of client-vendor shared understanding and that each influences the other. Based on these findings, we develop an integrative process model that explains how offshoring project managers make adjustments to the control configuration periodically to allow the ISD offshoring project and relationship to progress, yielding the iterative use of different three-dimensional control configurations that we conceptualize in the paper. Our process model of control balancing may trigger new ways of looking at control phenomena in temporary interfirm organizations such as client-vendor ISD offshoring projects. Implications for research on organizational control and ISD offshoring are discussed. In addition, guidelines for ISD offshoring practitioners are presented.
|keyword = Control balancing,control dynamics,organizational control,information systems development,offshoring projects,outsourcing relationships,longitudinal case study,grounded theory,process model,project management,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''MEDIA SELECTION AS A STRATEGIC COMPONENT OF COMMUNICATION'''
{{header}}
{{article
|author= Joey F. George,John R. Carlson,Joseph S. Valacich,
|source= MIS QUARTERLY
|year= 2013
|abstract = Why do people select the media they choose for a particular type of communication? The media choice literature has considered myriad contextual factors that influence media choice, from proximity of the communication partners, to the urgency of the situation, to time pressure, and so on. From this body of work, a contingency-based theory of media choice has emerged. An alternative approach is to investigate how communication strategies and media characteristics affect choice. We identified two approaches for investigating these issues: Te'eni's (2001) model of organizational communication and Dennis et al.'s (2008) media synchronicity theory. Using a scenario-based methodology, we asked respondents which medium they would use for a deceptive communication task and why they made that choice. We analyzed the data from the perspective of both the Te'eni and MST frameworks, enabling us to compare the extent to which each was able to explain our respondents' media choices. Both frameworks, at differing levels of communication granularity, suggest that the intent of the communication drives a strategy that ultimately informs media choice. The results suggest that the prior contingency-based explanations of media choice could be improved by not only understanding the intent of the communication, but also the strategy used by an individual to execute this communication. Additionally, we found that the more finely grained view of communication contained in MST explained more of the outcomes and was more parsimonious as well.
|keyword = Computer-mediated communication,deceptive communication,media synchronicity theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFERRING APP DEMAND FROM PUBLICLY AVAILABLE DATA'''
{{header}}
{{article
|author= Rajiv Garg,Rahul Telang,
|source= MIS QUARTERLY
|year= 2013
|abstract = With an abundance of products available online, many online retailers provide sales rankings to make it easier for consumers to find the best-selling products. Successfully implementing product rankings online was done a decade ago by Amazon, and more recently by Apple's App Store. However, neither market provides actual download data, a very useful statistic for both practitioners and researchers. In the past, researchers developed various strategies that allowed them to infer demand from rank data. Almost all of that work is based on an experiment that shifts sales or collaboration with a vendor to get actual sales data. In this research, we present an innovative method to use public data to infer the rank-demand relationship for the paid apps on Apple's iTunes App Store. We find that the top-ranked paid app for iPhone generates 150 times more downloads compared to the paid app ranked at 200. Similarly, the top paid app on iPad generates 120 times more downloads compared to the paid app ranked at 200. We conclude with a discussion on an extension of this framework to the Android platform, in-app purchases, and free apps.
|keyword = Mobile apps,app store,sales-rank calibration,app downloads,pareto distribution,Android,Apple iTunes,in-app purchase,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''SENSEMAKING AND SUSTAINABLE PRACTICING: FUNCTIONAL AFFORDANCES OF INFORMATION SYSTEMS IN GREEN TRANSFORMATIONS'''
{{header}}
{{article
|author= Stefan Seidel,Jan Recker,Jan vom Brocke,
|source= MIS QUARTERLY
|year= 2013
|abstract = This paper explores how a world-wide operating software solutions provider implemented environmentally sustainable business practices in response to emerging environmental concerns. Through an interpretive case study, we develop a theoretical framework that identifies four important functional affordances originating in information systems, which are required in environmental sustainability transformations as they create an actionable context in which (1) organizations can engage in a sensemaking process related to understanding emerging environmental requirements, and (2) individuals can implement environmentally sustainable work practices. Through our work, we provide several contributions, including a better understanding of IS-enabled organizational change and the types of functional affordances of information systems that are required in sustainability transformations. We describe implications relating to (1) how information systems can contribute to the creation of environmentally sustainable organizations, (2) the design of information systems to create required functional affordances, (3) the management of sustainability transformations, and (4) the further development of the concept of functional affordances in IS research.
|keyword = Green IS,environmental sustainability,business transformation,case study,socio-technical systems theory,functional affordances,sensemaking,sustainable practicing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''ASSESSING THE EFFECTS OF BENEFITS AND INSTITUTIONAL INFLUENCES ON THE CONTINUED USE OF ENVIRONMENTALLY MUNIFICENT BYPASS SYSTEMS IN LONG-HAUL TRUCKING'''
{{header}}
{{article
|author= Kent Marett,Robert F. Otondo,G. Stephen Taylor,
|source= MIS QUARTERLY
|year= 2013
|abstract = Commercial truck driving is an essential part of the national supply chain but one that adversely affects the environment. The purpose of this study is to determine the influence of the potential environmental benefits, among other factors, on continued use of bypass systems that can be discontinued at any time by a driver. The results from our study show that (1) economic benefits and industry pressures positively influence drivers' use of bypass systems but (2) the environmental benefits of the technology do not, even though system vendors and state transportation agencies emphasize these benefits of the technology. Based on these findings, we conclude that sustainable information systems can be a viable option in a business context if usage leads to economic benefits. Our results and conclusions support the U. S. Environmental Protection Agency's differentiation of public policy versus business perspectives on sustainable technology.
|keyword = Sustainable information systems,energy informatics,commercial trucking,intelligent transportation systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''MOTIVATING ENERGY-EFFICIENT BEHAVIOR WITH GREEN IS: AN INVESTIGATION OF GOAL SETTING AND THE ROLE OF DEFAULTS'''
{{header}}
{{article
|author= Claire-Michelle Loock,Thorsten Staake,Frederic Thiesse,
|source= MIS QUARTERLY
|year= 2013
|abstract = This study investigates the role of information systems in stimulating energy-efficient behavior in private households. We present the example of Velix, a web portal designed to motivate customers of a utility company to reduce their electricity consumption. In particular, we consider the effectiveness of goal setting functionality and defaults in influencing energy conservation behavior. For this purpose, we use the web portal as a test of the theoretical propositions underlying its design. Based on data collected from a field experiment with 1,791 electricity consumers, we test hypotheses regarding the structural relations between defaults and goals, the impact of defaults and goals on consumption behavior, and the moderating role of feedback on goal choice. Our results confirm the positive impact of goal setting on energy conservation. We show that default goals lead to statistically significant savings by affecting goal choice. However, if the default goals are set too low or too high with respect to a self-set goal, the defaults will detrimentally affect behavior. We also show that feedback on goal attainment moderates the effect of default goals on goal choice. The results extend the knowledge on goal setting and defaults and have implications for the design of effective energy feedback systems. The study's approach, which combines hypothesis-driven work and design-oriented IS research, could serve as a blueprint for further research endeavors of this kind, particularly with regard to feedback systems based on future smart metering infrastructures.
|keyword = Green IS,energy conservation,consumption feedback,goal setting,defaults,field experiment,design research,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Too Big to Fail: Large Samples and the p-Value Problem'''
{{header}}
{{article
|author= Mingfeng Lin,Jr. Henry C. Lucas,Galit Shmueli,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = The Internet has provided IS researchers with the opportunity to conduct studies with extremely large samples, frequently well over 10,000 observations. There are many advantages to large samples, but researchers using statistical inference must be aware of the p-value problem associated with them. In very large samples, p-values go quickly to zero, and solely relying on p-values can lead the researcher to claim support for results of no practical significance. In a survey of large sample IS research, we found that a significant number of papers rely on a low p-value and the sign of a regression coefficient alone to support their hypotheses. This research commentary recommends a series of actions the researcher can take to mitigate the p-value problem in large samples and illustrates them with an example of over 300,000 camera sales on eBay. We believe that addressing the p-value problem will increase the credibility of large sample IS research as well as provide more insights for readers.
|keyword = empirical modeling,practical significance,effect size,p-value,statistical significance,inference,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Blunting Damocles' Sword: A Longitudinal Model of Healthcare IT Impact on Malpractice Insurance Premium and Quality of Patient Care'''
{{header}}
{{article
|author= Nirup M. Menon,Rajiv Kohli,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Prior studies on the business value of information technology (IT) mainly focus on the impact of IT investments on productivity and firm profitability. Few have considered its implication on expected and actual product or service quality. This paper fills this gap by investigating the impact of past healthcare IT (HIT) expenditure on the malpractice insurance premium (MIP) and the moderating effect of past HIT expenditure on the relationship between past MIP and current quality of patient care in a longitudinal model. Based on archival panel data on costs, operations, and patient care outcomes of 66 hospitals in the U. S. state of Washington from 1998 to 2007, we find that past HIT expenditure is negatively associated with MIP, supporting our argument that HIT provides value that is anticipated by insurers and is captured by a change in MIP. We find that past HIT is positively associated with quality of patient care. We also find that past MIP is positively associated with quality of patient care, supporting the premise that hospitals respond to MIP by making risk mitigation efforts. However, we find that past HIT moderates this relationship negatively, suggesting a reliance on HIT at the expense of risk mitigation.
|keyword = business value of IT,organizational risk,hospital,dynamic panel model,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''From Knowing It to "Getting It": Envisioning Practices in Computer Games Development'''
{{header}}
{{article
|author= Joe Nandhakumar,Nikiforos S. Panourgias,Harry Scarbrough,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = The development of information systems and software applications increasingly needs to deliver culturally rich and affective experiences for user groups. In this paper, we explore how the collaborative practices across different expert groups can enable this experiential dimension of use to be integrated into the development of a software product. In an empirical study of computer games development-an arena in which the novelty and richness of the user experience is central to competitive success-we identify the challenges of conceptualizing and realizing a desired user experience when it cannot be readily specified in an initial design template, nor represented within the expertise of existing groups. Our study develops a theoretical framework to address these challenges. Through this framework, we are able to show how achieving a desired user experience requires developer groups to not only work across the boundaries that arise from specialized expertise, but also across wider fields centred on cultural production and software development, respectively. We find that their ability to do this is supported by distinctive "envisioning practices" that sustain an emerging shared "vision" for each game. The key research contributions that we then make are (a) grounding envisioning practices as a means of theorizing the collaborative practices centred on conceptualizing the user experience; (b) identifying how these practices are interwoven with the "producing practices" of software development, thus enabling collaboration to span expert groups and disparate fields; and (c) theorizing the role of vision as an emerging conceptual boundary object in these practices.
|keyword = collaborative practice,envizioning,interpretive,computer games development,emergence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Do Recommender Systems Manipulate Consumer Preferences? A Study of Anchoring Effects'''
{{header}}
{{article
|author= Gediminas Adomavicius,Jesse C. Bockstedt,Shawn P. Curley,Jingjing Zhang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Recommender systems are becoming a salient part of many e-commerce websites. Much research has focused on advancing recommendation technologies to improve accuracy of predictions, although behavioral aspects of using recommender systems are often overlooked. In our studies, we explore how consumer preferences at the time of consumption are impacted by predictions generated by recommender systems. We conducted three controlled laboratory experiments to explore the effects of system recommendations on preferences. Studies 1 and 2 investigated user preferences for television programs across a variety of conditions, which were surveyed immediately following program viewing. Study 3 investigated the granularity of the observed effects within individual participants. Results provide strong evidence that the rating presented by a recommender system serves as an anchor for the consumer's constructed preference. Viewers' preference ratings are malleable and can be significantly influenced by the recommendation received. The effect is sensitive to the perceived reliability of a recommender system and, thus, not a purely numerical or priming-based effect. Finally, the effect of anchoring is continuous and linear, operating over a range of perturbations of the system. These general findings have a number of important implications (e.g., on recommender systems performance metrics and design, preference bias, potential strategic behavior, and trust), which are discussed.
|keyword = anchoring effects,behavioral decision making,behavioral economics,electronic commerce,experimental research,preferences,recommender systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Technology Competencies, Organizational Agility, and Firm Performance: Enabling and Facilitating Roles'''
{{header}}
{{article
|author= Anindita Chakravarty,Rajdeep Grewal,V. Sambamurthy,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = The hypercompetitive aspects of modern business environments have drawn organizational attention toward agility as a strategic capability. Information technologies are expected to be an important competency in the development of organizational agility. This research proposes two distinct roles to understand how information technology competencies shape organizational agility and firm performance. In their enabling role, IT competencies are expected to directly enhance entrepreneurial and adaptive organizational agility. In their facilitating role, IT competencies should enhance firm performance by helping the implementation of requisite entrepreneurial and adaptive actions. Furthermore, we argue that the effects of the dual roles of IT competencies are moderated by multiple contingencies arising from environmental dynamism and other sources. We test our model and hypotheses through a latent class regression analysis on data from a sample of 109 business-to-business electronic marketplaces. The results provide support for the enabling and facilitating roles of IT competencies. Moreover, we find that these dual effects vary according to environmental dynamism. The results suggest that managers should account for (multiple) contingencies (observed and unobserved) while assessing the effects of IT competencies on organizational agility and firm performance.
|keyword = organizational agility,IT competencies,latent class regression,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Product-Oriented Web Technologies and Product Returns: An Exploratory Study'''
{{header}}
{{article
|author= Prabuddha De,Yu (Jeffrey) Hu,Mohammad S. Rahman,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Internet retailers have been making significant investments in Web technologies, such as zoom, alternative photos, and color swatch, that are capable of providing detailed product-oriented information and, thereby, mitigating the lack of "touch and feel," which, in turn, is expected to lower product returns. However, a clear understanding of the relationship between these technologies and product returns is still lacking. Our study attempts to fill this gap by using several econometric models to explore the said relationship. Our unique and rich data set from a women's clothing company allows us to measure technology usage at the product level for each consumer. The results show that, in this context, zoom usage has a negative coefficient, suggesting that a higher use of the zoom technology is associated with fewer returns. Interestingly, we find that a higher use of alternative photos is associated with more returns and, perhaps more importantly, with lower net sales. Color swatch, on the other hand, does not seem to have any effect on returns. Thus, our findings show that different technologies have different effects on product returns. We provide explanations for these findings based on the extant literature. We also conduct a number of tests to ensure the robustness of the results.
|keyword = online shopping,product returns,type of information,product-oriented technologies,econometric models,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Real Options Model for Generalized Meta-Staged Projects-Valuing the Migration to SOA'''
{{header}}
{{article
|author= Suvankar Ghosh,Xiaolin Li,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = This paper develops an innovative real options (RO) model for valuing multistage information technology (IT) projects that can be viewed as comprising meta stages. In RO literature, multistage investment programs have been treated as either interproject or intraproject programs, with intraproject programs being evaluated using n-fold Geske compound options and interproject programs valued using the so-called "subsidy-to-exercise price" logic. Our innovative RO model integrates the Geske compound option model with the subsidy-to-exercise price approach to value sequential investment programs that are neither purely interproject nor purely intraproject in nature but are composed of meta-stages. A meta-stage as a whole can be considered an interproject stage resulting in cash flows, but internally it consists of several intraproject stages that do not result in cash flows. We show that a key problem in IT, which is migrating to a Service-Oriented Architecture (SOA) for integrating a firm's many disparate applications, systems, data, and business processes, is best viewed as an investment program comprising meta-stages. Examining SOA migration from an RO lens is particularly apt at this time not only because of the importance of SOA but also because doubts have surfaced about the value of SOA. We illustrate our RO model by applying it to the simulated case of a firm migrating to SOA. We also develop a software tool based on the Mathematica T computational platform so that practitioners can easily apply our innovative options pricing model to determine the true value of SOA in their business contexts.
|keyword = business value of IT,real options,economics of IS,service-oriented architecture (SOA),enterprise systems,analytical modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Outsourcing Contracts and Equity Prices'''
{{header}}
{{article
|author= Deepa Mani,Anitesh Barua,Andrew B. Whinston,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = We investigate the impact of outsourcing on the long-term market performance of the firm. Outsourcing initiatives vary in terms of uncertainty in business requirements, complexity of coordination between the outsourcing firm and provider, and the consequent choice of the governing contract (fixed or variable price). Using theories from institutional economics, strategy, and information systems, we argue that firms pursuing large-scale, fixed price outsourcing, which are characterized by lower business uncertainty and simpler coordination requirements, will realize higher market returns relative to similar firms in the same industry who did not outsource. In contrast, variable price contracts that proxy for higher business uncertainty and coordination complexity may have a higher risk of failure and loss of shareholder value; however, prior outsourcing experience and prior association with the vendor may reduce uncertainty in the outsourcing relationship to help the outsourcing firm better manage challenges associated with complex, variable price engagements. We posit that financial markets are either not privy to or unlikely to accurately interpret such intangible information on the antecedents of outsourcing success during the announcement period. The delay in incorporation of this information in market prices results in positive long-term abnormal returns to fixed price contracts. Variable price contracts characterized by prior association between participant firms and greater outsourcing experience also realize positive long-term abnormal returns. Data on the hundred largest outsourcing initiatives implemented between 1996 and 2005 strongly support our hypotheses. The results imply that firms who retain simple functions and tasks in-house as well as those who outsource complex functions without pertinent experience or association with the vendor experience significant loss of shareholder value.
|keyword = stock return,event study,business value of IT,outsourcing,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Valuation and Confirmation Bias in Virtual Communities: Evidence from Stock Message Boards'''
{{header}}
{{article
|author= JaeHong Park,Prabhudev Konana,Bin Gu,Alok Kumar,Rajagopal Raghunathan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Virtual communities continue to play a greater role in social, political, and economic interactions. However, how users value information from these communities and how that affects their behavior and future expectations is not fully understood. Stock message boards provide an excellent setting to analyze these issues given the large user base and market uncertainty. Using data from 502 investor responses from a field experiment on one of the largest message board operators in South Korea, our analyses revealed that investors exhibit confirmation bias, whereby they preferentially treat messages that support their prior beliefs. This behavior is more pronounced for investors with higher perceived knowledge about the market and higher strength of belief (i.e., sentiment) toward a particular stock. We also find a negative interaction effect between the perceived knowledge and the strength of prior belief on confirmation bias. Those exhibiting confirmation bias are also more overconfident; as a result, they trade more actively and expect higher market returns than is warranted. Collectively, these results suggest that participation in virtual communities may not necessarily lead to superior financial returns.
|keyword = confirmation bias,overconfidence,investment decisions,virtual communities,stock message boards,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Licensing and Competition for Services in Open Source Software'''
{{header}}
{{article
|author= Terrence August,Hyoduk Shin,Tunay I. Tunca,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Open source software is becoming increasingly prominent, and the economic structure of open-source development is changing. In recent years, firms motivated by revenues from software services markets have become the primary contributors to open-source development. In this paper we study the role of services in open source software development and explore the choice between open source and proprietary software. Specifically, our economic model jointly analyzes the investment and pricing decisions of the originators of software and of subsequent open-source contributors. We find that if a contributor is efficient in software development, the originator should adopt an open-source strategy, allowing the contributor to offer higher total quality and capture the higher end of the market while the originator focuses on providing software services to lower end consumers. Conversely, if the contributor is not efficient in development, the originator should adopt a proprietary software development strategy, gaining revenue from software sales and squeezing the contributor out of the services market. In certain cases an increase in originator development efficiency can result in increased contributor profits. Finally, we find that, somewhat counterintuitively, an increase in contributor development efficiency can reduce overall social welfare.
|keyword = analytical modeling,competitive impacts of IS,economics of IS,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Dynamic View of the Impact of Network Structure on Technology Adoption: The Case of OSS Development'''
{{header}}
{{article
|author= Gang Peng,Debabrata Dey,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = We examine how network centrality and closure, two key aspects of network structure, affect technology adoption. In doing so, we consider the content of potential information flows within the network and argue that the impact of network structure on technology adoption can be better understood by separately examining its impact from two groups of alters-current and potential adopters. We contend that increased network centrality and closure among current adopters contribute positively to adoption, whereas the same among potential adopters has exactly the opposite impact. Accordingly, we propose a dynamic view where the fraction of current adopters in the network positively moderates the impact of network centrality and closure. We empirically test the theory by analyzing the adoption of software version control technology by open source software projects. Our results strongly support the theory.
|keyword = technology adoption,network structure,network centrality,network closure,dynamic view,software version control technology,open source software,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Value of Third-Party Assurance Seals in Online Retailing: An Empirical Investigation'''
{{header}}
{{article
|author= Koray Oezpolat,Guodong (Gordon) Gao,Wolfgang Jank,Siva Viswanathan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Third-party quality assurance seals have emerged as a prominent mechanism to reduce uncertainty and increase purchase conversion in online markets. However, systematic studies of the effectiveness of these seals are scarce. In this study, we exploit a unique data set of 9,098 shopping sessions at an online retailer's website to empirically measure the value and effectiveness of assurance seals on the likelihood of purchase by shoppers. The data set is collected from a randomized field experiment conducted by a large seal provider, which enables us to infer the causal impacts of the presence of an assurance seal. We find strong evidence that the presence of the assurance seal increases the likelihood of purchase conversion. We discuss the implications of our findings for online retailers, third-party certifiers, policymakers, and researchers.
|keyword = electronic commerce,online certification,online assurance seals,trust seals,information asymmetry,field experiments,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Continued Participation in Online Innovation Communities: Does Community Response Matter Equally for Everyone?'''
{{header}}
{{article
|author= Chen Zhang,Jungpil Hahn,Prabuddha De,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = In this study, we focus on the factors that influence online innovation community members' continued participation in the context of open source software development ( OSSD) communities. Prior research on continued participation in online communities has primarily focused on social interactions among members and benefits obtained from these interactions. However, members of these communities often play different roles, which have been examined extensively, albeit in a separate stream of research. This study attempts to bridge these two streams of research by investigating the joint influence of community response and members' roles on continued participation. We categorize OSSD community members into users and modifiers and empirically examine the differential effects of community response across these roles. By analyzing a longitudinal data set of activities in the discussion forums of more than 300 OSSD projects, we not only confirm the positive influence of community response on members' continued participation but also find that community response is more influential in driving the continuance behavior of users than that of modifiers. In addition, this research highlights the importance of modifiers, a key subgroup of OSSD participants that has been largely overlooked by prior research.
|keyword = online innovation communities,open source software development (OSSD),continued participation,member roles,community response,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of Intellectual Property Rights Enforcement on Open Source Software Project Success'''
{{header}}
{{article
|author= Wen Wen,Chris Forman,Stuart J. H. Graham,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = We investigate how intellectual property rights (IPR) enforcement against developers and users of open source software (OSS) affects the success of related OSS projects. We hypothesize that when an IPR enforcement action is filed, user interest and developer activity will be negatively affected in two types of related OSS projects-those that display technology overlap with the OSS application in dispute and business projects that are specific to the disputed OSS platform. We examine two widely publicized lawsuits-SCO v. IBM and FireStar/DataTern v. Red Hat-using data from SourceForge. net. Our difference-in-difference estimates show that in the months following the filing of SCO v. IBM, OSS projects that exhibit high technology overlap with the disputed OSS experienced a 15% greater decline in user interest and 45% less developer activity than projects in the control group; OSS projects that are intended for business and specific to the disputed OSS platform had a 34% greater decline in user interest and 86% less developer activity than the control group. We find similar results following the filing of FireStar/DataTern v. Red Hat. Our results are also robust to a variety of robustness checks, including a falsification exercise and subsample analyses.
|keyword = open source software (OSS),OSS success,intellectual property rights (IPR),intellectual property rights enforcement,difference-in-difference estimation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Business Value of Information Technology: Testing the Interaction Effect of IT and R&D on Tobin's Q'''
{{header}}
{{article
|author= Indranil Bardhan,Viswanathan Krishnan,Shu Lin,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = The business case for investing in information technology (IT) has received increasing scrutiny in recent years. We propose that IT investments create additional business value through interactions with other business processes. In this paper, we formalize the interaction effect of IT by focusing on one core function, namely, research and development (R&D). We hypothesize that investments in IT can interact with and complement a firm's R&D investments, enhancing the firm's shareholder value creation potential. We test this by hypothesis by estimating the interaction impact of IT and R&D investments on Tobin's q, a forward-looking measure of firm performance using a recent multiyear, firm-level, archival data set. Our results suggest that the interaction effect of R&D and IT on Tobin's q is positive and significant after controlling for other firm-and industry-specific effects. Our findings provide rigorous empirical support for recent anecdotal evidence in the managerial literature with respect to the manner in which IT is enabling R&D-intensive innovation processes. Our analysis underscores the need for coordinated investments in IT and R&D, and permeating IT capabilities throughout other business processes such as R&D.
|keyword = R&D,IT investments,innovation,firm performance,complementarity,Tobin's q,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DISCOVERING UNOBSERVED HETEROGENEITY IN STRUCTURAL EQUATION MODELS TO AVERT VALIDITY THREATS'''
{{header}}
{{article
|author= Jan-Michael Becker,Arun Rai,Christian M. Ringle,Franziska Voelckner,
|source= MIS QUARTERLY
|year= 2013
|abstract = A large proportion of information systems research is concerned with developing and testing models pertaining to complex cognition, behaviors, and outcomes of individuals, teams, organizations, and other social systems that are involved in the development, implementation, and utilization of information technology. Given the complexity of these social and behavioral phenomena, heterogeneity is likely to exist in the samples used in IS studies. While researchers now routinely address observed heterogeneity by introducing moderators, a priori groupings, and contextual factors in their research models, they have not examined how unobserved heterogeneity may affect their findings. We describe why unobserved heterogeneity threatens different types of validity and use simulations to demonstrate that unobserved heterogeneity biases parameter estimates, thereby leading to Type I and Type II errors. We also review different methods that can be used to uncover unobserved heterogeneity in structural equation models. While methods to uncover unobserved heterogeneity in covariance-based structural equation models (CB-SEM) are relatively advanced, the methods for partial least squares (PLS) path models are limited and have relied on an extension of mixture regression-finite mixture partial least squares (FIMIX-PLS) and distance measure-based methods-that have mismatches with some characteristics of PLS path modeling. We propose a new method-prediction-oriented segmentation (PLS-POS)-to overcome the limitations of FIMIX-PLS and other distance measure-based methods and conduct extensive simulations to evaluate the ability of PLS-POS and FIMIX-PLS to discover unobserved heterogeneity in both structural and measurement models. Our results show that both PLS-POS and FIMIX-PLS perform
|keyword = Unobserved heterogeneity,validity,structural equation modeling,partial least squares,formative measures,prediction-oriented segmentation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EXPLAINING EMPLOYEE JOB PERFORMANCE: THE ROLE OF ONLINE AND OFFLINE WORKPLACE COMMUNICATION NETWORKS'''
{{header}}
{{article
|author= Xiaojun Zhang,Viswanath Venkatesh,
|source= MIS QUARTERLY
|year= 2013
|abstract = By distinguishing between employees' online and offline workplace communication networks, this paper incorporates technology into social network theory to understand employees' job performance. Specifically, we conceptualize network ties as direct and indirect ties in both online and offline workplace communication networks, thus resulting in four distinct types of ties. We theorize that employees' ties in online and offline workplace communication networks are complementary resources that interact to influence their job performance. We found support for our model in a field study among 104 employees in a large telecommunication company. The paper concludes with theoretical and practical implications.
|keyword = Online networks,offline networks,communication networks,social networks,complementarity,job performance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A DRAMATURGICAL MODEL OF THE PRODUCTION OF PERFORMANCE DATA'''
{{header}}
{{article
|author= Joao Vieira da Cunha,
|source= MIS QUARTERLY
|year= 2013
|abstract = The production of performance data in organizations is often described as a functional process that managers enforce on their employees to provide leaders with accurate information about employees' work and their achievements. This study draws on a 15-month ethnography of a desk sales unit to build a dramaturgical model that explains how managers participate in the production of performance data to impress rather than inform leaders. Research on management information systems is reviewed to outline a protective specification of this model where managers participate in the production of performance data to suppress information that threatens the image they present to leaders. Ethnographic data about the production and use of performance records and performance reports in a desk sales unit is examined to induce an exploitive specification of this dramaturgical model. This specification explains how people can take advantage of the opportunities, rather than just avoid the threats that performance data presents for impression management. It also demonstrates how managers can participate in the production of performance data to create an idealized version of their accomplishments and that leaders reify these data by using them in their own attempts at impressing others. By doing so, leaders and managers turn information systems into store windows to show achievement upward instead of transparent windows to monitor compliance downward.
|keyword = Management information systems,production of performance data,performance monitoring,implementation of information technology,ethnography,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WHEN DOES TECHNOLOGY USE ENABLE NETWORK CHANGE IN ORGANIZATIONS? A COMPARATIVE STUDY OF FEATURE USE AND SHARED AFFORDANCES'''
{{header}}
{{article
|author= Paul M. Leonardi,
|source= MIS QUARTERLY
|year= 2013
|abstract = The goal of this study is to augment explanations of how newly implemented technologies enable network change within organizations with an understanding of when such change is likely to happen. Drawing on the emerging literature on technology affordances, the paper suggests that informal network change within interdependent organizational groups is unlikely to occur until users converge on a shared appropriation of the new technology's features such that the affordances the technology enables are jointly realized. In making the argument for the importance of shared affordances, this paper suggests that group-level network change has its most profound implications at the organization level when individuals use the same subset of a new information technology's features. To explore this tentative theory, we turn to a comparative, multimethod, longitudinal study of computer-based simulation technology use in automotive engineering. The findings of this explanatory case study show that engineers used the new technology for more than three months, during which time neither group experienced changes to their advice networks. Initially, divergent uses of the technology's features by engineers in both groups precluded them from being able to coordinate their work in ways that allowed them to structure their advice networks differently. Eventually, engineers in only one of the two groups converged on the use of a common set of the technology's features to enact a shared affordance. This convergence was necessary to turn the technology into a resource that could collectively afford group members the ability to compare their simulation outputs with one another and, in so doing, alter the content and structure of the group's advice network. The implications of these findings for the literatures on technology feature use, affordances, social networks, and post-adoption behaviors in organizations are discussed.
|keyword = Technology implementation,organizational change,advice networks,feature use,affordances,frames,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INTEGRATING SERVICE QUALITY WITH SYSTEM AND INFORMATION QUALITY: AN EMPIRICAL TEST IN THE E-SERVICE CONTEXT'''
{{header}}
{{article
|author= Jingjun (David) Xu,Izak Benbasat,Ronald T. Cenfetelli,
|source= MIS QUARTERLY
|year= 2013
|abstract = Wixom and Todd (2005) integrated the user satisfaction and the technology acceptance literatures to theorize about and account for the influence of the information technology artifact on usage. Based on Wixom and Todd's integrated model of technology usage, we propose the 3Q model by investigating the role of service quality (SQ), in addition to system quality (SysQ) and information quality (IQ), in website adoption. Attention to SQ is critical, as consumer websites have increasingly become the target of SQ assessment made by consumers, not just traditional SysQ and IQ evaluations. As part of our study, we further theorize and empirically test the relationships among these three types of quality constructs and hypothesize that perceived SysQ influences perceived IQ and perceived SQ, and perceived IQ influences perceived SQ. Our study extends the Wixom and Todd model in the e-service context and is the first of its kind to empirically examine the combined impact of perceived SQ, perceived SysQ, and perceived IQ on usage intention. Our study advances the theoretical understanding of SQ and the relationships among perceptions of SysQ, IQ, and SQ in the e-service context. The results also inform practitioners that high IQ and SysQ can directly or indirectly improve SQ in the e-service context.
|keyword = Service quality (SQ),information quality (IQ),system quality (SysQ),service satisfaction,perceived enjoyment (PE),empirical,e-service,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TECHNOLOGICAL OBJECTS, SOCIAL POSITIONS, AND THE TRANSFORMATIONAL MODEL OF SOCIAL ACTIVITY'''
{{header}}
{{article
|author= Philip Faulkner,Jochen Runde,
|source= MIS QUARTERLY
|year= 2013
|abstract = The transformational model of social activity (TMSA), in many ways the centerpiece of critical realism, has been widely used in areas of information systems research. However, little has been done so far to develop a systematic theory of the nature, position, and identity of technological objects within the context of the TMSA. Our aim in this paper is to fill this gap, paying particular attention to the important category of nonmaterial technological objects that lie at the heart of modern information systems.
|keyword = Organizational theory,sociological theory,society,practice,societal change,position,socio-technical system,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CRITICAL REALISM AND AFFORDANCES: THEORIZING IT-ASSOCIATED ORGANIZATIONAL CHANGE PROCESSES'''
{{header}}
{{article
|author= Olga Volkoff,Diane M. Strong,
|source= MIS QUARTERLY
|year= 2013
|abstract = Convincing arguments for using critical realism as an underpinning for theories of IT-associated organizational change have appeared in the Information Systems literature. A central task in developing such theories is to uncover the generative mechanisms by which IT is implicated in organizational change processes, but to do so, we must explain how critical realism's concept of generative mechanisms applies in an IS context. Similarly, convincing arguments have been made for using Gibson's (1986) affordance theory from ecological psychology for developing theories of IT-associated organizational change, but this effort has been hampered due to insufficient attention to the ontological status of affordances. In this paper, we argue that affordances are the generative mechanisms we need to specify and explain how affordances are a specific type of generative mechanism. We use the core principles of critical realism to argue how affordances arise in the real domain from the relation between the complex assemblages of organizations and of IT artifacts, how affordances are actualized over time by organizational actors, and how these actualizations lead to the various effects we observe in the empirical domain. After presenting these arguments, we reanalyze two published cases in the literature, those of ACRO and Autoworks, to illustrate how affordance-based theories informed by critical realism enhance our ability to explain IT-associated organizational change. These examples show how researchers using this approach should proceed, and how managers can use these ideas to diagnose and address IT implementation problems.
|keyword = Affordance,critical realism,generative mechanism,organizational change,case study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''HOW SHOULD TECHNOLOGY-MEDIATED ORGANIZATIONAL CHANGE BE EXPLAINED? A COMPARISON OF THE CONTRIBUTIONS OF CRITICAL REALISM AND ACTIVITY THEORY'''
{{header}}
{{article
|author= David K. Allen,Andrew Brown,Stan Karanasios,Alistair Norman,
|source= MIS QUARTERLY
|year= 2013
|abstract = In this paper, critical realism and activity theory are compared within the context of theorizing technology-mediated organizational change. An activity theoretic analysis of the implementation of large-scale disruptive information systems in a public sector setting (in particular concerning paramedic treatment of heart attack patients and ambulance dispatch work activity) is used to illustrate how activity theory makes a significant contribution to critical realism, by (1) locating technology within "activity systems" and theorizing change through contradictions and congruencies within those systems; (2) developing recent critical realism-inspired theorization of the "inscription" of cultural and social relations within technology; and (3) developing recent insights of critical realist researchers regarding the way in which the performance management agenda is mediated through IS.
|keyword = Critical realism,activity theory,theory,information systems,organization change,evaluation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''METHODOLOGICAL IMPLICATIONS OF CRITICAL REALISM FOR MIXED-METHODS RESEARCH'''
{{header}}
{{article
|author= Markos Zachariadis,Susan Scott,Michael Barrett,
|source= MIS QUARTERLY
|year= 2013
|abstract = Building on recent developments in mixed methods, we discuss the methodological implications of critical realism and explore how these can guide dynamic mixed-methods research design in information systems. Specifically, we examine the core ontological assumptions of CR in order to gain some perspective on key epistemological issues such as causation and validity, and illustrate how these shape our logic of inference in the research process through what is known as retroduction. We demonstrate the value of a CR-led mixed-methods research approach by drawing on a study that examines the impact of ICT adoption in the financial services sector. In doing so, we provide insight into the interplay between qualitative and quantitative methods and the particular value of applying mixed methods guided by CR methodological principles. Our positioning of demi-regularities within the process of retroduction contributes a distinctive development in this regard. We argue that such a research design enables us to better address issues of validity and the development of more robust meta-inferences.
|keyword = IS research,critical realism,retroduction,mixed methods,qualitative and quantitative methods,econometric modeling,qualitative enquiry,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE BROADER CONTEXT FOR ICT4D PROJECTS: A MORPHOGENETIC ANALYSIS'''
{{header}}
{{article
|author= James Muranga Njihia,Yasmin Merali,
|source= MIS QUARTERLY
|year= 2013
|abstract = This paper demonstrates the value of Archer's morphogenetic approach (MA) in understanding and explaining the complexity of the broader context within which many developing country information and communication technology (ICT) projects are implemented. It does this by using MA's analytical and explanatory apparatus to examine the evolution of the context of public sector ICT provision in Kenya over the period 1963-2006. In addition to demonstrating the practical value of MA, the paper contributes to the Information Systems literature on ICT for development (ICT4D). The analysis identifies (1) global normative pressures, polity, the national socio-economic base, disruptive technology, and the emergence of multistakeholder networks as key forces in shaping the evolutionary trajectory, (2) the explicit treatment of time and temporality as key for understanding mechanisms underpinning the evolutionary process, and (3) the difficulty of cleanly isolating the implementation of individual public sector ICT projects from the broader context and ICT4D agendas. The discussion elaborates on the features of MA found to be particularly valuable in this study. The paper concludes that explicitly attending to time and temporality, and to the broader context for ICT4D projects, would contribute to the development of more nuanced accounts of such projects and a more emancipatory outlook for ICT4D research.
|keyword = Morphogenetic approach,ICT4D,temporality,networks,emergent social systems,agency and structure,broader context,information systems,development,critical realism,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE GENERATIVE MECHANISMS OF DIGITAL INFRASTRUCTURE EVOLUTION'''
{{header}}
{{article
|author= Ola Henfridsson,Bendik Bygstad,
|source= MIS QUARTERLY
|year= 2013
|abstract = The current literature on digital infrastructure offers powerful lenses for conceptualizing the increasingly interconnected information system collectives found in contemporary organizations. However, little attention has been paid to the generative mechanisms of digital infrastructure, that is, the causal powers that explain how and why such infrastructure evolves over time. This is unfortunate, since more knowledge about what drives digital infrastructures would be highly valuable for managers and IT professionals confronted by the complexity of managing them. To this end, this paper adopts a critical realist view for developing a configurational perspective of infrastructure evolution. Our theorizing draws on a multimethod research design comprising an in-depth case study and a case survey. The in-depth case study, conducted at a Scandinavian airline, distinguishes three key mechanisms of digital infrastructure evolution: adoption, innovation, and scaling. The case survey research of 41 cases of digital infrastructure then identifies and analyzes causal paths through which configurations of these mechanisms lead to successful evolution outcomes. The study reported in this paper contributes to the infrastructure literature in two ways. First, we identify three generative mechanisms of digital infrastructure and how they contingently lead to evolution outcomes. Second, we use these mechanisms as a basis for developing a configurational perspective that advances current knowledge about why some digital infrastructures evolve successfully while others do not. In addition, the paper demonstrates and discusses the efficacy of critical realism as a philosophical tradition for developing substantive contributions in the field of information systems.
|keyword = Digital infrastructure,case study,case survey,configuration theory,critical realism,generative mechanism,information infrastructure,multimethod,adoption,innovation,scaling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CAUSAL EXPLANATION IN THE COORDINATING PROCESS: A CRITICAL REALIST CASE STUDY OF FEDERATED IT GOVERNANCE STRUCTURES'''
{{header}}
{{article
|author= Clay K. Williams,Elena Karahanna,
|source= MIS QUARTERLY
|year= 2013
|abstract = Large, multi-unit organizations are continually challenged to balance demands for centralization of information technology that lead to cost and service efficiencies through standardization while providing flexibility at the local unit level in order to meet unique business, customer, and service needs. This has led many organizations to adopt hybrid federated information technology governance (ITG) structures to find this balance. This approach to ITG establishes demand for various means to coordinate effectively across the organization to achieve the desired benefits. Past research has focused on the efficacy of various coordination mechanisms (e. g., steering committees, task forces) to coordinate activities related to information technology. However, we lack insights as to how and why these various coordination approaches help organizations achieve desired coordinated outcomes. This research specifically identifies coordinating as a process. Adopting the philosophy of critical realism, we conducted a longitudinal, comparative case study of two coordinating efforts in a federated ITG structure. Through a multifaceted approach to scientific logic employing deductive, inductive, and retroductive elements, we explicate two causal mechanisms, consensus making and unit aligning, which help to explain the coordinating process and the coordination outcomes observed in these efforts. We additionally elaborate the operation of the mechanisms through the typology of macro-micro-macro influences. Further, we demonstrate the value of the causal mechanisms to understanding the coordinating process by highlighting the complementarity in insights relative to the theories of power and politics and of rational choice. The study contributes to our understanding of coordinating as a process and of governance in federated IT organizations. Importantly, our study illustrates the value of applying critical realism to develop causal explanations and generate insights about a phenomenon.
|keyword = Critical realism,causal mechanisms,coordination,coordinating process,consensus-making mechanism,unit-aligning mechanism,federated IT governance,case study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''EXPLAINING BROADBAND ADOPTION IN RURAL AUSTRALIA: MODES OF REFLEXIVITY AND THE MORPHOGENETIC APPROACH'''
{{header}}
{{article
|author= Philip Dobson,Paul Jackson,Denise Gengatharen,
|source= MIS QUARTERLY
|year= 2013
|abstract = Universal fast broadband is currently being implemented by the Australian government. It is the largest single project in Australia's history. Represented as a nation-building exercise by the government and many public and private promoters, it is vilified by others as a massive waste of taxpayers' money. Ultimately the target of successful universal availability will require that metropolitan installations subsidize rural adoption. The take-up of these facilities, particularly in regional and remote areas, constitutes a complex, multi-factorial scenario in which political, personal, and organizational decisions are shaped by physical, cultural, economic, and ideological elements. Critical realism is proposed here as an aid for examining the complex reality of rural adoption for communities and small businesses in the regions. This article highlights the importance of considering individual reflexivity in explaining the adoption decision and potential adoption barriers.
|keyword = Critical realism,broadband adoption,internal conversation theory,morphogenetic approach,technology adoption,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Firm Strategy and the Internet in US Commercial Banking'''
{{header}}
{{article
|author= Kim Huat Goh,Robert J. Kauffman,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = As information technology (IT) becomes more accessible, sustaining any competitive advantage from it becomes challenging. This has caused some critics to dismiss IT as a less valuable resource. We argue that, in addition to being able to generate strategic advantage, IT should also be viewed as a strategic necessity that prevents competitive disadvantage in rapidly changing business environments. We test a set of hypotheses on strategic advantage and strategic necessity in the context of Internet banking investments for the population of U. S. Federal Deposit Insurance Corporation (FDIC) banks from 2003 to 2005. We seek to understand whether their IT investments were made as a strategic choice or as a result of strategic necessity. Our econometric analysis suggests that IT investments (1) were made to complement firm strategy for strategic advantage as well as due to strategic necessity, and (2) paid off by enhancing firm performance and addressing the issue of strategic necessity. In addition, our analysis reveals the simultaneous relationship between performance and IT investments: high-performing banking firms appear to have been more likely to invest in IT. The econometric analysis methods that we employ made it possible for us to state all of our quantitative findings for the FDIC data to be stated after adjusting for this endogeneity through simultaneity.
|keyword = banking,econometrics,financial services IS and technology,Internet banking,IT investments,strategic advantage,strategic necessity,strategy,transaction costs,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Health-Care Security Strategies for Data Protection and Regulatory Compliance'''
{{header}}
{{article
|author= Juhee Kwon,M. Eric Johnson,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = This study identifies how security performance and compliance influence each other and how security resources contribute to two security outcomes: data protection and regulatory compliance. Using simultaneous equation models and data from 243 hospitals, we find that the effects of security resources vary for data breaches and perceived compliance and that security operational maturity plays an important role in the outcomes. In operationally mature organizations, breach occurrences hurt compliance, but, surprisingly, compliance does not affect actual security. In operationally immature organizations, breach occurrences do not affect compliance, whereas compliance significantly improves actual security. The results imply that operationally mature organizations are more likely to be motivated by actual security than compliance, whereas operationally immature organizations are more likely to be motivated by compliance than actual security. Our findings provide policy insights on effective security programs in complex health-care environments.
|keyword = compliance,data breach,health care,organizational maturity,security,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of Cloud Computing: Should the IT Department Be Organized as a Cost Center or a Profit Center?'''
{{header}}
{{article
|author= Vidyanand Choudhary,Joseph Vithayathil,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = How does the adoption of cloud computing by a firm affect the organizational structure of its information technology (IT) department? To analyze this question, we consider an IT department that procures IT services from a cloud computing vendor and enhances these services for consuming units within the firm. Our model incorporates the competitive environment faced by the cloud vendor, which affects the price of the cloud vendor. We find that when the cloud vendor faces intense competition, the cost-center organizational model is preferred over the profit-center model. Infrastructure services such as basic storage, e-mail, and raw computing face intense competition, and our results suggest that such services be offered as a free corporate resource under the cost-center organizational structure. When the cloud vendor has pricing power, a profit-center organizational structure is likely to be preferred. Our results suggest that highly differentiated services such as cloud-based enterprise-wide enterprise resource planning or business intelligence be offered under the profit-center structure. Finally, the profit-center structure provides greater internal quality enhancement to cloud-based IT services than the cost center.
|keyword = chargeback,cloud,cloud computing,cost center,IaaS,IT governance,PaaS,profit center,SaaS,supply chain,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Channel Capabilities, Product Characteristics, and the Impacts of Mobile Channel Introduction'''
{{header}}
{{article
|author= Youngsok Bang,Dong-Joo Lee,Kunsoo Han,Minha Hwang,Jae-Hyeon Ahn,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Drawing on the notion of channel capability, we develop a theoretical framework for understanding the interactions between mobile and traditional online channels for products with different characteristics. Specifically, we identify two channel capabilities-access and search capabilities-that differentiate mobile and online channels, and two product characteristics that are directly related to the channel capabilities-time criticality and information intensity. Based on this framework, we generate a set of predictions on the differential effects of mobile channel introduction across different product categories. We test the predictions by applying a counterfactual analysis based on vector autoregression to a large panel data set from a leading e-market in Korea that covers a 28-month period and contains all of the transactions made through the online and mobile channels before and after the mobile channel introduction. Consistent with our theoretical predictions, our results suggest that the performance impact of the mobile channel depends on the two product characteristics and the resulting product-channel fit. We discuss implications for theory and multichannel strategy.
|keyword = counterfactual analysis,e-commerce,mobile commerce,multichannel strategy,multivariate baseline analysis,substitute and complement,times series,vector autoregression,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Competitive Business Impact of Using Telemedicine for the Treatment of Patients with Chronic Conditions'''
{{header}}
{{article
|author= Balaraman Rajan,Abraham Seidman,Earl R. Dorsey,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = The use of telemedicine to improve patients' health has been evolving rapidly over the past few years. Initially, our clinical research focus was on the development of effective ways for treating chronically ill patients, mostly those suffering from neurological disorders. While we identified the medical benefits of this information technology, there remains a salient strategic question addressing its competitive impact. In this paper, we analyze the impact of introducing telemedicine on the market share of the specialty hospital deploying this technology and on the competing hospitals in the region. Our analytical results prove that, contrary to earlier expectations, the value of telemedicine relative to in-person visits is not always increasing with the distance of the patient from the hospital. This result explains why patients located far from the specialty hospital may not prefer telemedicine care. We prove that telemedicine, unlike numerous other e-commerce applications, does not lead to the "winner takes all" phenomenon. We found that the advent of telemedicine changes the competitive equilibrium between specialty hospitals and community hospitals. Both hospital types will significantly benefit from delivering complementary care to chronic patients, rather than continuing to compete with each other.
|keyword = chronic conditions,community hospitals,economics of telemedicine,health-care competition,health-care IT,telemedicine,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Competing with Piracy: A Multichannel Sequential Search Approach'''
{{header}}
{{article
|author= Xianjun Geng,Young-Jin Lee,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = We consider an online market where consumers may obtain digital goods from two mutually exclusive channels: a legitimate channel consisting of many law-abiding retailers and a piracy channel consisting of many piracy services. We analyze consumer choice, retailer strategy, and piracy control using a sequential-search approach where information acquisition is costly for some consumers (nonshoppers), yet costless for others (shoppers). First, we show that a nonshopper's channel choice is determined by a simple comparison of two reservation prices. Second, we analyze how piracy threats affect in-channel pricing among retailers. If the in-channel competition intensity among retailers is high, piracy does not affect retailer pricing. If the intensity is medium, retailers respond to piracy by giving up some shoppers and, surprisingly, raising prices. If the intensity is low, the legitimate channel loses some shoppers as well as some nonshoppers to the piracy channel. Third, we consider several mechanisms for fighting piracy and analyze their effects on firm profit and consumer surplus. Reducing piracy quality and increasing piracy search costs are both effective in controlling piracy, yet they affect consumer surplus differently. Reducing the number of piracy services is less effective in controlling piracy.
|keyword = channel competition,digital good,digital piracy,price dispersion,search costs,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Network Structure and Observational Learning: Evidence from a Location-Based Social Network'''
{{header}}
{{article
|author= Zhan Shi,Andrew B. Whinston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = In recent years, there has been stellar growth of location-based/enabled social networks in which people can "check in" to physical venues they are visiting and share with friends. In this paper, we hypothesize that the "check-ins" made by friends help users learn the potential payoff of visiting a venue. We argue that this learning-in-a-network process differs from the classic observational learning model in a subtle yet important way: Rather than from anonymous others, the agents learn from their network friends, about whose tastes in experience goods the agents are better informed. The empirical analyses are conducted on a unique data set in which we observe both the explicit interpersonal relationships and their ensuing check-ins. The key result is that the proportion of checked-in friends is not positively associated with the likelihood of a new visit, rejecting the prediction of the conventional observational learning model. Drawing on the literature in sociology and computer science, we show that weighting the friends' check-ins by a parsimonious proximity measure can yield a more intuitive result than the plain proportion does. Repeated check-ins by friends are found to have a pronounced effect. Our empirical result calls for the revisiting of observational learning in a social network setting. It also suggests that practitioners should incorporate network proximity when designing social recommendation products and conducting promotional campaigns in a social network.
|keyword = experience goods,location-based social network,matrix factorization,observational learning,social effect,social networks,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''How Do Consumer Buzz and Traffic in Social Media Marketing Predict the Value of the Firm?'''
{{header}}
{{article
|author= Xueming Luo,Jie Zhang,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Consumer buzz in the form of user-generated reviews, recommendations, and blogs signals that consumer attitude and advocacy can influence firm value. Web traffic also affects brand awareness and customer acquisition, and is a predictor of the performance of a firm's stock in the market. The information systems and accounting literature have treated buzz and traffic separately in studying their relationships with firm performance. We consider the interactions between buzz and traffic as well as competitive effects that have been overlooked heretofore. To study the relationship between user-initiated Web activities and firm performance, we collected a unique data set with metrics for consumer buzz, Web traffic, and firm value. We employed a vector autoregression with exogenous variables model that captures the evolution and interdependence between the time series of dependent variables. This model enables us to examine a series of questions that have been raised but not fully explored to date, such as dynamic effects, interaction effects, and market competition effects. Our results support the dynamic relationships of buzz and traffic with firm value as well as the related mediation effects of buzz and traffic. They also reveal significant market competition effects, including effects of both a firm's own and its rivals' buzz and traffic. The findings also provide insights for e-commerce managers regarding Web site design, customer relation management, and how to best respond to competitors' strategic moves.
|keyword = consumer buzz,firm value,online reviews,social media,stock market performance,vector autoregression,Web traffic,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Consumer Learning and Time-Locked Trials of Software Products'''
{{header}}
{{article
|author= Debabrata Dey,Atanu Lahiri,Dengpan Liu,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = The usefulness of a software product becomes obvious to consumers only after they get to experience it and, upon experiencing it, they may reach different conclusions regarding its true value. We examine the problem of designing free software trials under a general learning function. Our analyses lead to several new findings. We find that a time-locked trial is optimal only when the rate of learning is sufficiently large. It is not optimal in other situations, even when it has an overall positive effect on consumers' valuations. We also find that positive network effects have a minimal impact on this optimality. Interestingly, we find that neither the optimal trial period nor the optimal price is monotonically increasing in the rate of learning. At moderate rates, the software manufacturer pursues a dual strategy of offering a longer trial as well as a lower price. At higher rates of learning, the manufacturer does the opposite. Our results are robust, and incorporating possibilities such as a trial providing a signal of quality or learning being correlated with prior valuation has little impact on their applicability.
|keyword = consumer learning,experience goods,free trial,network effects,signaling,software trial,time-locked trial,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Reducing Buyers' Uncertainty About Taste-Related Product Attributes'''
{{header}}
{{article
|author= Panos M. Markopoulos,Eric K. Clemons,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = It is becoming increasingly important for firms to know when to take steps to reduce buyers' uncertainty about products and services. This paper focuses on investments that firms can make to reduce buyers' uncertainty about taste-related product attributes. Using an analytical model, we show that firms should disclose more taste-related information when the customer segment they directly target represents a larger share of the overall market. We further show that there are practical ways by which managers can decide if such disclosure investments are financially beneficial to their firms. Specifically, we show that the variance of consumer reviews can guide such decisions. The paper's main contribution to the extant literature is to show that firms must consider the variance, but not the mean, of buyer reviews, to determine the need to invest in reducing consumer uncertainty about taste-related attributes. The papers's findings are managerially important due to the ubiquity of consumer reviews. They are novel because most of the previous literature views the mean of the review as the key indicator. Finally, they are general in their applicability since they are independent of any assumptions about heuristics that buyers may use to ascertain product quality from the reviews of previous buyers.
|keyword = consumer uncertainty reduction,information dissemination,product ratings,product review variance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Empirical Examination of the Antecedents and Consequences of Contribution Patterns in Crowd-Funded Markets'''
{{header}}
{{article
|author= Gordon Burtch,Anindya Ghose,Sunil Wattal,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Crowd-funded markets have recently emerged as a novel source of capital for entrepreneurs. As the economic potential of these markets is now being realized, they are beginning to go mainstream, a trend reflected by the explicit attention crowdfunding has received in the American Jobs Act as a potential avenue for economic growth, as well as the recent focus that regulators such as the U.S. Securities and Exchange Commission have placed upon it. Although the formulation of regulation and policy surrounding crowd-funded markets is becoming increasingly important, the behavior of crowdfunders, an important aspect that must be considered in this formulation effort, is not yet well understood. A key factor that can influence the behavior of crowd funders is information on prior contribution behavior, including the amount and timing of others' contributions, which is published for general consumption. With that in mind, in this study, we empirically examine social influence in a crowd-funded marketplace for online journalism projects, employing a unique data set that incorporates contribution events and Web traffic statistics for approximately 100 story pitches. This data set allows us to examine both the antecedents and consequences of the contribution process. First, noting that digital journalism is a form of public good, we evaluate the applicability of two competing classes of economic models that explain private contribution toward public goods in the presence of social information: substitution models and reinforcement models. We also propose a new measure that captures both the amount and the timing of others' contribution behavior: contribution frequency (dollars per unit time). We find evidence in support of a substitution model, which suggests a partial crowding-out effect, where contributors may experience a decrease in their marginal utility from making a contribution as it becomes less important to the recipient. Further, we find that the duration of funding and, more importantly, the degree of exposure that a pitch receives over the course of the funding process, are positively associated with readership upon the story's publication. This appears to validate the widely held belief that a key benefit of the crowdfunding model is the potential it offers for awareness and attention-building around causes and ventures. This last aspect is a major contribution of the study, as it demonstrates a clear linkage between marketing effort and the success of crowd-funded projects.
|keyword = economics of IS,electronic commerce,crowdfunding,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''All Are Not Equal: An Examination of the Economic Returns to Different Forms of Participation in Open Source Software Communities'''
{{header}}
{{article
|author= Il-Horn Hann,Jeffrey A. Roberts,Sandra A. Slaughter,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Open source software (OSS) communities live and die with the continuous contributions of programmers who often participate without direct remuneration. An intriguing question is whether such sustained participation in OSS projects yields economic benefits to the participants. Moreover, as participants engage in OSS projects, they take on different roles and activities in the community. This raises additional questions of whether different forms of participation in OSS communities are associated with different economic rewards and, if so, in which contexts. In this paper, we draw upon theories of signaling and job matching to hypothesize that participants who possess "proof" of their skills in OSS projects are financially rewarded for their activities in the labor market. More specifically, we distinguish between participation in OSS communities that is associated with a signaling value for unobserved productivity characteristics and an additional value that accrues to participants whose OSS roles and activities match those in their paid employment. Following a cohort of OSS programmers over a six-year period, we empirically examine the wages and OSS performance of participants in three of the foremost OSS projects operating within the Apache Software Foundation. Controlling for individual characteristics and other wage-related factors, our findings reveal that credentials earned through a merit-based ranking system are associated with as much as an 18% increase in wages. Moreover, we find that participants who have OSS project management responsibilities receive additional financial rewards if their professional job is in IT management. These findings suggest that rank within an OSS meritocracy is a credible and precise signal of participants' productive capacity and that participants' roles and activities in an OSS community have additional financial value when aligned with their paid employment.
|keyword = open source software,signaling theory,job matching theory,labor economics,software industry,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Networks, Social Influence, and the Choice Among Competing Innovations: Insights from Open Source Software Licenses'''
{{header}}
{{article
|author= Param Vir Singh,Corey Phelps,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Existing research provides little insight into how social influence affects the adoption and diffusion of competing innovative artifacts and how the experiences of organizational members who have worked with particular innovations in their previous employers affect their current organizations' adoption decision. We adapt and extend the heterogeneous diffusion model from sociology and examine the conditions under which prior adopters of competing open source software (OSS) licenses socially influence how a new OSS project chooses among such licenses and how the experiences of the project manager of a new OSS project with particular licenses affects its susceptibility to this social influence. We test our predictions using a sample of 5,307 open source projects hosted at SourceForge. Our results suggest the most important factor determining a new project's license choice is the type of license chosen by existing projects that are socially closer to it in its inter-project social network. Moreover, we find that prior adopters of a particular license are more infectious in their influence on the license choice of a new project as their size and performance rankings increase. We also find that managers of new projects who have been members of more successful prior OSS projects and who have greater depth and diversity, of experience in the OSS community are less susceptible to social influence. Finally, we find a project manager is more likely to adopt a particular license type when his or her project occupies a similar social role as other projects that have adopted the same license. These results have implications for research on innovation adoption and diffusion, open source software licensing, and the governance of economic exchange.
|keyword = open source software license,social networks,innovation adoption and diffusion,social influence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Empirical Analysis of Technical Efficiency: The Role of IT Intensity and Competition'''
{{header}}
{{article
|author= Young Bong Chang,Vijay Gurbaxani,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = We analyze the impact of information technology (IT) on the technical efficiency of firms in the context of their observed competitive settings. Because competition can be a driver of efficiency and industries display varying degrees of competitiveness, firm-level efficiency is likely to display considerable heterogeneity. To shed light on these questions, we analyze the economic impact of IT on technical efficiency, a key component of efficiency, in heterogeneous competitive settings. Our study employs a number of econometric techniques, including a stochastic frontier and a generalized method of moments approach, on data from firms in a wide cross-section of industries. We find, after controlling for firm-level heterogeneity and potential endogeneity, that IT is positively associated with gains in technical efficiency but its impact is moderated by the degree of competition. Firms display large variation in their levels of technical efficiency partly because of the heterogeneous market competitiveness conditions they face. In more competitive industries, firms tend to deploy IT more intensively and use it more efficiently. Our study makes a distinct contribution relative to prior studies that have focused on the productivity impacts of IT while assuming perfect competition and not allowing for potential heterogeneity in firm-level efficiency. Overall, our results demonstrate that IT and competition are significant determinants of gains in technical efficiency and provide insight into how competition affects the returns to IT investment.
|keyword = technical efficiency,competition,productivity,economics of IS,business value of IT,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Privacy Concerns and Privacy-Protective Behavior in Synchronous Online Social Interactions'''
{{header}}
{{article
|author= Zhenhui (Jack) Jiang,Cheng Suang Heng,Ben C. F. Choi,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Privacy is of prime importance to many individuals when they attempt to develop online social relationships. Nonetheless, it has been observed that individuals' behavior is at times inconsistent with their privacy concerns, e.g., they disclose substantial private information in synchronous online social interactions, even though they are aware of the risks involved. Drawing on the hyperpersonal framework and the privacy calculus perspective, this paper elucidates the interesting roles of privacy concerns and social rewards in synchronous online social Interactions by examining the causes and the behavioral strategies that individuals utilize to protect their privacy. An empirical study involving 251 respondents was conducted in online chat rooms. Our results indicate that individuals utilize both self-disclosure and misrepresentation to protect their privacy and that social rewards help explain why individuals may not behave in accordance with their privacy concerns. In addition, we find that perceived anonymity of others and perceived intrusiveness affect both privacy concerns and social rewards. Our findings also suggest that higher perceived anonymity of self decreases individuals' privacy concerns, and higher perceived media richness increases social rewards. Generally, this study contributes to the information systems literature by integrating the hyperpersonal framework and the privacy calculus perspective to identify antecedents of privacy trade-off and predict individuals' behavior in synchronous online social interactions.
|keyword = synchronous online social interactions,privacy concerns,privacy-protective behavior,social rewards,self-disclosure,misrepresentation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Promotional Marketing or Word-of-Mouth? Evidence from Online Restaurant Reviews'''
{{header}}
{{article
|author= Xianghua Lu,Sulin Ba,Lihua Huang,Yue Feng,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = The value of promotional marketing and word-of-mouth (WOM) is well recognized, but few studies have compared the effects of these two types of information in online settings. This research examines the effect of marketing efforts and online WOM on product sales by measuring the effects of online coupons, sponsored keyword search, and online reviews. It aims to understand the relationship between firms' promotional marketing and WOM in the context of a third party review platform. Using a three-year panel data set from one of the biggest restaurant review websites in China, the study finds that both online promotional marketing and reviews have a significant impact on product sales, which suggests promotional marketing on third party review platforms is still an effective marketing tool. This research further explores the interaction effects between WOM and promotional marketing when these two types of information coexist. The results demonstrate a substitute relationship between the WOM volume and coupon offerings, but a complementary relationship between WOM volume and keyword advertising.
|keyword = promotional marketing,online review,keyword sponsored search,online coupon,word of mouth,product price,product sales,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''How Is the Mobile Internet Different? Search Costs and Local Activities'''
{{header}}
{{article
|author= Anindya Ghose,Avi Goldfarb,Sang Pil Han,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = We explore how Internet browsing behavior varies between mobile phones and personal computers. Smaller screen sizes on mobile phones increase the cost to the user of browsing for information. In addition, a wider range of offline locations for mobile Internet usage suggests that local activities are particularly important. Using data on user behavior at a (Twitter-like) microblogging service, we exploit exogenous variation in the ranking mechanism of posts to identify the ranking effects. We show that (1) ranking effects are higher on mobile phones suggesting higher search costs: links that appear at the top of the screen are especially likely to be clicked on mobile phones and (2) the benefit of browsing for geographically close matches is higher on mobile phones: stores located in close proximity to a user's home are much more likely to be clicked on mobile phones. Thus, the mobile Internet is somewhat less "Internet-like": search costs are higher and distance matters more. We speculate on how these changes may affect the future direction of Internet commerce.
|keyword = mobile Internet,search costs,ranking effects,cognitive load,recency effects,local interests,microblogging,social media,hierarchical Bayesian methods,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''From Use to Effective Use: A Representation Theory Perspective'''
{{header}}
{{article
|author= Andrew Burton-Jones,Camille Grange,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Information systems must be used effectively to obtain maximum benefits from them. However, despite a great deal of research on when and why systems are used, very little research has examined what effective system use involves and what drives it. To move from use to effective use requires understanding an information system's nature and purpose, which in turn requires a theory of information systems. We draw on representation theory, which states that an information system is made up of several structures that serve to represent some part of the world that a user and other stakeholders must understand. From this theory, we derive a high-level framework of how effective use and performance evolve, as well as specific models of the nature and drivers of effective use. The models are designed to explain the effective use of any information system and offer unique insights that would not be offered by traditional views, which tend to consider information systems to be just another tool. We explain how our theory extends existing research, provides a rich platform for research on effective use, and how it contributes back to the theory of information systems from which it was derived.
|keyword = effective system use,performance,goals,representation theory,system structure,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Motivational Differences Across Post-Acceptance Information System Usage Behaviors: An Investigation in the Business Intelligence Systems Context'''
{{header}}
{{article
|author= Xixi Li,J. J. Po-An Hsieh,Arun Rai,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = We identify two post-acceptance information system (IS) usage behaviors related to how employees leverage implemented systems. Routine use (RTN) refers to employees' using IS in a routine and standardized manner to support their work, and innovative use (INV) describes employees' discovering new ways to use IS to support their work. We use motivation theory as the overarching perspective to explain RTN and INV and appropriate the rich intrinsic motivation (RIM) concept from social psychology to propose a conceptualization of RIM toward IS use, which includes intrinsic motivation toward accomplishment (IMap), intrinsic motivation to know (IMkw), and intrinsic motivation to experience stimulation (IMst). We also consider the influence of perceived usefulness (PU)-a representative surrogate construct of extrinsic motivation toward IS use on RTN and INV. We theorize the relative impacts of the RIM constructs and PU on RTN and INV and the role of personal innovativeness with IT (PIIT) in moderating the RIM constructs' influences on INV. Based on data from 193 employees using a business intelligence system at one of the largest telecom service companies in China, we found (1) PU had a stronger impact on RTN than the RIM constructs, (2) IMkw and IMst each had a stronger impact on INV than either PU or IMap, and (3) PIIT positively moderated the impact of each RIM construct on INV. Our findings provide insights on managing RTN and INV in the post-acceptance stage.
|keyword = post-acceptance stage,post-acceptance behaviors,routine use,innovative use,motivation theory,intrinsic motivation,business intelligence systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''To Personalize or Not to Personalize Online Purchase Interactions: Implications of Self-Selection by Retailers'''
{{header}}
{{article
|author= Sriram Thirumalai,Kingshuk K. Sinha,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Personalization technologies today enable retailers to tailor online purchase interactions to the individual preferences and needs of customers. With personalization being increasingly perceived as a source of competitive advantage, there is a growing trend toward pursuing technology-enabled personalization strategies in online retailing. However, the choice of a retailer whether or not to select into technology-enabled personalization and its implications for customer loyalty are at best ambiguous. This paper is an attempt to resolve this apparent ambiguity. Specifically, the paper conceptualizes retailer selection into technology-enabled personalization strategies relevant to two steps of an online purchase, namely, transaction personalization strategy and decision personalization strategy, based on the operating characteristics of a retailer. The implications of the retailers' self-selection into technology-enabled personalization strategies for customer loyalty are then empirically investigated with data collected from 422 retailers. Further, based on a counterfactual analysis, the paper reveals the implications of making a normatively incorrect decision with respect to personalization strategy. Contrary to popular belief, the results of this study indicate that personalization may not be uniformly beneficial in terms of customer loyalty to all retailers. Although a majority of retailers pursue transaction personalization and realize benefits by way of improved customer loyalty, we find that the choice of a retailer to pursue decision personalization is self-selected and dependent on idiosyncratic characteristics related to its operating context. Retailers that have relatively large-scale operations, provide greater variety and realize higher customer satisfaction with product selection, and that do not necessarily compete on price (i.e., realize lower customer satisfaction with prices relative to competing retailers) are more likely to pursue the decision personalization strategy. Although some retailers pursue decision personalization because they clearly stand to benefit from doing so, other retailers are better off not following suit. Theoretical contributions of the study, managerial implications of the study findings, limitations, and directions for future research are identified.
|keyword = personalization strategy,self-selection,customer loyalty,econometric analysis,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Moving from Access to Use of the Information Infrastructure: A Multilevel Sociotechnical Framework'''
{{header}}
{{article
|author= Pradeep Racherla,Munir Mandviwalla,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Universal access (UA) to the Internet and the associated information infrastructure has become an important economic and societal goal. However, UA initiatives tend to focus on issues such as physical access and geographical ubiquity, and they measure adoption through penetration rates. In this paper, we apply an interpretive case study approach to analyze the Philadelphia wireless initiative to provide insights into the nature of UA and extend this concept to also consider universal use (UU). UU is important because simply providing access does not guarantee use. UU is presented as a conceptual goal that starts with the challenge of physical access, but which necessarily also leads to considerations of use. The results show that the human and technological elements underlying individual access and use are deeply embedded within various institutional elements and collectives that enable but also constrain meaningful use. We integrate our findings into a multilevel framework that shows how access and use are influenced by both micro and macro factors. This framework provides new insights into the study of the information infrastructure, digital divide, and public policy.
|keyword = universal access,universal use,digital divide,information infrastructure,broadband policy, telecommunications policy,sociotechnical systems,multilevel,interpretive case study,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''On Risk Management with Information Flows in Business Processes'''
{{header}}
{{article
|author= Xue Bai,Ramayya Krishnan,Rema Padman,Harry Jiannan Wang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = This article investigates the economic consequences of data errors in the information flows associated with business processes. We develop a process modeling-based methodology for managing the risks associated with such data errors. Our method focuses on the topological structure of a process and takes into account its effect on error propagation and risk mitigation using both expected loss and conditional value-at-risk risk measures. Using this method, optimal strategies can be designed for control resource allocation to manage risk in a business process. Our work contributes to the literature on both ex ante risk management-based business process design and ex post risk assessments of existing business processes and control models. This research applies not only to the literature on and practice of process design and risk management but also to business decision support systems in general. An order-fulfillment process of an online pharmacy is used to illustrate the methodology.
|keyword = business process management,control,information flow,expected loss,conditional value at risk,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact and Implications of On-Demand Services on Market Structure'''
{{header}}
{{article
|author= Pei-Yu Chen,Shin-Yi Wu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = This paper considers on-demand services and its impact on market structure, firm profitability, and consumer welfare. The unique properties of on-demand services are the conversion of fixed costs to variable costs, removal of capacity constraint, and fast setup time (which enables quick entry by any firm at any time when there is opportunity), whereas privacy and security concerns and switching costs have been noted as the biggest barriers from adopting on-demand services. With a stylized model capturing these benefits and barriers to using on-demand services, we establish several results. First, we show that conversion of fixed cost to variable cost enables new and small firms to enter existing markets and leads to the creation of new markets. Second, we show that competition and the threat of new entrants can be an important driver of a firm's decision to switch to on-demand services. In addition, a firm's barriers to using on-demand services can influence another firm's entry decision. Third, we show that two identical firms may employ different technologies in equilibrium. Fourth, we show that fast setup time and removal of capacity constraint associated with on-demand services make it impossible for firms to make supranormal return and would lead to a perfect competitive market, even when there is only one firm, under very general conditions. Such a result still holds even when there exists an economy of scale (e.g., quantity discount) from using on-demand services. On the other hand, when there are barriers preventing firms from offering similar products and products are substantially differentiated, on-demand services can amplify this advantage of entry barriers by enabling firms to further increase prices and enhance their profitability. Therefore, contrary to the common belief that offering on-demand services is best for firms offering commodity products, we show on-demand services to be more profitable for firms with differentiated products.
|keyword = on-demand services,utility computing,cloud computing,outsourcing,technology adoption,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Ascending Combinatorial Auctions with Allocation Constraints: On Game Theoretical and Computational Properties of Generic Pricing Rules'''
{{header}}
{{article
|author= Ioannis Petrakis,Georg Ziegler,Martin Bichler,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Combinatorial auctions are used in a variety of application domains, such as transportation or industrial procurement, using a variety of bidding languages and different allocation constraints. This flexibility in the bidding languages and the allocation constraints is essential in these domains but has not been considered in the theoretical literature so far. In this paper, we analyze different pricing rules for ascending combinatorial auctions that allow for such flexibility: winning levels and deadness levels. We determine the computational complexity of these pricing rules and show that deadness levels actually satisfy an ex post equilibrium, whereas winning levels do not allow for a strong game theoretical solution concept. We investigate the relationship of deadness levels and the simple price update rules used in efficient ascending combinatorial auction formats. We show that ascending combinatorial auctions with deadness level pricing rules maintain a strong game theoretical solution concept and reduce the number of bids and rounds required at the expense of higher computational effort. The calculation of exact deadness levels is a Pi(P)(2)-complete problem. Nevertheless, numerical experiments show that for mid-sized auctions this is a feasible approach. The paper provides a foundation for allocation constraints in combinatorial auctions and a theoretical framework for recent Information Systems contributions in this field.
|keyword = electronic markets and auctions,economics of IS,electronic commerce,decision support systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IT Implementation Contract Design: Analytical and Experimental Investigation of IT Value, Learning, and Contract Structure'''
{{header}}
{{article
|author= D. J. Wu,Min Ding,Lorin M. Hitt,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = This article analytically and experimentally investigates how firms can best capture the business value of information technology (IT) investments through IT contract design. Using a small sample of outsourcing contracts for enterprise information technology (EIT) projects in several industries-coupled with reviews of contracts used by a major enterprise software maker-the authors determine the common provisions and structural characteristics of EIT contracts. The authors use these characteristics to develop an analytical model of optimal contract design with principal-agent techniques. The model captures a set of key characteristics of EIT contracts, including a staged, multiperiod project structure; learning; probabilistic binary outcomes; variable fee structures; possibly risk-averse agents; and implementation risks. The model characterizes conditions under which multistage contracts enable clients to create and capture greater project value than single-stage projects, and how project staging enables firms to reduce project risks, capture learning benefits, and increase development effort. Finally, the authors use controlled laboratory experiments to complement their analytical approaches and demonstrate robustness of their key findings.
|keyword = analytical modeling,enterprise systems,economics of IS,management of IS projects,laboratory experiments,business value of IT,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Status Locality on the Web: Implications for Building Focused Collections'''
{{header}}
{{article
|author= Gautam Pant,Padmini Srinivasan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Topical locality on the Web is the notion that pages tend to link to other topically similar pages and that such similarity decays rapidly with link distance. This supports meaningful Web browsing and searching by information consumers. It also allows topical Web crawlers, programs that fetch pages by following hyperlinks, to harvest topical subsets of the Web for applications such as those in vertical search and business intelligence. We show that the Web exhibits another property that we call "status locality." It is based on the notion that pages tend to link to other pages of similar status (importance) and that this status similarity also decays rapidly with link distance. Analogous to topical locality status locality may also be exploited by Web crawlers. Collections built by such crawlers include pages that are both topically relevant and also important. This capability is crucial because of the large numbers of Web pages addressing even niche topics. The challenge in exploiting status locality while crawling is that page importance (or status) is typically recognized through global measures computed by processing link data from billion of pages. In contrast, topical Web crawlers depend on local information based on previously downloaded pages. We solve this problem by using methods developed previously that utilize local characteristics of pages to estimate their global status. This leads to the design of new crawlers, specifically of utility-biased crawlers guided by a Cobb-Douglas utility function. Our crawler experiments show that status and topicality of Web collections present a trade-off. An adaptive version of our utility-biased crawler dynamically modifies output elasticities of topicality and status to create Web collections that maintain high average topicality. This can be done while simultaneously achieving significantly higher average status as compared to several benchmarks including a state-of-the-art topical crawler.
|keyword = status locality,predictive models,topical crawlers,homophily,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Interdependencies in IT Infrastructure Services: Analyzing Service Processes for Optimal Incentive Design'''
{{header}}
{{article
|author= Sagnika Sen,T. S. Raghu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Information technology (IT) infrastructure outsourcing arrangements involve multiple services and processes that are interdependent. The interdependencies pose significant challenges in designing appropriate incentives to influence a provider's effort-allocation decisions. By integrating process modeling fundamentals with multitask agency theory, we enumerate the base set of possible interrelationships among different IT service processes and derive corresponding optimal incentives. Our results demonstrate the impacts of risk profile, random noise, value-cost ratio, and process structure on optimal incentive rates. We find that the current practice of treating IT services as essentially independent is optimal only in limited settings where both the service provider and customer are risk neutral. Interestingly, incongruent performance measures require optimal incentive rates to respond in complex ways to the strength of coupling between services and the complementarity and substitutability of services. We also analyze more complex process scenarios using different combinations of the base set. The results demonstrate that, while the findings from the base set largely hold, the value-cost ratio of the services and the performance measure congruity can pose unique challenges in determining incentive rates.
|keyword = IT outsourcing,service level agreements,incentives,agency theory,process interdependence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A View from the Top: Integrated Information Delivery and Effective Information Use from the Senior Executive's Perspective'''
{{header}}
{{article
|author= William J. Kettinger,Chen Zhang,Kuo-Chung Chang,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = This study frames antecedents of effective information use, outlining a nomological network that firms follow to achieve integrated information delivery and effective information use. Our focus is on senior business executives' assessment of information delivered by their organizations' information systems. We first clarify the definition of information as it relates to information delivery and effective use. Then, drawing from institutional theory and the resource-based view of the firm, we propose a research model consisting of external institutional pressure, internal information systems (IS) resources, integrated information delivery, and effective information use and empirically test it through a field survey of senior business executives and post hoc qualitative analysis. Our findings position information delivery as an important research construct leading to effective information use and value. Our study also highlights the important role of the IS function as a facilitator of effective information use and a nurturer of a strong information culture in organizations. Finally, we offer practical advice on how senior executives assess and improve integrated information delivery and effective use.
|keyword = senior executive,integrated information delivery,effective information use,IS resource-based view,institutional forces,information orientation,information view,information management,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Contingency Approach to Investigating the Effects of User-System Interaction Modes of Online Decision Aids'''
{{header}}
{{article
|author= Weiquan Wang,Izak Benbasat,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Interactive online decision aids often employ User-decision aid dialogues as forms of user-system interaction to help construct and elicit users' attribute preferences about a product type. This study extends prior research on online decision aids by investigating the effects of a decision aid's user-system interaction mode (USIM), which can be either user-guided or system-controlled, on users' effort-related (number of iterations of using the aid and perceived cognitive effort expended in using it) and quality-related (perceived quality of the aid and acceptance of the product advice it provides) assessments. A contingency approach with two moderating factors is employed. One factor is the decision strategy (additive-compensatory or elimination) employed by the aid, and the other is the users' product knowledge (high or low). A laboratory experiment was conducted to compare online decision aids with different USIMs. Although the results largely confirm that users assess the user-guided USIM more positively than the system-controlled USIM, the effects of USIM are stronger in two settings: for the elimination-based aid than for the additive-compensatory-based aid and for users with low product knowledge than for those with high product knowledge, especially in terms of effort assessments. This research advances the theoretical understanding of the effects of interaction between two critical components of online decision aids (USIMs and decision strategies) and the moderating role of user characteristics (product knowledge) in affecting users' evaluations. It also provides practitioners with design advice for developing these aids.
|keyword = online decision aid,decision strategy,user-system interaction mode,product knowledge,cognitive effort,system quality,system restrictiveness,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''POSITIONING AND PRESENTING DESIGN SCIENCE RESEARCH FOR MAXIMUM IMPACT'''
{{header}}
{{article
|author= Shirley Gregor,Alan R. Hevner,
|source= MIS QUARTERLY
|year= 2013
|abstract = Design science research (DSR) has staked its rightful ground as an important and legitimate Information Systems (IS) research paradigm. We contend that DSR has yet to attain its full potential impact on the development and use of information systems due to gaps in the understanding and application of DSR concepts and methods. This essay aims to help researchers (1) appreciate the levels of artifact abstractions that may be DSR contributions, (2) identify appropriate ways of consuming and producing knowledge when they are preparing journal articles or other scholarly works, (3) understand and position the knowledge contributions of their research projects, and (4) structure a DSR article so that it emphasizes significant contributions to the knowledge base. Our focal contribution is the DSR knowledge contribution framework with two dimensions based on the existing state of knowledge in both the problem and solution domains for the research opportunity under study. In addition, we propose a DSR communication schema with similarities to more conventional publication patterns, but which substitutes the description of the DSR artifact in place of a traditional results section. We evaluate the DSR contribution framework and the DSR communication schema via examinations of DSR exemplar publications.
|keyword = Design science research (DSR),knowledge,design artifact,knowledge contribution framework,publication schema,information systems,computer science discipline,engineering discipline,DSR theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE AMBIVALENT ONTOLOGY OF DIGITAL ARTIFACTS'''
{{header}}
{{article
|author= Jannis Kallinikos,Aleksi Aaltonen,Attila Marton,
|source= MIS QUARTERLY
|year= 2013
|abstract = Digital artifacts are embedded in wider and constantly shifting ecosystems such that they become increasingly editable, interactive, reprogrammable, and distributable. This state of flux and constant transfiguration renders the value and utility of these artifacts contingent on shifting webs of functional relations with other artifacts across specific contexts and organizations. By the same token, it apportions control over the development and use of these artifacts over a range of dispersed stakeholders and makes their management a complex technical and social undertaking. These ideas are illustrated with reference to (1) provenance and authenticity of digital documents within the overall context of archiving and social memory and ( 2) the content dynamics occasioned by the findability of content mediated by Internet search engines. We conclude that the steady change and transfiguration of digital artifacts signal a shift of epochal dimensions that calls for rethinking some of the inherited wisdom in IS research and practice.
|keyword = Digital artifacts,digital objects,archives,search engines,information platforms and infrastructures,modularity,reflexivity,change,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''IMPACTFUL RESEARCH ON TRANSFORMATIONAL INFORMATION TECHNOLOGY: AN OPPORTUNITY TO INFORM NEW AUDIENCES'''
{{header}}
{{article
|author= Jr. Henry C. Lucas,Ritu Agarwal,Eric K. Clemons,Omar A. El Sawy,Bruce Weber,
|source= MIS QUARTERLY
|year= 2013
|abstract = Information technology has arguably been one of the most important drivers of economic and social value in the last 50 years, enabling transformational change in virtually every aspect of society. Although the Information Systems community is engaged in significant research on IT, the reach of our findings may be limited. In this commentary, our objective is to focus the IS community's attention on the striking transformations in economic and social systems spawned by IT and to encourage more research that offers useful implications for policy. We present examples of transformations occurring in four distinct sectors of the economy and propose policy-relevant questions that need to be addressed. We urge researchers to write papers based on their findings that inform policy makers, managers, and decision makers about the issues that transformational technologies raise. Finally, we suggest a new outlet to publish these essays on the implications of transformational informational technology.
|keyword = Transformation,strategy,disruptive technology,research policy,academic journals,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''WHEN FILLING THE WAIT MAKES IT FEEL LONGER: A PARADIGM SHIFT PERSPECTIVE FOR MANAGING ONLINE DELAY'''
{{header}}
{{article
|author= Weiyin Hong,Traci J. Hess,Andrew Hardin,
|source= MIS QUARTERLY
|year= 2013
|abstract = As one of the most commonly experienced problems on the Internet, download delay is a significant impediment to the success of e-commerce websites. While some research has examined how such delays can be reduced and how much delay online users will tolerate, little research has taken a theoretically grounded approach to managing perceptions of the wait. Based on time perception theories, we develop a research model of the effects of actual wait time, amount of information, and direction of attention on perceptions of the wait. Two empirical studies were conducted using an experimental travel website to test the proposed hypotheses. The results show that with shorter waits, providing additional visual content, such as a travel picture, may make the wait feel longer. However, with longer waits, additional visual content that distracts the user from the passage of time makes the wait feel shorter and reduces users' negative affect toward the wait. Further, the benefits of providing visual content in longer waits are enhanced as more content is provided. Visual content should also be chosen to distract the user from time and temporal processing, as reminding users of the passage of time can encourage temporal processing and make the wait feel longer, especially in longer waits or when the amount of temporal visual content is high. Our findings extend time perception theories and contribute to the literature by identifying a potential paradigm shift, from the retrospective to the prospective paradigm, when waiting times are prolonged. Post hoc study results confirm the practical contribution of our research, demonstrating that several key findings are counter-intuitive to professional web designers.
|keyword = Online waiting,time perception theory,perceptions of wait,amount of information,visual content,direction of attention,download delay,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''COMMUNITY INTELLIGENCE AND SOCIAL MEDIA SERVICES: A RUMOR THEORETIC ANALYSIS OF TWEETS DURING SOCIAL CRISES'''
{{header}}
{{article
|author= Onook Oh,Manish Agrawal,H. Raghav Rao,
|source= MIS QUARTERLY
|year= 2013
|abstract = Recent extreme events show that Twitter, a micro-blogging service, is emerging as the dominant social reporting tool to spread information on social crises. It is elevating the online public community to the status of first responders who can collectively cope with social crises. However, at the same time, many warnings have been raised about the reliability of community intelligence obtained through social reporting by the amateur online community. Using rumor theory, this paper studies citizen-driven information processing through Twitter services using data from three social crises: the Mumbai terrorist attacks in 2008, the Toyota recall in 2010, and the Seattle cafe shooting incident in 2012. We approach social crises as communal efforts for community intelligence gathering and collective information processing to cope with and adapt to uncertain external situations. We explore two issues: (1) collective social reporting as an information processing mechanism to address crisis problems and gather community intelligence, and (2) the degeneration of social reporting into collective rumor mills. Our analysis reveals that information with no clear source provided was the most important, personal involvement next in importance, and anxiety the least yet still important rumor causing factor on Twitter under social crisis situations.
|keyword = Twitter,social reporting,social information processing,rumor theory,social crisis,extreme events,community intelligence,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''KNOWING WHAT A USER LIKES: A DESIGN SCIENCE APPROACH TO INTERFACES THAT AUTOMATICALLY ADAPT TO CULTURE'''
{{header}}
{{article
|author= Katharina Reinecke,Abraham Bernstein,
|source= MIS QUARTERLY
|year= 2013
|abstract = Adapting user interfaces to a user's cultural background can increase satisfaction, revenue, and market share. Conventional approaches to catering for culture are restricted to adaptations for specific countries and modify only a limited number of interface components, such as the language or date and time formats. We argue that a more comprehensive personalization of interfaces to cultural background is needed to appeal to users in expanding markets. This paper introduces a low-cost, yet efficient method to achieve this goal: cultural adaptivity. Culturally adaptive interfaces are able to adapt their look and feel to suit visual preferences. In a design science approach, we have developed a number of artifacts that support cultural adaptivity, including a prototype web application. We evaluate the efficacy of the prototype's automatically generated interfaces by comparing them with the preferred interfaces of 105 Rwandan, Swiss, Thai, and multicultural users. The findings demonstrate the feasibility of providing users with interfaces that correspond to their cultural preferences in a novel yet effective manner.
|keyword = Culture,design science,adaptive systems,personalization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''THE IMPACT OF SHAPING ON KNOWLEDGE REUSE FOR ORGANIZATIONAL IMPROVEMENT WITH WIKIS'''
{{header}}
{{article
|author= Ann Majchrzak,Christian Wagner,Dave Yates,
|source= MIS QUARTERLY
|year= 2013
|abstract = In this study, we explore the Wiki affordance of enabling shaping behavior within organizational intranets supported by Wikis. Shaping is the continuous revision of one's own and others' contributions to a Wiki. Shaping promotes knowledge reuse through improved knowledge integration. Recognizing and clarifying the role of shaping allows us to theorize new ways in which knowledge resources affect knowledge reuse. We examine the role of three knowledge resources of a Wiki contributor: knowledge depth, knowledge breadth, and assessment of the level of development of the Wiki community's transactive memory system. We offer preliminary evidence based on a sample of experienced organizational Wiki users that the three different knowledge resources have differential effects on shaping, that these effects differ from the effects on the more common user behavior of simply adding domain knowledge to a Wiki, and that shaping and adding each independently affect contributors' perceptions that their knowledge in the Wiki has been reused for organizational improvement. By empirically distinguishing between the different knowledge antecedents and consequences of shaping and adding, we derive implications for theory and research on knowledge integration and reuse.
|keyword = Wiki,Intranet,knowledge management,KMS,knowledge reuse,shaping,knowledge depth,knowledge breadth,transactive memory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DIGITAL BUSINESS STRATEGY: TOWARD A NEXT GENERATION OF INSIGHTS'''
{{header}}
{{article
|author= Anandhi Bharadwaj,Omar A. El Sawy,Paul A. Pavlou,N. Venkatraman,
|source= MIS QUARTERLY
|year= 2013
|abstract = Over the last three decades, the prevailing view of information technology strategy has been that it is a functional-level strategy that must be aligned with the firm's chosen business strategy. Even within this so-called alignment view, business strategy directed IT strategy. During the last decade, the business infrastructure has become digital with increased interconnections among products, processes, and services. Across many firms spanning different industries and sectors, digital technologies (viewed as combinations of information, computing, communication, and connectivity technologies) are fundamentally transforming business strategies, business processes, firm capabilities, products and services, and key interfirm relationships in extended business networks. Accordingly, we argue that the time is right to rethink the role of IT strategy, from that of a functional-level strategy-aligned but essentially always subordinate to business strategy-to one that reflects a fusion between IT strategy and business strategy. This fusion is herein termed digital business strategy. We identify four key themes to guide our thinking on digital business strategy and help provide a framework to define the next generation of insights. The four themes are (1) the scope of digital business strategy, (2) the scale of digital business strategy, (3) the speed of digital business strategy, and (4) the sources of business value creation and capture in digital business strategy. After elaborating on each of these four themes, we discuss the success metrics and potential performance implications from pursuing a digital business strategy. We also show how the papers in the special issue shed light on digital strategies and offer directions to advance insights and shape future research.
|keyword = Digital business strategy,scope of digital business strategy,scale of digital business strategy,speed of digital business strategy,digital business strategy value creation and capture,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''INFORMATION TECHNOLOGY AND BUSINESS-LEVEL STRATEGY: TOWARD AN INTEGRATED THEORETICAL PERSPECTIVE'''
{{header}}
{{article
|author= Paul L. Drnevich,David C. Croson,
|source= MIS QUARTERLY
|year= 2013
|abstract = Information technology matters to business success because it directly affects the mechanisms through which they create and capture value to earn a profit: IT is thus integral to a firm's business-level strategy. Much of the extant research on the IT/strategy relationship, however, inaccurately frames IT as only a functional-level strategy. This widespread under-appreciation of the business-level role of IT indicates a need for substantial retheorizing of its role in strategy and its complex and interdependent relationship with the mechanisms through which firms generate profit. Using a comprehensive framework of potential profit mechanisms, we argue that while IT activities remain integral to the functional-level strategies of the firm, they also play several significant roles in business strategy, with substantial performance implications. IT affects industry structure and the set of business-level strategic alternatives and value-creation opportunities that a firm may pursue. Along with complementary organizational changes, IT both enhances the firm's current (ordinary) capabilities and enables new (dynamic) capabilities, including the flexibility to focus on rapidly changing opportunities or to abandon losing initiatives while salvaging substantial asset value. Such digitally attributable capabilities also determine how much of this value, once created, can be captured by the firm-and how much will be dissipated through competition or through the power of value chain partners, the governance of which itself depends on IT. We explore these business-level strategic roles of IT and discuss several provocative implications and future research directions in the converging information systems and strategy domains.
|keyword = Management theory,information technology,information systems,competitive advantage,performance,technology management,IT capability,IT strategy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''HOW A FIRM'S COMPETITIVE ENVIRONMENT AND DIGITAL STRATEGIC POSTURE INFLUENCE DIGITAL BUSINESS STRATEGY'''
{{header}}
{{article
|author= Sunil Mithas,Ali Tafti,Will Mitchell,
|source= MIS QUARTERLY
|year= 2013
|abstract = In this paper, we examine how the competitive industry environment shapes the way that digital strategic posture (defined as a focal firm's degree of engagement in a particular class of digital business practices relative to the industry norm) influences firms' realized digital business strategy. We focus on two forms of digital strategy: general IT investment and IT outsourcing investment. Drawing from prior literature on determinants of IT activity and competitive dynamics, we argue that three elements of the industry environment determine whether digital strategic posture has an increasingly convergent or divergent influence on digital business strategy. By divergent influence, we mean an influence that leads to spending substantially more or less on a particular strategic activity than industry norms. We predict that a digital strategic posture (difference from the industry mean) has an increasingly divergent effect on digital business strategy under higher industry turbulence, while having an increasingly convergent effect on digital business strategy under higher industry concentration and higher industry growth. The study uses archival data for 400 U.S.-based firms from 1999 to 2006. Our findings imply that digital business strategy is not solely a matter of optimizing firm operations internally or of responding to one or two focal competitors, but also arises strikingly from awareness and responsiveness to the digital business competitive environment. Collectively, the findings provide insights on how strategic posture and industry environment influence firms' digital business strategy.
|keyword = Digital business strategy,strategic posture,industry environment,industry turbulence,industry competition,industry growth,IT investments,IT strategy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DESIGN CAPITAL AND DESIGN MOVES: THE LOGIC OF DIGITAL BUSINESS STRATEGY'''
{{header}}
{{article
|author= C. Jason Woodard,Narayan Ramasubbu,F. Ted Tschang,V. Sambamurthy,
|source= MIS QUARTERLY
|year= 2013
|abstract = As information technology becomes integral to the products and services in a growing range of industries, there has been a corresponding surge of interest in understanding how firms can effectively formulate and execute digital business strategies. This fusion of IT within the business environment gives rise to a strategic tension between investing in digital artifacts for long-term value creation and exploiting them for short-term value appropriation. Further, relentless innovation and competitive pressures dictate that firms continually adapt these artifacts to changing market and technological conditions, but sustained profitability requires scalable architectures that can serve a large customer base and stable interfaces that support integration across a diverse ecosystem of complementary offerings. The study of digital business strategy needs new concepts and methods to examine how these forces are managed in pursuit of competitive advantage. We conceptualize the logic of digital business strategy in terms of two constructs: design capital (i.e., the cumulative stock of designs owned or controlled by a firm) and design moves (i.e., the discrete strategic actions that enlarge, reduce, or modify a firm's stock of designs). We also identify two salient dimensions of design capital, namely, option value and technical debt. Using embedded case studies of four firms, we develop a rich conceptual model and testable propositions to lay out a design-based logic of digital business strategy. This logic highlights the interplay between design moves and design capital in the context of digital business strategy and contributes to a growing body of insights that link the design of digital artifacts to competitive strategy and firm-level performance.
|keyword = Design capital,design moves,digital options,technical debt,IT architecture,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''LEVERAGING DIGITAL TECHNOLOGIES: HOW INFORMATION QUALITY LEADS TO LOCALIZED CAPABILITIES AND CUSTOMER SERVICE PERFORMANCE'''
{{header}}
{{article
|author= Pankaj Setia,Viswanath Venkatesh,Supreet Joglekar,
|source= MIS QUARTERLY
|year= 2013
|abstract = With the growing recognition of the customer's role in service creation and delivery, there is an increased impetus on building customer-centric organizations. Digital technologies play a key role in such organizations. Prior research studying digital business strategies has largely focused on building production-side competencies and there has been little focus on customer-side digital business strategies to leverage these technologies. We propose a theory to understand the effectiveness of a customer-side digital business strategy focused on localized dynamics-here, a firm's customer service units (CSUs). Specifically, we use a capabilities perspective to propose digital design as an antecedent to two customer service capabilities-namely, customer orientation capability and customer response capability-across a firm's CSUs. These two capabilities will help a firm to locally sense and respond to customer needs, respectively. Information quality from the digital design of the CSU is proposed as the antecedent to the two capabilities. Proposed capability-building dynamics are tested using data collected from multiple respondents across 170 branches of a large bank. Findings suggest that the impacts of information quality in capability-building are contingent on the local process characteristics. We offer implications for a firm's customer-side digital business strategy and present new areas for future examination of such strategies.
|keyword = Customer service,capabilities,information quality,process,customer response,customer orientation,business value of IT,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''CONTENT OR COMMUNITY? A DIGITAL BUSINESS STRATEGY FOR CONTENT PROVIDERS IN THE SOCIAL AGE'''
{{header}}
{{article
|author= Gal Oestreicher-Singer,Lior Zalmanson,
|source= MIS QUARTERLY
|year= 2013
|abstract = The content industry has been undergoing a tremendous transformation in the last two decades. We focus in this paper on recent changes in the form of social computing. Although the content industry has implemented social computing to a large extent, it has done so from a techno-centric approach in which social features are viewed as complementary rather than integral to content. This approach does not capitalize on users' social behavior in the website and does not answer the content industry's need to elicit payment from consumers. We suggest that both of these objectives can be achieved by acknowledging the fusion between content and community, making the social experience central to the content website's digital business strategy. We use data from Last.fm, a site offering both music consumption and online community features. The basic use of Last.fm is free, and premium services are provided for a fixed monthly subscription fee. Although the premium services on Last.fm are aimed primarily at improving the content consumption experience, we find that willingness to pay for premium services is strongly associated with the level of community participation of the user. Drawing from the literature on levels of participation in online communities, we show that consumers' willingness to pay increases as they climb the so-called "ladder of participation" on the website. Moreover, we find that willingness to pay is more strongly linked to community participation than to the volume of content consumption. We control for self-selection bias by using propensity score matching. We extend our results by estimating a hazard model to study the effect of community activity on the time between joining the website and the subscription decision. Our results suggest that firms whose digital business models remain viable in a world of "freemium" will be those that take a strategic rather than techno-centric view of social media, that integrate social media into the consumption and purchase experience rather than use it merely as a substitute for offline soft marketing. We provide new evidence of the importance of fusing social computing with content delivery and, in the process, lay a foundation for a broader strategic path for the digital content industry in an age of growing user participation.
|keyword = Premium services,social media,online communities,propensity score matching,UGC,digital business strategy,ladder of participation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''DIGITAL BUSINESS STRATEGY AND VALUE CREATION: FRAMING THE DYNAMIC CYCLE OF CONTROL POINTS'''
{{header}}
{{article
|author= Margherita Pagani,
|source= MIS QUARTERLY
|year= 2013
|abstract = Within changing value networks, the profits and competitive advantages of participation reside dynamically at control points that are the positions of greatest value and/or power. The enterprises that hold these positions have a great deal of control over how the network operates, how the benefits are redistributed, and how this influences the execution of a digital business strategy. This article is based on a field study that provides preliminary, yet promising, empirical evidence that sheds light on the dynamic cycle of value creation and value capture points in digitally enabled networks in response to triggers related to technology and business strategy. The context used is that of the European and U. S. broadcasting industry. Specifically, the paper illustrates how incremental innovations may shift value networks from static, vertically integrated networks to more loosely coupled networks, and how cross-boundary industry disruptions may then, in turn, shift those to two-sided markets. Based on the analysis, insights and implications for digital business strategy research and practice are then provided.
|keyword = Control points,incremental innovation,disruptive innovation,digital business strategy,value network,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''TRANSPARENCY STRATEGY: COMPETING WITH INFORMATION IN A DIGITAL WORLD'''
{{header}}
{{article
|author= Nelson Granados,Alok Gupta,
|source= MIS QUARTERLY
|year= 2013
|abstract = We contend that in order to compete effectively in a digital business environment, firms should develop a transparency strategy by selectively disclosing information outside the boundaries of the firm. We make the case for transparency strategy by showing why it is relevant in the digital business world, and the consequences of not having such a strategy. We then provide some foundations to develop the strategy and make a call for research.
|keyword = Digital business strategy,electronic markets,transparency strategy,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''REVEALING YOUR HAND: CAVEATS IN IMPLEMENTING DIGITAL BUSINESS STRATEGY'''
{{header}}
{{article
|author= Varun Grover,Rajiv Kohli,
|source= MIS QUARTERLY
|year= 2013
|abstract = Digital business strategies (DBS) offer significant opportunities for firms to enhance competitiveness. Unlike the large proprietary systems of the 1980s, today's "micro-applications" allow firms to create and reconfigure digital capabilities to appropriate short-term competitive advantage. In the quest to provide value to customers through digitization, such applications can be efficiently deployed. However, we propose that in the long-term not all digitization is desirable. Indiscriminate digital initiatives through the use of micro-applications by a firm could "reveal its hand" to competitors and erode competitiveness. We propose that a firm's DBS must balance its system-software, process, and information-visibility with the ability to appropriate value from such systems. Through a visibility-value framework, and examples drawn from practice, this article illustrates the tradeoffs involved in making these choices as the firm traverses a dynamic business environment. In doing so, it raises sensitivity to an important caveat in digital environments epitomized by hyper-competition and transparency.
|keyword = Digital business strategy,competitiveness,flexibility,phasing,design,digitization,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Effect of Social Capital of the Relationship Between the CIO and Top Management Team on Firm Performance'''
{{header}}
{{article
|author= Elena Karahanna,David S. Preston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = The paper empirically examines the effects of social capital of the relationship between the chief information officer (CIO) and top management team (TMT) on organizational value creation based on responses from CIOs and matched TMT respondents from 81 hospitals in the United States. Specifically, we theorize how the three dimensions of social capital-structural, cognitive, and relational social capital-facilitate knowledge exchange and combination between the CIO and TMT resulting in the alignment between the organization's information systems (IS) strategy and business strategy. Results show that IS alignment significantly influences the firm's financial performance and mediates the relationship between CIO-TMT social capital and performance. The findings also indicate that cognitive and relational social capital influence information systems strategic alignment but that structural social capital exerts its influence through its effects on cognitive social capital. Recommendations are provided as to how organizations can develop CIO-TMT structural, cognitive, and relational social capital to positively influence firm performance via IS strategic alignment.
|keyword = chief information officer,cognitive social capital,financial performance,information systems,IS leadership,relational social capital,social capital,strategic alignment,structural social capital,top management team,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Sustainability of a Firm's Reputation for Information Technology Capability: The Role of Senior IT Executives'''
{{header}}
{{article
|author= Jee-Hae Lim,Theophanis C. Stratopoulos,Tony S. Wirjanto,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = This study investigates the development and sustainability of a firm's information technology (IT) capability reputation from an IT executive's standpoint. Building on institutional theory, we argue that IT executives will try to achieve external legitimacy (i.e., project an image of superior IT capability to external stakeholders) in the hope that the top management team and board members will reciprocate by elevating the internal legitimacy of IT executives. Firms that develop such a culture of reciprocity with their IT executives are more likely to sustain their IT capability reputation. Econometric results based on panel data for 1,326 large U. S. firms from a wide spectrum of industries over a 13-year period (1997-2009) validate these predictions. More specifically, we find that IT executives with greater structural power (e. g., higher job titles) or IT-related expert power (e. g., IT-related education or experience) are more likely to attract public recognition for their firm's IT capability. Firms that build such an IT capability reputation are more likely to promote their IT executives, and IT executives who are promoted are more likely to stay longer with their firms. This continuity in IT strategic leadership is positively associated with the firm's ability to sustain its IT capability reputation. Our findings have important practical implications related to a firm's IT reputation strategy as well as the motivation and career of IT executives. Firms wanting to develop and sustain their IT capability reputation would do well to foster the creation of a cycle of positive reciprocity with their IT executives. IT executives hoping to increase their power within their firm's top management team and improve the legitimacy of the firm's IT organization need to project an image of IT superiority to external stakeholders.
|keyword = external legitimacy,institutional theory,internal legitimacy,IT capability reputation,IT executives,IT strategic leadership,reciprocity,structural power,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Technology and Productivity in Developed and Developing Countries'''
{{header}}
{{article
|author= Jason Dedrick,Keneth L. Kraemer,Eric Shih,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Previous research has found that information technology (IT) investment is associated with significant productivity gains for developed countries but not for developing countries. Yet developing countries have continued to increase their investment in IT rapidly. Given this apparent disconnect, there is a need for new research to study whether the investment has begun to pay off in greater productivity for developing countries. We analyze new data on IT investment and productivity for 45 countries from 1994 to 2007, and compare the results with earlier research. We find that upper-income developing countries have achieved positive and significant productivity gains from IT investment in the more recent period as they have increased their IT capital stocks and gained experience with the use of IT. We also find that the productivity effects of IT are moderated by country factors, including human resources, openness to foreign investment, and the quality and cost of the telecommunications infrastructure. The academic implication is that the effect of IT on productivity is expanding from the richest countries into a large group of developing countries. The policy implication is that lower-tier developing countries can also expect productivity gains from IT investments, particularly through policies that support IT use, such as greater openness to foreign investment, increased investment in tertiary education, and reduced telecommunications costs.
|keyword = developed countries,developing countries,human resources,IT and productivity,longitudinal analysis,openness to trade and investment,production function,telecommunications cost,telecommunications infrastructure,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Managing Interdependent Information Security Risks: Cyberinsurance, Managed Security Services, and Risk Pooling Arrangements'''
{{header}}
{{article
|author= Xia Zhao,Ling Xue,Andrew B. Whinston,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = The interdependency of information security risks often induces firms to invest inefficiently in information technology security management. Cyberinsurance has been proposed as a promising solution to help firms optimize security spending. However, cyberinsurance is ineffective in addressing the investment inefficiency caused by risk interdependency. In this paper, we examine two alternative risk management approaches: risk pooling arrangements (RPAs) and managed security services (MSSs). We show that firms can use an RPA as a complement to cyberinsurance to address the overinvestment issue caused by negative externalities of security investments; however, the adoption of an RPA is not incentive-compatible for firms when the security investments generate positive externalities. We then show that the MSS provider serving multiple firms can internalize the externalities of security investments and mitigate the security investment inefficiency. As a result of risk interdependency, collective outsourcing arises as an equilibrium only when the total number of firms is small.
|keyword = cyberinsurance,information security,interdependent risks,managed security services,risk management,risk pooling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Drivers in the Use of Online Whistle-Blowing Reporting Systems'''
{{header}}
{{article
|author= Paul Benjamin Lowry,Gregory D. Moody,Denis F. Galletta,Anthony Vance,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Online whistle-blowing reporting systems (WBRS) have become increasingly prevalent channels for reporting organizational failures. The Sarbanes-Oxley Act and similar international laws now require firms to establish whistle-blowing (WB) procedures and WBRSs, increasing the importance of WB research and applications. Although the literature has addressed conventional WB behavior, it has not explained or measured the use of WBRSs in online contexts that could significantly alter elements of anonymity, trust, and risk for those using such reporting tools. This study proposes the WBRS model (WBRS-M). Using actual working professionals in an online experiment of hypothetical scenarios, we empirically tested the WBRS-M for reporting computer abuse and find that anonymity, trust, and risk are highly salient in the WBRS context. Our findings suggest that we have an improved WB model with increased explanatory power. Organizations can make WB less of a professional taboo by enhancing WBRS users' perceptions of trust and anonymity. We also demonstrate that anonymity means more than the mere lack of identification, which is not as important in this context as other elements of anonymity.
|keyword = anonymity,computer abuse,IT artifacts,organizational failure,organizational governance,risk,trust,whistle-blowing,whistle-blowing reporting systems,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Impact of Influence Tactics in Information System Development Projects: A Control-Loss Perspective'''
{{header}}
{{article
|author= Ravi Narayanaswamy,Varun Grover,Raymond M. Henry,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Information systems development (ISD) projects are prone to high levels of failure. One of the major reasons attributed to these failures is the inability to harmonize values held by a diverse set of participants in an environment that is characterized by uncertainty due to changing requirements. In this paper, we focus on a relational approach to achieve congruence between a project manager and a team member with respect to influence tactics. Constructs of perceptual congruence and communication congruence that reflect a level of agreement and degree of shared understanding between the project manager and team members are described. A congruence model is constructed and tied to an intermediate outcome variable of control loss. One hundred and thirteen dyadic pairs of project managers and team members are surveyed in order to test the model. The results indicate that having strong relational equity and common understanding can minimize control loss. It is important to consider the perspectives of both the project manager and a team member while formulating and assessing monitoring strategies to promote the success of an ISD project. Especially, encouraging team members to discuss disagreements constructively can motivate them to perform better and keep things under control. Finally, it is critical to address the performance problems as they occur rather than wait until the completion of the project.
|keyword = developer relationships,development project,influence tactics,information systems development,leadership exchange,project management,project manager,shared understanding,teams,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Service-Oriented Methodology for Systems Development'''
{{header}}
{{article
|author= Mark Keith,Haluk Demirkan,Michael Goul,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Despite advances in software development practices, organizations struggle to implement methodologies that match the risk in a project environment with needed coordination capabilities. Plan-driven and agile software development methodologies each have strengths and risks. However, most project environments cannot be classified as entirely "risky" or "stable," suggesting the need for hybrid approaches. We leverage a design science approach to implement a novel hybrid methodology based on concepts from the service-oriented paradigm. We motivate the approach using theory on interdependence and coordination, and design the methodology using theory on modularity and service-dominant logic. We also examine the effects of its adoption at a large electrical power company over a three-year period. The results imply that service-oriented theory should be applied to the human processes involved in systems development in order to achieve better fit between project risk, interdependencies, and the selected methodology(ies) in order to improve overall project performance.
|keyword = design science,modularization,project management,service orientation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''A Test of Two Models of Value Creation in Virtual Communities'''
{{header}}
{{article
|author= Constance Elise Porter,Sarv Devaraj,Daewon Sun,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Does a firm get any extra value from investing resources in sponsoring its own virtual community above and beyond the value that could be created for the firm, indirectly, via customer-initiated communities? If so, what explains the extra value derived from a firm-sponsored virtual community and how might this understanding inform managers about appropriate strategies for leveraging virtual communities as part of a value-creating strategy for the firm? We test two models of virtual community to help shed light on the answers to these questions. We hypothesize that in customer-initiated virtual communities, three attributes of member-generated information (MGI) drive value, while in firm-sponsored virtual communities, a sponsoring firm's efforts, as well as MGI, drive value. Drawing on information search and processing theories, and developing new measures of three attributes of MGI (consensus, consistency, and distinctiveness), we surveyed 465 consumers across numerous communities. We find that value can emerge via both models, but that in a firm-sponsored model, a sponsor's efforts are more powerful than MGI and have a positive, direct effect on the trust-building process. Our results suggest a continuum of value creation whereby firms extract greater value as they migrate toward the firm-sponsored model.
|keyword = attribution theory,co-creation,online communities,online trust,user-generated content,virtual communities,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Credibility of Anonymous Online Product Reviews: A Language Expectancy Perspective'''
{{header}}
{{article
|author= Matthew L. Jensen,Joshua M. Averbeck,Zhu Zhang,Kevin B. Wright,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Online reviews play a significant role in forming and shaping perceptions about a product. With the credibility of online reviewers a frequent question, this research investigates how potential buyers assess the credibility of anonymous reviewers. Technology separates the reviewer from the review, and potential buyers are left to rely on characteristics of the review itself to determine the credibility of the reviewer. By extending the language expectancy theory to the online setting, we develop hypotheses about how expectancy violations of lexical complexity, two-sidedness (highlighting positive and negative aspects of a product), and affect intensity influence credibility attributions. We present an experiment in which favorable experimental reviews were generated based on actual reviews for a digital camera. The results indicate that two-sidedness caused a positive expectancy violation resulting in greater credibility attribution. High affect intensity caused a negative expectancy violation resulting in lower credibility attribution. Finally, high reviewer credibility significantly improved perceptions of product quality. Our results demonstrate the importance of expectancies and violations when attributing credibility to anonymous individuals. Even small expectancy violations can meaningfully influence reviewer credibility and perceptions of products.
|keyword = affect intensity,credibility,electronic word of mouth,eWOM,language expectancy theory,lexical complexity,persuasion,product reviews,two-sidedness,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Risk Mitigation in Supply Chain Digitization: System Modularity and Information Technology Governance'''
{{header}}
{{article
|author= Ling Xue,Cheng Zhang,Hong Ling,Xia Zhao,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Firms face significant risk when they adopt digital supply chain systems to transact and coordinate with their partners. Drawn upon modular systems theory, this study proposes that system modularity mitigates the risk of adopting digital supply chain systems and therefore motivates firms to digitize more of their supply chain operations. The study theorizes how the risk-mitigating effect of system modularity can be enhanced by the allocation of decision rights to the IT (information technology) unit. The main logic is that IT managers with more domain IT knowledge can better utilize their knowledge in decision making to achieve effective system modularity. We tested these theoretical propositions using a survey study of Chinese companies and found empirical support. We also found that the allocation of decision rights to the IT unit does not directly mitigate the perceived risk of digital supply chain systems, which highlights the role of decision allocation to the IT unit as a key moderator in risk mitigation. The study generates theoretical and practical implications on how IT governance and system modularity may jointly mitigate risk and foster supply chain digitization.
|keyword = IT governance,modular systems,risk mitigation,supply chain management,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Association Between the Disclosure and the Realization of Information Security Risk Factors'''
{{header}}
{{article
|author= Tawei Wang,Karthik N. Kannan,Jackie Rees Ulmer,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Firms often disclose information security risk factors in public filings such as 10-K reports. The internal information associated with disclosures may be positive or negative. In this paper, we evaluate how the nature of the disclosed security risk factors, believed to represent the firm's internal information regarding information security, is associated with future breach announcements reported in the media. For this purpose, we build a decision tree model, which classifies the occurrence of future security breaches based on the textual contents of the disclosed security risk factors. The model is able to accurately associate disclosure characteristics with breach announcements about 77% of the time. We further explore the contents of the security risk factors using text-mining techniques to provide a richer interpretation of the results. The results show that the disclosed security risk factors with risk-mitigation themes are less likely to be related to future breach announcements. We also investigate how the market interprets the nature of information security risk factors in annual reports. We find that the market reaction following the security breach announcement is different depending on the nature of the preceding disclosure. Thus, our paper contributes to the literature in information security and sheds light on how market participants can better interpret security risk factors disclosed in financial reports at the time when financial reports are released.
|keyword = information security,information security incident,risk factor,text mining,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Breaking the Ice in B2C Relationships: Understanding Pre-Adoption E-Commerce Attraction'''
{{header}}
{{article
|author= Damon E. Campbell,John D. Wells,Joseph S. Valacich,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = This research proposes that the forming of a business-to-consumer (B2C) customer relationship is part of a multiphased technology adoption process where attraction is the first step in this sequence. A conceptual model, called the electronic commerce (e-commerce) attraction model (eCAM), offers a theoretical foundation for guiding two empirical studies (N = 345 and N = 240, respectively) investigating how initial customer perceptions of a website influence attraction toward this website. The results support the eCAM as a new theoretical lens for understanding electronic commerce-based attraction. Comparisons are made between the proposed eCAM and previously established adoption models (i.e., the Technology Acceptance Model and WebQual) as well as the discriminant validity of the constructs in these models. Results demonstrate that the eCAM provides additional insights for understanding how website design influences e-commerce attraction and adoption. The implications of these results for future research and website design are discussed.
|keyword = attraction,competitive impacts of IS,electronic commerce,field experiments,IT adoption,laboratory experiments,questionnaire surveys,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Digital Divide Initiative Success in Developing Countries: A Longitudinal Field Study in a Village in India'''
{{header}}
{{article
|author= Viswanath Venkatesh,Tracy Ann Sykes,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Digital divide initiatives in developing countries are an important avenue for the socioeconomic advancement of those countries. Yet little research has focused on understanding the success of such initiatives. We develop a model of technology use and economic outcomes of digital divide initiatives in developing countries. We use social networks as the guiding theoretical lens because it is well suited to this context, given the low literacy, high poverty, high collectivism, and an oral tradition of information dissemination in developing countries. We test our model with longitudinal data gathered from 210 families in a rural village in India in the context of a digital divide initiative. As theorized, we found that the social network constructs contributed significantly to the explanation of technology use (R-2 = 0.39). Also as we predicted, technology use partially mediated the effect of social network constructs on economic outcomes (R-2 = 0.47). We discuss implications for theory and practice.
|keyword = Internet kiosk,system use,economic benefits,digital divide,technology adoption,technology diffusion,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Governance of Interorganizational Information Systems: A Resource Dependence Perspective'''
{{header}}
{{article
|author= Dipanjan Chatterjee,T. Ravichandran,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = In this paper we examine why firms seek to control and own interorganizational information systems, or IOS. Practitioners have largely cited the issues related to control and ownership of IOS, referred to as IOS governance in this paper, as the key reason behind the failure of many IOS initiatives. We distinguish between two IOS governance modes, transactional and financial, and develop a mediated-moderation model to explain the factors influencing the governance choices. In our model, the key motivators of IOS governance are the criticality and the replaceability of the resources that firms procure, which affect IOS governance through their influence on the degree of operational integration existing between partners. We hypothesize that while resource criticality will increase the needs for financial and transactional governance because of its positive impact on operational integration, resource replaceability will negatively influence governance needs because of its negative impact on operational integration. Furthermore, technological uncertainty associated with the resources is argued to negatively impact the extent of IOS governance exercised by firms by weakening the positive impact of resource criticality and strengthening the negative impact of resource replaceability on operational integration respectively. We empirically test our model using data gathered from a survey of 159 United States manufacturing firms. Results show that resource criticality positively affects the extent of financial and transactional IOS governance by increasing the need for operational integration, whereas resource replaceability negatively affects them by reducing the need for operational integration. Furthermore, technological uncertainty creates disincentives for IOS governance primarily by weakening the positive influence of resource criticality on operational integration, while no statistically significant effect of technological uncertainty on the relationship between resource replaceability and operational integration was discerned.
|keyword = interorganizational information systems,IOS governance,inter-firm relationships,procurement systems,resource dependence theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Ensuring Employees' IT Compliance: Carrot or Stick?'''
{{header}}
{{article
|author= Huigang Liang,Yajiong Xue,Liansheng Wu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = With reward (carrot) and punishment (stick) widely applied by organizations to regulate mandatory IT usage, it is imperative to understand how these incentives influence employee compliance behavior. Drawing upon control theory and regulatory focus theory, this study investigates the relationships among regulatory focus, reward, punishment, and compliance behavior in mandatory IT settings. Survey data were collected from 186 employees in companies where enterprise resource planning (ERP) compliance was mandated. Analyses reveal that punishment expectancy is a strong determinant of compliance behavior, whereas the main effect of reward expectancy is not significant. Moreover, the relationship between reward expectancy and compliance behavior is moderated by promotion focus and the relationship between punishment expectancy and compliance behavior is moderated by prevention focus. This study provides an in-depth understanding of reward and punishment in mandatory IT settings and suggests that regulatory focus plays an important role in affecting employees' compliance with organizational controls.
|keyword = organizational control,reward,punishment,regulatory focus,promotion focus,prevention focus,compliance,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Contracting Information Security in the Presence of Double Moral Hazard'''
{{header}}
{{article
|author= Chul Ho Lee,Xianjun Geng,Srinivasan Raghunathan,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = In information security outsourcing, it is the norm that the outsourcing firms and the outsourcers (commonly called managed security service providers, MSSPs) need to coordinate their efforts for better security. Nevertheless, efforts are often private and thus both firms and MSSPs can suffer from double moral hazard. Furthermore, the double moral hazard problem in security outsourcing is complicated by the existence of strong externality and the multiclient nature of MSSP services. In this prescriptive research, we first show that the prevailing contract structure in security outsourcing, bilateral refund contract, cannot solve double moral hazard. Adding breach-contingent sunk cost or external payment cannot solve double moral hazard either. Furthermore, positive externality can worsen double moral hazard. We then propose a new contract structure termed multilateral contract and show that it can solve double moral hazard and induce first-best efforts from all contractual parties when an MSSP serves two or more client firms, regardless of the externality. Firm-side externality significantly affects how payments flow under a multilateral contract when a security breach happens. When the number of client firms for an MSSP increases, we show that the contingent payments under multilateral contracts for any security breach scenario can be easily calculated using an additive method, and thus are computationally simple to implement.
|keyword = information security outsourcing,managed security service providers,double moral hazard,externality,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Effects of Diversity in Global, Distributed Collectives: A Study of Open Source Project Success'''
{{header}}
{{article
|author= Sherae Daniel,Ritu Agarwal,Katherine J. Stewart,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Diversity is a defining characteristic of global collectives facilitated by the Internet. Though substantial evidence suggests that diversity has profound implications for a variety of outcomes including performance, member engagement, and withdrawal behavior, the effects of diversity have been predominantly investigated in the context of organizational workgroups or virtual teams. We use a diversity lens to study the success of nontraditional virtual work groups exemplified by open source software (OSS) projects. Building on the diversity literature, we propose that three types of diversity (separation, variety, and disparity) influence two critical outcomes for OSS projects: community engagement and market success. We draw on the OSS literature to further suggest that the effects of diversity on market success are moderated by the application development stage. We instantiate the operational definitions of three forms of diversity to the unique context of open source projects. Using archival data from 357 projects hosted on SourceForge, we find that disparity diversity, reflecting variation in participants' contribution-based reputation, is positively associated with success. The impact of separation diversity, conceptualized as culture and measured as diversity in the spoken language and country of participants, has a negative impact on community engagement but an unexpected positive effect on market success. Variety diversity, reflected in dispersion in project participant roles, positively influences community engagement and market success. The impact of diversity on market success is conditional on the development stage of the project. We discuss how the study's findings advance the literature on antecedents of OSS success, expand our theoretical understanding of diversity, and present the practical implications of the results for managers of distributed collectives.
|keyword = open source software,diversity,global collectives,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''The Framing Effects of Multipart Pricing on Consumer Purchasing Behavior of Customized Information Good Bundles'''
{{header}}
{{article
|author= Kim Huat Goh,Jesse C. Bockstedt,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Applying behavioral economic theories, we hypothesize that consumers have sticky reference prices for individual information goods, but their perceived value for customizable bundle offers can be significantly influenced by the framing of a multipart pricing scheme. The potential impacts of these framing effects are measurable changes in consumer behavior and sales outcomes. We conducted a series of behavioral experiments and a large-scale natural field experiment involving actual purchases of customized information good bundles to confirm and analyze the hypothesized effects. The results demonstrate a consumer's willingness to purchase a customized bundle of information goods, the size of the resulting bundling, and the consumer's perceptions of the transaction are each significantly influenced by the design of the multipart pricing scheme. These results hold even when the final price and size of a customized bundle are the same across differing schemes. We discuss the potential tradeoffs in economic outcomes that result from price framing (e.g., likelihood of sale versus size of purchased bundles) and the implications for information good retailers.
|keyword = behavioral economics,behavioral experiments,bundling,customization,consumer behavior,econometrics,information goods,multipart pricing,natural experiments,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Multicommunicating: Juggling Multiple Conversations in the Workplace'''
{{header}}
{{article
|author= Ann-Frances Cameron,Jane Webster,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = As a result of newer communication technologies and an increase in virtual communication, employees often find themselves multicommunicating, or participating in multiple conversations at the same time. This research seeks to explore multicommunicating from the perspective of the person juggling multiple conversations at the same time-the focal individual. To better understand this phenomenon, we extend previous theorizing by including the concepts of the episode initiator (whether the second conversation was focal or partner initiated), the fit of the set of media used in the episode, one process gain (conversation leveraging), and process losses. Employing a series of pilot studies and a main study, the resulting model was analyzed using structural equation modeling, finding overall support for the model. Findings suggest that experienced intensity is an important factor influencing process losses experienced during multicommunicating, whereas episode initiator influences process losses and the process gain. Further, media fit moderates the relationship between intensity and process losses. The importance of multicommunicating in the workplace is discussed, the theoretical and practical contributions of this research are described, and limitations and suggestions for future research are outlined.
|keyword = multicommunicating,polychronic communication,multitasking,dual-task performance,fit,productivity,process losses,intensity,PLS,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Sequential Pricing of Multiple Products: Leveraging Revealed Preferences of Retail Customers Online and with Auto-ID Technologies'''
{{header}}
{{article
|author= John Aloysius,Cary Deck,Amy Farmer,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Technological advances enable sellers to price discriminate based on a customer's revealed purchasing intentions. E-tailers can track items in online shopping carts and radio frequency identification tags enable retailers to do the same in brick-and-mortar stores. To leverage this information, it is important to understand how this new visibility impacts pricing and market outcomes. We propose a model in which a seller sets prices for goods A and B, allowing for the possibility of sequentially revising the price for good B if the buyer reveals a preference for good A by making an initial purchase decision. We derive comparative statics results for the prices of products that have superadditive or subadditive values, and also for the associated profits. We also run simulations for a range of distributions of buyer values, to compare sequential pricing with mixed bundling. The results indicate that information technology-enabled sequential pricing can increase profits relative to mixed bundling or pure components pricing for substitute goods due to a reduction of intraseller competition. We also consider the case of goods with positively or negatively correlated values and find that when sellers can condition the second good's price on the buyer's decision to purchase the first good, sequential pricing increases profits when customer's values for the goods are highly positively correlated.
|keyword = electronic commerce,RFID,electronic markets and auctions,online shopping carts,sequential pricing,price discrimination,mixed bundling,complements/substitutes,correlated product values,analytical modeling,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Efficiency with Linear Prices? A Game-Theoretical and Computational Analysis of the Combinatorial Clock Auction'''
{{header}}
{{article
|author= Martin Bichler,Pasha Shabalin,Georg Ziegler,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = Combinatorial auctions have been suggested as a means to raise efficiency in multi-item negotiations with complementarities among goods because they can be applied in procurement, energy markets, transportation, and the sale of spectrum auctions. The combinatorial clock (CC) auction has become very popular in these markets for its simplicity and for its highly usable price discovery, derived by the use of linear prices. Unfortunately, no equilibrium bidding strategies are known. Given the importance of the CC auction in the field, it is highly desirable to understand whether there are efficient versions of the CC auction providing a strong game theoretical solution concept. So far, equilibrium strategies have only been found for combinatorial auctions with nonlinear and personalized prices for very restricted sets of bidder valuations. We introduce an extension of the CC auction, the CC+ auction, and show that it actually leads to efficient outcomes in an ex post equilibrium for general valuations with only linear ask prices. We also provide a theoretical analysis on the worst case efficiency of the CC auction, which highlights situations in which the CC leads to highly inefficient outcomes. As in other theoretical models of combinatorial auctions, bidders in the field might not be able to follow the equilibrium strategies suggested by the game-theoretical predictions. Therefore, we complement the theoretical findings with results from computational and laboratory experiments using realistic value models. The experimental results illustrate that the CC+ auction can have a significant impact on efficiency compared to the CC auction.
|keyword = electronic market,combinatorial auction,allocative efficiency,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Pricing of Wireless Services: Service Pricing vs. Traffic Pricing'''
{{header}}
{{article
|author= Atanu Lahiri,Rajiv M. Dewan,Marshall Freimer,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = As the ability to measure technology resource usage gets easier with increased connectivity, the question whether a technology resource should be priced by the amount of the resource used or by the particular use of the resource has become increasingly important. We examine this issue in the context of pricing of wireless services: should the price be based on the service, e.g., voice, multimedia messages, short messages, or should it be based on the traffic generated? Many consumer advocates oppose discriminatory pricing across services believing that it enriches carriers at the expense of consumers. The opposition to discrimination has grown significantly, and it has even prompted the U.S. Congress to question executives of some of the biggest carriers. With this ongoing debate on discrimination in mind, we compare two pricing regimes here. One regime, namely, service pricing, involves pricing different services differently. The other one, namely, traffic pricing, involves pricing the traffic (i.e., bytes) transmitted. We show why the common wisdom, that discriminatory pricing across services increases profits and harms consumers, may not always hold. We also show that such discrimination can increase social welfare.
|keyword = nonlinear pricing,second-degree discrimination,quasi-bundling,telecommunication,net neutrality,dumb pipe,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Fighting Fire with Fire: Commercial Piracy and the Role of File Sharing on Copyright Protection Policy for Digital Goods'''
{{header}}
{{article
|author= Tunay I. Tunca,Qiong Wu,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = In recent years, with the emergence and growth of illegal file sharing on the Internet, individual piracy of digital goods, i.e., consumers making illegal copies on their own rather than relying on purchasing copies from commercial pirates, has stirred substantial controversy. Threatened by this growth, the information goods industry took legal action by suing the file sharing peer-to-peer networks and the consumers who illegally share copyrighted material on these networks. In this paper we demonstrate that each one of these two actions aimed to fight individual piracy can backfire by providing strategic disadvantage to legal publishers of information goods. In particular, we show that in the presence of commercial piracy (i) a higher population of consumers who are capable of individual piracy can increase a legal publisher's profits; and (ii) a higher detection and prosecution rate for individual piracy can reduce a legal publisher's profits. Both effects can be observed in markets where commercial piracy is suppressed because the legal publisher can be coerced to take a price cut to minimize the loss of market share. The latter effect can also be observed in markets with active commercial piracy presence because the legal publisher can be forced to raise prices and concede market share to piracy. Our results suggest that information goods producers may be better off by considering their copyright protection policies concerning individual piracy from a more strategic point of view.
|keyword = analytical modeling,competitive impacts of information systems,economics of information systems,strategic management of information technology,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''An Investigation of the Appropriation of Technology-Mediated Training Methods Incorporating Enactive and Collaborative Learning'''
{{header}}
{{article
|author= Saurabh Gupta,Robert Bostrom,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = The growth in the application of information technology to student and employee learning underscores the need to understand the impact of technology-mediated learning (TML) methods. Using previous developed TML models, based on social cognitive theory and adaptive structuration meta-theory, the effectiveness of three training methods were examined in this study: technology mediated (using both vicarious and enactive learning), and collaborative and combined (collaborative plus technology mediated). The study also focused on the learning process. The experimental study results showed a significant positive influence of enactive learning enabled TML and collaborative training on specific training outcomes, and the combined training method shows positive results on all training outcomes. The study results also showed that faithful appropriation of the training methods during the learning process has a moderator effect on training outcomes. The study provides important research implications for theory and practice.
|keyword = technology-mediated learning,appropriation,simulation,e-learning,training,laboratory experiments,longitudinal research,collaborative learning,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Do Large Firms Become Smaller by Using Information Technology?'''
{{header}}
{{article
|author= Kun Shin Im,Varun Grover,James T. C. Teng,
|source= INFORMATION SYSTEMS RESEARCH
|year= 2013
|abstract = The relationship between information technology (IT) and a key organizational design variable, firm size, is an important area of study, particularly given the ongoing transition to an information-based economy. To better understand the more nuanced aspects of the relationship, we formulated a bidirectional and time-lagged model that incorporates different perspectives from organizational theories and transaction cost economics. Our two models-the bidirectional and one-year lagged model and the bidirectional and two-year lagged model-were tested using nine-year panel data on IT spending, IT stock, coordination costs, firm size, and relevant control variables for 277 manufacturing firms. We found a sequential interaction between IT and firm size in both of the two models: as a firm grows in size, its coordination activities increase; the firm then uses more IT to handle the increased activities of coordination; this increased use of IT, in turn, decreases coordination costs, and eventually, the size of the firm decreases. It was also found that the presence of coordination costs is necessary for the sequential interaction between IT and firm size, indicating coordination between and within firms is a major reason for firms to invest in IT and for IT effect to take place on firm size. This study has taken an initial step by attempting to empirically examine dual causality and longitudinal effects between IT and firm size, and to reconcile different theoretical perspectives on the relationship between them. We hope this work can act as a catalyst for developing a better understanding of the complex relationship between IT and organizations, with the ultimate goal of offering robust prescriptions for successful structural change.
|keyword = information systems and organizational change,bidirectional model,time-lagged model,longitudinal research,firm size,coordination costs,production theory,transaction cost economics,information processing perspective,coordination theory,structuration theory,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Information Systems Success: The Quest for the Independent Variables'''
{{header}}
{{article
|author= Stacie Petter,William deLone,Ephraim R. McLean,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = In 1992, DeLone and McLean suggested that the dependent variable for information systems (IS) research is IS Success. Their research resulted in the widely cited DeLone and McLean (D&M) IS Success Model, in which System Quality, Information Quality, Use, User Satisfaction, Individual Impact, and Organizational Impact are distinct, but related dimensions of IS success. Since the original IS Success Model was published, research has developed a better understanding of IS success. Meanwhile, comprehensive and integrative research on the variables that influence IS success has been lacking. Therefore, we examine the literature on the independent variables that affect IS success. After examining over 600 articles, we focused our attention on integrating the findings of over 140 studies. In this research, we identify 43 specific variables posited to influence the different dimensions of IS success, and we organize these success factors into five categories based on the Leavitt Diamond of Organizational Change: task characteristics, user characteristics, social characteristics, project characteristics, and organizational characteristics. Next, we identify 15 success factors that have consistently been found to influence IS success: Enjoyment, Trust, User Expectations, Extrinsic Motivation, IT Infrastructure, Task Compatibility, Task Difficulty, Attitudes Toward Technology, Organizational Role, User Involvement, Relationship with Developers, Domain Expert Knowledge, Management Support, Management Processes, and Organizational Competence. Finally, we highlight gaps in our knowledge of success factors and propose a road map for future research.
|keyword = independent variables,IS success,research integration,success determinants,success factors,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Effect Mechanisms of Perceptual Congruence Between Information Systems Professionals and Users on Satisfaction with Service'''
{{header}}
{{article
|author= Alexander Benlian,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = With the proliferation of available electronic service channels for information systems (IS) users such as mobile or intranet services in companies, service interactions between IS users and IS professionals have become an increasingly important factor for organizational business-IT alignment. Despite the increasing relevance of such interactions, the implications of agreement or disagreement on the fulfillment of critical service quality factors for successful alignment and higher user satisfaction are far from being well understood. While prior research has extensively studied the question of matching different viewpoints on IS service quality in organizations, little or no attention has been paid to the role of perceptual congruence or incongruence in the dyadic relationship between IS professionals and users in forming user satisfaction with the IS function. Drawing on cognitive dissonance theory, prospect theory, and perceptual congruence research, this study examines survey responses from 169 matching pairs of IS professionals and users in different organizations and explains how perceptual fit patterns affect user satisfaction with the IS function. The paper demonstrates that perceptual congruence can, in and of itself, have an impact on user satisfaction, which goes beyond what was found before. Moreover, the results of the study reveal the relevance of nonlinear and asymmetric effect mechanisms arising from perceptual (in)congruence that may affect user satisfaction. This study extends our theoretical understanding of the role of perceptual alignment or misalignment on IS service quality factors in forming user satisfaction and lays the foundation for further study of the interplay between perceptions in the dyadic relationship between IS professionals and IS users. Managers who seek to encourage particular behaviors by the IS professionals or IS users may use the results of this study to reconcile the often troubled business-IT relationship.
|keyword = alignment,IS service quality,perceptual congruence,polynomial modeling,response surface analysis,SERVQUAL,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Strategic Alignment and Misalignment of Knowledge Management Systems: A Social Representation Perspective'''
{{header}}
{{article
|author= Alina Dulipovici,Daniel Robey,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = To derive more business value from existing organizational knowledge, many organizations seek to rely on strategically aligned knowledge management systems (KMS). However, as documented in prior studies, they often underestimate the challenges about social interactions and users' perceptions in response to new information systems. Based on an interpretive case study, this paper examines the implementation of a KMS to show how social representations of four groups of users resulted in the misalignment of the KMS with the organizational strategy. The social representation lens allows us to interpret strategic alignment in terms of dynamic processes of anchoring and objectification that aid individuals and groups to make sense of KMS initiatives. The groups studied developed different cognitive views of the KMS that ultimately led to a strategic misalignment. The key implication is that social interactions within and among groups shape KMS alignment with organizational strategy, thus elucidating the nature of system use.
|keyword = interpretive research,IS alignment,IS implementation,knowledge management system,social representation,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Service Expansion of Product Firms in the Information Technology Industry: An Empirical Study'''
{{header}}
{{article
|author= Shu Han,Jason Kuruzovi,T. Ravi Chandran,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = The provision of services has become an increasingly important component of the economy of industrialized countries and the revenue stream for many traditional product companies. This is especially true for companies that offer information technology (IT) products. This paper examines factors that are associated with the extent to which IT product companies are able to develop service revenue, which we refer to as service expansion of IT product companies. We identify the characteristics of the product portfolio-specifically, the composition and scope of firm offerings among hardware, application software, and infrastructure software-as key to successful service expansion. We also propose that this relationship is moderated by prior performance of the product business and industry characteristics such as concentration and maturity. Data from IT product vendors spanning five years are used to test the proposed relationships. Overall, this research provides a theoretical foundation for understanding service expansion and diversification in the IT industry as well as practical guidance for IT product companies considering expansion to services.
|keyword = IT services,IT stack,IT vendors,service diversification,software product portfolio,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Facilitator-in-a-Box: Process Support Applications to Help Practitioners Realize the Potential of Collaboration Technology'''
{{header}}
{{article
|author= Robert O. Briggs,Gwendolyn L. Kolfschoten,Gert-Jan De Vrede,Stephan Lukosch,Conan C. Albrecht,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = The potential benefits of collaboration technologies are typically realized only in groups led by collaboration experts. This raises the facilitator-in-the-box challenge: Can collaboration expertise be packaged with collaboration technology in a form that nonexperts can reuse with no training on either tools or techniques? We address that challenge with process support applications (PSAs). We describe a collaboration support system (CSS) that combines a computer-assisted collaboration engineering platform for creating PSAs with a process support system runtime platform for executing PSAs. We show that the CSS meets its design goals: (1) to reduce development cycles for collaboration systems, (2) to allow nonprogrammers to design and develop PSAs, and (3) to package enough expertise in the tools that nonexperts could execute a well-designed collaborative work process without training.
|keyword = collaboration,collaboration engineering,collaboration support system,collaboration technology,computer-assisted collaboration engineering,process support application,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Sparking Creativity: Improving Electronic Brainstorming with Individual Cognitive Priming'''
{{header}}
{{article
|author= Alan R. Denis,Randall K. Minas,Akshay P. Bhagwatwar,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Much of human behavior involves subconscious cognition that can be manipulated through "priming"-the presentation of a stimulus designed to subconsciously implant a concept in working memory that alters subsequent behavior. Priming is a well-known phenomenon for individual behavior, but we do not know whether priming can be used to influence group behavior. We developed a Web-based computer game that was designed to improve creativity through priming. Participants were exposed to a priming game and then worked as members of a group using electronic brainstorming (EBS) to generate ideas on a creativity task. Our results show that when users played the game, designed to improve performance, their groups generated significantly more ideas that were more creative than when they were exposed to neutral priming. Our findings extend the literature by providing evidence that individual priming substantially affects group idea generation performance. Avenues for future research include designing EBS software that optimizes group ideation through priming, examining the conditions under which priming has the most substantial impact on ideation performance, and examining whether priming can be used to enhance other group processes (e.g., convergence tasks).
|keyword = collaboration,creativity,electronic brainstorming,idea generation,individual cognition,priming,virtual groups,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Emotions and Information Diffusion in Social Media-Sentiment of Microblogs and Sharing Behavior'''
{{header}}
{{article
|author= Stefan Stieglitz,Linh Dang-Xuan,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = As a new communication paradigm, social media has promoted information dissemination in social networks. Previous research has identified several content-related features as well as user and network characteristics that may drive information diffusion. However, little research has focused on the relationship between emotions and information diffusion in a social media setting. In this paper, we examine whether sentiment occurring in social media content is associated with a user's information sharing behavior. We carry out our research in the context of political communication on Twitter. Based on two data sets of more than 165,000 tweets in total, we find that emotionally charged Twitter messages tend to be retweeted more often and more quickly compared to neutral ones. As a practical implication, companies should pay more attention to the analysis of sentiment related to their brands and products in social media communication as well as in designing advertising content that triggers emotions.
|keyword = information diffusion,sentiment,social media,Twitter,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
 
---start---
'''Are Users Threatened by Credibility Assessment Systems?'''
{{header}}
{{article
|author= Aaron C. Elkins,Norah E. Dunbar,Bradley Adame,Jr. Jay F. Nunamaker,
|source= JOURNAL OF MANAGEMENT INFORMATION SYSTEMS
|year= 2013
|abstract = Despite the improving accuracy of agent-based expert systems, human expert users aided by these systems have not improved their accuracy. Self-affirmation theory suggests that human expert users could be experiencing threat, causing them to act defensively and ignore the system's conflicting recommendations. Previous research has demonstrated that affirming an individual in an unrelated area reduces defensiveness and increases objectivity to conflicting information. Using an affirmation manipulation prior to a credibility assessment task, this study investigated if experts are threatened by counterattitudinal expert system recommendations. For our study, 178 credibility assessment experts from the American Polygraph Association (n = 134) and the European Union's border security agency Frontex (n = 44) interacted with a deception detection expert system to make a deception judgment that was immediately contradicted. Reducing the threat prior to making their judgments did not improve accuracy, but did improve objectivity toward the system. This study demonstrates that human experts are threatened by advanced expert systems that contradict their expertise. As more and more systems increase integration of artificial intelligence and inadvertently assail the expertise and abilities of users, threat and self-evaluative concerns will become an impediment to technology acceptance.
|keyword = credibility assessment systems,deception detection,expert systems,user anxiety,
}}
{{topics}}
{{theories}}
{{methods}}
{{footer}}
[[Category:article]]
---end---
